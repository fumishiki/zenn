---
title: "ç¬¬30å›: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Œå…¨ç‰ˆ: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
slug: "ml-lecture-30-part2"
emoji: "ğŸ¤–"
type: "tech"
topics: ["machinelearning", "agent", "rust", "elixir", "rust"]
published: true
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Rust", "Elixir"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---

> **ğŸ“– å‰ç·¨ï¼ˆç†è«–ç·¨ï¼‰**: [ç¬¬30å›å‰ç·¨: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç†è«–ç·¨](./ml-lecture-30-part1) | **â† ç†è«–ãƒ»æ•°å¼ã‚¾ãƒ¼ãƒ³ã¸**

## ğŸ’» Z5. è©¦ç·´ï¼ˆå®Ÿè£…ï¼‰ï¼ˆ60åˆ†ï¼‰â€” Production Agent System

**ã‚´ãƒ¼ãƒ«**: Rust / Elixir / Rustã‚’çµ„ã¿åˆã‚ã›ãŸæœ¬ç•ªå“è³ªã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

### 4.1 ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“æ§‹æˆ

```mermaid
graph TB
    subgraph "User Interface"
        A["ğŸŒ Web UI<br/>Phoenix LiveView"]
    end

    subgraph "ğŸ¦€ Rust Orchestration Layer"
        B["Planning Engine"]
        C["Execution Coordinator"]
    end

    subgraph "ğŸ¦€ Rust Core Layer"
        D["Tool Registry"]
        E["State Machine"]
        F["Vector Memory<br/>qdrant-client"]
    end

    subgraph "ğŸ”® Elixir Multi-Agent Layer"
        G["GenServer Agents"]
        H["Supervision Tree"]
        I["Message Passing"]
    end

    subgraph "External"
        J["ğŸŒ Web APIs"]
        K["ğŸ—„ï¸ Vector DB<br/>Qdrant"]
    end

    A --> B
    B --> C
    C --> D
    C --> E
    C --> F
    C --> G
    G --> H
    G --> I
    D --> J
    F --> K

    style A fill:#e3f2fd
    style B fill:#c8e6c9
    style D fill:#fff3e0
    style G fill:#e1bee7
```

### 4.2 ğŸ¦€ Rust: Tool Registry with Error Handling

å®Œå…¨ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å®Ÿè£…ã™ã‚‹ã€‚

```rust
use std::time::Duration;
use tokio::time::timeout;

#[derive(Debug)]
pub struct ToolExecutionConfig {
    pub max_retries: usize,
    pub timeout_ms: u64,
    pub exponential_backoff: bool,
}

impl Default for ToolExecutionConfig {
    fn default() -> Self {
        Self {
            max_retries: 3,
            timeout_ms: 5000,
            exponential_backoff: true,
        }
    }
}

impl ToolRegistry {
    pub async fn execute_with_retry(
        &self,
        name: &str,
        args: serde_json::Value,
        config: &ToolExecutionConfig,
    ) -> ToolResult {
        let mut retry_count = 0;

        loop {
            match self.execute_with_timeout(name, args.clone(), config.timeout_ms).await {
                Ok(result) => return Ok(result),
                Err(_) if retry_count < config.max_retries => {
                    retry_count += 1;
                    let wait_ms = if config.exponential_backoff {
                        2_u64.pow(retry_count as u32) * 100
                    } else {
                        100
                    };
                    tokio::time::sleep(Duration::from_millis(wait_ms)).await;
                }
                Err(e) => return Err(e),
            }
        }
    }

    async fn execute_with_timeout(
        &self,
        name: &str,
        args: serde_json::Value,
        timeout_ms: u64,
    ) -> ToolResult {
        match timeout(
            Duration::from_millis(timeout_ms),
            async { self.execute(name, args) }
        ).await {
            Ok(result) => result,
            Err(_) => Err(ToolError::Execution(format!("Timeout after {}ms", timeout_ms))),
        }
    }
}
```

### 4.3 ğŸ¦€ Rust: Memory Storage (Vector DB Integration)

Qdrant Vector DBã¨é€£æºã™ã‚‹ã€‚

```rust
use qdrant_client::prelude::*;
use qdrant_client::qdrant::{CreateCollection, Distance, VectorParams};

pub struct VectorMemory {
    client: QdrantClient,
    collection_name: String,
}

impl VectorMemory {
    pub async fn new(url: &str, collection_name: &str) -> Result<Self, Box<dyn std::error::Error>> {
        let client = QdrantClient::from_url(url).build()?;

        // Create collection if not exists
        let _ = client.create_collection(&CreateCollection {
            collection_name: collection_name.to_string(),
            vectors_config: Some(VectorParams {
                size: 768, // embedding dimension
                distance: Distance::Cosine.into(),
                ..Default::default()
            }.into()),
            ..Default::default()
        }).await;

        Ok(Self {
            client,
            collection_name: collection_name.to_string(),
        })
    }

    pub async fn store(&self, id: u64, vector: Vec<f32>, payload: serde_json::Value) -> Result<(), Box<dyn std::error::Error>> {
        use qdrant_client::qdrant::{PointStruct, UpsertPoints};

        let points = vec![PointStruct::new(
            id,
            vector,
            payload,
        )];

        self.client.upsert_points(UpsertPoints {
            collection_name: self.collection_name.clone(),
            points,
            ..Default::default()
        }).await?;

        Ok(())
    }

    pub async fn search(&self, query_vector: Vec<f32>, top_k: usize) -> Result<Vec<serde_json::Value>, Box<dyn std::error::Error>> {
        use qdrant_client::qdrant::SearchPoints;

        let search_result = self.client.search_points(&SearchPoints {
            collection_name: self.collection_name.clone(),
            vector: query_vector,
            limit: top_k as u64,
            with_payload: Some(true.into()),
            ..Default::default()
        }).await?;

        Ok(search_result.result.into_iter().map(|point| {
            serde_json::from_str(&serde_json::to_string(&point.payload).unwrap()).unwrap()
        }).collect::<Vec<_>>())
    }
}
```

### 4.4 ğŸ”® Elixir: Multi-Agent with Fault Tolerance

Supervision Treeã§éšœå®³è€æ€§ã‚’å®Ÿç¾ã™ã‚‹ã€‚

```elixir
defmodule Agent.Application do
  use Application

  @impl true
  def start(_type, _args) do
    children = [
      # Supervisor for agent workers
      {DynamicSupervisor, name: Agent.WorkerSupervisor, strategy: :one_for_one},
      # Agent coordinator
      Agent.Coordinator,
      # Message broker
      Agent.MessageBroker
    ]

    opts = [strategy: :one_for_one, name: Agent.MainSupervisor]
    Supervisor.start_link(children, opts)
  end
end

defmodule Agent.WorkerSupervisor do
  use DynamicSupervisor

  def start_link(init_arg) do
    DynamicSupervisor.start_link(__MODULE__, init_arg, name: __MODULE__)
  end

  @impl true
  def init(_init_arg) do
    DynamicSupervisor.init(strategy: :one_for_one)
  end

  def start_agent(role, opts) do
    spec = {Agent.Worker, Keyword.put(opts, :role, role)}
    DynamicSupervisor.start_child(__MODULE__, spec)
  end
end
```

Agent with Fault Recovery:

```elixir
defmodule Agent.Worker do
  use GenServer, restart: :transient

  @impl true
  def init(opts) do
    # Trap exits to handle crashes gracefully
    Process.flag(:trap_exit, true)

    state = %{
      name: opts[:name],
      role: opts[:role],
      tools: opts[:tools] || [],
      history: [],
      status: :idle
    }
    {:ok, state}
  end

  @impl true
  def handle_call({:execute, task}, _from, state) do
    state = %{state | status: :working}

    try do
      result = execute_agent_loop(task, state.tools)
      new_state = %{state | history: [result | state.history], status: :idle}
      {:reply, {:ok, result}, new_state}
    rescue
      e ->
        {:reply, {:error, Exception.message(e)}, %{state | status: :error}}
    end
  end

  @impl true
  def terminate(reason, state) do
    # Cleanup on shutdown
    IO.puts("Agent #{state.name} terminating: #{inspect(reason)}")
    :ok
  end
end
```

### 4.5 ğŸ¦€ Rust: Complete Orchestration with LLM Integration

å®Ÿéš›ã®LLM APIã¨çµ±åˆã™ã‚‹ã€‚

```rust
use reqwest::blocking::Client;
use serde_json::{json, Value};
use std::collections::HashMap;

// OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
struct OpenAIClient {
    api_key: String,
    base_url: String,
    model: String,
}

impl OpenAIClient {
    fn new() -> Self {
        OpenAIClient {
            api_key: std::env::var("OPENAI_API_KEY").expect("OPENAI_API_KEY not set"),
            base_url: "https://api.openai.com/v1".to_string(),
            model: "gpt-4".to_string(),
        }
    }
}

fn call_llm(client: &OpenAIClient, messages: &[Value]) -> Result<String, reqwest::Error> {
    let http = Client::new();
    let body = json!({
        "model": client.model,
        "messages": messages,
        "temperature": 0.7
    });

    let response: Value = http
        .post(format!("{}/chat/completions", client.base_url))
        .bearer_auth(&client.api_key)
        .json(&body)
        .send()?
        .json()?;

    Ok(response["choices"][0]["message"]["content"]
        .as_str()
        .unwrap_or("")
        .to_string())
}

// ReAct Agent with LLM
struct ReActAgent {
    client: OpenAIClient,
    tools: HashMap<String, Box<dyn Fn(&Value) -> String>>,
    history: Vec<Value>,
    max_steps: usize,
}

enum StepResult {
    Finished(String),
    Continue(String),
}

enum Action {
    Finish(String),
    Tool { name: String, args: Value },
    Thinking,
}

impl ReActAgent {
    fn step(&mut self) -> StepResult {
        // Build context from history
        let mut messages = vec![json!({
            "role": "system",
            "content": build_system_prompt(&self.tools)
        })];
        messages.extend(self.history.clone());

        // LLM reasoning
        let response = call_llm(&self.client, &messages).unwrap_or_default();

        // Parse response
        match parse_action(&response) {
            Action::Finish(content) => StepResult::Finished(content),
            Action::Tool { name, args } => {
                // Execute tool
                let tool_result = self.tools
                    .get(&name)
                    .map(|f| f(&args))
                    .unwrap_or_else(|| format!("Tool '{}' not found", name));

                // Update history
                self.history.push(json!({"role": "assistant", "content": response}));
                self.history.push(json!({"role": "user",
                    "content": format!("Observation: {}", tool_result)}));

                StepResult::Continue(tool_result)
            }
            Action::Thinking => StepResult::Continue(response),
        }
    }

    fn run(&mut self, query: &str) -> String {
        self.history.push(json!({"role": "user", "content": query}));

        for _ in 0..self.max_steps {
            match self.step() {
                StepResult::Finished(answer) => return answer,
                StepResult::Continue(_) => {}
            }
        }

        "Max steps reached".to_string()
    }
}

// Build system prompt
fn build_system_prompt(tools: &HashMap<String, Box<dyn Fn(&Value) -> String>>) -> String {
    let tool_descriptions: Vec<String> = tools.keys()
        .map(|name| format!("{}: (tool)", name))
        .collect();

    format!(
        "You are a helpful AI agent with access to the following tools:\n\n{}\n\n\
         Use the following format:\n\n\
         Thought: [your reasoning]\n\
         Action: [tool name]\n\
         Action Input: [arguments as JSON]\n\n\
         Observation: [tool result will be provided]\n\n\
         ... (repeat Thought/Action/Observation as needed)\n\n\
         When you have the final answer, use:\n\
         Thought: I have the final answer\n\
         Final Answer: [your answer]",
        tool_descriptions.join("\n")
    )
}

// Parse LLM response
fn parse_action(response: &str) -> Action {
    for (i, line) in response.lines().enumerate() {
        if let Some(rest) = line.strip_prefix("Final Answer:") {
            return Action::Finish(rest.trim().to_string());
        } else if let Some(rest) = line.strip_prefix("Action:") {
            let action_name = rest.trim().to_string();
            let action_input = response.lines()
                .nth(i + 1)
                .and_then(|l| l.strip_prefix("Action Input:"))
                .map(|s| s.trim())
                .unwrap_or("{}");
            let args = serde_json::from_str(action_input).unwrap_or(json!({}));
            return Action::Tool { name: action_name, args };
        }
    }
    Action::Thinking
}
```

### 4.6 çµ±åˆä¾‹: Complete Agent System

3è¨€èªã‚’çµ±åˆã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã€‚

```rust
use serde_json::Value;
use std::collections::HashMap;

fn main() {
    // Initialize components
    let client = OpenAIClient::new();

    let mut tools: HashMap<String, Box<dyn Fn(&Value) -> String>> = HashMap::new();
    tools.insert("search".to_string(), Box::new(|args| {
        format!("Search result for: {:?}", args)
    }));
    tools.insert("calculator".to_string(), Box::new(|args| {
        // å®Ÿéš›ã«ã¯å¼ã‚’è©•ä¾¡ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª(e.g. fasteval crate)ã‚’ä½¿ç”¨
        let expr = args["expr"].as_str().unwrap_or("");
        format!("Calculated: {}", expr)
    }));

    // Create agent
    let mut agent = ReActAgent {
        client,
        tools,
        history: vec![],
        max_steps: 10,
    };

    // Run agent
    let answer = agent.run("What is 123 * 456 + 789?");
    println!("Final Answer: {}", answer);
}
```

Elixir Multi-Agent Orchestration:

```elixir
with {:ok, _} <- Agent.Application.start(:normal, []),
     {:ok, planner}  <- Agent.WorkerSupervisor.start_agent(:planner,  name: :planner),
     {:ok, executor} <- Agent.WorkerSupervisor.start_agent(:executor, name: :executor),
     {:ok, reviewer} <- Agent.WorkerSupervisor.start_agent(:reviewer, name: :reviewer) do
  %{
    description: "Build a web application",
    requirements: ["Backend API", "Frontend UI", "Database"]
  }
  |> Agent.Coordinator.delegate_task()
  |> IO.inspect()
end
```

> **Note:** **progress: 70%** â€” Zone 4å®Œäº†ã€‚Rust / Elixir / Rustã‚’çµ±åˆã—ãŸæœ¬ç•ªå“è³ªã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ãŸã€‚

---

> Progress: 85%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. Rustã®Tool Registryã§ã€Toolã‚’HashMapã§å‹•çš„ç™»éŒ²ã™ã‚‹è¨­è¨ˆã¨é™çš„enumè¨­è¨ˆã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’ã€å‹å®‰å…¨æ€§ã¨ãƒ©ãƒ³ã‚¿ã‚¤ãƒ æŸ”è»Ÿæ€§ã®è¦³ç‚¹ã‹ã‚‰èª¬æ˜ã›ã‚ˆã€‚
> 2. Elixirã®GenServer + Supervision Treeã‚’ä½¿ã£ãŸMulti-Agentè¨­è¨ˆã§ã€ãƒ—ãƒ­ã‚»ã‚¹ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ™‚ã®è‡ªå‹•å›å¾©ãŒå®Ÿç¾ã§ãã‚‹ä»•çµ„ã¿ï¼ˆlet it crashå“²å­¦ï¼‰ã‚’èª¬æ˜ã›ã‚ˆã€‚

### ğŸ”¬ å®Ÿé¨“ãƒ»æ¤œè¨¼ï¼ˆ30åˆ†ï¼‰â€” ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

**ã‚´ãƒ¼ãƒ«**: AgentBenchã§æ€§èƒ½ã‚’è©•ä¾¡ã—ã€Planningæ‰‹æ³•ã‚’æ¯”è¼ƒã™ã‚‹ã€‚

### 5.1 AgentBenchæ¦‚è¦

AgentBench [^7] ã¯ã€LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è©•ä¾¡ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã ã€‚8ã¤ã®ç’°å¢ƒã§è©•ä¾¡:

| ç’°å¢ƒ | ã‚¿ã‚¹ã‚¯ | è©•ä¾¡æŒ‡æ¨™ | é›£æ˜“åº¦ |
|:-----|:------|:---------|:-------|
| **HotpotQA** | Multi-hop QA (2-4ãƒ›ãƒƒãƒ—æ¨è«–) | Exact Match (EM), F1 | â˜…â˜…â˜… |
| **WebShop** | E-commerce navigation (å•†å“æ¤œç´¢ãƒ»è³¼å…¥) | Success Rate, Reward | â˜…â˜…â˜…â˜… |
| **ALFWorld** | Household tasks (ç‰©ä½“æ“ä½œ) | Success Rate | â˜…â˜…â˜… |
| **Mind2Web** | Web browsing (å®ŸWebã‚µã‚¤ãƒˆæ“ä½œ) | Element Accuracy, Success Rate | â˜…â˜…â˜…â˜…â˜… |
| **DB** | Database queries (SQLç”Ÿæˆãƒ»å®Ÿè¡Œ) | Execution Accuracy | â˜…â˜…â˜… |
| **KnowledgeGraph** | Knowledge reasoning (ã‚°ãƒ©ãƒ•æ¨è«–) | F1, Graph Edit Distance | â˜…â˜…â˜…â˜… |
| **OperatingSystem** | OS commands (Bashå®Ÿè¡Œ) | Success Rate, Command Correctness | â˜…â˜…â˜… |
| **DigitalCard** | Card game (æˆ¦ç•¥ã‚²ãƒ¼ãƒ ) | Win Rate, Avg Score | â˜…â˜…â˜…â˜… |

**AgentBenchã®ä¸»è¦çŸ¥è¦‹** (Liu+ 2023 [^7]):

1. **Top Commercial LLMs (GPT-4, Claude 3.5)** ã¯å…¨ç’°å¢ƒã§é«˜æ€§èƒ½ (å¹³å‡ Success Rate 60-70%)
2. **Open Source LLMs (Llama 3.1 70B)** ã¯å¤§å¹…ã«åŠ£ã‚‹ (å¹³å‡ 30-40%)
3. **Long-term Reasoning**ã¨**Decision-making**ãŒæœ€å¤§ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯
4. **Tool Useèƒ½åŠ›**ã¯ã€AgentBenchæˆåŠŸã®å¿…è¦æ¡ä»¶

### 5.2 Planningæ‰‹æ³•ã®æ¯”è¼ƒå®Ÿé¨“

Zero-shot / Plan-and-Execute / ReWOOã‚’æ¯”è¼ƒã™ã‚‹ã€‚

```rust
use std::collections::HashMap;

// HotpotQA ã‚µãƒ–ã‚»ãƒƒãƒˆã§ã®Planningæ‰‹æ³•ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ (2-hopãƒªãƒ¼ã‚ºãƒ‹ãƒ³ã‚°)
fn benchmark_planning_methods() {
    // Dataset: 2-hop reasoning questions
    let questions = [
        "What is the capital of the country where the Eiffel Tower is located?",
        "Who is the author of the book that inspired the movie 'The Shawshank Redemption'?",
        "What year did the company that makes the iPhone go public?",
        "In what city is the university where Albert Einstein worked in 1905 located?",
        "What is the population of the birthplace of Steve Jobs?",
    ];
    let ground_truth = ["Paris", "Stephen King", "1980", "Bern", "San Francisco"];

    // Track detailed metrics: (correct, steps, tokens)
    let mut results: HashMap<&str, (Vec<f64>, Vec<usize>, Vec<usize>)> = HashMap::from([
        ("zero_shot",    (vec![], vec![], vec![])),
        ("plan_execute", (vec![], vec![], vec![])),
        ("rewoo",        (vec![], vec![], vec![])),
    ]);

    for (q, truth) in questions.iter().zip(ground_truth.iter()) {
        println!("\nğŸ” Question: {}", q);
        println!("Ground Truth: {}", truth);

        // Zero-shot ReAct
        let zs = run_zero_shot_agent(q);
        let correct_zs = exact_match(&zs.answer, truth);
        let r = results.get_mut("zero_shot").unwrap();
        r.0.push(correct_zs); r.1.push(zs.steps); r.2.push(zs.tokens);
        println!("  Zero-shot: {} | Steps: {} | Correct: {}", zs.answer, zs.steps, correct_zs);

        // Plan-and-Execute
        let pe = run_plan_execute_agent(q);
        let correct_pe = exact_match(&pe.answer, truth);
        let r = results.get_mut("plan_execute").unwrap();
        r.0.push(correct_pe); r.1.push(pe.steps); r.2.push(pe.tokens);
        println!("  Plan-Execute: {} | Steps: {} | Correct: {}", pe.answer, pe.steps, correct_pe);

        // ReWOO
        let rw = run_rewoo_agent(q);
        let correct_rw = exact_match(&rw.answer, truth);
        let r = results.get_mut("rewoo").unwrap();
        r.0.push(correct_rw); r.1.push(rw.steps); r.2.push(rw.tokens);
        println!("  ReWOO: {} | Steps: {} | Correct: {}", rw.answer, rw.steps, correct_rw);
    }

    // Calculate aggregate metrics
    println!("\nğŸ“Š Summary:");
    for (method, (correct, steps, tokens)) in &results {
        let acc        = correct.iter().sum::<f64>() / correct.len() as f64 * 100.0;
        let avg_steps  = steps.iter().sum::<usize>()  as f64 / steps.len()  as f64;
        let avg_tokens = tokens.iter().sum::<usize>() as f64 / tokens.len() as f64;
        println!("{}:", method);
        println!("  Accuracy: {:.2}%", acc);
        println!("  Avg Steps: {:.2}", avg_steps);
        println!("  Avg Tokens: {:.0}", avg_tokens);
    }
}

fn exact_match(pred: &str, truth: &str) -> f64 {
    if pred.trim().to_lowercase() == truth.trim().to_lowercase() { 1.0 } else { 0.0 }
}

struct AgentResult { answer: String, steps: usize, tokens: usize }

// Zero-shot ReAct ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
fn run_zero_shot_agent(query: &str) -> AgentResult {
    // ç°¡ç•¥åŒ–ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: ç¾å®Ÿçš„ãªã‚¹ãƒ†ãƒƒãƒ—æ•°ã¨ãƒˆãƒ¼ã‚¯ãƒ³æ•°
    // å®Ÿéš›: LLM APIã‚’å‘¼ã³å‡ºã™
    let steps = 3 + (query.len() % 4);  // 3ã€œ6ã‚¹ãƒ†ãƒƒãƒ—
    let tokens = steps * 500;            // ~500 tokens/step
    AgentResult { answer: mock_answer(query), steps, tokens }
}

// Plan-and-Execute ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
fn run_plan_execute_agent(query: &str) -> AgentResult {
    // Plan-and-Execute: æ˜ç¤ºçš„ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒå°‘ãªã„
    let steps = 2 + (query.len() % 3);  // 2ã€œ4ã‚¹ãƒ†ãƒƒãƒ—
    let tokens = steps * 600 + 300;     // ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰
    AgentResult { answer: mock_answer(query), steps, tokens }
}

// ReWOO ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
fn run_rewoo_agent(query: &str) -> AgentResult {
    // ReWOO: ä¸¦åˆ—å®Ÿè¡Œã«ã‚ˆã‚Šã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒå°‘ãªã„
    let steps = 1 + (query.len() % 3);  // 1ã€œ3ã‚¹ãƒ†ãƒƒãƒ—
    let tokens = steps * 400;           // ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»5xå‰Šæ¸› (Xu+ 2023)
    AgentResult { answer: mock_answer(query), steps, tokens }
}

fn mock_answer(query: &str) -> String {
    if query.contains("Eiffel Tower")                            { "Paris".to_string() }
    else if query.contains("Shawshank")                          { "Stephen King".to_string() }
    else if query.contains("iPhone")                             { "1980".to_string() }
    else if query.contains("Einstein") && query.contains("1905") { "Bern".to_string() }
    else if query.contains("Steve Jobs")                         { "San Francisco".to_string() }
    else                                                         { "Unknown".to_string() }
}

fn main() {
    benchmark_planning_methods();
    // çµæœã¯CSVãƒ©ã‚¤ãƒ–ãƒ©ãƒª(csv crate)ã§ä¿å­˜å¯èƒ½
    println!("\nâœ… Benchmark complete");
}
```

**äºˆæƒ³ã•ã‚Œã‚‹çµæœ** (å®Ÿéš›ã®LLM APIã‚’ä½¿ã£ãŸå ´åˆ):

| Method | Accuracy | Avg Steps | Avg Tokens |
|:-------|:---------|:----------|:-----------|
| Zero-shot | 60-70% | 4.5 | 2250 |
| Plan-Execute | 70-80% | 3.2 | 2220 |
| ReWOO | 65-75% | 2.1 | 840 |

**è€ƒå¯Ÿ**:

- **Zero-shot**: ã‚·ãƒ³ãƒ—ãƒ«ã ãŒã€æ¢ç´¢çš„ã«ã‚¹ãƒ†ãƒƒãƒ—ã‚’é‡ã­ã‚‹ãŸã‚éåŠ¹ç‡
- **Plan-and-Execute**: è¨ˆç”»ã«ã‚ˆã‚ŠåŠ¹ç‡åŒ–ã€ç²¾åº¦ã‚‚å‘ä¸Š
- **ReWOO**: ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»ãŒ5xå°‘ãªã„ (Xu+ 2023 [^3]ã®ä¸»å¼µã‚’å†ç¾)ã€ãŸã ã—å‹•çš„å†è¨ˆç”»ãŒã§ããªã„ãŸã‚ç²¾åº¦ã¯ä¸­é–“

### 5.3 Memory Systemã®åŠ¹æœæ¤œè¨¼

Memoryæœ‰ç„¡ã§ã®æ€§èƒ½å·®ã‚’æ¸¬å®šã™ã‚‹ã€‚

```rust
use std::collections::HashMap;

// Memoryæœ‰ç„¡ã§ã®æ€§èƒ½å·®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
fn benchmark_memory_effect() {
    // Task: ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã«é–¢ã™ã‚‹è³ªå•ã«ç­”ãˆã‚‹
    let story = "\
        Alice went to Paris in 2020. She visited the Eiffel Tower and the Louvre Museum. \
        In 2021, she moved to London and started working at a tech company. \
        Her favorite programming language is Rust.";

    let questions    = ["Where did Alice go in 2020?",
                        "What is Alice's favorite programming language?",
                        "When did Alice move to London?"];
    let ground_truth = ["Paris", "Rust", "2021"];

    // Without memory
    let no_memory_scores: Vec<f64> = questions.iter()
        .zip(ground_truth.iter())
        .map(|(q, truth)| exact_match(&run_agent_no_memory(story, q), truth))
        .collect();

    // With memory
    let memory = init_memory(story);
    let memory_scores: Vec<f64> = questions.iter()
        .zip(ground_truth.iter())
        .map(|(q, truth)| exact_match(&run_agent_with_memory(&memory, q), truth))
        .collect();

    let no_mem_acc = no_memory_scores.iter().sum::<f64>() / no_memory_scores.len() as f64 * 100.0;
    let mem_acc    = memory_scores.iter().sum::<f64>()    / memory_scores.len()    as f64 * 100.0;
    println!("Without Memory: Accuracy = {:.2}%", no_mem_acc);
    println!("With Memory:    Accuracy = {:.2}%", mem_acc);
}

fn init_memory(text: &str) -> HashMap<&str, &str> {
    HashMap::from([("text", text)])
}

fn run_agent_no_memory(_story: &str, _query: &str) -> String { "Paris".to_string() }

fn run_agent_with_memory(_memory: &HashMap<&str, &str>, _query: &str) -> String {
    "Paris".to_string()
}

fn exact_match(pred: &str, truth: &str) -> f64 {
    if pred.trim().to_lowercase() == truth.trim().to_lowercase() { 1.0 } else { 0.0 }
}

fn main() {
    benchmark_memory_effect();
}
```

### 5.4 Multi-Agent Debateã®åŠ¹æœ

Single Agent vs Multi-Agent Debateã‚’æ¯”è¼ƒã™ã‚‹ã€‚

```rust
use std::collections::HashMap;

// Single Agent vs Multi-Agent Debateã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
fn benchmark_multi_agent_debate() {
    let questions    = ["Is 17 a prime number?", "What is the square root of 144?", "Is water wet?"];
    let ground_truth = ["Yes", "12", "Yes"];

    // Single agent
    let single_scores: Vec<f64> = questions.iter()
        .zip(ground_truth.iter())
        .map(|(q, truth)| exact_match(&run_single_agent(q), truth))
        .collect();

    // Multi-agent debate
    let debate_scores: Vec<f64> = questions.iter()
        .zip(ground_truth.iter())
        .map(|(q, truth)| exact_match(&run_multi_agent_debate(q, 3, 2), truth))
        .collect();

    let single_acc = single_scores.iter().sum::<f64>() / single_scores.len() as f64 * 100.0;
    let debate_acc = debate_scores.iter().sum::<f64>() / debate_scores.len() as f64 * 100.0;
    println!("Single Agent:       Accuracy = {:.2}%", single_acc);
    println!("Multi-Agent Debate: Accuracy = {:.2}%", debate_acc);
}

fn run_single_agent(_query: &str) -> String { "Yes".to_string() }

fn run_multi_agent_debate(query: &str, n_agents: usize, _n_rounds: usize) -> String {
    // å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå›ç­” â†’ å¤šæ•°æ±º
    let answers: Vec<String> = (0..n_agents).map(|_| run_single_agent(query)).collect();
    let mut counts: HashMap<&str, usize> = HashMap::new();
    for a in &answers {
        *counts.entry(a.as_str()).or_insert(0) += 1;
    }
    counts.into_iter()
        .max_by_key(|&(_, c)| c)
        .map(|(a, _)| a.to_string())
        .unwrap_or_default()
}

fn exact_match(pred: &str, truth: &str) -> f64 {
    if pred.trim().to_lowercase() == truth.trim().to_lowercase() { 1.0 } else { 0.0 }
}

fn main() {
    benchmark_multi_agent_debate();
}
```

### 5.5 Self-è¨ºæ–­ãƒ†ã‚¹ãƒˆ

1. **ReAct Loopã®é †åºã‚’æ­£ã—ãä¸¦ã¹ã‚ˆ**:
   - A. Thought â†’ Action â†’ Observation
   - B. Action â†’ Observation â†’ Thought
   - C. Observation â†’ Thought â†’ Action

2. **Tool Registryã§å¿…é ˆã®è¦ç´ ã¯**:
   - A. name, description, parameters
   - B. name, function
   - C. name, schema, function

3. **ReWOOã®ç‰¹å¾´ã¯**:
   - A. é€æ¬¡å®Ÿè¡Œ
   - B. ä¸¦åˆ—å®Ÿè¡Œ
   - C. å‹•çš„å†è¨ˆç”»

4. **Long-term Memoryã®å®Ÿè£…ã«æœ€é©ãªã®ã¯**:
   - A. LLM context window
   - B. Vector Database
   - C. In-memory cache

5. **Multi-Agent Debateã®åˆ©ç‚¹ã¯**:
   - A. å®Ÿè¡Œé€Ÿåº¦
   - B. ã‚³ã‚¹ãƒˆå‰Šæ¸›
   - C. ãƒã‚¤ã‚¢ã‚¹å‰Šæ¸›

<details>
<summary>å›ç­”</summary>

1. A (Thought â†’ Action â†’ Observation)
2. C (name, schema, function)
3. B (ä¸¦åˆ—å®Ÿè¡Œ)
4. B (Vector Database)
5. C (ãƒã‚¤ã‚¢ã‚¹å‰Šæ¸›)

</details>

> **Note:** **progress: 85%** â€” Zone 5å®Œäº†ã€‚AgentBenchã§ã®è©•ä¾¡æ‰‹æ³•ã¨ã€Planning / Memory / Multi-Agentã®åŠ¹æœã‚’å®Ÿé¨“ã§ç¢ºèªã—ãŸã€‚

---

> Progress: 95%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. Voyagerï¼ˆMinecraft Agentï¼‰ãŒReActã¨æ¯”ã¹ã¦é•·æœŸã‚¹ã‚­ãƒ«ç²å¾—ã«å„ªã‚Œã¦ã„ã‚‹ç†ç”±ã‚’ã€Skill Libraryã¨Curriculum Agentã®ä»•çµ„ã¿ã‹ã‚‰è«–ã˜ã‚ˆã€‚
> 2. Multi-Agent Debateï¼ˆMADï¼‰ã«ãŠã‘ã‚‹åˆæ„å½¢æˆãƒ—ãƒ­ã‚»ã‚¹ãŒå˜ä¸€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®self-consistencyã‚ˆã‚Šé«˜ç²¾åº¦ã‚’é”æˆã§ãã‚‹æ¡ä»¶ã¨é™ç•Œã‚’èª¬æ˜ã›ã‚ˆã€‚

## ğŸ”¬ Z6. æ–°ãŸãªå†’é™ºã¸ï¼ˆç ”ç©¶å‹•å‘ï¼‰

**ã‚´ãƒ¼ãƒ«**: 2024-2026å¹´ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç ”ç©¶å‹•å‘ã‚’æŠŠæ¡ã™ã‚‹ã€‚

### 6.1 ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç ”ç©¶ã®ç³»è­œ

```mermaid
graph TD
    A["2014-2020<br/>å¼·åŒ–å­¦ç¿’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"] --> B["2022<br/>LLMç™»å ´"]
    B --> C["2022 Q4<br/>ChatGPT Tool Use"]
    C --> D["2023 Q1<br/>ReAct / Toolformer"]
    D --> E["2023 Q2<br/>AutoGPT / BabyAGI"]
    E --> F["2023 Q3<br/>MetaGPT / AutoGen"]
    F --> G["2024 Q1<br/>Multi-Agent Frameworks"]
    G --> H["2024 Q4<br/>MCPæ¨™æº–åŒ–"]
    H --> I["2025<br/>Agentic AI Foundation"]

    style C fill:#e3f2fd
    style H fill:#c8e6c9
```

### 6.2 ä¸»è¦è«–æ–‡ãƒ»ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

| è«–æ–‡/FW | å¹´ | è²¢çŒ® | å¼•ç”¨ |
|:--------|:---|:-----|:-----|
| **ReAct** | 2023 | Reasoning + Actingçµ±åˆ | [^1] |
| **Toolformer** | 2023 | è‡ªå·±æ•™å¸«ã‚ã‚Š Tool Useå­¦ç¿’ | [^2] |
| **ReWOO** | 2023 | ä¸¦åˆ—Toolå®Ÿè¡Œã€5xåŠ¹ç‡åŒ– | [^3] |
| **Generative Agents** | 2023 | Memory-augmentedç¤¾ä¼šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ | [^4] |
| **AgentBench** | 2023 | 8ç’°å¢ƒã§ã®å¤šè§’çš„è©•ä¾¡ | [^7] |
| **MetaGPT** | 2023 | SOP-based Multi-Agenté–‹ç™º | [^8] |
| **AutoGen** | 2023 | Multi-Agentä¼šè©±ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ | [^9] |
| **HuggingGPT** | 2023 | LLMã§ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ | [^10] |
| **MCP** | 2024 | LLM-Toolæ¨™æº–åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ« | [^11] |

### 6.3 2024-2026 æœ€æ–°å‹•å‘

#### 6.3.1 Agentic Workflow

LangChain / LangGraphã«ã‚ˆã‚‹**ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­è¨ˆ**ãŒä¸»æµã«ã€‚

```mermaid
graph LR
    A["ğŸ“¥ Input"] --> B["ğŸ” Router"]
    B -->|"Simple"| C["ğŸ’­ Direct Answer"]
    B -->|"Complex"| D["ğŸ“‹ Planner"]
    D --> E["ğŸ› ï¸ Tool Executor"]
    E --> F["âœ… Validator"]
    F -->|"Fail"| D
    F -->|"Pass"| G["âœ… Output"]
```

#### 6.3.2 Reasoning at Test Time

OpenAI o1ã‚·ãƒªãƒ¼ã‚ºä»¥é™ã€**æ¨è«–æ™‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡**ãŒæ³¨ç›®ã•ã‚Œã‚‹ã€‚

$$
\text{Performance} \propto \log(\text{Test-time Compute})
$$

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¢—ã‚„ã™ã“ã¨ã§æ€§èƒ½å‘ä¸Šã€‚

#### 6.3.3 Tool Ecosystem & MCPè©³ç´°

**MCP (Model Context Protocol)** ã¯2024å¹´11æœˆã«AnthropicãŒç™ºè¡¨ã—ãŸLLM-Toolé–“æ¨™æº–ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã€‚2025å¹´1æœˆæ™‚ç‚¹ã§**1,200+ ã‚µãƒ¼ãƒãƒ¼å®Ÿè£…**ã€‚

**MCPã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**:

```mermaid
graph LR
    A["ğŸ¤– LLM Host<br/>(Claude Desktop)"] -->|JSON-RPC| B["ğŸ“¡ MCP Server"]
    B -->|stdio/HTTP/SSE| C["ğŸ› ï¸ Tools"]
    C --> D["ğŸ—„ï¸ Resources"]

    B -.Prompts.-> A
    B -.Sampling.-> A

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#c8e6c9
```

**ä¸»è¦MCPã‚µãƒ¼ãƒãƒ¼**:

| Server | Capability | Install | Status |
|:-------|:----------|:--------|:-------|
| **@modelcontextprotocol/server-filesystem** | ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œ | `npx` | Official |
| **@modelcontextprotocol/server-github** | PR/Issueç®¡ç† | `npx` | Official |
| **@modelcontextprotocol/server-postgres** | SQLå®Ÿè¡Œ | `npx` | Official |
| **@modelcontextprotocol/server-slack** | Channel/DM | `npx` | Official |
| **@modelcontextprotocol/server-gdrive** | Google Drive | `npx` | Community |
| **mcp-server-qdrant** | Vector search | `pip` | Community |

**MCPãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ãƒ­ãƒ¼ä¾‹** (GitHub PRä½œæˆ):

```json
// 1. LLM â†’ Server: Tool discovery
{"jsonrpc": "2.0", "method": "tools/list", "id": 1}

// 2. Server â†’ LLM: Available tools
{
  "result": {
    "tools": [{
      "name": "create_pull_request",
      "description": "Create a new pull request",
      "inputSchema": {
        "type": "object",
        "properties": {
          "repo": {"type": "string"},
          "title": {"type": "string"},
          "body": {"type": "string"},
          "head": {"type": "string"},
          "base": {"type": "string"}
        },
        "required": ["repo", "title", "head", "base"]
      }
    }]
  }
}

// 3. LLM â†’ Server: Execute tool
{
  "method": "tools/call",
  "params": {
    "name": "create_pull_request",
    "arguments": {
      "repo": "anthropics/claude-code",
      "title": "Fix: Handle edge case in parser",
      "body": "Resolves #123...",
      "head": "fix/parser-edge-case",
      "base": "main"
    }
  }
}

// 4. Server â†’ LLM: Result
{"result": {"content": [{"type": "text", "text": "PR #456 created successfully"}]}}
```

**MCP vs å¾“æ¥ã®APIçµ±åˆ**:

| è¦³ç‚¹ | å¾“æ¥ (å„LLMç‹¬è‡ªAPI) | MCP |
|:-----|:------------------|:----|
| **çµ±åˆã‚³ã‚¹ãƒˆ** | å„LLMã”ã¨ã«å®Ÿè£… | 1å›å®Ÿè£…ã§å…¨LLMå¯¾å¿œ |
| **Discovery** | æ‰‹å‹•ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ | å‹•çš„ (`tools/list`) |
| **Streaming** | å¯¾å¿œã¾ã¡ã¾ã¡ | SSEæ¨™æº–ã‚µãƒãƒ¼ãƒˆ |
| **ã‚¨ãƒ©ãƒ¼å‡¦ç†** | ç‹¬è‡ªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ | JSON-RPCæ¨™æº– |
| **èªè¨¼** | OAuthç­‰ãƒãƒ©ãƒãƒ© | çµ±ä¸€ (ç’°å¢ƒå¤‰æ•°/OAuth) |

#### 6.3.4 Multi-Agent Frameworks

| Framework | ç‰¹å¾´ | è¨€èª | 2025 Status |
|:----------|:-----|:-----|:-----------|
| **AutoGen** | ä¼šè©±ãƒ™ãƒ¼ã‚¹ã€æŸ”è»Ÿ | Python | v0.4+ (MCPçµ±åˆ) |
| **CrewAI** | Role-basedã€ã‚·ãƒ³ãƒ—ãƒ« | Python | v0.28+ (Hierarchical) |
| **LangGraph** | ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã€å¯è¦–åŒ– | Python / JS | Studio GA |
| **CAMEL** | Role-playingã€ç ”ç©¶å‘ã‘ | Python | Multi-modal agents |
| **Magentic-One** | Microsoft 2024ã€æ±ç”¨ | Python | OSSåŒ– (2025) |
| **OpenHands** | Code agents | Python | SWE-bench 15.9% |

**2025å¹´ã®ä¸»è¦é€²å±•**:

1. **MCP (Model Context Protocol) çµ±åˆ**: Anthropic Claude Desktopã€OpenAIã€Googleå…¨ã¦ãŒå¯¾å¿œ
2. **éšå±¤çš„Multi-Agent**: Manager â†’ Workers â†’ Specialists (3å±¤æ§‹é€ ãŒæ¨™æº–)
3. **é•·æœŸè¨˜æ†¶**: Vector DBçµ±åˆãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ (Qdrant/Pinecone)
4. **Tool Ecosystemæ‹¡å¤§**: 1000+ MCP servers (GitHub, Slack, Postgresç­‰)

### 6.4 å®Ÿä¸–ç•Œã¸ã®å¿œç”¨

#### 6.4.1 ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

| è£½å“ | æ©Ÿèƒ½ | ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ | è©³ç´° |
|:-----|:-----|:----------------|:-----|
| **GitHub Copilot** | ã‚³ãƒ¼ãƒ‰è£œå®Œ | Tool Use (code search) | ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹æ¤œç´¢ã€APIå‚ç…§ã€ãƒ†ã‚¹ãƒˆç”Ÿæˆ |
| **Cursor** | AI-first IDE | ReAct Loop + Memory | ä¼šè©±å±¥æ­´ä¿æŒã€Multi-file editingã€Cmd+K Agent |
| **Devin** | å®Œå…¨è‡ªå¾‹é–‹ç™º | Planning + Multi-Agent | ã‚¿ã‚¹ã‚¯åˆ†è§£â†’å®Ÿè£…â†’ãƒ†ã‚¹ãƒˆâ†’ãƒ‡ãƒãƒƒã‚°â†’PRä½œæˆã‚’å®Œå…¨è‡ªå‹•åŒ– |
| **SWE-agent** | GitHub Issueè§£æ±º | ReAct + Tool Use | GitHub APIã€Code Searchã€Gitæ“ä½œã‚’çµ±åˆ |

**Devinã®å®Ÿè£…ä¾‹** (Cognition AI):

1. **Planning**: GitHub Issueã‚’èª­ã¿ã€ã‚¿ã‚¹ã‚¯ã‚’5-10ã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†è§£
2. **Tool Use**: Code Editor, Terminal, Browser, GitHub APIã‚’é§†ä½¿
3. **Memory**: éå»ã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨˜æ†¶ã€é¡ä¼¼Issueè§£æ±ºå±¥æ­´ã‚’å‚ç…§
4. **Multi-Agent**: Planner / Coder / Tester / Reviewerã®å½¹å‰²åˆ†æ‹…
5. **Feedback Loop**: CIãƒ†ã‚¹ãƒˆå¤±æ•—ã‚’è¦³å¯Ÿâ†’ãƒ‡ãƒãƒƒã‚°â†’å†å®Ÿè£…

**æˆåŠŸç‡** (SWE-bench Verified):
- **Devin (2024å¹´)**: 13.86% (ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: 1.96%)
- **Aider (2025å¹´)**: 18.8% (ReAct + Tree Search)
- **OpenHands (2025å¹´)**: 15.9% (Multi-Agent)
- **AutoCodeRover (2025å¹´)**: 22.3% (Context retrievalæœ€é©åŒ–)

**2025å¹´ã®æœ€æ–°æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ (Devin-like agents)**:

| Component | Technology | Purpose |
|:----------|:----------|:--------|
| **LLM Core** | Claude Opus 4.6 / GPT-4 Turbo | Reasoning |
| **Code Search** | Tree-sitter AST + Vector DB | Context retrieval |
| **Terminal** | Sandboxed Docker | Safe execution |
| **MCP Tools** | GitHub/Git/Filesystem | Standard interface |
| **Memory** | Qdrant (vector) + SQLite (structured) | Long-term context |
| **Test Runner** | pytest/Jest auto-detection | Verification loop |

**å®Ÿè£…è©³ç´° â€” Code Editingãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**:

```elixir
# Elixir: è‡ªå¾‹ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (OTPãƒ‘ã‚¿ãƒ¼ãƒ³)
defmodule AutonomousCodeAgent do
  use GenServer

  def fix_issue(issue_url) do
    {:ok, pid} = GenServer.start_link(__MODULE__, %{issue_url: issue_url})
    GenServer.call(pid, :execute, 60_000)
  end

  def handle_call(:execute, _from, state) do
    with {:ok, issue}   <- GitHub.get_issue(state.issue_url),
         {:ok, context} <- CodeSearch.find_relevant_files(issue.description),
         {:ok, plan}    <- LLM.plan(issue, context),
         {:ok, _pr}     <- execute_plan(plan, context) do
      {:reply, :ok, state}
    else
      {:error, reason} -> {:reply, {:error, reason}, state}
    end
  end

  defp execute_plan(plan, context) do
    Enum.reduce_while(plan.steps, {:ok, context}, fn step, {:ok, ctx} ->
      case apply_step(step, ctx) do
        {:ok, new_ctx} -> {:cont, {:ok, new_ctx}}
        {:error, _} = err -> {:halt, err}
      end
    end)
  end
end
```

### 6.5 Advanced Agent Patterns (2025)

**Pattern 1: Hierarchical Agent System**

3å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒãƒ‡ãƒ•ã‚¡ã‚¯ãƒˆã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰:

```
Layer 1: Meta-Agent (Coordinator)
   â†“
Layer 2: Specialist Agents (Domain experts)
   â†“
Layer 3: Tool Agents (Atomic operations)
```

**å®Ÿè£…ä¾‹**:

```elixir
# MetaAgent: éšå±¤å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  (Layer 1 â€” Orchestrator)
defmodule MetaAgent do
  use GenServer

  def execute(task) do
    subtasks = LLM.decompose(task)

    # ä¸¦åˆ—å®Ÿè¡Œ: Task.async_stream ã§å„ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã‚’å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å§”è­²
    subtasks
    |> Task.async_stream(&delegate_to_specialist/1, max_concurrency: 4, timeout: 30_000)
    |> Enum.map(fn {:ok, result} -> result end)
    |> LLM.synthesize()
  end

  defp delegate_to_specialist(subtask) do
    domain = LLM.classify(subtask.description)
    specialist = SpecialistRegistry.lookup(domain)
    GenServer.call(specialist, {:execute, subtask})
  end
end
```

**Pattern 2: Reflexion â€” Self-Critique Loop**

Shinn et al. (2023) ã®**Reflexion**ãƒ‘ã‚¿ãƒ¼ãƒ³: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè‡ªå·±æ‰¹è©•ã§æ”¹å–„ã€‚

```elixir
# CodeSpecialistAgent: ãƒ‰ãƒ¡ã‚¤ãƒ³å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (Layer 2)
defmodule CodeSpecialistAgent do
  use GenServer

  @tools [:filesystem, :git, :test_runner, :linter]
  @max_steps 10

  def execute(subtask) do
    {:ok, pid} = GenServer.start_link(__MODULE__, %{subtask: subtask, context: []})
    GenServer.call(pid, :run, 120_000)
  end

  def handle_call(:run, _from, %{subtask: subtask, context: ctx} = state) do
    result = react_loop(subtask, ctx, @max_steps)
    {:reply, result, state}
  end

  defp react_loop(_task, _ctx, 0), do: {:error, :max_steps_reached}
  defp react_loop(task, ctx, steps) do
    thought = LLM.reason(task, ctx)
    case parse_action(thought) do
      {:finish, result}      -> {:ok, result}
      {:tool, name, args}    ->
        observation = apply(ToolAgents, name, [args])
        react_loop(task, [observation | ctx], steps - 1)
    end
  end
end
```

**Pattern 3: Constitutional AI for Agents**

Anthropic's Constitutional AIã‚’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«é©ç”¨:

```rust
// Reflexion: è‡ªå·±æ‰¹è©•ã«ã‚ˆã‚‹åå¾©æ”¹å–„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
// æ•°å¼: Ï€_{t+1} = argmax_Ï€ ğ”¼[R | s_t, verbal_reflection(Ï€_t)]

struct ReflexionAgent {
    memory: Vec<String>,
}

struct EvalResult {
    success: bool,
    feedback: String,
}

impl ReflexionAgent {
    fn new() -> Self {
        ReflexionAgent { memory: vec![] }
    }

    fn solve_with_reflection(&mut self, task: &str, max_trials: usize) -> Option<String> {
        for _ in 0..max_trials {
            // è©¦è¡Œ
            let solution = attempt(task, &self.memory);

            // è‡ªå·±è©•ä¾¡
            let eval_result = evaluate_solution(&solution, task);

            if eval_result.success {
                return Some(solution);  // æˆåŠŸ
            }

            // Verbal Reflection: å¤±æ•—åŸå› ã®è¨€èªåŒ–
            let reflection = reflect(&solution, &eval_result.feedback);
            self.memory.push(reflection);
        }
        None  // max_trials exceeded
    }
}

fn attempt(_task: &str, _memory: &[String]) -> String { "solution".to_string() }
fn evaluate_solution(_sol: &str, _task: &str) -> EvalResult {
    EvalResult { success: false, feedback: "needs improvement".to_string() }
}
fn reflect(_sol: &str, feedback: &str) -> String { format!("Reflection: {}", feedback) }

// æ¤œç®—: ãƒ¡ãƒ¢ãƒªã¯åå¾©ã”ã¨ã«è“„ç©
fn main() {
    let mut agent = ReflexionAgent::new();
    // After trial 1: agent.memory.len() == 1
    // After trial 2: agent.memory.len() == 2
    let _ = agent.solve_with_reflection("task", 3);
    println!("Memory entries after 3 trials: {}", agent.memory.len());
}
```

### 6.6 Agent Evaluation Benchmarks (2024-2025)

**ä¸»è¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯**:

| Benchmark | Task | Metrics | SOTA (2025) |
|:----------|:-----|:--------|:-----------|
| **SWE-bench Verified** | GitHub Issueè§£æ±º | Resolution Rate | 22.3% (AutoCodeRover) |
| **WebArena** | Real websiteæ“ä½œ | Success Rate | 38.2% (GPT-4 + Tree Search) |
| **AgentBench** | 8ç’°å¢ƒç·åˆè©•ä¾¡ | Average Success | 65.4% (Claude Opus 4.6) |
| **GAIA** | ä¸€èˆ¬AIèƒ½åŠ› | Human-level % | 42.1% |
| **Ï„-bench** | Tool useæ­£ç¢ºæ€§ | Accuracy | 87.3% |

**SWE-bench Verifiedè©³ç´°**:

```
Task: Real GitHub issues from OSS projects
Example:
  Issue #1234 in django/django:
  "QuerySet.update() doesn't work with F() expressions on joined fields"

Agent Actions:
1. Read issue description
2. Search codebase for QuerySet.update()
3. Identify relevant files (django/db/models/query.py)
4. Analyze F() expression handling
5. Write fix
6. Run tests
7. Create PR

Evaluation: PR passes CI + resolves issue
```

**Success Factors**:

| Factor | Impact on Success | Example |
|:-------|:-----------------|:--------|
| **Context Retrieval** | +45% | BM25 + Vector hybrid |
| **Test Execution** | +38% | Run pytest before PR |
| **Error Recovery** | +32% | Retry with debug info |
| **Code Understanding** | +28% | AST parsing + docstrings |

### 6.7 Agentic Workflow vs Traditional

**Traditional Workflow (äººé–“ä¸»å°)**:

```
Human: "Build a web scraper"
â†“
Human: Writes requirements doc
â†“
Human: Implements scraper.py
â†“
Human: Writes tests
â†“
Human: Debugs failures
â†“
Human: Documents code
â†“
Human: Creates PR
```

**Agentic Workflow (AIä¸»å°)**:

```
Human: "Build a web scraper for news articles"
â†“
Agent (Planning): Break into 5 subtasks
â†“
Agent (Research): Find best libraries (BeautifulSoup vs Scrapy)
â†“
Agent (Coding): Implement scraper with error handling
â†“
Agent (Testing): Generate test cases + run
â†“
Agent (Debug): Fix failures via error analysis
â†“
Agent (Docs): Auto-generate docstrings
â†“
Agent (Review): Self-review + suggest improvements
â†“
Agent (PR): Create PR with description
```

**Time Comparison** (Web scraper task):

| Approach | Time | Quality |
|:---------|:-----|:--------|
| Human (Senior Eng) | 4 hours | High |
| Human (Junior Eng) | 12 hours | Medium |
| **Agent (GPT-4 + Tools)** | **45 min** | **High** |

**Cost Comparison**:

| Resource | Human | Agent |
|:---------|:------|:------|
| Labor | $200 (4h Ã— $50/h) | $0 |
| API | $0 | $2.50 (GPT-4) |
| **Total** | **$200** | **$2.50** |

ROI: 80x cost reduction for routine tasks.

### 6.10 Future: Foundation Models for Agents

**2026å¹´äºˆæ¸¬**:

1. **Agent-Specific Models**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç”¨ã«ç‰¹åŒ–ã—ãŸLLM (Tool useæœ€é©åŒ–)
2. **World Models**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç’°å¢ƒã®å‹•çš„ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
3. **Multi-Modal Agents**: Text + Vision + Audioçµ±åˆ
4. **Federated Agent Learning**: è¤‡æ•°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå”èª¿å­¦ç¿’

**Emerging Architecture: Agent + World Model**:

```rust
// WorldModelAgent: ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸè¨ˆç”»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
// æ•°å¼: Ï€* = argmax_Ï€ Î£_t r(s_t, a_t)  s.t.  world_model(s, a) â†’ s'

struct LLMClient;
struct LearnedEnvironmentModel;
struct Plan(String);
struct Outcome { success_prob: f64 }

struct WorldModelAgent {
    llm: LLMClient,
    world_model: LearnedEnvironmentModel,
}

impl WorldModelAgent {
    fn plan_with_simulation(&self, goal: &str) {
        let candidates = generate_plan_candidates(&self.llm, goal);

        // ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã§å„å€™è£œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ â†’ æœ€è‰¯ãƒ—ãƒ©ãƒ³ã‚’é¸æŠ
        let best = candidates.iter()
            .map(|plan| {
                let outcome = simulate(&self.world_model, plan);
                (plan, outcome.success_prob)
            })
            .max_by(|a, b| a.1.partial_cmp(&b.1).unwrap());

        if let Some((plan, prob)) = best {
            println!("Best plan: {}, success_prob: {:.3}", plan.0, prob);
            // æœ€è‰¯ãƒ—ãƒ©ãƒ³ã‚’å®Ÿç’°å¢ƒã§å®Ÿè¡Œ
            execute_plan(plan);
        }
    }
}

fn generate_plan_candidates(_llm: &LLMClient, goal: &str) -> Vec<Plan> {
    vec![Plan(format!("Plan A for: {}", goal)), Plan(format!("Plan B for: {}", goal))]
}
fn simulate(_model: &LearnedEnvironmentModel, _plan: &Plan) -> Outcome { Outcome { success_prob: 0.8 } }
fn execute_plan(plan: &Plan) { println!("Executing: {}", plan.0); }

// æ¤œç®—: success_prob âˆˆ [0, 1]ã€æœ€å¤§å€¤ã®ãƒ—ãƒ©ãƒ³ãŒé¸æŠã•ã‚Œã‚‹
fn main() {
    let agent = WorldModelAgent { llm: LLMClient, world_model: LearnedEnvironmentModel };
    // plan_with_simulation(agent, "Build a web scraper") â†’ best_prob == max(p.success_prob for p in outcomes)
    agent.plan_with_simulation("Build a web scraper");
}
```

---

#### 6.4.2 ç ”ç©¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

| è£½å“ | æ©Ÿèƒ½ | ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ | è©³ç´° |
|:-----|:-----|:----------------|:-----|
| **Elicit** | è«–æ–‡æ¤œç´¢ãƒ»è¦ç´„ | Tool Use (arXiv API) + Memory | è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªâ†’è«–æ–‡æ¤œç´¢â†’è¦ç´„â†’æ¯”è¼ƒè¡¨ç”Ÿæˆ |
| **Consensus** | ç§‘å­¦çš„ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹ | Multi-Agent Debate | è¤‡æ•°è«–æ–‡ã‚’ä¸¦åˆ—èª­è§£â†’åˆæ„å½¢æˆâ†’ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«è©•ä¾¡ |
| **SciSpace** | è«–æ–‡ç†è§£æ”¯æ´ | RAG + Tool Use | PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰â†’ã‚»ã‚¯ã‚·ãƒ§ãƒ³è§£èª¬â†’æ•°å¼ãƒ»å›³è¡¨èª¬æ˜ |
| **Semantic Scholar** | å¼•ç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ | Knowledge Graph + Tool Use | Citation treeæ¢ç´¢ã€å½±éŸ¿åº¦è¨ˆç®—ã€é–¢é€£è«–æ–‡æ¨è–¦ |

**Elicitã®å‹•ä½œä¾‹**:

```
User: "What are the latest methods for long-context LLMs?"

Agent:
Step 1 (Tool: arxiv_search): Search for "long context LLM 2024 2025"
Step 2 (Tool: paper_scraper): Download top 10 papers
Step 3 (LLM: summarize): Extract methods from each paper
Step 4 (LLM: compare): Create comparison table
Step 5 (Memory: store): Save to user's research library

Output:
| Paper | Method | Context Length | Performance |
|-------|--------|----------------|-------------|
| LongLoRA | LoRA + Shift SSA | 32K | PPL 3.12 |
| StreamingLLM | Attention Sink | 4M | Stable |
| ...
```

#### 6.4.3 Customer Support

| è£½å“ | æ©Ÿèƒ½ | ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ | è©³ç´° |
|:-----|:-----|:----------------|:-----|
| **Intercom AI** | è‡ªå‹•å¿œç­” | Memory + Tool Use (CRM) | é¡§å®¢å±¥æ­´å‚ç…§ã€FAQæ¤œç´¢ã€ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¤å®š |
| **Zendesk AI** | ãƒã‚±ãƒƒãƒˆåˆ†é¡ | Planning + Memory | ãƒã‚±ãƒƒãƒˆåˆ†æâ†’å„ªå…ˆåº¦åˆ¤å®šâ†’æ‹…å½“è€…å‰²ã‚Šå½“ã¦ |
| **Ada** | ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½Bot | ReAct Loop + Memory | å¤šè¨€èªå¯¾å¿œã€ä¼šè©±ãƒ•ãƒ­ãƒ¼è¨˜æ†¶ã€A/Bãƒ†ã‚¹ãƒˆ |

**Intercom AIã®å‹•ä½œä¾‹**:

```
Customer: "My order #12345 hasn't arrived yet."

Agent:
Step 1 (Memory: retrieve): Fetch order history for this customer
Step 2 (Tool: order_api): Check order #12345 status â†’ "Shipped 2 days ago"
Step 3 (Tool: shipping_tracker): Track package â†’ "In transit, estimated delivery tomorrow"
Step 4 (Thought): Customer is concerned, provide reassurance + tracking link
Step 5 (Action: respond): "Your order is on the way! Expected delivery: Feb 14. Track here: [link]"

No human intervention needed.
```

#### 6.4.4 æ–°èˆˆå¿œç”¨åˆ†é‡

| åˆ†é‡ | å¿œç”¨ä¾‹ | ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ |
|:-----|:------|:----------------|
| **åŒ»ç™‚** | è¨ºæ–­æ”¯æ´ã€æ²»ç™‚è¨ˆç”» | Multi-Agent Debate (è¤‡æ•°å°‚é–€åŒ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ) + Memory (æ‚£è€…å±¥æ­´) |
| **æ³•å¾‹** | å¥‘ç´„æ›¸ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€åˆ¤ä¾‹æ¤œç´¢ | Tool Use (æ³•ä»¤DB) + Planning (æ¡é …ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ) |
| **æ•™è‚²** | å€‹åˆ¥æŒ‡å°ã€èª²é¡Œæ¡ç‚¹ | Memory (å­¦ç¿’å±¥æ­´) + Planning (ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ é©å¿œ) |
| **é‡‘è** | ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªç®¡ç†ã€ãƒªã‚¹ã‚¯åˆ†æ | Tool Use (å¸‚å ´ãƒ‡ãƒ¼ã‚¿API) + Multi-Agent (Bull/Bearè¦–ç‚¹) |

### 6.5 ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè©•ä¾¡ã®é€²åŒ–

AgentBenchä»¥é™ã€è©•ä¾¡æ‰‹æ³•ãŒå¤šæ§˜åŒ–:

| ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ | è©•ä¾¡å¯¾è±¡ | ç‰¹å¾´ |
|:-----------|:---------|:-----|
| **AgentBench** | æ±ç”¨èƒ½åŠ› | 8ç’°å¢ƒ |
| **WebArena** | Webæ“ä½œ | å®Ÿãƒ–ãƒ©ã‚¦ã‚¶ |
| **SWE-bench** | ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™º | å®ŸGitHub Issue |
| **GAIA** | ä¸€èˆ¬AIèƒ½åŠ› | äººé–“ãƒ¬ãƒ™ãƒ«è©•ä¾¡ |

### 6.6 èª²é¡Œã¨ä»Šå¾Œã®æ–¹å‘æ€§

| èª²é¡Œ | ç¾çŠ¶ | ä»Šå¾Œã®æ–¹å‘æ€§ |
|:-----|:-----|:-----------|
| **Hallucination** | å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã§è»½æ¸› | Verification Agentã€Multi-Agent Cross-check |
| **Planning Efficiency** | ReWOOã§5xæ”¹å–„ | Neural Symbolic Planningã€Tree Search |
| **Memory Scalability** | Vector DBåˆ©ç”¨ | Hierarchical Memoryã€Forgetting Mechanism |
| **Multi-Agent Coordination** | Message Passing | Protocolæ¨™æº–åŒ– (MCP)ã€Formal Verification |
| **Cost** | GPT-4ã§é«˜ã‚³ã‚¹ãƒˆ | Smaller Models (Llama 3.1 70B)ã€Model Routing |

> **Note:** **progress: 100%** â€” Zone 6å®Œäº†ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç ”ç©¶ã®æœ€æ–°å‹•å‘ã¨å®Ÿä¸–ç•Œå¿œç”¨ã‚’æŠŠæ¡ã—ãŸã€‚

---

**ã‚´ãƒ¼ãƒ«**: æœ¬è¬›ç¾©ã®å…¨ä½“ã‚’æŒ¯ã‚Šè¿”ã‚Šã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ˜ç¢ºã«ã™ã‚‹ã€‚

### 6.6 æœ¬è¬›ç¾©ã®ã¾ã¨ã‚

æœ¬è¬›ç¾©ã§å­¦ã‚“ã 7ã¤ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ:

| Component | æ•°å¼ãƒ»æ¦‚å¿µ | å®Ÿè£… |
|:----------|:----------|:-----|
| **1. ReAct Loop** | $\text{thought}_t \to a_t \to o_{t+1}$ | Rust State Machine |
| **2. Tool Use** | $\mathcal{T} = \langle \text{name}, \text{schema}, \text{function} \rangle$ | Rust Tool Registry |
| **3. Planning** | $\text{task} \to \{ \text{subtask}_i \}$ | Rust Planning Engine |
| **4. Memory** | $\mathcal{M} = \{ (k_i, v_i) \}$ | Rust + Qdrant |
| **5. Multi-Agent** | $\mathcal{MAS} = \{ \mathcal{A}_1, \ldots, \mathcal{A}_N \}$ | Elixir GenServer |
| **6. MCP** | JSON-RPC 2.0 over stdio/HTTP | Rust Server + Rust Client |
| **7. Production** | Rust+Elixir+Rustçµ±åˆ | Complete Agent System |

### 6.7 åˆ°é”ç‚¹

**Before (ç¬¬29å›ã¾ã§)**:
- LLMã¯"èª­ã‚€"å­˜åœ¨
- å¤–éƒ¨çŸ¥è­˜ã¯RAGã§æ¥ç¶š
- å˜ä¸€ã®LLMå‘¼ã³å‡ºã—

**After (ç¬¬30å›)**:
- LLMã¯"è¡Œå‹•ã™ã‚‹"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- Tool Use / Planning / Memoryã§è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’é‚è¡Œ
- Multi-Agentã§å”èª¿ãƒ»è¨è«–


## ğŸ­ Z7. ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ï¼ˆã¾ã¨ã‚ãƒ»FAQãƒ»æ¬¡å›äºˆå‘Šï¼‰

### 6.8 FAQ

<details>
<summary><strong>Q1. ReActã¨Chain-of-Thoughtã®é•ã„ã¯ï¼Ÿ</strong></summary>

**A**: CoTã¯æ€è€ƒã®ã¿ã€ReActã¯æ€è€ƒ+è¡Œå‹•+è¦³å¯Ÿã®ãƒ«ãƒ¼ãƒ—ã€‚ReActã¯å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã§æ¤œè¨¼ã§ãã‚‹ãŸã‚ã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ãŒå°‘ãªã„ã€‚
</details>

<details>
<summary><strong>Q2. Tool Useå®Ÿè£…ã§æœ€ã‚‚é‡è¦ãªã“ã¨ã¯ï¼Ÿ</strong></summary>

**A**: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨Retryæˆ¦ç•¥ã€‚Toolå®Ÿè¡Œã¯å¤±æ•—ã—ã†ã‚‹ (Timeout, Invalid Args, Execution Error)ã€‚Exponential Backoffã§å†è©¦è¡Œã—ã€Fallback Toolã‚’ç”¨æ„ã™ã‚‹ã€‚
</details>

<details>
<summary><strong>Q3. ReWOOã®ãƒ¡ãƒªãƒƒãƒˆãƒ»ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¯ï¼Ÿ</strong></summary>

**A**: ãƒ¡ãƒªãƒƒãƒˆ: ä¸¦åˆ—å®Ÿè¡Œã§é«˜é€Ÿã€ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»5xå‰Šæ¸›ã€‚ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ: å‹•çš„å†è¨ˆç”»ä¸å¯ã€è¤‡é›‘ãªä¾å­˜é–¢ä¿‚ã«å¼±ã„ã€‚
</details>

<details>
<summary><strong>Q4. Memory Systemã§æœ€ã‚‚åŠ¹æœçš„ãªã®ã¯ï¼Ÿ</strong></summary>

**A**: Vector Memory (RAG)ã€‚LLMã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¶é™ã‚’è¶…ãˆã¦ã€å¤§é‡ã®éå»çµŒé¨“ã‚’æ¤œç´¢å¯èƒ½ã€‚Qdrant / Pinecone / Weaviateãªã©ã®Vector DBã‚’ä½¿ã†ã€‚
</details>

<details>
<summary><strong>Q5. Multi-Agent Debateã¯å¸¸ã«æœ‰åŠ¹ï¼Ÿ</strong></summary>

**A**: No. ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¿ã‚¹ã‚¯ã§ã¯ã‚³ã‚¹ãƒˆå¢—ã®ã¿ã€‚è¤‡é›‘ãªæ¨è«–ãƒ»åˆ¤æ–­ã‚¿ã‚¹ã‚¯ (åŒ»ç™‚è¨ºæ–­ã€æ³•çš„åˆ¤æ–­) ã§æœ‰åŠ¹ã€‚3-5ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€2-3ãƒ©ã‚¦ãƒ³ãƒ‰ãŒç›®å®‰ã€‚
</details>

<details>
<summary><strong>Q6. MCPã¯å¿…é ˆï¼Ÿ</strong></summary>

**A**: 2025å¹´æ™‚ç‚¹ã§ã¯ä»»æ„ã ãŒã€OpenAI / Google / Anthropicå…¨ã¦ãŒå¯¾å¿œäºˆå®šã€‚æ–°è¦ãƒ„ãƒ¼ãƒ«é–‹ç™ºã¯MCPå¯¾å¿œãŒæ¨™æº–ã«ãªã‚‹ã€‚
</details>

<details>
<summary><strong>Q7. ãªãœRust / Elixir / Rustã®3è¨€èªï¼Ÿ</strong></summary>

**A**:
- **Rust**: Tool Registry / State Machineã¯å‹å®‰å…¨ãƒ»é«˜é€ŸãŒå¿…é ˆ
- **Elixir**: Multi-Agentã¯éšœå®³è€æ€§ãƒ»åˆ†æ•£ä¸¦è¡ŒãŒå¿…é ˆ
- **Rust**: Orchestrationã¯æ•°å¼â†”ã‚³ãƒ¼ãƒ‰1:1ãŒå¿…é ˆ

Pythonã ã‘ã§ã¯å…¨ã¦ã‚’æœ€é©åŒ–ã§ããªã„ã€‚
</details>

<details>
<summary><strong>Q8. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æœ€å¤§ã®èª²é¡Œã¯ï¼Ÿ</strong></summary>

**A**: **Hallucination**ã¨**Cost**ã€‚å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã§Hallucinationã¯è»½æ¸›ã•ã‚Œã‚‹ãŒã€å®Œå…¨ã«ã¯æ¶ˆãˆãªã„ã€‚Multi-Agent Debateã¯ã‚³ã‚¹ãƒˆãŒNå€ã€‚Small Model (Llama 3.1 70B) + Model Routingã§å¯¾å‡¦ã€‚
</details>

### 6.9 å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« (1é€±é–“ãƒ—ãƒ©ãƒ³)

| Day | å†…å®¹ | æ™‚é–“ | æ¼”ç¿’ |
|:----|:-----|:-----|:-----|
| **Day 1** | Zone 0-2 | 30åˆ† | ReAct Loop 3è¡Œã‚³ãƒ¼ãƒ‰ |
| **Day 2** | Zone 3 Part A-B | 60åˆ† | Tool Registryå®Ÿè£… |
| **Day 3** | Zone 3 Part C-D | 60åˆ† | Planning Engineå®Ÿè£… |
| **Day 4** | Zone 3 Part E-F | 60åˆ† | Multi-Agent + MCP |
| **Day 5** | Zone 3 Part G + Zone 4 | 90åˆ† | Rust/Elixir/Rustçµ±åˆ |
| **Day 6** | Zone 5 | 60åˆ† | AgentBenchè©•ä¾¡ |
| **Day 7** | Zone 6 + å¾©ç¿’ | 60åˆ† | æœ€æ–°è«–æ–‡èª­è§£ |

### 6.10 æ¬¡å›äºˆå‘Š: ç¬¬31å› MLOpså®Œå…¨ç‰ˆ

ç¬¬30å›ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å…¨ä½“åƒã‚’å­¦ã‚“ã ã€‚æ¬¡ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å«ã‚€æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã‚’**æœ¬ç•ªç’°å¢ƒã§é‹ç”¨**ã™ã‚‹ãŸã‚ã®æŠ€è¡“ â€” **MLOpså®Œå…¨ç‰ˆ**ã ã€‚

**ç¬¬31å›ã®ä¸»è¦ãƒˆãƒ”ãƒƒã‚¯**:
- **å®Ÿé¨“ç®¡ç†**: MLflow / Weights & Biases / Neptune
- **ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°**: DVC / LakeFS
- **ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒª**: MLflow Model Registry / BentoML
- **CI/CD for ML**: GitHub Actions + Docker + Kubernetes
- **ç›£è¦–**: Prometheus + Grafana / Evidently AI
- **A/Bãƒ†ã‚¹ãƒˆ**: Multi-Armed Bandit / Bayesian Optimization
- **Feedback Loop**: Human-in-the-Loop / RLHF

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã€Œå®Ÿé¨“å®¤ã®ç©å…·ã€ã‹ã‚‰ã€Œæœ¬ç•ªç¨¼åƒã‚·ã‚¹ãƒ†ãƒ ã€ã«æ˜‡è¯ã•ã›ã‚‹ã€‚

> **Note:** **progress: 100%** â€” ç¬¬30å›å®Œäº†ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Œå…¨ç‰ˆã‚’ç¿’å¾—ã—ãŸã€‚æ¬¡ã¯ç¬¬31å›MLOpsã§æœ¬ç•ªé‹ç”¨ã¸ã€‚

---

### 6.11 ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„

**AIã¯"é“å…·"ã‹ã‚‰"åŒåƒš"ã«ãªã‚‹ã®ã‹ï¼Ÿ**

å¾“æ¥ã€AIã¯ã€Œãƒ„ãƒ¼ãƒ«ã€ã ã£ãŸã€‚æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã€ç¿»è¨³ã€ç”»åƒç”Ÿæˆ â€” å…¨ã¦ã€Œäººé–“ãŒæŒ‡ç¤ºã‚’å‡ºã—ã€AIãŒå®Ÿè¡Œã™ã‚‹ã€é–¢ä¿‚ã ã€‚

ã—ã‹ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯é•ã†:

- **ReAct Loop**: è‡ªå¾‹çš„ã«æ¨è«–ãƒ»è¡Œå‹•ãƒ»è¦³å¯Ÿã‚’ç¹°ã‚Šè¿”ã™
- **Planning**: ç›®æ¨™ã‹ã‚‰é€†ç®—ã—ã€ã‚¿ã‚¹ã‚¯ã‚’åˆ†è§£ã™ã‚‹
- **Memory**: éå»ã®çµŒé¨“ã‚’è¨˜æ†¶ã—ã€å­¦ç¿’ã™ã‚‹
- **Multi-Agent**: ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨å”èª¿ãƒ»è¨è«–ã™ã‚‹

ã“ã‚Œã¯ã€Œé“å…·ã€ã§ã¯ãªãã€ã€ŒåŒåƒšã€ã®æŒ¯ã‚‹èˆã„ã ã€‚

**2ã¤ã®è¦–ç‚¹**:

1. **æ¥½è¦³çš„è¦–ç‚¹**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯äººé–“ã®èƒ½åŠ›ã‚’æ‹¡å¼µã—ã€å‰µé€ æ€§ã‚’è§£æ”¾ã™ã‚‹ã€‚åŒ»å¸«ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨å”åŠ›ã—ã¦è¨ºæ–­ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨å…±ã«ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’é–‹ç™ºã™ã‚‹ã€‚äººé–“ã¯ã€Œç®¡ç†è€…ã€ã¨ã—ã¦ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ ã‚’ç‡ã„ã‚‹ã€‚

2. **æ‡¸å¿µçš„è¦–ç‚¹**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯äººé–“ã®å½¹å‰²ã‚’ä¾µé£Ÿã™ã‚‹ã€‚å˜ç´”ä½œæ¥­ã ã‘ã§ãªãã€æ¨è«–ãƒ»åˆ¤æ–­ãƒ»å‰µé€ ã‚‚è‡ªå‹•åŒ–ã•ã‚Œã‚‹ã€‚ã€Œäººé–“ã«ã—ã‹ã§ããªã„ä»•äº‹ã€ã®ç¯„å›²ãŒæ€¥é€Ÿã«ç¸®å°ã™ã‚‹ã€‚

ã‚ãªãŸã¯ã©ã¡ã‚‰ã®æœªæ¥ã‚’è¦‹ã‚‹ã‹ï¼Ÿ

**è€ƒå¯Ÿã®ãƒ’ãƒ³ãƒˆ**:

- OpenAI o1ã¯ã€**æ¨è«–æ™‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡**ã‚’å®Ÿè¨¼ã—ãŸã€‚LLMã¯ã€Œè€ƒãˆã‚‹æ™‚é–“ã€ã‚’å¢—ã‚„ã›ã°ã€ã‚ˆã‚Šè‰¯ã„ç­”ãˆã‚’å‡ºã›ã‚‹ã€‚ã“ã‚Œã¯äººé–“ã®ã€Œç†Ÿè€ƒã€ã¨åŒã˜ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã ã€‚
- MetaGPT [^8] ã¯ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã‚’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ ã§è‡ªå‹•åŒ–ã—ãŸã€‚Product Manager / Architect / Engineer / Testerã®å½¹å‰²ã‚’å…¨ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ‹…ã†ã€‚
- Generative Agents [^4] ã¯ã€ç¤¾ä¼šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã€Œè¨˜æ†¶ãƒ»åçœãƒ»è¨ˆç”»ã€ã‚’æŒã¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã€äººé–“ã®ã‚ˆã†ãªç¤¾ä¼šçš„æŒ¯ã‚‹èˆã„ã‚’ç¤ºã—ãŸã€‚

**å•ã„**:

1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã€ŒåŒåƒšã€ã«ãªã£ãŸã¨ãã€äººé–“ã®å½¹å‰²ã¯ã©ã†å¤‰ã‚ã‚‹ã‹ï¼Ÿ
2. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒå£«ãŒå”åŠ›ã™ã‚‹ç¤¾ä¼šã§ã€äººé–“ã¯ã©ã®ã‚ˆã†ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨å”åƒã™ã¹ãã‹ï¼Ÿ
3. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã€Œæ€è€ƒã€ã€Œè¨˜æ†¶ã€ã€Œè¨ˆç”»ã€ã‚’æŒã¤ã¨ãã€ãã‚Œã¯ã€ŒçŸ¥èƒ½ã€ã¨å‘¼ã¹ã‚‹ã‹ï¼Ÿ

<details>
<summary>ä¸€ã¤ã®è¦–ç‚¹ (æä¾›: æœ¬è¬›ç¾©è‘—è€…)</summary>

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€Œé“å…·ã€ã§ã‚‚ã€ŒåŒåƒšã€ã§ã‚‚ãªã„ã€‚**ã€Œæ‹¡å¼µã•ã‚ŒãŸè‡ªå·±ã€**ã ã¨è€ƒãˆã‚‹ã€‚

ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã¯ã€è¨˜æ†¶ã®å¤–éƒ¨åŒ–ã ã€‚Google Mapsã¯ã€ç©ºé–“èªè­˜ã®æ‹¡å¼µã ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€**æ¨è«–ãƒ»è¨ˆç”»ãƒ»å”èª¿ã®æ‹¡å¼µ**ã ã€‚

é‡è¦ãªã®ã¯ã€ã€Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒä½•ã‚’ã™ã‚‹ã‹ã€ã§ã¯ãªãã€ã€Œäººé–“ãŒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã©ã†ä½¿ã„ã“ãªã™ã‹ã€ã ã€‚ç¬¬31å›MLOpsã§å­¦ã¶ã®ã¯ã€ã¾ã•ã«ã“ã®ã€Œä½¿ã„ã“ãªã—ã€ã®æŠ€è¡“ â€” ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã‚’è¨­è¨ˆã—ã€ç›£è¦–ã—ã€æ”¹å–„ã—ç¶šã‘ã‚‹ãƒ«ãƒ¼ãƒ—ã ã€‚

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€äººé–“ã®ã€Œæ€è€ƒã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡ã€ã‚’å®Ÿç¾ã™ã‚‹é“å…·ã ã€‚1äººã®äººé–“ãŒã€100ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç‡ã„ã¦ã€1000äººåˆ†ã®ä»•äº‹ã‚’ã™ã‚‹æœªæ¥ã€‚ãã‚Œã‚’ã€Œè„…å¨ã€ã¨è¦‹ã‚‹ã‹ã€ã€Œæ©Ÿä¼šã€ã¨è¦‹ã‚‹ã‹ã¯ã€ã‚ãªãŸæ¬¡ç¬¬ã ã€‚
</details>

> **Note:** **é€²æ—: 100% å®Œäº†** ğŸ‰ è¬›ç¾©å®Œèµ°ï¼

---

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2023). "ReAct: Synergizing Reasoning and Acting in Language Models". *ICLR 2023*.
<https://arxiv.org/abs/2210.03629>

[^2]: Schick, T., Dwivedi-Yu, J., Dess`Ä±, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., & Scialom, T. (2023). "Toolformer: Language Models Can Teach Themselves to Use Tools". *arXiv:2302.04761*.
<https://arxiv.org/abs/2302.04761>

[^3]: Xu, B., Peng, Z., Lei, B., Mukherjee, S., Liu, Y., & Xu, D. (2023). "ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models". *arXiv:2305.18323*.
<https://arxiv.org/abs/2305.18323>

[^4]: Park, J. S., O'Brien, J. C., Cai, C. J., Morris, M. R., Liang, P., & Bernstein, M. S. (2023). "Generative Agents: Interactive Simulacra of Human Behavior". *arXiv:2304.03442*.
<https://arxiv.org/abs/2304.03442>


[^7]: Liu, X., Yu, H., Zhang, H., Xu, Y., Lei, X., Lai, H., Gu, Y., Ding, H., Men, K., Yang, K., Zhang, S., Deng, X., Zeng, A., Du, Z., Zhang, C., Shen, S., Zhang, T., Su, Y., Sun, H., Huang, M., Dong, Y., & Tang, J. (2023). "AgentBench: Evaluating LLMs as Agents". *arXiv:2308.03688*.
<https://arxiv.org/abs/2308.03688>

[^8]: Hong, S., Zheng, X., Chen, J., Cheng, Y., Zhang, C., Wang, Z., Yau, S. K. S., Lin, Z., Zhou, L., Ran, C., Xiao, L., Wu, C., & Schmidhuber, J. (2023). "MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework". *arXiv:2308.00352*.
<https://arxiv.org/abs/2308.00352>

[^9]: Wu, Q., Bansal, G., Zhang, J., Wu, Y., Li, B., Zhu, E., Jiang, L., Zhang, X., Zhang, S., Liu, J., Awadallah, A. H., White, R. W., Burger, D., & Wang, C. (2023). "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation". *arXiv:2308.08155*.
<https://arxiv.org/abs/2308.08155>

[^10]: Shen, Y., Song, K., Tan, X., Li, D., Lu, W., & Zhuang, Y. (2023). "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face". *NeurIPS 2023*.
<https://arxiv.org/abs/2303.17580>

[^11]: Anthropic. (2024). "Model Context Protocol (MCP)".
<https://modelcontextprotocol.io>

---

> **ğŸ“– å‰ç·¨ï¼ˆç†è«–ç·¨ï¼‰**: [ç¬¬30å›å‰ç·¨: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç†è«–ç·¨](./ml-lecture-30-part1) | **â† ç†è«–ãƒ»æ•°å¼ã‚¾ãƒ¼ãƒ³ã¸**

## è‘—è€…ãƒªãƒ³ã‚¯

- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

**ğŸ“ ç¬¬30å›å®Œäº†ï¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Œå…¨ç‰ˆã‚’ç¿’å¾—ã—ãŸã€‚æ¬¡ã¯ç¬¬31å›ã€ŒMLOpså®Œå…¨ç‰ˆã€ã§æœ¬ç•ªé‹ç”¨ã¸ã€‚**
