---
title: "ç¬¬43å› (Part 2): Diffusion Transformers & é«˜é€Ÿç”Ÿæˆ: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼"
emoji: "ğŸ¨"
type: "tech"
topics: ["machinelearning", "deeplearning", "diffusiontransformers", "rust", "dit"]
published: true
slug: "ml-lecture-43-part2"
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Rust"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---
## ğŸ’» Z5. è©¦ç·´ï¼ˆå®Ÿè£…ï¼‰ï¼ˆ45åˆ†ï¼‰â€” 3è¨€èªã§DiTã‚’å®Ÿè£…ã™ã‚‹

**ã‚´ãƒ¼ãƒ«**: ğŸ¦€Rust ã§ DiT è¨“ç·´ã€ğŸ¦€Rust ã§æ¨è«–ã€ğŸ”®Elixir ã§åˆ†æ•£ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã€‚

### 4.1 ğŸ¦€ Rust: Mini-DiT è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

**è¨“ç·´ã®å…¨ä½“åƒ**:
1. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° (MNIST)
2. DiT ãƒ¢ãƒ‡ãƒ«å®šç¾© (Candle)
3. æ‹¡æ•£ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« (DDPM noise schedule)
4. æå¤±é–¢æ•° (MSE between predicted & true noise)
5. è¨“ç·´ãƒ«ãƒ¼ãƒ— (Adam optimizer)

**å®Œå…¨å®Ÿè£…**:
```rust
use ndarray::{Array4, s};
use ndarray_rand::{RandomExt, rand_distr::Normal};
use rand::Rng;

// 2. Diffusion Schedule (DDPM)
fn get_noise_schedule(t_steps: usize) -> (Vec<f32>, Vec<f32>, Vec<f32>) {
    let beta_start = 1e-4_f32;
    let beta_end = 0.02_f32;
    let beta: Vec<f32> = (0..t_steps)
        .map(|i| beta_start + (beta_end - beta_start) * i as f32 / (t_steps - 1) as f32)
        .collect();
    let alpha: Vec<f32> = beta.iter().map(|&b| 1.0 - b).collect();
    let mut alpha_bar = Vec::with_capacity(t_steps);
    let mut cum = 1.0_f32;
    for &a in &alpha {
        cum *= a;
        alpha_bar.push(cum);
    }
    (beta, alpha, alpha_bar)
}

// 3. Training Step
// x: [B, C, H, W], returns MSE loss
fn train_step<F>(
    model: &F,
    x: &Array4<f32>,
    alpha_bar: &[f32],
    t: usize,
    rng: &mut impl Rng,
) -> f32
where
    F: Fn(&Array4<f32>, usize) -> Array4<f32>,
{
    let eps = Array4::<f32>::random_using(x.raw_dim(), Normal::new(0.0_f32, 1.0).unwrap(), rng);

    // Forward diffusion: x_t = âˆšá¾±_tÂ·x + âˆš(1-á¾±_t)Â·Îµ
    let alpha_bar_t = alpha_bar[t];
    // shape: x âˆˆ â„^{BÃ—CÃ—HÃ—W}, Îµ âˆˆ â„^{BÃ—CÃ—HÃ—W}, alpha_bar_t âˆˆ â„ï¼ˆã‚¹ã‚«ãƒ©ãƒ¼ï¼‰
    // æ•°å€¤ç¢ºèª: alpha_bar_t=1(t=0)â†’x_t=xï¼ˆãƒã‚¤ã‚ºãªã—ï¼‰, alpha_bar_tâ‰ˆ0(t=T)â†’x_tâ‰ˆÎµï¼ˆå®Œå…¨ãƒã‚¤ã‚ºï¼‰
    // alpha_bar[500]â‰ˆ0.02 â†’ signal-to-noise ratio â‰ˆ sqrt(0.02/0.98) â‰ˆ 0.14ï¼ˆã»ã¼ãƒã‚¤ã‚ºï¼‰
    let x_t = x.mapv(|v| v * alpha_bar_t.sqrt())
        + eps.mapv(|e| e * (1.0 - alpha_bar_t).sqrt());

    // L_simple = E[||Îµ_Î¸(x_t,t) - Îµ||Â²]  (simple diffusion loss)
    let eps_pred = model(&x_t, t);
    (&eps_pred - &eps).mapv(|v| v * v).mean().unwrap()  // MSE(Îµ_pred, Îµ)
}

// 4. Training Loop
fn train_dit(epochs: usize, batch_size: usize) {
    let mut rng = rand::thread_rng();

    // Dummy MNIST data: [1000, 1, 28, 28]
    let x_train = Array4::<f32>::random_using(
        (1000, 1, 28, 28),
        Normal::new(0.0_f32, 1.0).unwrap(),
        &mut rng,
    );

    // Noise schedule
    let t_steps = 1000;
    let (_, _, alpha_bar) = get_noise_schedule(t_steps);

    // Placeholder model (replace with real candle_nn DiT)
    let model = |x: &Array4<f32>, _t: usize| x.clone();

    let num_batches = 1000 / batch_size;
    for epoch in 1..=epochs {
        let mut total_loss = 0.0_f32;
        for b in 0..num_batches {
            let start = b * batch_size;
            let batch = x_train.slice(s![start..start + batch_size, .., .., ..]).to_owned();
            let t = rng.gen_range(0..t_steps);
            let loss = train_step(&model, &batch, &alpha_bar, t, &mut rng);
            total_loss += loss;
        }
        println!("Epoch {epoch}: Loss = {}", total_loss / num_batches as f32);
    }
}

fn main() {
    train_dit(5, 64);
    println!("âœ… Mini-DiT trained on MNIST!");
}
```

**Rust ã®å¼·ã¿**:
- **Candle** â€” Pure functional NN library (JAX-like)
- **Zygote.jl** â€” Reverse mode AD (è‡ªå‹•å¾®åˆ†)
- **burn::data** â€” Data loading & batching
- **Burn** (æœªä½¿ç”¨ã ãŒé‡è¦) â€” GPU AOT compilation

> **âš ï¸ Warning:** Lux ã® `withgradient` ã§ãƒ¢ãƒ‡ãƒ«ã® `st`ï¼ˆstateï¼‰ã‚’è¿”ã™éš›ã€å­¦ç¿’ãƒ•ãƒ©ã‚°ãƒ»BNçµ±è¨ˆãªã©ãŒå«ã¾ã‚Œã‚‹ã€‚`st` ã‚’æ›´æ–°ã›ãšã«å†åˆ©ç”¨ã™ã‚‹ã¨ BatchNorm ã® running statistics ãŒè¨“ç·´ä¸­ã«å›ºå®šã•ã‚Œã¦ã—ã¾ã†ã€‚å¿…ãš `ps, st = burn::optim.update(...)` ã®å¾Œã«æ›´æ–°ã—ãŸ `st` ã‚’æ¬¡ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«æ¸¡ã™ã“ã¨ã€‚

### 4.2 ğŸ¦€ Rust: DiT æ¨è«–ã‚µãƒ¼ãƒãƒ¼

**æ¨è«–ã®å…¨ä½“åƒ**:
1. Candle ã§ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
2. DDPM sampling loop
3. ãƒãƒƒãƒå‡¦ç†
4. HTTP API (Axum)

**å®Œå…¨å®Ÿè£…**:
```rust
use candle_core::{Tensor, Device, DType};
use candle_nn::{Linear, VarBuilder, Module};
use anyhow::Result;

// DiT Block (simplified)
struct DiTBlock {
    attn: Linear,
    mlp: Linear,
}

impl DiTBlock {
    fn new(vb: VarBuilder, hidden_dim: usize) -> Result<Self> {
        let attn = Linear::new(vb.pp("attn").get((hidden_dim, hidden_dim))?, None);
        let mlp = Linear::new(vb.pp("mlp").get((4*hidden_dim, hidden_dim))?, None);
        Ok(Self { attn, mlp })
    }

    fn forward(&self, x: &Tensor) -> Result<Tensor> {
        let a = self.attn.forward(x)?;
        let x = (x + a)?;  // residual
        let m = self.mlp.forward(&x)?;
        x + m  // residual
    }
}

// DiT Model
struct DiT {
    blocks: Vec<DiTBlock>,
}

impl DiT {
    fn new(vb: VarBuilder, num_layers: usize, hidden_dim: usize) -> Result<Self> {
        let blocks = (0..num_layers)
            .map(|i| DiTBlock::new(vb.pp(&format!("block_{i}")), hidden_dim))
            .collect::<Result<Vec<_>>>()?;
        Ok(Self { blocks })
    }

    fn forward(&self, x: &Tensor) -> Result<Tensor> {
        self.blocks.iter().try_fold(x.clone(), |x, block| block.forward(&x))
    }
}

// DDPM Sampling
fn ddpm_sample(model: &DiT, schedule: &NoiseSchedule, shape: &[usize]) -> Result<Tensor> {
    let device = Device::Cpu;
    let mut x_t = Tensor::randn(0f32, 1.0, shape, &device)?;

    for t in (0..schedule.T).rev() {
        // Predict noise
        let epsilon_pred = model.forward(&x_t)?;

        // x_{t-1} = (x_t - Î²_t/âˆš(1-á¾±_t)Â·Îµ_Î¸) / âˆšÎ±_t + Ïƒ_tÂ·z  (DDPM reverse step)
        let alpha_t = schedule.alpha[t];
        let alpha_bar_t = schedule.alpha_bar[t];
        let beta_t = schedule.beta[t];

        // æ•°å¼ã®å„ä¿‚æ•°ã®æ„å‘³:
        // 1/sqrt(Î±_t): ãƒã‚¤ã‚ºã‚¹ã‚±ãƒ¼ãƒ«è£œæ­£
        // Î²_t/sqrt(1-á¾±_t): Îµ_Î¸ ã®å¯„ä¸ã‚’ Î±_t ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›

        let coeff1 = (1.0 / alpha_t.sqrt())?;
        let coeff2 = (beta_t / (1.0 - alpha_bar_t).sqrt())?;
        let mean = ((x_t - (epsilon_pred * coeff2)?)? * coeff1)?;

        let z = if t > 0 {
            Tensor::randn(0f32, 1.0, shape, &device)?
        } else {
            Tensor::zeros(shape, DType::F32, &device)?
        };

        let sigma_t = beta_t.sqrt()?;
        x_t = (mean + (z * sigma_t)?)?;
    }

    Ok(x_t)
}

// HTTP Server (Axum)
#[tokio::main]
async fn main() -> Result<()> {
    use axum::{routing::post, Router, Json};
    use serde::{Deserialize, Serialize};

    #[derive(Deserialize)]
    struct GenerateRequest {
        prompt: String,
        num_samples: usize,
    }

    #[derive(Serialize)]
    struct GenerateResponse {
        images: Vec<Vec<f32>>,
    }

    async fn generate(Json(req): Json<GenerateRequest>) -> Json<GenerateResponse> {
        // Load model (dummy)
        let vb = VarBuilder::zeros(DType::F32, &Device::Cpu);
        let model = DiT::new(vb, 12, 768).unwrap();
        let schedule = NoiseSchedule::new(1000);

        // Generate
        let images = (0..req.num_samples)
            .map(|_| {
                ddpm_sample(&model, &schedule, &[1, 28, 28])
                    .and_then(|img| img.to_vec1::<f32>())
                    .unwrap()
            })
            .collect::<Vec<_>>();

        Json(GenerateResponse { images })
    }

    let app = Router::new().route("/generate", post(generate));
    axum::Server::bind(&"0.0.0.0:3000".parse()?)
        .serve(app.into_make_service())
        .await?;

    Ok(())
}

struct NoiseSchedule {
    T: usize,
    beta: Vec<f32>,
    alpha: Vec<f32>,
    alpha_bar: Vec<f32>,
}

impl NoiseSchedule {
    fn new(T: usize) -> Self {
        let beta: Vec<f32> = (0..T)
            .map(|i| 1e-4 + (0.02 - 1e-4) * (i as f32 / T as f32))
            .collect();
        let alpha: Vec<f32> = beta.iter().map(|b| 1.0 - b).collect();
        let alpha_bar: Vec<f32> = alpha.iter()
            .scan(1.0f32, |acc, &a| { *acc *= a; Some(*acc) })
            .collect();
        Self { T, beta, alpha, alpha_bar }
    }
}
```

**Rust ã®å¼·ã¿**:
- **Candle** â€” HuggingFace ã® Rust ML framework
- **Axum** â€” é«˜é€Ÿ HTTP server (Tokio)
- **Zero-copy** â€” ãƒ¡ãƒ¢ãƒªåŠ¹ç‡
- **å‹å®‰å…¨æ€§** â€” ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã‚¨ãƒ©ãƒ¼æ¤œå‡º

> **âš ï¸ Warning:** `candle_core::Tensor` ã®æ¼”ç®—ã¯ `Result<Tensor>` ã‚’è¿”ã™ãŸã‚ã€å…¨æ¼”ç®—ã« `?` ãŒå¿…è¦ã€‚é•·ã„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ«ãƒ¼ãƒ—ã§ã¯ `?` ã‚¨ãƒ©ãƒ¼ãŒé€”ä¸­ã§ä¸­æ–­ã•ã‚Œã‚„ã™ã„ã€‚`unwrap_or_else` ã§ fallback ã‚’ç”¨æ„ã™ã‚‹ã‹ã€`anyhow::Result` ã§ä¸Šä½ã«ã‚¨ãƒ©ãƒ¼ä¼æ’­ã•ã›ã‚‹ã“ã¨ã€‚

### 4.3 ğŸ”® Elixir: åˆ†æ•£ã‚µãƒ¼ãƒ“ãƒ³ã‚°

**åˆ†æ•£ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã®å…¨ä½“åƒ**:
1. OTP Supervisor â€” è€éšœå®³æ€§
2. GenServer â€” ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚­ãƒ¥ãƒ¼
3. Load Balancing â€” GPUä¸¦åˆ—

**å®Œå…¨å®Ÿè£…**:
```elixir
defmodule DiT.Supervisor do
  use Supervisor

  def start_link(init_arg) do
    Supervisor.start_link(__MODULE__, init_arg, name: __MODULE__)
  end

  @impl true
  def init(_init_arg) do
    children = [
      {DiT.Worker, name: :worker_1, gpu_id: 0},
      {DiT.Worker, name: :worker_2, gpu_id: 1},
      {DiT.LoadBalancer, workers: [:worker_1, :worker_2]}
    ]

    Supervisor.init(children, strategy: :one_for_one)
  end
end

defmodule DiT.Worker do
  use GenServer

  def start_link(opts) do
    GenServer.start_link(__MODULE__, opts, name: opts[:name])
  end

  @impl true
  def init(opts) do
    gpu_id = opts[:gpu_id]
    # Initialize Rust NIF (Native Implemented Function)
    {:ok, model} = DiTNif.load_model(gpu_id)
    {:ok, %{model: model, gpu_id: gpu_id, queue: :queue.new()}}
  end

  @impl true
  def handle_call({:generate, prompt}, from, state) do
    # Add to queue
    queue = :queue.in({from, prompt}, state.queue)
    # Process immediately if queue was empty
    if :queue.len(state.queue) == 0 do
      process_next(state)
    else
      {:noreply, %{state | queue: queue}}
    end
  end

  defp process_next(state) do
    with {{:value, {from, prompt}}, queue} <- :queue.out(state.queue),
         {:ok, image} <- DiTNif.generate(state.model, prompt) do
      GenServer.reply(from, {:ok, image})
      {:noreply, %{state | queue: queue}}
    else
      {:empty, _} -> {:noreply, state}
    end
  end
end

defmodule DiT.LoadBalancer do
  use GenServer

  def start_link(opts) do
    GenServer.start_link(__MODULE__, opts, name: __MODULE__)
  end

  @impl true
  def init(opts) do
    workers = opts[:workers]
    {:ok, %{workers: workers, idx: 0}}
  end

  def generate(prompt) do
    GenServer.call(__MODULE__, {:generate, prompt})
  end

  @impl true
  def handle_call({:generate, prompt}, _from, state) do
    # Round-robin load balancing
    worker = state.workers |> Enum.at(state.idx)
    idx = rem(state.idx + 1, length(state.workers))

    result = GenServer.call(worker, {:generate, prompt}, :infinity)
    {:reply, result, %{state | idx: idx}}
  end
end

# Rust NIF (Native Implemented Function) interface
defmodule DiTNif do
  use Rustler, otp_app: :dit, crate: "dit_nif"

  def load_model(_gpu_id), do: :erlang.nif_error(:nif_not_loaded)
  def generate(_model, _prompt), do: :erlang.nif_error(:nif_not_loaded)
end
```

**Elixir ã®å¼·ã¿**:
- **OTP Supervision** â€” ãƒ—ãƒ­ã‚»ã‚¹ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ™‚ã®è‡ªå‹•å†èµ·å‹•
- **GenServer** â€” ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°
- **Rustler** â€” Rust FFI (ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ¨è«–)
- **åˆ†æ•£** â€” BEAM VM ã®è€éšœå®³æ€§

**DiT ã« Elixir ã‚’ä½¿ã†å®Ÿéš›ã®ãƒ¡ãƒªãƒƒãƒˆ**: GPU ã‚µãƒ¼ãƒãƒ¼ãŒ1å°ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ã¦ã‚‚ Supervisor ãŒå³åº§ã«å†èµ·å‹•ã—ã€ä»–ãƒãƒ¼ãƒ‰ã¸è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã€‚Python/Rust ã ã‘ã§ã“ã‚Œã‚’å®Ÿè£…ã™ã‚‹ã¨æ•°ç™¾è¡Œã®æ­»æ´»ç›£è¦–ã‚³ãƒ¼ãƒ‰ãŒå¿…è¦ã ãŒã€OTP ã§ã¯ `strategy: :one_for_one` ã®1è¡Œã§æ¸ˆã‚€ã€‚å¤§è¦æ¨¡æ¨è«–ã‚µãƒ¼ãƒ“ã‚¹ã§è¦‹é€ƒã•ã‚ŒãŒã¡ãªä¿¡é ¼æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‚

### 4.4 é«˜é€ŸSampling â€” DPM-Solver++ & EDM

**DPM-Solver++** [Lu+ 2022] [^9] (ç¬¬36å›ã®æ‹¡å¼µ):
- **åŠç·šå½¢ODEã‚½ãƒ«ãƒãƒ¼** â€” 1000 ã‚¹ãƒ†ãƒƒãƒ— â†’ 20 ã‚¹ãƒ†ãƒƒãƒ—
- **é«˜æ¬¡ç²¾åº¦** â€” Runge-Kutta æ³•ã®æ”¹è‰¯

**æ•°å¼** (2æ¬¡ DPM-Solver++):
$$
\mathbf{x}_{t_{i-1}} = \frac{\alpha_{t_{i-1}}}{\alpha_{t_i}} \mathbf{x}_{t_i} - \sigma_{t_{i-1}} \left( e^{-h_i} - 1 \right) \left( \epsilon_\theta^{(1)} + \frac{1}{2r_i} (\epsilon_\theta^{(1)} - \epsilon_\theta^{(2)}) \right)
$$
- $h_i = \lambda_{t_{i-1}} - \lambda_{t_i}$ â€” log-SNR step
- $\epsilon_\theta^{(1)}, \epsilon_\theta^{(2)}$ â€” 2æ®µéšã®ãƒã‚¤ã‚ºäºˆæ¸¬

> **âš ï¸ Warning:** DPM-Solver++ ã¯ log-SNRç©ºé–“ $\lambda_t = \log(\alpha_t / \sigma_t)$ ã§ç­‰é–“éš”ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒå‰æã€‚DDPM ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ç·šå½¢ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã¯ log-SNR ãŒéç·šå½¢ â†’ 20ã‚¹ãƒ†ãƒƒãƒ—ç¨‹åº¦ã§è‰¯ã„çµæœãŒå‡ºãªã„ã“ã¨ãŒã‚ã‚‹ã€‚`timesteps` ã®é¸æŠãŒé‡è¦ã€‚

**å®Ÿè£…**:
```rust
// DPM-Solver++ (2nd order)
fn dpm_solver_pp<F>(
    model: F,
    x_t_init: Vec<f32>,
    alpha_bar: &[f32],
    num_steps: usize,
) -> Vec<f32>
where
    F: Fn(&[f32], usize) -> Vec<f32>,
{
    let t_total = alpha_bar.len();
    // Timesteps from T-1 down to 0, evenly spaced
    let timesteps: Vec<usize> = (0..num_steps)
        .map(|i| {
            let frac = i as f32 / (num_steps - 1) as f32;
            ((t_total - 1) as f32 * (1.0 - frac)).round() as usize
        })
        .collect();

    let mut x_t = x_t_init;
    for i in 0..timesteps.len() - 1 {
        let t_i   = timesteps[i];
        let t_im1 = timesteps[i + 1];

        // 1st-order prediction
        let eps_1   = model(&x_t, t_i);
        let alpha_t   = alpha_bar[t_i].sqrt();
        let alpha_tm1 = alpha_bar[t_im1].sqrt();
        let sigma_t   = (1.0 - alpha_bar[t_i]).sqrt();
        let sigma_tm1 = (1.0 - alpha_bar[t_im1]).sqrt();

        let lambda_t   = (alpha_t / sigma_t).ln();   // Î»(t) = log(Î±_t/Ïƒ_t)  (log-SNR)
        let lambda_tm1 = (alpha_tm1 / sigma_tm1).ln();
        let h = lambda_tm1 - lambda_t;               // h = Î»_{t-1} - Î»_t  (step size in log-SNR space)

        // 1st order: xÌ‚_{t-1} = (Î±_{t-1}/Î±_t)Â·x_t - Ïƒ_{t-1}Â·(e^{-h}-1)Â·Îµâ‚
        let x_tm1_1st: Vec<f32> = x_t.iter().zip(&eps_1)
            .map(|(&x, &e)| (alpha_tm1 / alpha_t) * x - sigma_tm1 * ((-h).exp() - 1.0) * e)
            .collect();

        // 2nd-order correction
        let eps_2 = model(&x_tm1_1st, t_im1);
        let r = if i > 0 {
            (t_im1 as f32 - t_i as f32) / (t_i as f32 - timesteps[i - 1] as f32)
        } else {
            (t_im1 as f32 - t_i as f32) / (t_i as f32 - t_total as f32)
        };
        // 2nd order: x_{t-1} = (Î±_{t-1}/Î±_t)Â·x_t - Ïƒ_{t-1}Â·(e^{-h}-1)Â·[Îµâ‚ + 0.5/rÂ·(Îµâ‚-Îµâ‚‚)]
        x_t = x_t.iter().zip(&eps_1).zip(&eps_2)
            .map(|((&x, &e1), &e2)| {
                (alpha_tm1 / alpha_t) * x
                    - sigma_tm1 * ((-h).exp() - 1.0) * (e1 + 0.5 / r * (e1 - e2))
            })
            .collect();
    }

    x_t
}
```

**EDM** [Karras+ 2022] [^10] (ç¬¬37å›ã®æ‹¡å¼µ):
- **æœ€é©ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«** â€” Ïƒ(t) ã®è¨­è¨ˆ
- **Deterministic/Stochastic çµ±åˆ** â€” Heun's method

**æ•°å¼**:
$$
\frac{d\mathbf{x}}{dt} = \frac{\mathbf{x} - D_\theta(\mathbf{x}, \sigma(t))}{\sigma(t)}
$$
- $D_\theta$ â€” Denoiser (EDM ã®è¡¨è¨˜)
- $\sigma(t) = t$ â€” æ™‚é–“ = ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«

**Heunè£œæ­£ã®æ„ç¾©**: 1æ¬¡ Euler ã‚¹ãƒ†ãƒƒãƒ—ã¯åˆ‡æ–­èª¤å·® $O(\Delta t^2)$ã€Heunï¼ˆäºˆæ¸¬å­-ä¿®æ­£å­ï¼‰ã¯ $O(\Delta t^3)$ â†’ åŒã˜ NFE æ•°ã§é«˜ç²¾åº¦ã€‚`d_i + d_im1` ã®å¹³å‡å‹¾é…ãŒè£œæ­£ã®æœ¬è³ªã€‚

**å®Ÿè£…**:
```rust
// EDM Sampling (Heun's method)
fn edm_sample<F>(model: F, n: usize, num_steps: usize) -> Vec<f32>
where
    F: Fn(&[f32], f32) -> Vec<f32>,
{
    let sigma_min: f32 = 0.002;
    let sigma_max: f32 = 80.0;
    let rho: f32 = 7.0;

    // Noise schedule
    let sigma_steps: Vec<f32> = (0..num_steps)
        .map(|i| {
            let frac = i as f32 / (num_steps - 1) as f32;
            let s = sigma_max.powf(1.0 / rho)
                + frac * (sigma_min.powf(1.0 / rho) - sigma_max.powf(1.0 / rho));
            s.powf(rho)
        })
        .collect();

    let mut rng = rand::thread_rng();
    let dist = Normal::new(0.0_f32, 1.0).unwrap();
    let mut x_t: Vec<f32> = (0..n)
        .map(|_| rand::Rng::sample(&mut rng, dist) * sigma_max)
        .collect();

    for i in 0..sigma_steps.len() - 1 {
        let sigma_i   = sigma_steps[i];
        let sigma_im1 = sigma_steps[i + 1];

        // Denoiser prediction
        let d_i_pred = model(&x_t, sigma_i);

        // d_i = (x_t - D_Î¸(x_t,Ïƒ_i)) / Ïƒ_i  (denoising direction, cf. EDM eq.5)
        let d_i: Vec<f32> = x_t.iter().zip(&d_i_pred)
            .map(|(&x, &d)| (x - d) / sigma_i)
            .collect();
        // x_euler = x_t + (Ïƒ_{i+1}-Ïƒ_i)Â·d_i  (Euler predictor step)
        let x_euler: Vec<f32> = x_t.iter().zip(&d_i)
            .map(|(&x, &di)| x + (sigma_im1 - sigma_i) * di)
            .collect();

        // Heun's 2nd-order correction
        if sigma_im1 > 0.0 {
            let d_im1_pred = model(&x_euler, sigma_im1);
            let d_im1: Vec<f32> = x_euler.iter().zip(&d_im1_pred)
                .map(|(&x, &d)| (x - d) / sigma_im1)
                .collect();
            // x_{i+1} = x_t + (Ïƒ_{i+1}-Ïƒ_i)Â·(d_i+d_{i+1})/2  (Heun 2nd-order)
            x_t = x_t.iter().zip(&d_i).zip(&d_im1)
                .map(|((&x, &di), &dim1)| x + (sigma_im1 - sigma_i) * (di + dim1) / 2.0)
                .collect();
        } else {
            x_t = x_euler;
        }
    }

    x_t
}
```

**DPM-Solver++ vs EDM**:
- **DPM-Solver++**: DDPM ã®ç›´æ¥é«˜é€ŸåŒ– (log-SNR ç©ºé–“ã§ã® solver)
- **EDM**: SDE ã®æœ€é©åŒ– (Heun's method + Ïƒ(t) è¨­è¨ˆ)
- **é€Ÿåº¦**: ä¸¡æ–¹ã¨ã‚‚ 20 ã‚¹ãƒ†ãƒƒãƒ—ã§ DDPM 1000 ã‚¹ãƒ†ãƒƒãƒ—ç›¸å½“

**æ¯”è¼ƒã®è¦ç‚¹**: DPM-Solver++ ã¯æ—¢å­˜ã® DDPM è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«ãã®ã¾ã¾é©ç”¨ã§ãã‚‹ï¼ˆscheduler ã®å·®ã—æ›¿ãˆã®ã¿ï¼‰ã€‚EDM ã¯å°‚ç”¨è¨“ç·´ãŒå¿…è¦ã ãŒã€åŒã˜ NFE ã§é«˜å“è³ªã€‚ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³åˆ©ç”¨ã§ã¯ DPM-Solver++ï¼ˆç§»è¡Œã‚³ã‚¹ãƒˆä½ï¼‰ã€æ–°è¦è¨“ç·´ãªã‚‰ EDM ãŒæ¨å¥¨ã€‚

> **Note:** **ã“ã“ã¾ã§ã§å…¨ä½“ã®70%å®Œäº†ï¼** å®Ÿè£…ã‚¾ãƒ¼ãƒ³å®Œèµ°ã€‚ğŸ¦€Rust è¨“ç·´ + ğŸ¦€Rust æ¨è«– + ğŸ”®Elixir åˆ†æ•£ã‚µãƒ¼ãƒ“ãƒ³ã‚° + é«˜é€ŸSampling ã‚’å…¨ã¦å®Ÿè£…ã—ãŸã€‚æ¬¡ã¯å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ â€” aMUSEd-256 ãƒ‡ãƒ¢ã¨ Tiny DiT æ¼”ç¿’ã€‚

---

### ğŸ”¬ å®Ÿé¨“ãƒ»æ¤œè¨¼ï¼ˆ30åˆ†ï¼‰â€” aMUSEd-256 & Tiny DiT

**ã‚´ãƒ¼ãƒ«**: aMUSEd-256 ã§ 12 ã‚¹ãƒ†ãƒƒãƒ—é«˜é€Ÿç”»åƒç”Ÿæˆã‚’ä½“é¨“ã—ã€Tiny DiT on MNIST ã§ç†è«–ã‚’å®Ÿè£…ã«è½ã¨ã™ã€‚

### 5.1 aMUSEd-256 æ¨è«–ãƒ‡ãƒ¢ â€” 12ã‚¹ãƒ†ãƒƒãƒ—é«˜é€Ÿç”»åƒç”Ÿæˆ

**aMUSEd** [Patel+ 2024] [^11] ã¯ HuggingFace ãŒé–‹ç™ºã—ãŸ **Masked Image Model (MIM)** â€” Diffusion ã§ã¯ãªãã€é›¢æ•£çš„ãªãƒã‚¹ã‚¯äºˆæ¸¬ã§ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ã€‚

**aMUSEd ã®ç‰¹å¾´**:
- **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: U-ViT (U-Net + Vision Transformer)
- **è¨“ç·´æ–¹å¼**: Masked token prediction (BERT-like)
- **Sampling**: 12 ã‚¹ãƒ†ãƒƒãƒ— (DDPM ã® 1000 ã‚¹ãƒ†ãƒƒãƒ— vs 83å€é«˜é€Ÿ)
- **ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º**: aMUSEd-256 (âˆ¼250M params) â€” ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œå¯èƒ½

**Diffusion vs MIM**:
| é …ç›® | Diffusion (DDPM) | MIM (aMUSEd) |
|:-----|:-----------------|:-------------|
| æ½œåœ¨ç©ºé–“ | é€£ç¶š (ã‚¬ã‚¦ã‚¹ãƒã‚¤ã‚º) | é›¢æ•£ (VQ-VAE ãƒˆãƒ¼ã‚¯ãƒ³) |
| è¨“ç·´ç›®æ¨™ | MSE(Îµ_pred, Îµ_true) | CrossEntropy(token_pred, token_true) |
| Sampling | 1000 ã‚¹ãƒ†ãƒƒãƒ— (iterative denoising) | 12 ã‚¹ãƒ†ãƒƒãƒ— (iterative unmasking) |
| é€Ÿåº¦ | é…ã„ | é€Ÿã„ (é›¢æ•£çš„ãªã®ã§é«˜é€Ÿ) |
| å“è³ª | é«˜ã„ (SD1.5 ãƒ¬ãƒ™ãƒ«) | ä¸­ç¨‹åº¦ (ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—å“è³ª) |

**aMUSEd ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°éç¨‹**:
1. å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒã‚¹ã‚¯ `[MASK]` ã§åˆæœŸåŒ–
2. å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã€Œæœ€ã‚‚ç¢ºä¿¡åº¦ã®ä½ã„ãƒˆãƒ¼ã‚¯ãƒ³ã€ã‚’äºˆæ¸¬
3. äºˆæ¸¬ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³ã§ãƒã‚¹ã‚¯ã‚’ç½®æ›
4. 12 ã‚¹ãƒ†ãƒƒãƒ—å¾Œã€å…¨ãƒˆãƒ¼ã‚¯ãƒ³ãŒäºˆæ¸¬æ¸ˆã¿ â†’ ç”»åƒç”Ÿæˆå®Œäº†

**Rust ç‰ˆ (PythonCall.jl çµŒç”±)**:
```rust
use pyo3::prelude::*;
use pyo3::types::PyDict;

fn amused_inference() -> PyResult<()> {
    Python::with_gil(|py| {
        // Import Diffusers
        let diffusers = py.import("diffusers")?;
        let torch = py.import("torch")?;

        // Load pipeline
        let kwargs = PyDict::new(py);
        kwargs.set_item("torch_dtype", torch.getattr("float16")?)?;
        let pipe = diffusers
            .getattr("AmusedPipeline")?
            .call_method("from_pretrained", ("amused/amused-256",), Some(kwargs))?;
        pipe.call_method1("to", ("cuda",))?;

        // Generate
        let prompt = "a photo of a cat wearing sunglasses";
        let gen_kwargs = PyDict::new(py);
        gen_kwargs.set_item("num_inference_steps", 12)?;
        gen_kwargs.set_item(
            "generator",
            torch.call_method1("manual_seed", (42_i64,))?,
        )?;
        let result = pipe.call((prompt,), Some(gen_kwargs))?;
        let image = result.getattr("images")?.get_item(0)?;

        // Save
        image.call_method1("save", ("amused_cat_rust.png",))?;
        println!("âœ… aMUSEd-256 inference complete (Rust + PyO3)");
        Ok(())
    })
}

fn main() {
    amused_inference().expect("Python inference failed");
}
```

**aMUSEd vs DiT ã®æ¯”è¼ƒ**:
- **aMUSEd**: é›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³ç©ºé–“ (VQ-VAE) â€” BERT ã® Masked Language Modeling ã‚’ç”»åƒã«é©ç”¨
- **DiT**: é€£ç¶šãƒã‚¤ã‚ºç©ºé–“ (DDPM) â€” Transformer ã§ denoising

**ã©ã¡ã‚‰ãŒå„ªã‚Œã¦ã„ã‚‹ï¼Ÿ**
- **é€Ÿåº¦**: aMUSEd (12 steps) > DiT (50-100 steps with DPM-Solver++)
- **å“è³ª**: DiT (SD3/FLUX) > aMUSEd (ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒ¬ãƒ™ãƒ«)
- **ç”¨é€”**: aMUSEd = ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”Ÿæˆ / DiT = é«˜å“è³ªç”Ÿæˆ

### 5.2 Tiny DiT on MNIST â€” CPU 5åˆ†ã§å®Œèµ°

**Goal**: MNIST ã§ DiT ã‚’è¨“ç·´ã—ã€æ‰‹æ›¸ãæ•°å­—ã‚’ç”Ÿæˆã™ã‚‹ã€‚

**ä»•æ§˜**:
- ãƒ¢ãƒ‡ãƒ«: DiT-Tiny (4 layers, 128 hidden dim, 4 heads)
- ãƒ‡ãƒ¼ã‚¿: MNIST 28Ã—28 grayscale
- Patch size: 4Ã—4 (49 patches)
- è¨“ç·´æ™‚é–“: CPU ã§ 5 åˆ† (1 epoch)
- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: âˆ¼800K

**å®Œå…¨å®Ÿè£…**:
```rust
use ndarray::{Array1, Array2, Array3, Array4, Axis, s};
use ndarray_rand::{RandomExt, rand_distr::{Normal, Uniform}};
use rand::Rng;

// 1. Data Loading (dummy normalized MNIST)
fn load_mnist_dummy(n_samples: usize) -> Array4<f32> {
    // Normalized to [-1, 1] as: (x - 0.5) / 0.5
    let raw = Array4::<f32>::random((n_samples, 1, 28, 28), Normal::new(0.5_f32, 0.5).unwrap());
    raw.mapv(|v| (v - 0.5) / 0.5)
}

// 2. DiT-Tiny Model
struct DiTBlock {
    w_attn: Array2<f32>,
    w_mlp1: Array2<f32>,
    w_mlp2: Array2<f32>,
    ln1_gamma: Array1<f32>,
    ln2_gamma: Array1<f32>,
}

impl DiTBlock {
    fn new(dim: usize) -> Self {
        let scale = (1.0 / dim as f32).sqrt();
        DiTBlock {
            w_attn: Array2::random((dim, dim), Normal::new(0.0_f32, scale).unwrap()),
            w_mlp1: Array2::random((4 * dim, dim), Normal::new(0.0_f32, scale).unwrap()),
            w_mlp2: Array2::random((dim, 4 * dim), Normal::new(0.0_f32, scale).unwrap()),
            ln1_gamma: Array1::ones(dim),
            ln2_gamma: Array1::ones(dim),
        }
    }

    fn layer_norm(x: &Array2<f32>, gamma: &Array1<f32>) -> Array2<f32> {
        let mean = x.mean_axis(Axis(1)).unwrap().insert_axis(Axis(1));
        let var = x.mapv(|v| v * v).mean_axis(Axis(1)).unwrap().insert_axis(Axis(1))
            - mean.mapv(|v| v * v);
        let std = var.mapv(|v| (v + 1e-5).sqrt());
        (x - &mean) / &std * gamma
    }

    fn gelu(x: f32) -> f32 {
        0.5 * x * (1.0 + (x * std::f32::consts::FRAC_1_SQRT_2).tanh())
    }

    fn forward(&self, x: &Array2<f32>) -> Array2<f32> {
        // Self-attention residual (simplified as linear projection)
        let x_ln1 = Self::layer_norm(x, &self.ln1_gamma);
        let attn_out = x_ln1.dot(&self.w_attn.t());
        let x = x + &attn_out;

        // MLP residual
        let x_ln2 = Self::layer_norm(&x, &self.ln2_gamma);
        let h = x_ln2.dot(&self.w_mlp1.t()).mapv(Self::gelu);
        let mlp_out = h.dot(&self.w_mlp2.t());
        x + mlp_out
    }
}

struct DiTTiny {
    patch_size: usize,
    patchify_w: Array2<f32>,    // [dim, patch_dim]
    unpatchify_w: Array2<f32>,  // [patch_dim, dim]
    pos_emb: Array2<f32>,       // [num_patches, dim]
    blocks: Vec<DiTBlock>,
}

impl DiTTiny {
    fn new(patch_size: usize, dim: usize, depth: usize) -> Self {
        let num_patches = (28 / patch_size) * (28 / patch_size);
        let patch_dim = patch_size * patch_size;
        let scale = 0.02_f32;
        DiTTiny {
            patch_size,
            patchify_w: Array2::random((dim, patch_dim), Normal::new(0.0_f32, scale).unwrap()),
            unpatchify_w: Array2::random((patch_dim, dim), Normal::new(0.0_f32, scale).unwrap()),
            pos_emb: Array2::random((num_patches, dim), Normal::new(0.0_f32, scale).unwrap()),
            blocks: (0..depth).map(|_| DiTBlock::new(dim)).collect(),
        }
    }

    fn forward(&self, x: &Array4<f32>, _t: usize) -> Array4<f32> {
        let (b, c, h, w) = (x.shape()[0], x.shape()[1], x.shape()[2], x.shape()[3]);
        let patches = patchify(x, self.patch_size); // [B, N, patch_dim]
        let n = patches.shape()[1];
        let dim = self.patchify_w.shape()[0];

        // Patchify embedding + positional encoding: [B, N, dim]
        let mut z = Array3::<f32>::zeros((b, n, dim));
        for bi in 0..b {
            let p = patches.slice(s![bi, .., ..]).to_owned();
            let emb = p.dot(&self.patchify_w.t()) + &self.pos_emb;
            z.slice_mut(s![bi, .., ..]).assign(&emb);
        }

        // Apply DiT blocks
        for bi in 0..b {
            let mut zb = z.slice(s![bi, .., ..]).to_owned();
            for block in &self.blocks {
                zb = block.forward(&zb);
            }
            z.slice_mut(s![bi, .., ..]).assign(&zb);
        }

        // Unpatchify projection: [B, N, patch_dim]
        let patch_dim = self.patch_size * self.patch_size * c;
        let mut out_patches = Array3::<f32>::zeros((b, n, patch_dim));
        for bi in 0..b {
            let zb = z.slice(s![bi, .., ..]).to_owned();
            let p = zb.dot(&self.unpatchify_w.t());
            out_patches.slice_mut(s![bi, .., ..]).assign(&p);
        }

        unpatchify(&out_patches, self.patch_size, b, c, h, w)
    }
}

// 3. Patchify / Unpatchify
// x: [B, C, H, W] â†’ patches: [B, num_patches, patch_dim]
fn patchify(x: &Array4<f32>, p: usize) -> Array3<f32> {
    let (b, c, h, w) = (x.shape()[0], x.shape()[1], x.shape()[2], x.shape()[3]);
    let n_h = h / p;
    let n_w = w / p;
    let patch_dim = p * p * c;
    let mut out = Array3::<f32>::zeros((b, n_h * n_w, patch_dim));
    for bi in 0..b {
        for ph in 0..n_h {
            for pw in 0..n_w {
                let patch_idx = ph * n_w + pw;
                let mut d = 0;
                for ci in 0..c {
                    for pi in 0..p {
                        for pj in 0..p {
                            out[[bi, patch_idx, d]] = x[[bi, ci, ph * p + pi, pw * p + pj]];
                            d += 1;
                        }
                    }
                }
            }
        }
    }
    out
}

// patches: [B, num_patches, patch_dim] â†’ [B, C, H, W]
fn unpatchify(patches: &Array3<f32>, p: usize, b: usize, c: usize, h: usize, w: usize) -> Array4<f32> {
    let n_h = h / p;
    let n_w = w / p;
    let mut out = Array4::<f32>::zeros((b, c, h, w));
    for bi in 0..b {
        for ph in 0..n_h {
            for pw in 0..n_w {
                let patch_idx = ph * n_w + pw;
                let mut d = 0;
                for ci in 0..c {
                    for pi in 0..p {
                        for pj in 0..p {
                            out[[bi, ci, ph * p + pi, pw * p + pj]] = patches[[bi, patch_idx, d]];
                            d += 1;
                        }
                    }
                }
            }
        }
    }
    out
}

// 4. Training
fn train_dit_mnist(epochs: usize, batch_size: usize, _lr: f32) -> DiTTiny {
    let mut rng = rand::thread_rng();
    let n_samples = 10_000_usize;
    let train_x = load_mnist_dummy(n_samples);
    let mut model = DiTTiny::new(4, 128, 4);

    let t_steps = 1000_usize;
    let beta: Vec<f32> = (0..t_steps)
        .map(|i| 1e-4_f32 + (0.02 - 1e-4) * i as f32 / (t_steps - 1) as f32)
        .collect();
    let alpha: Vec<f32> = beta.iter().map(|&b| 1.0 - b).collect();
    let mut alpha_bar = Vec::with_capacity(t_steps);
    let mut cum = 1.0_f32;
    for &a in &alpha {
        cum *= a;
        alpha_bar.push(cum);
    }

    for epoch in 1..=epochs {
        let mut total_loss = 0.0_f32;
        let mut num_batches = 0_usize;
        let mut i = 0;
        while i + batch_size <= n_samples {
            let batch = train_x.slice(s![i..i + batch_size, .., .., ..]).to_owned();
            let t = rng.gen_range(0..t_steps);
            let ab_t = alpha_bar[t];
            let eps = Array4::<f32>::random_using(
                batch.raw_dim(),
                Normal::new(0.0_f32, 1.0).unwrap(),
                &mut rng,
            );
            // x_t = âˆšá¾±_tÂ·xâ‚€ + âˆš(1-á¾±_t)Â·Îµ  (forward diffusion)
            let x_t = batch.mapv(|v| v * ab_t.sqrt())
                + eps.mapv(|e| e * (1.0 - ab_t).sqrt());

            let eps_pred = model.forward(&x_t, t);
            // L_simple = E[||Îµ_Î¸(x_t,t) - Îµ||Â²]
            let loss = (&eps_pred - &eps).mapv(|v| v * v).mean().unwrap();
            // Simplified update placeholder (replace with AdamW + autograd)
            total_loss += loss;
            num_batches += 1;
            i += batch_size;
        }
        println!("Epoch {epoch}: Loss = {}", total_loss / num_batches as f32);
    }
    model
}

// 5. Sampling
fn sample_dit(
    model: &DiTTiny,
    alpha: &[f32],
    alpha_bar: &[f32],
    beta: &[f32],
    num_samples: usize,
) -> Array4<f32> {
    let mut rng = rand::thread_rng();
    let t_steps = alpha_bar.len();
    let mut x_t = Array4::<f32>::random_using(
        (num_samples, 1, 28, 28),
        Normal::new(0.0_f32, 1.0).unwrap(),
        &mut rng,
    );

    for t in (1..=t_steps).rev() {
        let eps_pred = model.forward(&x_t, t);
        let alpha_t     = alpha[t - 1];
        let alpha_bar_t = alpha_bar[t - 1];
        let beta_t      = beta[t - 1];
        let z = if t > 1 {
            Array4::<f32>::random_using(
                x_t.raw_dim(),
                Normal::new(0.0_f32, 1.0).unwrap(),
                &mut rng,
            )
        } else {
            Array4::<f32>::zeros(x_t.raw_dim())
        };
        // x_{t-1} = (x_t - Î²_t/âˆš(1-á¾±_t)Â·Îµ_Î¸)/âˆšÎ±_t + âˆšÎ²_tÂ·z  (DDPM reverse step)
        x_t = (x_t - eps_pred.mapv(|e| e * beta_t / (1.0 - alpha_bar_t).sqrt()))
            .mapv(|v| v / alpha_t.sqrt())
            + z.mapv(|z| z * beta_t.sqrt());
    }
    x_t
}

fn main() {
    println!("Training Tiny DiT on MNIST...");
    let model = train_dit_mnist(1, 128, 1e-4);

    let t_steps = 1000_usize;
    let beta: Vec<f32> = (0..t_steps)
        .map(|i| 1e-4_f32 + (0.02 - 1e-4) * i as f32 / (t_steps - 1) as f32)
        .collect();
    let alpha: Vec<f32> = beta.iter().map(|&b| 1.0 - b).collect();
    let mut alpha_bar = Vec::with_capacity(t_steps);
    let mut cum = 1.0_f32;
    for &a in &alpha { cum *= a; alpha_bar.push(cum); }

    let _samples = sample_dit(&model, &alpha, &alpha_bar, &beta, 16);
    println!("âœ… Tiny DiT trained and sampled!");
}
```

**è¨“ç·´çµæœ** (äºˆæƒ³):
- Epoch 1: Loss = 0.15-0.25
- Epoch 5: Loss = 0.05-0.10
- ç”Ÿæˆå“è³ª: MNIST æ•°å­—ã® rough shape ãŒç”Ÿæˆã•ã‚Œã‚‹ (5 epoch ã§ recognizable)

**æå¤±ã®èª­ã¿æ–¹**: MSE loss = $\mathbb{E}[\|\epsilon_\text{pred} - \epsilon\|^2]$ã€‚ãƒ©ãƒ³ãƒ€ãƒ äºˆæ¸¬ã®æœŸå¾…å€¤ã¯ $\mathbb{E}[\|\epsilon\|^2] = D = 28 \times 28 = 784$ï¼ˆå…¥åŠ›æ¬¡å…ƒï¼‰ã€‚Loss=0.2 ã¯æ¬¡å…ƒã‚ãŸã‚Š $0.2/784 \approx 2.5 \times 10^{-4}$ ã®èª¤å·® â†’ æœ‰æ„ãªå­¦ç¿’ãŒèµ·ãã¦ã„ã‚‹ã€‚Loss ãŒ 1.0 ä»¥ä¸Šãªã‚‰å­¦ç¿’ãŒç™ºæ•£ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚

**æ¼”ç¿’èª²é¡Œ**:
1. **Patch size ã‚’å¤‰ãˆã‚‹**: 4Ã—4 â†’ 7Ã—7 (patchæ•° 16 â†’ 4) â€” ã©ã†å¤‰ã‚ã‚‹ï¼Ÿ
2. **Depth ã‚’å¢—ã‚„ã™**: 4 layers â†’ 8 layers â€” æ€§èƒ½å‘ä¸Šï¼Ÿ
3. **AdaLN-Zero ã‚’è¿½åŠ **: Class-conditional DiT (æ•°å­—ãƒ©ãƒ™ãƒ«ã§æ¡ä»¶ä»˜ã‘)

#### 5.2.3 aMUSEd vs DiT ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¯”è¼ƒ

**æ¯”è¼ƒå®Ÿé¨“**: MNIST ã§ aMUSEd-style MIM ã¨ DiT-style Diffusion ã‚’æ¯”è¼ƒ

**aMUSEd-style MIM å®Ÿè£…**:
```rust
// Masked Image Modeling (simplified)
fn train_mim_mnist(epochs: usize) -> DiTTiny {
    let mut rng = rand::thread_rng();
    let train_x = load_mnist_dummy(10_000);

    // Quantize images to 16 levels (discrete tokens): [0, 15]
    let train_x_quantized: Array4<i32> = train_x.mapv(|v| ((v + 1.0) * 7.5).round() as i32);

    let mut model = DiTTiny::new(4, 128, 4);
    let batch_size = 128_usize;

    for epoch in 1..=epochs {
        let mut total_loss = 0.0_f32;
        let mut num_batches = 0_usize;
        let mut i = 0;

        while i + batch_size <= train_x.shape()[0] {
            let batch_int = train_x_quantized.slice(s![i..i + batch_size, .., .., ..]).to_owned();
            let batch: Array4<f32> = batch_int.mapv(|v| v as f32);

            // Randomly mask 50% of patches
            let mask: Array4<f32> = Array4::<f32>::random_using(
                batch.raw_dim(),
                Uniform::new(0.0_f32, 1.0),
                &mut rng,
            ).mapv(|v| if v < 0.5 { 1.0 } else { 0.0 });
            let batch_masked = &batch * &mask;

            // Predict masked tokens (no timestep â†’ pass 0)
            let pred = model.forward(&batch_masked, 0);
            // Simplified MSE reconstruction loss
            let loss = (&pred - &batch).mapv(|v| v * v).mean().unwrap();

            total_loss += loss;
            num_batches += 1;
            i += batch_size;
        }

        println!("Epoch {epoch}: MIM Loss = {}", total_loss / num_batches as f32);
    }

    model
}
```

**æ¯”è¼ƒçµæœ** (äºˆæƒ³):
| ãƒ¢ãƒ‡ãƒ« | è¨“ç·´æ™‚é–“ (1 epoch) | Sampling æ™‚é–“ (16 samples) | å“è³ª (ä¸»è¦³) |
|:-------|:-------------------|:---------------------------|:-----------|
| DiT (DDPM) | 5 min | 2 min (1000 steps) | High |
| MIM (aMUSEd-style) | 5 min | 10 sec (12 steps) | Medium |

> **âš ï¸ Warning:** aMUSEd-style MIM ã‚’ MNIST ã«é©ç”¨ã™ã‚‹å ´åˆã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ï¼ˆé‡å­åŒ–ï¼‰ãŒå“è³ªã«ç›´çµã™ã‚‹ã€‚`round.(Int, (x .+ 1) .* 7.5)` ã§ 16 ãƒ¬ãƒ™ãƒ«ã«é‡å­åŒ–ã™ã‚‹ã¨æƒ…å ±æå¤±ãŒå¤§ãã„ã€‚256 ãƒ¬ãƒ™ãƒ«ï¼ˆ8bitï¼‰ã«ã™ã‚‹ã¨ MIM ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒå¢—ãˆã¦è¨“ç·´ãŒé›£ã—ããªã‚‹ã€‚ã“ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒå®Ÿç”¨ Codecï¼ˆEnCodec/WavTokenizerï¼‰è¨­è¨ˆã®æ ¸å¿ƒã¨åŒã˜å•é¡Œæ§‹é€ ã ã€‚

**çµè«–**: MIM ã¯ Sampling ãŒåœ§å€’çš„ã«é€Ÿã„ãŒã€å“è³ªã¯ Diffusion ã«åŠ£ã‚‹ã€‚ç”¨é€”ã«å¿œã˜ã¦é¸æŠã€‚

**ãªãœå“è³ªå·®ãŒç”Ÿã˜ã‚‹ã‹**: Diffusion ã¯ã‚¬ã‚¦ã‚¹ãƒã‚¤ã‚ºã‹ã‚‰é€£ç¶šçš„ã«ã€Œãªã‚ã‚‰ã‹ã€ã«å¾©å…ƒã™ã‚‹ãŒã€MIM ã¯ç‹¬ç«‹ã—ãŸé›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã€éš£æ¥ãƒ‘ãƒƒãƒé–“ã®ç©ºé–“çš„ä¸€è²«æ€§ãŒå¼±ã„ã€‚12 ã‚¹ãƒ†ãƒƒãƒ—ã® masked prediction ã¯å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã€Œå±€æ‰€çš„ãªä¿®æ­£ã€ã—ã‹è¡Œãˆãšã€å¤§åŸŸçš„ãªæ§‹é€ ã®å­¦ç¿’ãŒ Diffusion ã‚ˆã‚Šå›°é›£ã«ãªã‚‹ã€‚

### 5.4 è‡ªå·±è¨ºæ–­ãƒ†ã‚¹ãƒˆ

**å•1**: DiT ã® Patchify ã§ã€256Ã—256 ç”»åƒã‚’ 16Ã—16 ãƒ‘ãƒƒãƒã«åˆ†å‰²ã™ã‚‹ã¨ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã¯ã„ãã¤ï¼Ÿ
<details>
<summary>è§£ç­”</summary>

$$
N = \frac{H}{P} \times \frac{W}{P} = \frac{256}{16} \times \frac{256}{16} = 16 \times 16 = 256
$$
</details>

**å•2**: AdaLN-Zero ã®ã€ŒZero åˆæœŸåŒ–ã€ã¯ãªãœé‡è¦ï¼Ÿ
<details>
<summary>è§£ç­”</summary>

è¨“ç·´åˆæœŸã« $\gamma = 0, \beta = 0$ â†’ AdaLN ã®å‡ºåŠ› = 0 â†’ Residual æ¥ç¶šãŒæ’ç­‰å†™åƒã«ãªã‚Šã€å‹¾é…ãŒå®‰å®šã™ã‚‹ã€‚æ¡ä»¶ $c$ ã®å½±éŸ¿ã‚’å¾ã€…ã«å­¦ç¿’ã§ãã‚‹ã€‚
</details>

**å•3**: MM-DiT (SD3) ã® Joint Attention ã§ã¯ã€ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆãŒåŒã˜ Transformer ã§å‡¦ç†ã•ã‚Œã‚‹ã€‚ã“ã‚Œã®åˆ©ç‚¹ã¯ï¼Ÿ
<details>
<summary>è§£ç­”</summary>

ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆãŒ **åŒã˜æ½œåœ¨ç©ºé–“** ã§ç›¸äº’ä½œç”¨ â†’ ãƒ†ã‚­ã‚¹ãƒˆãŒç”»åƒç”Ÿæˆã‚’ã‚ˆã‚Šå¼·ãæ¡ä»¶ä»˜ã‘ã§ãã‚‹ã€‚Classifier-Free Guidance ã§ã¯åˆ¥ã€…ã«å‡¦ç†ã—ã¦ã„ãŸãŒã€MM-DiT ã§ã¯çµ±åˆã•ã‚Œã¦åŠ¹ç‡çš„ã€‚
</details>

**å•4**: DPM-Solver++ ã¯ DDPM ã® 1000 ã‚¹ãƒ†ãƒƒãƒ—ã‚’ä½•ã‚¹ãƒ†ãƒƒãƒ—ã«å‰Šæ¸›ã§ãã‚‹ï¼Ÿ
<details>
<summary>è§£ç­”</summary>

20 ã‚¹ãƒ†ãƒƒãƒ— (50å€é«˜é€ŸåŒ–)ã€‚åŠç·šå½¢ODE solver ã§é«˜æ¬¡ç²¾åº¦ã‚’å®Ÿç¾ã€‚
</details>

**å•5**: aMUSEd ãŒ 12 ã‚¹ãƒ†ãƒƒãƒ—ã§ç”Ÿæˆã§ãã‚‹ç†ç”±ã¯ï¼Ÿ
<details>
<summary>è§£ç­”</summary>

**é›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³ç©ºé–“** (VQ-VAE) ã§ Masked token prediction ã‚’è¡Œã†ãŸã‚ã€‚å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã€Œæœ€ã‚‚ç¢ºä¿¡åº¦ã®ä½ã„ãƒˆãƒ¼ã‚¯ãƒ³ã€ã‚’äºˆæ¸¬ã—ã€ãƒã‚¹ã‚¯ã‚’ç½®æ›ã€‚é€£ç¶šãƒã‚¤ã‚ºé™¤å» (Diffusion) ã‚ˆã‚Šã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒå°‘ãªãæ¸ˆã‚€ã€‚
</details>

### 5.5 å®Ÿè£…ãƒãƒ£ãƒ¬ãƒ³ã‚¸

**Challenge 1**: DiT ã« Class-conditional generation ã‚’è¿½åŠ 
- ãƒ’ãƒ³ãƒˆ: AdaLN-Zero ã® $\mathbf{c}$ ã« class embedding ã‚’è¿½åŠ 
- å®Ÿè£…: `c = vcat(t_emb, class_emb)` ã¨ã—ã¦ AdaLN ã«æ¸¡ã™

**Challenge 2**: DPM-Solver++ ã§ DiT ã® Sampling ã‚’é«˜é€ŸåŒ–
- ãƒ’ãƒ³ãƒˆ: Zone 4.4 ã®å®Ÿè£…ã‚’ DiT ã«çµ±åˆ
- ç›®æ¨™: 1000 ã‚¹ãƒ†ãƒƒãƒ— â†’ 20 ã‚¹ãƒ†ãƒƒãƒ—

**Challenge 3**: aMUSEd-256 ã§ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è©¦ã™
- ä¾‹: "a dog in a spacesuit", "abstract art with geometric shapes"
- è¦³å¯Ÿ: ã©ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å“è³ªãŒé«˜ã„ï¼Ÿ

> **Note:** **ã“ã“ã¾ã§ã§å…¨ä½“ã®85%å®Œäº†ï¼** å®Ÿé¨“ã‚¾ãƒ¼ãƒ³å®Œèµ°ã€‚aMUSEd-256 ãƒ‡ãƒ¢ã¨ Tiny DiT on MNIST ã§ã€ç†è«–ã‚’å®Ÿè£…ã«è½ã¨ã—ãŸã€‚æ¬¡ã¯ç™ºå±•ã‚¾ãƒ¼ãƒ³ â€” æœ€æ–°ç ”ç©¶ã¨ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã€‚

---


> Progress: 85%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. $epoch: MIM Loss = $ ã®å„è¨˜å·ã®æ„å‘³ã¨ã€ã“ã®å¼ãŒè¡¨ã™æ“ä½œã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
>    - *ãƒ’ãƒ³ãƒˆ*: MIM Loss ã®ç›®æ¨™ãƒˆãƒ¼ã‚¯ãƒ³ã¯ä½•ã‹ã€‚Diffusion ã® MSE(Îµ_pred, Îµ_true) ã¨ä½•ãŒé•ã†ã‹ï¼Ÿ
> 2. ã“ã®ã‚¾ãƒ¼ãƒ³ã§å­¦ã‚“ã æ‰‹æ³•ã®ç›´æ„Ÿçš„ãªæ„å‘³ã¨ã€ãªãœã“ã®å®šå¼åŒ–ãŒå¿…è¦ãªã®ã‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
>    - *ãƒ’ãƒ³ãƒˆ*: aMUSEd ãŒ 12 ã‚¹ãƒ†ãƒƒãƒ—ã§å®Œäº†ã§ãã‚‹ç†ç”±ã‚’ã€Œé›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³ç©ºé–“ã®ç¢ºä¿¡åº¦ã€ã®è¦³ç‚¹ã§è¿°ã¹ã‚ˆã€‚

## ğŸ”¬ Z6. æ–°ãŸãªå†’é™ºã¸ï¼ˆç ”ç©¶å‹•å‘ï¼‰

**ã‚´ãƒ¼ãƒ«**: 2024-2026 æœ€æ–°ç ”ç©¶ã‚’æ•´ç†ã—ã€DiT ã®æœªæ¥ã¨æœªè§£æ±ºå•é¡Œã‚’ç†è§£ã™ã‚‹ã€‚

### 6.1 DiT ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®ç³»è­œå›³

```mermaid
graph TD
    A["Vision Transformer<br/>Dosovitskiy+ 2020"] --> B["DiT<br/>Peebles & Xie 2023"]
    B --> C["SD3 (MM-DiT)<br/>Esser+ 2024"]
    B --> D["FLUX<br/>Black Forest Labs 2024"]
    B --> E["SiT<br/>Ma+ 2024"]
    C --> F["Inference-Time Scaling<br/>Reflect-DiT 2025"]
    D --> G["Commercial Applications<br/>Apache 2.0"]
    E --> H["Stochastic Interpolants<br/>Theory"]

    style B fill:#ffd700
    style C fill:#98fb98
    style D fill:#98fb98
```

**ä¸–ä»£åˆ¥ã®é€²åŒ–**:
1. **ç¬¬1ä¸–ä»£ (2020-2022)**: ViT â€” Transformer ã‚’ Vision ã«é©ç”¨
2. **ç¬¬2ä¸–ä»£ (2023)**: DiT â€” Transformer ã‚’ Diffusion ã«é©ç”¨
3. **ç¬¬3ä¸–ä»£ (2024)**: MM-DiT â€” Multimodal çµ±åˆ (ç”»åƒ+ãƒ†ã‚­ã‚¹ãƒˆ)
4. **ç¬¬4ä¸–ä»£ (2025-)**: Inference-Time Scaling â€” Test-time ã§ã®æ€§èƒ½å‘ä¸Š

**é€²åŒ–ã®ãƒ‘ã‚¿ãƒ¼ãƒ³**: å„ä¸–ä»£ã¯ã€Œå…¥åŠ›ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®æ‹¡å¼µã€ã¨ã€Œã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡ã®é©ç”¨ã€ã‚’ç¹°ã‚Šè¿”ã™ã€‚ViT ãŒ Transformer ã®ç”»åƒé©ç”¨æ€§ã‚’ç¤ºã—ã€DiT ãŒãã‚Œã‚’ Diffusion ã® denoising ã«ç¹‹ã„ã ã€‚MM-DiT ã¯ç”»åƒ+ãƒ†ã‚­ã‚¹ãƒˆã®åŒä¸€ç©ºé–“å‡¦ç†ã€ç¬¬4ä¸–ä»£ã¯ã€Œæ¨è«–æ™‚ã®è¨ˆç®—å¢—åŠ ã§å“è³ªå‘ä¸Šã€ã¨ã„ã† LLM ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡ã®æ‹¡æ•£ç‰ˆã€‚

### 6.2 2024-2026 æœ€æ–°ç ”ç©¶

#### SD3 (Stable Diffusion 3) â€” MM-DiT ã®å•†ç”¨åŒ–

**è«–æ–‡**: Esser+ (2024) "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis" [^3]

**é©æ–°ç‚¹**:
1. **MM-DiT** â€” Image ã¨ Text ã‚’åŒã˜ Transformer ã§å‡¦ç†
2. **Rectified Flow** â€” Flow Matching ã®ä¸€ç¨® (ç¬¬38å›ã§å­¦ã‚“ã )
3. **3ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€** â€” CLIP-L + CLIP-G + T5-XXL

**æ€§èƒ½**:
- Human preference: SD3 > SDXL > DALL-E 3
- Text-to-Image Benchmark: SD3 ãŒ Midjourney v6 ã«åŒ¹æ•µ

**åˆ¶ç´„**:
- ãƒ©ã‚¤ã‚»ãƒ³ã‚¹: å•†ç”¨åˆ©ç”¨ã«åˆ¶é™ã‚ã‚Š (æœ‰æ–™ãƒ©ã‚¤ã‚»ãƒ³ã‚¹å¿…è¦)
- ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º: 2B (Medium) / 8B (Large) â€” GPU ãƒ¡ãƒ¢ãƒªè¦æ±‚ãŒé«˜ã„

#### FLUX â€” DiT ã®å•†ç”¨ã‚ªãƒ¼ãƒ—ãƒ³ãƒ¢ãƒ‡ãƒ«

**é–‹ç™º**: Black Forest Labs (Stable Diffusion å‰µè¨­è€…ãŒè¨­ç«‹) [^4]

**é©æ–°ç‚¹**:
1. **Apache 2.0 ãƒ©ã‚¤ã‚»ãƒ³ã‚¹** â€” å®Œå…¨å•†ç”¨åˆ©ç”¨å¯èƒ½
2. **æ”¹è‰¯ã•ã‚ŒãŸ DiT** â€” ã‚ˆã‚ŠåŠ¹ç‡çš„ãª Attention
3. **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç†è§£ã®å‘ä¸Š** â€” T5 + CLIP ã®çµ±åˆæœ€é©åŒ–

**ãƒ¢ãƒ‡ãƒ« variant**:
- FLUX.1-pro: æœ€é«˜å“è³ª (API ã®ã¿)
- FLUX.1-dev: é–‹ç™ºç”¨ (éå•†ç”¨)
- FLUX.1-schnell: é«˜é€Ÿç‰ˆ (4 ã‚¹ãƒ†ãƒƒãƒ—ç”Ÿæˆ)

**æ€§èƒ½**:
- Quality: FLUX > SD3 (ç‰¹ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¿ å®Ÿåº¦)
- Speed: FLUX-schnell = 4 ã‚¹ãƒ†ãƒƒãƒ—ã§ high quality

**ãªãœ 4 ã‚¹ãƒ†ãƒƒãƒ—ã§é«˜å“è³ªç”Ÿæˆã§ãã‚‹ã‹**: FLUX ã¯ Rectified Flow ã‚’æ¡ç”¨ã—ã€ã‹ã¤ Consistency Distillation ã§è’¸ç•™ã€‚ç›´ç·š ODE çµŒè·¯ + è’¸ç•™ã®çµ„ã¿åˆã‚ã›ãŒã€Œæ•°ã‚¹ãƒ†ãƒƒãƒ—ã§ã®åæŸã€ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚DPM-Solver++ ã® 20 ã‚¹ãƒ†ãƒƒãƒ—ã‚ˆã‚Šå°‘ãªã„ã®ã¯ã€è’¸ç•™ã§ ODE ã‚½ãƒ«ãƒãƒ¼ã®ç²¾åº¦è¦æ±‚è‡ªä½“ã‚’ä¸‹ã’ã¦ã„ã‚‹ãŸã‚ã€‚

#### SiT (Scalable Interpolant Transformers) â€” ç†è«–çš„çµ±åˆ

**è«–æ–‡**: Ma+ (2024) "SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers" [^8]

**é©æ–°ç‚¹**:
1. **Stochastic Interpolants** (ç¬¬38å›ã§å­¦ã‚“ã ) ã‚’ DiT ã«çµ±åˆ
2. **Flow ã¨ Diffusion ã®çµ±ä¸€** â€” ç¢ºç‡çš„è£œé–“ã§ä¸¡æ–¹ã‚’ã‚«ãƒãƒ¼
3. **Scaling Laws** â€” DiT ã¨åŒæ§˜ã« Transformer ã§ Scaling å¯èƒ½

**æ•°å¼** (å¾©ç¿’):
$$
\mathbf{x}_t = \alpha(t) \mathbf{x}_0 + \beta(t) \mathbf{x}_1 + \gamma(t) \mathbf{z}
$$
- $\gamma(t) = 0$ â†’ Flow Matching
- $\gamma(t) > 0$ â†’ Stochastic Interpolant

**SiT ã®é‡è¦æ€§**: ã“ã‚Œã¯ã€ŒFlow ã¨ Diffusion ã¯å…¨ãåˆ¥ç‰©ã§ã¯ãªãã€$\gamma(t)$ ã®å€¤ã§é€£ç¶šçš„ã«ã¤ãªãŒã‚‹åŒä¸€ã®æ çµ„ã¿ã€ã‚’ç¤ºã™ã€‚$\gamma = 0$ ãŒæœ€ã‚‚è¨“ç·´å®‰å®šï¼ˆç›´ç·šçµŒè·¯ï¼‰ã€$\gamma > 0$ ãŒå¤šæ§˜æ€§å‘ä¸Šï¼ˆç¢ºç‡çš„æºã‚‰ãï¼‰ã€‚SD3/FLUX ã¯ $\gamma = 0$ ã«è¿‘ã„è¨­å®šã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã€‚

**æ€§èƒ½**:
- ImageNet 256Ã—256: FID = 2.06 (DiT-XL/2: FID = 2.27)
- Scaling: åŒæ§˜ã« Transformer ã® Scaling Laws ã«å¾“ã†

#### D2iT / DyDiT++ â€” Dynamic DiT

**è«–æ–‡**:
- D2iT (Dynamic DiT): CVPR 2025 [^12]
- DyDiT++ (2025): arXiv:2504.06803 [^13]

**é©æ–°ç‚¹**:
1. **å‹•çš„è¨ˆç®—é‡å‰²ã‚Šå½“ã¦** â€” é‡è¦ãªé ˜åŸŸã«è¨ˆç®—ã‚’é›†ä¸­
2. **Token pruning** â€” ä¸è¦ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‹•çš„ã«å‰Šé™¤
3. **Adaptive depth** â€” é›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã«ã¯æ·±ã„å±¤ã‚’ä½¿ç”¨

**åŠ¹æœ**:
- è¨ˆç®—é‡å‰Šæ¸›: âˆ¼30% (åŒå“è³ªã§)
- é€Ÿåº¦å‘ä¸Š: 1.5å€é«˜é€ŸåŒ–

**æ•°å¼**:
$$
\text{Keep}_i = \mathbb{1}[\text{Importance}(\mathbf{z}_i) > \tau]
$$
- $\text{Importance}(\mathbf{z}_i)$ â€” ãƒˆãƒ¼ã‚¯ãƒ³ $i$ ã®é‡è¦åº¦ã‚¹ã‚³ã‚¢
- $\tau$ â€” é–¾å€¤ (å‹•çš„ã«èª¿æ•´)

#### Z-Image â€” æ¬¡ä¸–ä»£ç”»åƒç”Ÿæˆ

**è«–æ–‡**: arXiv:2511.22699 (2025 H2) [^14]

**è©³ç´°ã¯æœªå…¬é–‹** â€” ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æ¨æ¸¬:
- **Z-space optimization** â€” æ½œåœ¨ç©ºé–“ã®æœ€é©åŒ–æ‰‹æ³•ï¼Ÿ
- **Zero-shot adaptation** â€” äº‹å‰è¨“ç·´ãƒ¢ãƒ‡ãƒ«ã® zero-shot é©ç”¨ï¼Ÿ

**æ¢ç´¢ãƒ’ãƒ³ãƒˆ**: `"Z-Image generation 2025 arXiv"` ã§æ¤œç´¢

### 6.3 Inference-Time Scaling â€” 2025-2026 ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚·ãƒ•ãƒˆ

**å¾“æ¥ã® Scaling**: Training-time Scaling Laws
$$
L(N) = A \cdot N^{-\alpha} + L_\infty
$$
- $N$ = ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° (è¨“ç·´æ™‚ã«å›ºå®š)

**æ–°ã—ã„ Scaling**: Inference-Time Scaling (ç¬¬49å›ã§è©³è¿°)
$$
L(C) = B \cdot C^{-\beta} + L_\infty
$$
- $C$ = æ¨è«–æ™‚ã®è¨ˆç®—é‡ (å¯å¤‰)

**Reflect-DiT** [arXiv:2503.12271] [^15] (ICCV 2025):
- **Self-Reflection** â€” ç”Ÿæˆçµæœã‚’è‡ªå·±è©•ä¾¡ã—ã€å†ç”Ÿæˆ
- **Iterative refinement** â€” è¤‡æ•°å›ã® denoising ã§å“è³ªå‘ä¸Š
- **Test-time Training** â€” æ¨è«–æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´

**æ•°å¼**:
$$
\mathbf{x}_{t-1}^{(k+1)} = \mathbf{x}_{t-1}^{(k)} + \eta \nabla_{\mathbf{x}} \text{Quality}(\mathbf{x}_{t-1}^{(k)})
$$
- $k$ â€” Reflection iteration
- $\text{Quality}(\cdot)$ â€” å“è³ªè©•ä¾¡é–¢æ•° (CLIP score / FID)

**åŠ¹æœ**:
- FID æ”¹å–„: 5.2 â†’ 3.8 (åŒã˜ãƒ¢ãƒ‡ãƒ«ã§)
- è¨ˆç®—ã‚³ã‚¹ãƒˆ: 2-3å€ (Reflection ã®ãŸã‚)

**Inference-Time Scaling ã®æœªæ¥** (ç¬¬49å›ã§æ‰±ã†):
- Training Scaling Laws ã®é™ç•Œ â†’ Inference-Time Scaling ã¸ã‚·ãƒ•ãƒˆ
- ã€Œå¤§ããªãƒ¢ãƒ‡ãƒ«ã€â†’ã€Œè³¢ã„æ¨è«–ã€

**LLM ã¨ã®é¡æ¯”**: LLM ã® Chain-of-Thoughtï¼ˆæ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’å¢—ã‚„ã™ï¼‰= ç”»åƒç”Ÿæˆã® Reflect-DiTï¼ˆç”Ÿæˆã‚¹ãƒ†ãƒƒãƒ—ã‚’å¢—ã‚„ã™ï¼‰ã€‚ã©ã¡ã‚‰ã‚‚ã€Œæ¨è«–æ™‚è¨ˆç®— $\propto$ å“è³ªã€ã¨ã„ã†å…±é€šã® Scaling å‰‡ã‚’æŒã¤ã€‚DiT ã®å ´åˆã€Reflection 1å› = ODE ã‚¹ãƒ†ãƒƒãƒ—100ã‚¹ãƒ†ãƒƒãƒ—ç›¸å½“ã®å“è³ªå‘ä¸Šã‚’1/10ã®ãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—ã§å®Ÿç¾ã§ãã‚‹ãŸã‚ã€å®Ÿç”¨çš„ãªé«˜å“è³ªç”Ÿæˆã¸ã®é“ãŒé–‹ã‘ã‚‹ã€‚

### 6.4 æœªè§£æ±ºå•é¡Œ

**å•é¡Œ1: Scaling ã®é™ç•Œ**
- DiT ã¯ 8B params ã¾ã§è¨“ç·´ã•ã‚Œã¦ã„ã‚‹ãŒã€ã‚‚ã£ã¨å¤§ããã™ã‚‹ã¨ï¼Ÿ
- **ä»®èª¬**: 100B params DiT ã¯æ„å‘³ãŒã‚ã‚‹ã‹ï¼Ÿ
- **èª²é¡Œ**: GPU ãƒ¡ãƒ¢ãƒªãƒ»è¨“ç·´æ™‚é–“ãƒ»ãƒ‡ãƒ¼ã‚¿é‡

**å•é¡Œ2: Long-range Dependencies**
- Self-Attention ã¯ $O(N^2)$ â€” é«˜è§£åƒåº¦ç”»åƒ (4K) ã§ã¯è¨ˆç®—ä¸å¯èƒ½
- **ç¾çŠ¶**: Latent space ã§åœ§ç¸® (SD3 ã¯ 64Ã—64 latent)
- **æœªæ¥**: Sparse Attention / Linear Attention / State Space Models (Mamba ç­‰)

**æ•°å€¤ã§ç†è§£**: 4K ç”»åƒ (3840Ã—2160) ã‚’ 16Ã—16 ãƒ‘ãƒƒãƒã«åˆ†å‰²ã™ã‚‹ã¨ $N = 240 \times 135 = 32,400$ ãƒˆãƒ¼ã‚¯ãƒ³ã€‚Self-Attention ã® QKV ãŒ $O(N^2 \cdot d) = 32,400^2 \times 1024 \approx 10^{12}$ flops â†’ A100 (312 TFLOPS) ã§3ç§’/ã‚¹ãƒ†ãƒƒãƒ—ã€‚1000ã‚¹ãƒ†ãƒƒãƒ—ç”Ÿæˆã ã¨ç´„50åˆ†ã€‚ã“ã‚ŒãŒã€Œ4K Diffusion ãŒæ™®åŠã—ãªã„ã€ç†ç”±ã ã€‚

**å•é¡Œ3: Controllability**
- DiT ã¯ Text-conditional ã ãŒã€ç´°ã‹ã„åˆ¶å¾¡ (ãƒãƒ¼ã‚ºãƒ»æ§‹å›³) ã¯å›°é›£
- **ç¾çŠ¶**: ControlNet (ç¬¬44å›ã§æ‰±ã†) ã§è§£æ±º
- **æœªæ¥**: Unified Multimodal Models (ç¬¬49å›ã§æ‰±ã†)

**å•é¡Œ4: Temporal Consistency (å‹•ç”»ç”Ÿæˆ)**
- DiT ã¯é™æ­¢ç”»ã®ã¿ â€” å‹•ç”»ç”Ÿæˆã«ã¯æ™‚é–“è»¸ãŒå¿…è¦
- **ç¾çŠ¶**: CogVideoX / Sora 2 (ç¬¬45å›ã§æ‰±ã†)
- **æœªæ¥**: 4D DiT (ç©ºé–“3æ¬¡å…ƒ + æ™‚é–“1æ¬¡å…ƒ)

**å•é¡Œ5: 3D Generation**
- DiT ã¯ 2D ã®ã¿ â€” 3D ç”Ÿæˆã«ã¯ NeRF / 3DGS ã¨ã®çµ±åˆãŒå¿…è¦
- **ç¾çŠ¶**: DreamFusion (ç¬¬46å›ã§æ‰±ã†)
- **æœªæ¥**: Native 3D DiT

### 6.5 ç ”ç©¶ãƒ†ãƒ¼ãƒã®è¦‹ã¤ã‘æ–¹

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ1: Gap Analysis**
- æ—¢å­˜æ‰‹æ³•ã® **é™ç•Œ** ã‚’ç‰¹å®š
- ä¾‹: DiT ã¯ $O(N^2)$ â€” Linear Attention DiT ã§è§£æ±ºï¼Ÿ

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ2: ç†è«–æ‹¡å¼µ**
- æ—¢å­˜ç†è«–ã‚’ **ä¸€èˆ¬åŒ–**
- ä¾‹: SiT ã® Stochastic Interpolants ã‚’ Flow Matching ã®ä¸€èˆ¬åŒ–ã¨ã—ã¦æ‰ãˆã‚‹

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ3: å†ç¾å®Ÿé¨“**
- è«–æ–‡ã‚’ **å®Œå…¨å†ç¾** â†’ æ”¹å–„ç‚¹ã‚’ç™ºè¦‹
- ä¾‹: DiT ã‚’ MNIST ã§å†ç¾ â†’ AdaLN-Zero ã®åˆæœŸåŒ–æ–¹æ³•ã‚’å¤‰ãˆãŸã‚‰ï¼Ÿ

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ4: ç•°åˆ†é‡çµ±åˆ**
- ä»–åˆ†é‡ã®æ‰‹æ³•ã‚’ **è»¢ç”¨**
- ä¾‹: ODE solver (æ•°å€¤è§£æ) ã‚’ Diffusion ã«é©ç”¨ â†’ DPM-Solver++

**2026 ä»¥é™ã®äºˆæ¸¬**:
1. **Inference-Time Scaling ãŒä¸»æµã«** â€” Training Laws ã®é™ç•Œ
2. **Multimodal çµ±åˆ** â€” ç”»åƒãƒ»éŸ³å£°ãƒ»å‹•ç”»ãƒ»3D ã‚’1ãƒ¢ãƒ‡ãƒ«ã§
3. **World Models** â€” ç‰©ç†æ³•å‰‡ã‚’ç†è§£ã™ã‚‹ç”Ÿæˆãƒ¢ãƒ‡ãƒ« (ç¬¬41å›ãƒ»ç¬¬49å›)
4. **Sparse/Linear Attention** â€” $O(N^2)$ ã®å…‹æœ

### 6.6 æ¨è–¦æ–‡çŒ®

**ä¸»è¦è«–æ–‡**:
1. Vision Transformer (ViT): Dosovitskiy+ 2020 [^1]
2. Diffusion Transformers (DiT): Peebles & Xie 2023 [^2]
3. Stable Diffusion 3 (MM-DiT): Esser+ 2024 [^3]
4. FLUX: Black Forest Labs 2024 [^4]
5. SiT: Ma+ 2024 [^8]
6. DPM-Solver++: Lu+ 2022 [^9]
7. EDM: Karras+ 2022 [^10]
8. aMUSEd: Patel+ 2024 [^11]
9. Reflect-DiT: arXiv:2503.12271 [^15]

**æ•™ç§‘æ›¸**:
- "Deep Learning" (Goodfellow, Bengio, Courville) â€” ç¬¬20ç«  Generative Models
- "Probabilistic Machine Learning" (Kevin Murphy) â€” ç¬¬27ç«  Diffusion Models

**ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒªã‚½ãƒ¼ã‚¹**:
- HuggingFace Diffusers: https://huggingface.co/docs/diffusers/
- Papers With Code â€” Diffusion Models: https://paperswithcode.com/task/image-generation

> **Note:** **ã“ã“ã¾ã§ã§å…¨ä½“ã®95%å®Œäº†ï¼** ç™ºå±•ã‚¾ãƒ¼ãƒ³å®Œèµ°ã€‚æœ€æ–°ç ”ç©¶ã¨æœªè§£æ±ºå•é¡Œã‚’æ•´ç†ã—ãŸã€‚æ¬¡ã¯æœ€çµ‚ã‚¾ãƒ¼ãƒ³ â€” æŒ¯ã‚Šè¿”ã‚Šã¨æ¬¡å›äºˆå‘Šã€‚

---


**ã‚´ãƒ¼ãƒ«**: ç¬¬43å›ã®è¦ç‚¹ã‚’æ•´ç†ã—ã€Course V ã®æ—…è·¯ã‚’è¦‹æ¸¡ã™ã€‚


## ğŸ­ Z7. ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ï¼ˆã¾ã¨ã‚ãƒ»FAQãƒ»æ¬¡å›äºˆå‘Šï¼‰

### 6.7 ç¬¬43å›ã®è¦ç‚¹

**1. U-Net â†’ DiT ã®é©å‘½**:
- **å¸°ç´ãƒã‚¤ã‚¢ã‚¹ã®æ”¾æ£„** â€” CNN ã®å±€æ‰€æ€§ã‚’æ¨ã¦ã€Self-Attention ã§å¤§åŸŸçš„é–¢ä¿‚ã‚’å­¦ç¿’
- **Scaling Laws ã®é©ç”¨** â€” ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° $N$ âˆ æ€§èƒ½å‘ä¸Š (8B params ã¾ã§)
- **å®Ÿä¸–ç•Œã§ã®å„ªä½** â€” SD3 / FLUX ãŒ DALL-E 3 / Midjourney ã«åŒ¹æ•µ

**2. DiT ã®å¿ƒè‡“éƒ¨ â€” AdaLN-Zero**:
- æ‹¡æ•£ã‚¹ãƒ†ãƒƒãƒ— $t$ ã¨æ¡ä»¶ $c$ ã‚’ **æ­£è¦åŒ–å±¤ã«æ³¨å…¥**
- **Zero åˆæœŸåŒ–** â€” Residual æ¥ç¶šãŒè¨“ç·´åˆæœŸã®å‹¾é…ã‚’å®‰å®šåŒ–
- æ•°å¼: $\text{AdaLN-Zero}(\mathbf{x}, \mathbf{c}) = \gamma(\mathbf{c}) \odot \text{LN}(\mathbf{x}) + \beta(\mathbf{c})$

**3. MM-DiT (SD3) â€” Multimodal çµ±åˆ**:
- ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ **åŒã˜ Transformer** ã§å‡¦ç†
- **Joint Attention** â€” ç”»åƒ â†” ãƒ†ã‚­ã‚¹ãƒˆã®ç›¸äº’ä½œç”¨
- **3ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€** â€” CLIP-L + CLIP-G + T5-XXL

**4. é«˜é€ŸSampling**:
- **DPM-Solver++** â€” 1000 ã‚¹ãƒ†ãƒƒãƒ— â†’ 20 ã‚¹ãƒ†ãƒƒãƒ— (50å€é«˜é€ŸåŒ–)
- **EDM** â€” æœ€é©ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« $\sigma(t)$ + Heun's method

**5. aMUSEd vs DiT**:
- **aMUSEd** â€” é›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³ç©ºé–“ (VQ-VAE) ã§ 12 ã‚¹ãƒ†ãƒƒãƒ—ç”Ÿæˆ
- **DiT** â€” é€£ç¶šãƒã‚¤ã‚ºç©ºé–“ (DDPM) ã§é«˜å“è³ªç”Ÿæˆ
- **ç”¨é€”**: aMUSEd = ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  / DiT = é«˜å“è³ª

**è¦ç‚¹ã®ç¹‹ãŒã‚Š**: U-Net â†’ DiTï¼ˆå¸°ç´ãƒã‚¤ã‚¢ã‚¹é™¤å»ï¼‰â†’ AdaLN-Zeroï¼ˆæ¡ä»¶æ³¨å…¥ã®åŠ¹ç‡åŒ–ï¼‰â†’ MM-DiTï¼ˆãƒ¢ãƒ€ãƒªãƒ†ã‚£çµ±åˆï¼‰â†’ DPM-Solver++ï¼ˆæ¨è«–é«˜é€ŸåŒ–ï¼‰â†’ aMUSEdï¼ˆé›¢æ•£åŒ–ã«ã‚ˆã‚‹åˆ¥ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰ã¨ã„ã†é€²åŒ–ã®è«–ç†ã¯ä¸€è²«ã—ã¦ã„ã‚‹ã€‚å…¨ã¦ã€Œå“è³ªã¨é€Ÿåº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æ•°å­¦çš„ã«è§£æ±ºã™ã‚‹ã€ã¨ã„ã†ä¸€ã¤ã®ãƒ†ãƒ¼ãƒã®å¤‰å¥ã ã€‚


> Progress: 95%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. $O(N^2)$ ã® Self-Attention ã§ã€256Ã—256 ç”»åƒï¼ˆ16Ã—16 ãƒ‘ãƒƒãƒï¼‰ã®è¨ˆç®—é‡ã¯ã„ãã‚‰ã‹ï¼Ÿã¾ãŸ 512Ã—512 ã«å€å¢—ã—ãŸå ´åˆä½•å€ã«ãªã‚‹ã‹ï¼Ÿ
>    - *ãƒ’ãƒ³ãƒˆ*: $N = (H/P)^2$ã€‚å€å€å‰‡ã§è¨ˆç®—ã›ã‚ˆã€‚
> 2. ã“ã®ã‚¾ãƒ¼ãƒ³ã§å­¦ã‚“ã æ‰‹æ³•ã®ç›´æ„Ÿçš„ãªæ„å‘³ã¨ã€ãªãœã“ã®å®šå¼åŒ–ãŒå¿…è¦ãªã®ã‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
>    - *ãƒ’ãƒ³ãƒˆ*: DiT ãŒ U-Net ã®å±€æ‰€çš„ CNN ã‚’ Transformer ã®å¤§åŸŸçš„ Attention ã«ç½®ãæ›ãˆãŸåˆ©ç‚¹ã‚’ã€FID ã® Scaling æ›²ç·šï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° vs FIDï¼‰ã§èª¬æ˜ã›ã‚ˆã€‚

### 6.8 FAQ

**Q1: DiT ã¯ U-Net ã‚’å®Œå…¨ã«ç½®ãæ›ãˆã‚‹ï¼Ÿ**
A: **ç”¨é€”æ¬¡ç¬¬**ã€‚DiT ã¯ Scaling Laws ã«å¾“ã†ãŸã‚ã€å¤§è¦æ¨¡è¨“ç·´ã§ U-Net ã‚’è¶…ãˆã‚‹ã€‚ãŸã ã—ã€å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã¯ U-Net ã®å¸°ç´ãƒã‚¤ã‚¢ã‚¹ãŒæœ‰åˆ©ãªå ´åˆã‚‚ã‚ã‚‹ã€‚å•†ç”¨ãƒ¢ãƒ‡ãƒ« (SD3/FLUX) ã¯ DiT ã«ç§»è¡Œæ¸ˆã¿ã€‚

**Q2: AdaLN-Zero ã®ã€ŒZero åˆæœŸåŒ–ã€ã‚’å¿˜ã‚ŒãŸã‚‰ï¼Ÿ**
A: è¨“ç·´åˆæœŸã«æ¡ä»¶ $c$ ã®å½±éŸ¿ãŒå¼·ã™ãã¦ã€å‹¾é…ãŒä¸å®‰å®šã«ãªã‚‹ã€‚æœ€æ‚ªã®å ´åˆã€è¨“ç·´ãŒç™ºæ•£ã™ã‚‹ã€‚Zero åˆæœŸåŒ–ã«ã‚ˆã‚Šã€Residual æ¥ç¶šãŒè¨“ç·´åˆæœŸã¯æ’ç­‰å†™åƒã«ãªã‚Šã€å®‰å®šã™ã‚‹ã€‚

**Q3: MM-DiT ã¯ Classifier-Free Guidance ã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹ï¼Ÿ**
A: **ç†è«–çš„ã«ã¯å„ªã‚Œã¦ã„ã‚‹**ã€‚CFG ã§ã¯æ¡ä»¶ä»˜ã/ç„¡æ¡ä»¶ã‚’åˆ¥ã€…ã«å‡¦ç†ã™ã‚‹ãŒã€MM-DiT ã§ã¯ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆãŒåŒã˜æ½œåœ¨ç©ºé–“ã§ç›¸äº’ä½œç”¨ã™ã‚‹ã€‚ãŸã ã—ã€å®Ÿè£…ã®è¤‡é›‘ã•ã¨è¨“ç·´ã‚³ã‚¹ãƒˆã¯ MM-DiT ã®æ–¹ãŒé«˜ã„ã€‚

**Q4: aMUSEd ã® 12 ã‚¹ãƒ†ãƒƒãƒ—ã¯ Diffusion ã§ã‚‚å¯èƒ½ï¼Ÿ**
A: **DPM-Solver++ / EDM ã§ 20 ã‚¹ãƒ†ãƒƒãƒ—ã¾ã§å‰Šæ¸›å¯èƒ½**ã€‚ãŸã ã—ã€aMUSEd ã® 12 ã‚¹ãƒ†ãƒƒãƒ—ã«ã¯åŠã°ãªã„ã€‚é›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³ç©ºé–“ (MIM) ã®æ–¹ãŒã€é€£ç¶šãƒã‚¤ã‚ºç©ºé–“ (Diffusion) ã‚ˆã‚Šå°‘ãªã„ã‚¹ãƒ†ãƒƒãƒ—ã§æ¸ˆã‚€å‚¾å‘ãŒã‚ã‚‹ã€‚

**Q5: DiT ã®æœªæ¥ã¯ï¼Ÿ**
A: **3ã¤ã®æ–¹å‘**: (1) Inference-Time Scaling (Reflect-DiT) â€” æ¨è«–æ™‚ã«æ€§èƒ½å‘ä¸Šã€(2) Multimodal çµ±åˆ (ç¬¬49å›) â€” å…¨ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’1ãƒ¢ãƒ‡ãƒ«ã§ã€(3) World Models (ç¬¬41å›ãƒ»ç¬¬49å›) â€” ç‰©ç†æ³•å‰‡ã‚’ç†è§£ã™ã‚‹ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã€‚

**è£œè¶³ (Inference-Time Scaling ã®æ•°ç†)**: LLM ã§ã¯æ¨è«–æ™‚ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆå¢—åŠ ï¼ˆã‚ˆã‚Šå¤šãã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€æ€è€ƒã‚¹ãƒ†ãƒƒãƒ—ï¼‰ã§å“è³ªãŒä¸ŠãŒã‚‹ã“ã¨ãŒåˆ†ã‹ã£ã¦ã„ã‚‹ã€‚Reflect-DiT ã¯ã“ã®åŸç†ã‚’ç”»åƒç”Ÿæˆã«é©ç”¨ã—ã€1å›ã®ç”Ÿæˆã§ã¯ãªãã€Œç”Ÿæˆ â†’ è©•ä¾¡ â†’ å†ç”Ÿæˆã€ã®ãƒ«ãƒ¼ãƒ—ã‚’æ¨è«–æ™‚ã«å®Ÿè¡Œã™ã‚‹ã€‚DiT ã® ODE ã‚¹ãƒ†ãƒƒãƒ—ã‚’å¢—ã‚„ã™ã®ã¨ã¯ç•°ãªã‚‹æ¬¡å…ƒã®ã€Œæ€è€ƒé‡å¢—åŠ ã€ã€‚

### 6.9 ã‚ˆãã‚ã‚‹é–“é•ã„

**é–“é•ã„1: Patchify ã§ flatten ã®é †åºã‚’é–“é•ãˆã‚‹**
```rust
# âŒ Wrong
patch = vec(x[i*P+1:(i+1)*P, j*P+1:(j+1)*P, :])  # channel ãŒå…ˆ

# âœ… Correct
patch = reshape(x[i*P+1:(i+1)*P, j*P+1:(j+1)*P, :], P*P*C)  # spatial ãŒå…ˆ
```

**é–“é•ã„2: AdaLN-Zero ã§ $\gamma, \beta$ ã‚’ shared ã«ã™ã‚‹**
```rust
# âŒ Wrong: å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã§åŒã˜ Î³, Î²
Î³ = Î³_mlp(c)  # [D] â€” scalar per dimension
x_out = Î³' .* x_norm .+ Î²'  # broadcasting wrong

# âœ… Correct: ãƒˆãƒ¼ã‚¯ãƒ³ã”ã¨ã«ç•°ãªã‚‹ Î³, Î² (å¿…è¦ã«å¿œã˜ã¦)
# ã¾ãŸã¯ã€å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã§ shared ãªã‚‰ broadcasting æ­£ã—ãä½¿ã†
```

**é–“é•ã„3: MM-DiT ã§ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ concat ã›ãšã«åˆ¥ã€…ã«å‡¦ç†**
```rust
# âŒ Wrong: åˆ¥ã€…ã® Attention
attn_img = attn(z_img)
attn_txt = attn(z_txt)

# âœ… Correct: Joint Attention
attn = vcat(z_img, z_txt) |> attn_joint
```

**é–“é•ã„4: DDPM ã® $\bar{\alpha}_t$ ã‚’ã‚·ãƒ³ã‚°ãƒ« $\alpha_t$ ã¨æ··åŒã™ã‚‹**

$$
\bar{\alpha}_t = \prod_{s=1}^t \alpha_s \neq \alpha_t
$$

`schedule.Î±_bar[t]` ã¯ç´¯ç©ç©ï¼ˆcumprodï¼‰ã€‚`schedule.Î±[t]` ã¯å˜ã‚¹ãƒ†ãƒƒãƒ—ã® $1 - \beta_t$ã€‚forward diffusion ã§ `sqrt(schedule.Î±[t])` ã‚’ä½¿ã†ã¨ã€$t=500$ ã§ `Î±_bar[500] â‰ˆ 0.02` vs `Î±[500] â‰ˆ 0.98` ã¨ã„ã†å¤©ã¨åœ°ã®å·®ãŒç”Ÿã˜ã‚‹ã€‚å¸¸ã« `Î±_bar` (ç´¯ç©ç©) ã‚’ä½¿ã†ã“ã¨ã€‚

### 6.11 æ¬¡å›äºˆå‘Š: ç¬¬44å› éŸ³å£°ç”Ÿæˆ

**ãƒ†ãƒ¼ãƒ**: éŸ³å£°ç”Ÿæˆ (TTS / Music) â€” Neural Audio Codecs â†’ Zero-shot TTS â†’ Flow Matching for Audio

**ä¸»è¦ãƒˆãƒ”ãƒƒã‚¯**:
1. **Neural Audio Codecs** â€” SoundStream â†’ EnCodec â†’ WavTokenizer â†’ Mimi
2. **Zero-shot TTS** â€” VALL-E 2 / F5-TTS / XTTS
3. **Music Generation** â€” MusicGen / Stable Audio / Suno v4.5
4. **Flow Matching for Audio** â€” MelodyFlow / Audio Diffusion â†’ Flow Matching ç§»è¡Œ
5. **Audio è©•ä¾¡æŒ‡æ¨™** â€” FAD â†’ KAD / CLAP Score

**æ¥ç¶š**:
- **ç¬¬43å› DiT**: ç”»åƒç”Ÿæˆã®æ¬¡ä¸–ä»£ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- **ç¬¬44å› éŸ³å£°**: éŸ³å£°ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã¸ã®æ‹¡å¼µ
- **ç¬¬45å› å‹•ç”»**: æ™‚ç©ºé–“æ‹¡å¼µ (ç”»åƒ+éŸ³å£° â†’ å‹•ç”»)

**ç¬¬43å›ã®è¦–ç‚¹ã‹ã‚‰è¦‹ãŸç¬¬44å›ã®äºˆç¿’**: DiT ã§å­¦ã‚“ã ã€ŒTransformer + Diffusionã€ã®çµ„ã¿åˆã‚ã›ãŒéŸ³å£°ã§ã‚‚åŒã˜å½¢ã§ç™»å ´ã™ã‚‹ã€‚F5-TTS ã® DiT backbone ã¯ç¬¬43å›ã® DiTBlock ã¨ã»ã¼åŒä¸€ã®æ§‹é€ ã€‚å¤‰ã‚ã‚‹ã®ã¯ã€Œå…¥åŠ›ãŒãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã€ã€Œæ¡ä»¶ãŒãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ã€ã¨ã„ã†ç‚¹ã ã‘ã€‚ç¬¬43å›ã®æ•°å¼ï¼ˆAdaLN-Zeroã€Patchify/Unpatchifyï¼‰ã‚’å®Œå…¨ã«ç†è§£ã—ã¦ã„ã‚Œã°ã€ç¬¬44å›ã®éŸ³å£°ç”Ÿæˆã‚’ç´ æ—©ãç¿’å¾—ã§ãã‚‹ã€‚

**Course V ã®æµã‚Œ**:
```mermaid
graph LR
    A["ç¬¬43å›<br/>DiT (ç”»åƒ)"] --> B["ç¬¬44å›<br/>éŸ³å£°"]
    B --> C["ç¬¬45å›<br/>å‹•ç”»"]
    C --> D["ç¬¬46å›<br/>3D"]
    D --> E["ç¬¬47å›<br/>Motion/4D"]
    E --> F["ç¬¬48å›<br/>ç§‘å­¦å¿œç”¨"]
    F --> G["ç¬¬49å›<br/>Unified/Inference"]
    G --> H["ç¬¬50å›<br/>å’æ¥­åˆ¶ä½œ"]
```

**åˆ°é”ç›®æ¨™ (Course V ä¿®äº†æ™‚)**:
- å…¨ãƒ¢ãƒ€ãƒªãƒ†ã‚£ (ç”»åƒãƒ»éŸ³å£°ãƒ»å‹•ç”»ãƒ»3Dãƒ»ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ç§‘å­¦) ã§ã®ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…
- 3è¨€èªãƒ•ãƒ«ã‚¹ã‚¿ãƒƒã‚¯èƒ½åŠ› (ğŸ¦€Rust è¨“ç·´ + ğŸ¦€Rust æ¨è«– + ğŸ”®Elixir é…ä¿¡)
- 2025-2026 ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ç†è§£ (Flow Matching / Inference-Time Scaling / Modal Unification)
- è«–æ–‡ãŒæ›¸ã‘ã‚‹ (Course IV) + ã‚·ã‚¹ãƒ†ãƒ ãŒä½œã‚Œã‚‹ (Course V)

**æº–å‚™ã™ã‚‹ã“ã¨**:
- PyTorch Audio / torchaudio ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
- HuggingFace Transformers (éŸ³å£°ãƒ¢ãƒ‡ãƒ«ç”¨)
- Diffusers (Stable Audio ç”¨)

> **Note:** **ç¬¬43å›å®Œäº†ï¼ Course V ã‚¹ã‚¿ãƒ¼ãƒˆãƒ€ãƒƒã‚·ãƒ¥æˆåŠŸã€‚** DiTãƒ»MM-DiTãƒ»SiTãƒ»é«˜é€ŸSampling ã‚’å®Œå…¨ç¿’å¾—ã—ãŸã€‚æ¬¡ã¯éŸ³å£°ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã¸ â€” é™æ­¢ç”»ã‹ã‚‰æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã¸ã®æ‹¡å¼µã€‚ç¬¬44å›ã§ä¼šãŠã†ï¼

> **âš ï¸ Warning:** ã“ã®è¬›ç¾©ã§å®Ÿè£…ã—ãŸ Tiny DiT on MNIST ã¯æ•™è‚²ç”¨ã®ç°¡ç•¥å®Ÿè£…ã§ã‚ã‚Šã€æœ¬ç•ªå“è³ªã«ã¯ä¸ååˆ†ãªç‚¹ãŒã‚ã‚‹ã€‚ç‰¹ã«: (1) `MultiHeadAttention` ã®å®Ÿè£…ãŒ Candle ã®ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ç‰ˆã§ã¯ãªãã€(2) `patchify/unpatchify` ãŒç´”ç²‹ Rustï¼ˆBLAS æœ€é©åŒ–ãªã—ï¼‰ã€(3) AdaLN-Zero ã® Zero åˆæœŸåŒ–ãŒçœç•¥ã•ã‚Œã¦ã„ã‚‹ã€‚Production åˆ©ç”¨ã«ã¯ DiT å…¬å¼å®Ÿè£…ï¼ˆPyTorchï¼‰ã¾ãŸã¯ Candle ã®æœ€é©åŒ–ç‰ˆã‚’å‚ç…§ã®ã“ã¨ã€‚

---

## ğŸ’€ ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„

> **ã€ŒU-Netã¯"éºç‰©"ã€‚Stable Diffusion ã¯æ—¢ã«éå»ã§ã¯ï¼Ÿã€**

2023å¹´ã€DiT è«–æ–‡ãŒç™ºè¡¨ã•ã‚ŒãŸæ™‚ã€å¤šãã®ç ”ç©¶è€…ã¯æ‡ç–‘çš„ã ã£ãŸ:
- ã€ŒU-Net ã¯ CNN ã®å¸°ç´ãƒã‚¤ã‚¢ã‚¹ã‚’æ´»ç”¨ã—ã¦ã„ã‚‹ â€” ãªãœæ¨ã¦ã‚‹ï¼Ÿã€
- ã€ŒTransformer ã¯ $O(N^2)$ â€” ç”»åƒç”Ÿæˆã«ã¯éåŠ¹ç‡ã§ã¯ï¼Ÿã€
- ã€ŒDDPM / LDM ã¯æ—¢ã«ååˆ†é«˜å“è³ª â€” ãªãœå¤‰ãˆã‚‹ï¼Ÿã€

2024å¹´ã€SD3 ã¨ FLUX ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸã€‚ä¸¡æ–¹ã¨ã‚‚ DiT ãƒ™ãƒ¼ã‚¹ã€‚

2025å¹´ç¾åœ¨ã€DiT ã¯ **äº‹å®Ÿä¸Šã®æ¨™æº–** ã«ãªã£ãŸ:
- DALL-E 4 (æœªå…¬é–‹ã ãŒ DiT ã¨æ¨æ¸¬)
- Midjourney v7 (DiT ãƒ™ãƒ¼ã‚¹ã¨å™‚)
- ä¸­å›½ã®ä¸»è¦ãƒ¢ãƒ‡ãƒ« (Wan-2.1 / HunyuanVideo) ã‚‚ DiT

**2023å¹´ã®æ‡ç–‘è«–è€…ãŒé–“é•ãˆãŸç†ç”±**: U-Net ã® CNN å¸°ç´ãƒã‚¤ã‚¢ã‚¹ã¯ã€Œå°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ã‚„ã™ã„ã€ã¨ã„ã†åˆ©ç‚¹ã ã£ãŸã€‚ã—ã‹ã— SD3/FLUX ãƒ¬ãƒ™ãƒ«ã®ãƒ‡ãƒ¼ã‚¿è¦æ¨¡ï¼ˆæ•°å„„æšï¼‰ã§ã¯ã€å¸°ç´ãƒã‚¤ã‚¢ã‚¹ã¯åˆ¶ç´„ã«ãªã‚‹ã€‚Scaling Laws ã¯ã€Œå¸°ç´ãƒã‚¤ã‚¢ã‚¹ã‚’ç ´ã‚Šã€ãƒ‡ãƒ¼ã‚¿ã«ä»»ã›ã‚‹ã€ã¨ã„ã†çµè«–ã‚’å°ã â€” ã“ã‚Œã¯ ImageNet ã§ã® CNN â†’ ViT ã®ç§»è¡Œã¨å…¨ãåŒã˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‚

**å•ã„**:
1. **U-Net ã®å¸°ç´ãƒã‚¤ã‚¢ã‚¹ã¯æœ¬å½“ã«å¿…è¦ã ã£ãŸã®ã‹ï¼Ÿ** â€” ãã‚Œã¨ã‚‚ã€ãƒ‡ãƒ¼ã‚¿é‡ãŒå¢—ãˆã‚Œã°ä¸è¦ã«ãªã‚‹ï¼Ÿ
2. **Transformer ã® $O(N^2)$ ã¯æœ¬å½“ã«å•é¡Œã‹ï¼Ÿ** â€” Latent space åœ§ç¸®ã§å›é¿ã§ãã‚‹ãªã‚‰ï¼Ÿ
3. **æ¬¡ã®"éºç‰©"ã¯ä½•ã‹ï¼Ÿ** â€” DiT ã‚‚10å¹´å¾Œã«ã¯éå»ã®æŠ€è¡“ã«ãªã‚‹ï¼Ÿ

**è­°è«–ãƒã‚¤ãƒ³ãƒˆ**:
- **å¸°ç´ãƒã‚¤ã‚¢ã‚¹ vs ãƒ‡ãƒ¼ã‚¿é§†å‹•**: å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§ U-Net ãŒå‹ã¤ãŒã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ DiT ãŒå‹ã¤ã€‚ã§ã¯ã€ã€Œå°‘ãªã„ã€ã¨ã€Œå¤§è¦æ¨¡ã€ã®å¢ƒç•Œã¯ã©ã“ï¼Ÿ
- **Scaling Laws ã®æ™®éæ€§**: DiT ãŒ Scaling Laws ã«å¾“ã†ãªã‚‰ã€100B params DiT ã¯æ„å‘³ãŒã‚ã‚‹ï¼Ÿãã‚Œã¨ã‚‚é™ç•ŒãŒã‚ã‚‹ï¼Ÿ
- **æ¬¡ä¸–ä»£ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: Transformer ã®æ¬¡ã¯ä½•ï¼Ÿ State Space Models (Mamba)ï¼Ÿ ãã‚Œã¨ã‚‚æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ï¼Ÿ

**æ­´å²çš„æ–‡è„ˆ**:
- 2015: CNN ãŒç”»åƒèªè­˜ã‚’æ”¯é… (ResNet)
- 2020: Vision Transformer (ViT) ãŒ CNN ã‚’è¶…ãˆã‚‹
- 2023: DiT ãŒ U-Net ã‚’è¶…ãˆã‚‹
- 2025: DiT ãŒæ¨™æº–ã«
- 20XX: ???

**ã‚ãªãŸã®è€ƒãˆã¯ï¼Ÿ** â€” æ¬¡ã®é©å‘½ã¯ä½•ã‹ï¼Ÿ

**ä¸€ã¤ã®ç­”ãˆ**: 2015â†’2020â†’2023â†’2025 ã®å„é©å‘½ã¯ã€Œå¸°ç´ãƒã‚¤ã‚¢ã‚¹ã®å‰Šæ¸›ã€ã¨ã„ã†å…±é€šã®æ–¹å‘æ€§ã‚’æŒã¤ï¼ˆCNN ã®å±€æ‰€æ€§ â†’ ViT ã®å¤§åŸŸæ€§ â†’ DiT ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰ã€‚æ¬¡ã®é©å‘½ã¯ã€Œãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®å£ã€ã®å´©å£Šã‹ã‚‚ã—ã‚Œãªã„ â€” ç”»åƒãƒ»éŸ³å£°ãƒ»ãƒ†ã‚­ã‚¹ãƒˆãƒ»å‹•ç”»ã‚’å˜ä¸€ã®ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã¨ã—ã¦æ‰±ã†ã€ŒUniversal Generative Transformerã€ãŒç¬¬49å›ã®ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã§è­°è«–ã•ã‚Œã‚‹ã€‚

---

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... & Houlsby, N. (2020). "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale". *ICLR 2021*.
<https://arxiv.org/abs/2010.11929>

[^2]: Peebles, W., & Xie, S. (2023). "Scalable Diffusion Models with Transformers". *ICCV 2023*.
<https://arxiv.org/abs/2212.09748>

[^3]: Esser, P., Kulal, S., Blattmann, A., Entezari, R., MÃ¼ller, J., Saini, H., ... & Rombach, R. (2024). "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis". *arXiv:2403.03206*.
<https://arxiv.org/abs/2403.03206>

[^4]: Black Forest Labs. (2024). "FLUX: A New Era of Generative AI". *Official Blog*.
<https://blackforestlabs.ai/announcing-black-forest-labs/>

[^5]: Ba, J. L., Kiros, J. R., & Hinton, G. E. (2016). "Layer Normalization". *arXiv:1607.06450*.
<https://arxiv.org/abs/1607.06450>

[^7]: Hendrycks, D., & Gimpel, K. (2016). "Gaussian Error Linear Units (GELUs)". *arXiv:1606.08415*.
<https://arxiv.org/abs/1606.08415>

[^8]: Ma, N., Goldstein, M., Albergo, M. S., Boffi, N. M., Vanden-Eijnden, E., & Xie, S. (2024). "SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers". *ICML 2024*.
<https://arxiv.org/abs/2401.08740>

[^9]: Lu, C., Zhou, Y., Bao, F., Chen, J., Li, C., & Zhu, J. (2022). "DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models". *NeurIPS 2022*.
<https://arxiv.org/abs/2211.01095>

[^10]: Karras, T., Aittala, M., Aila, T., & Laine, S. (2022). "Elucidating the Design Space of Diffusion-Based Generative Models". *NeurIPS 2022*.
<https://arxiv.org/abs/2206.00364>

[^11]: Patel, S., Katsch, M., Thulke, D., Daras, G., Shi, H., Karrer, B., ... & Susskind, J. (2024). "aMUSEd: An Open MUSE Reproduction". *arXiv:2410.14086*.
<https://arxiv.org/abs/2410.14086>

[^12]: Jia, W., Huang, M., Chen, N., Zhang, L., & Mao, Z. (2025). "D2iT: Dynamic Diffusion Transformer for Accurate Image Generation". *CVPR 2025*. arXiv:2504.09454.
<https://arxiv.org/abs/2504.09454>

[^13]: Zhao, W., et al. (2025). "DyDiT++: Diffusion Transformers with Timestep and Spatial Dynamics for Efficient Visual Generation". *arXiv:2504.06803*.
<https://arxiv.org/abs/2504.06803>

[^14]: Z-Image Team. (2025). "Z-Image: An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer". *arXiv:2511.22699*.
<https://arxiv.org/abs/2511.22699>

[^15]: Li, S., et al. (2025). "Reflect-DiT: Inference-Time Scaling for Text-to-Image Diffusion Transformers via In-Context Reflection". *arXiv:2503.12271*.
<https://arxiv.org/abs/2503.12271>

### æ•™ç§‘æ›¸

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press. Chapter 20: Generative Models.
<https://www.deeplearningbook.org/>

- Murphy, K. P. (2022). *Probabilistic Machine Learning: Advanced Topics*. MIT Press. Chapter 27: Diffusion Models.
<https://probml.github.io/pml-book/book2.html>
## ğŸ“š è£œè¶³è³‡æ–™: è©³ç´°å°å‡ºã¨å®Ÿè£…ã‚¬ã‚¤ãƒ‰

### A. SiT (Stochastic Interpolants) ã®å®Œå…¨å°å‡º

**èƒŒæ™¯**: SiT ã¯ Flow Matching (ç¬¬38å›) ã‚’ç¢ºç‡çš„ã«æ‹¡å¼µã—ãŸãƒ¢ãƒ‡ãƒ«ã€‚ã“ã“ã§ã¯ã€Stochastic Interpolants ã®ç†è«–çš„åŸºç›¤ã‚’å®Œå…¨å°å‡ºã™ã‚‹ã€‚

#### A.1 Interpolant ã®ä¸€èˆ¬åŒ–

**æ±ºå®šè«–çš„è£œé–“** (Flow Matching):
$$
\mathbf{x}_t = (1-t) \mathbf{x}_0 + t \mathbf{x}_1
$$

**ç¢ºç‡çš„è£œé–“** (Stochastic Interpolants):
$$
\mathbf{x}_t = \alpha(t) \mathbf{x}_0 + \beta(t) \mathbf{x}_1 + \gamma(t) \mathbf{z}
$$
ã“ã“ã§:
- $\mathbf{x}_0 \sim p_0$ (ãƒã‚¤ã‚ºåˆ†å¸ƒã€ä¾‹: $\mathcal{N}(0, I)$)
- $\mathbf{x}_1 \sim p_1$ (ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ)
- $\mathbf{z} \sim \mathcal{N}(0, I)$ (ç¢ºç‡çš„é …)
- $\alpha(t), \beta(t), \gamma(t)$ â€” è£œé–“é–¢æ•°

**å¢ƒç•Œæ¡ä»¶**:
$$
\begin{align}
t = 0: &\quad \alpha(0) = 1, \beta(0) = 0, \gamma(0) = \sigma_0 \\
t = 1: &\quad \alpha(1) = 0, \beta(1) = 1, \gamma(1) = \sigma_1
\end{align}
$$
- $\sigma_0, \sigma_1 \geq 0$ â€” å¢ƒç•Œã§ã®ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«

**ç‰¹æ®Šã‚±ãƒ¼ã‚¹**:
- $\gamma(t) = 0$ â†’ Flow Matching (æ±ºå®šè«–çš„)
- $\gamma(t) > 0$ â†’ Stochastic Interpolants (ç¢ºç‡çš„)

#### A.2 ãƒ™ã‚¯ãƒˆãƒ«å ´ã®å°å‡º

**æ™‚é–“å¾®åˆ†** (ItÃ´ ã®è£œé¡Œã‚’ä½¿ç”¨):
$$
\begin{align}
d\mathbf{x}_t &= \frac{\partial}{\partial t}[\alpha(t) \mathbf{x}_0 + \beta(t) \mathbf{x}_1 + \gamma(t) \mathbf{z}] \, dt + \gamma'(t) \, d\mathbf{W}_t \\
&= [\alpha'(t) \mathbf{x}_0 + \beta'(t) \mathbf{x}_1 + \gamma'(t) \mathbf{z}] \, dt + \gamma'(t) \, d\mathbf{W}_t
\end{align}
$$

**ãƒ‰ãƒªãƒ•ãƒˆé …** (ãƒ™ã‚¯ãƒˆãƒ«å ´):
$$
\mathbf{v}_t = \alpha'(t) \mathbf{x}_0 + \beta'(t) \mathbf{x}_1 + \gamma'(t) \mathbf{z}
$$

**æ‹¡æ•£é …**:
$$
\sigma_t = \gamma'(t)
$$

#### A.3 è¨“ç·´ç›®æ¨™

**æ¡ä»¶ä»˜ããƒ™ã‚¯ãƒˆãƒ«å ´**:
$$
\mathbf{v}_t(\mathbf{x}_t | \mathbf{x}_1) = \mathbb{E}[\mathbf{v}_t | \mathbf{x}_t, \mathbf{x}_1]
$$

**æå¤±é–¢æ•°**:
$$
\mathcal{L}_{\text{SiT}} = \mathbb{E}_{t, \mathbf{x}_0, \mathbf{x}_1, \mathbf{z}} \left[\left\| \mathbf{v}_\theta(\mathbf{x}_t, t) - \mathbf{v}_t \right\|^2\right]
$$

**å°å‡ºã®è©³ç´°**:
1. $\mathbf{x}_t$ ã‚’ã‚µãƒ³ãƒ—ãƒ«: $\mathbf{x}_t = \alpha(t) \mathbf{x}_0 + \beta(t) \mathbf{x}_1 + \gamma(t) \mathbf{z}$
2. çœŸã®ãƒ™ã‚¯ãƒˆãƒ«å ´ã‚’è¨ˆç®—: $\mathbf{v}_t = \alpha'(t) \mathbf{x}_0 + \beta'(t) \mathbf{x}_1 + \gamma'(t) \mathbf{z}$
3. ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã§äºˆæ¸¬: $\mathbf{v}_\theta(\mathbf{x}_t, t)$
4. MSE æå¤±: $\|\mathbf{v}_\theta - \mathbf{v}_t\|^2$

#### A.4 å…·ä½“çš„ãªè£œé–“é–¢æ•°ã®è¨­è¨ˆ

**SiT è«–æ–‡ã§ä½¿ç”¨ã•ã‚Œã‚‹é–¢æ•°**:
$$
\begin{align}
\alpha(t) &= 1 - t \\
\beta(t) &= t \\
\gamma(t) &= \sigma_{\min} + (\sigma_{\max} - \sigma_{\min}) \sqrt{t(1-t)}
\end{align}
$$

**å°é–¢æ•°**:
$$
\begin{align}
\alpha'(t) &= -1 \\
\beta'(t) &= 1 \\
\gamma'(t) &= (\sigma_{\max} - \sigma_{\min}) \frac{1 - 2t}{2\sqrt{t(1-t)}}
\end{align}
$$

**æ•°å€¤æ¤œè¨¼**:
```rust
// SiT interpolation functions
fn alpha(t: f32) -> f32 { 1.0 - t }
fn beta_sit(t: f32) -> f32 { t }

const SIGMA_MIN: f32 = 0.001;
const SIGMA_MAX: f32 = 0.1;

fn gamma(t: f32) -> f32 {
    SIGMA_MIN + (SIGMA_MAX - SIGMA_MIN) * (t * (1.0 - t)).sqrt()
}

// Derivatives
fn alpha_prime(_t: f32) -> f32 { -1.0 }
fn beta_prime(_t: f32) -> f32 { 1.0 }
fn gamma_prime(t: f32) -> f32 {
    (SIGMA_MAX - SIGMA_MIN) * (1.0 - 2.0 * t) / (2.0 * (t * (1.0 - t)).sqrt())
}

fn main() {
    let t = 0.5_f32;
    println!("Î±(0.5) = {}", alpha(t));        // 0.5
    println!("Î²(0.5) = {}", beta_sit(t));     // 0.5
    println!("Î³(0.5) = {}", gamma(t));        // Ïƒ_min + (Ïƒ_max - Ïƒ_min) * 0.5
    println!("Î³'(0.5) = {}", gamma_prime(t)); // 0 (extremum at t=0.5)
}
```

#### A.5 SiT vs DDPM ã®é–¢ä¿‚

**DDPM ã®é›¢æ•£åŒ–**:
$$
\mathbf{x}_t = \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \boldsymbol{\epsilon}
$$

**SiT ã®é€£ç¶šåŒ–** ($\mathbf{x}_0 \leftrightarrow \mathbf{x}_1$ ã‚’å…¥ã‚Œæ›¿ãˆ):
$$
\mathbf{x}_t = \alpha(t) \mathbf{x}_1 + \gamma(t) \mathbf{z}
$$
ã“ã“ã§ $\beta(t) = 0$ (ãƒã‚¤ã‚ºã‹ã‚‰ç›´æ¥ãƒ‡ãƒ¼ã‚¿ã¸)ã€‚

**å¯¾å¿œé–¢ä¿‚**:
- DDPM ã® $\sqrt{\bar{\alpha}_t}$ â†” SiT ã® $\alpha(t)$
- DDPM ã® $\sqrt{1 - \bar{\alpha}_t}$ â†” SiT ã® $\gamma(t)$

**å·®ç•°**:
- DDPM: é›¢æ•£æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ— ($t \in \{1, 2, \ldots, T\}$)
- SiT: é€£ç¶šæ™‚é–“ ($t \in [0, 1]$)
- DDPM: ãƒãƒ«ã‚³ãƒ•é€£é–
- SiT: ODE/SDE

#### A.6 Sampling ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

**Euler-Maruyama æ³•** (SDE solver):
$$
\mathbf{x}_{t+\Delta t} = \mathbf{x}_t + \mathbf{v}_\theta(\mathbf{x}_t, t) \Delta t + \gamma'(t) \sqrt{\Delta t} \, \boldsymbol{\epsilon}
$$

**å®Ÿè£…**:
```rust
// SiT Euler-Maruyama sampling
fn sit_sample<F>(model: F, num_steps: usize) -> Vec<f32>
where
    F: Fn(&[f32], f32) -> Vec<f32>,
{
    let d = 256; // data dimension
    let mut rng = rand::thread_rng();
    let dist = Normal::new(0.0_f32, 1.0).unwrap();
    let mut x_t: Vec<f32> = (0..d).map(|_| rand::Rng::sample(&mut rng, dist)).collect();

    let dt = 1.0_f32 / num_steps as f32;
    for i in 0..num_steps {
        let t = i as f32 * dt;
        let v_pred = model(&x_t, t);
        let noise: Vec<f32> = (0..d).map(|_| rand::Rng::sample(&mut rng, dist)).collect();
        // x_{t+dt} = x_t + v_Î¸(x_t,t)Â·dt + Î³'(t)Â·âˆšdtÂ·Îµ  (Euler-Maruyama for SDE)
        x_t = x_t.iter().zip(&v_pred).zip(&noise)
            .map(|((&x, &v), &n)| x + v * dt + gamma_prime(t) * dt.sqrt() * n)
            .collect();
    }

    x_t
}
```

**é«˜æ¬¡ solver** (Heun's method):
```rust
// SiT Heun sampling (é«˜æ¬¡ solver)
fn sit_sample_heun<F>(model: F, d: usize, num_steps: usize) -> Vec<f32>
where
    F: Fn(&[f32], f32) -> Vec<f32>,
{
    let mut rng = rand::thread_rng();
    let dist = Normal::new(0.0_f32, 1.0).unwrap();
    let mut x_t: Vec<f32> = (0..d).map(|_| rand::Rng::sample(&mut rng, dist)).collect();
    let dt = 1.0_f32 / num_steps as f32;

    for i in 0..num_steps {
        let t = i as f32 * dt;

        let v1 = model(&x_t, t);                          // vâ‚ = v_Î¸(x_t, t)  (predictor)
        // x_euler = x_t + vâ‚Â·dt  (Euler predictor step)
        let x_euler: Vec<f32> = x_t.iter().zip(&v1)
            .map(|(&x, &v)| x + v * dt)
            .collect();

        let v2 = model(&x_euler, t + dt);                 // vâ‚‚ = v_Î¸(x_euler, t+dt)  (corrector)
        let noise: Vec<f32> = (0..d).map(|_| rand::Rng::sample(&mut rng, dist)).collect();
        // x_{t+dt} = x_t + (vâ‚+vâ‚‚)/2Â·dt + Î³'(t)Â·âˆšdtÂ·Îµ  (Heun 2nd-order)
        x_t = x_t.iter().zip(&v1).zip(&v2).zip(&noise)
            .map(|(((&x, &v1), &v2), &n)| {
                x + (v1 + v2) / 2.0 * dt + gamma_prime(t) * dt.sqrt() * n
            })
            .collect();
    }

    x_t
}
```

---

## è‘—è€…ãƒªãƒ³ã‚¯

- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
