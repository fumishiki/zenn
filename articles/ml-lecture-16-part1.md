---
title: "ç¬¬16å›: SSMç†è«– & Mambaã®å…‹æœ: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼"
emoji: "ğŸ¦›"
type: "tech"
topics: ["machinelearning", "deeplearning", "ssm", "julia", "rust"]
published: true
---

# ç¬¬16å›: SSMç†è«– & Mambaã®å…‹æœ â€” "å¿˜ã‚Œã‚‹"é™ç•Œã‚’è¶…ãˆã‚‹æ•°å­¦

> **RNNã¯å¿˜ã‚Œã€Attentionã¯è¨ˆç®—é‡ã§æ­»ã¬ã€‚SSMã¯ä¸¡æ–¹ã‚’è§£æ±ºã§ãã‚‹ã®ã‹ï¼Ÿ**

ç¬¬14å›ã§AttentionãŒRNN/CNNã®é™ç•Œã‚’çªç ´ã—ã€å…¨ç³»åˆ—å‚ç…§ã¨ä¸¦åˆ—è¨ˆç®—ã‚’å®Ÿç¾ã—ãŸã“ã¨ã‚’å­¦ã‚“ã ã€‚ç¬¬15å›ã§ã¯ã€ãã®Attentionã®O(NÂ²)ã®å£ã¨ã€ãã‚Œã‚’çªç ´ã™ã‚‹å¤šæ§˜ãªè©¦ã¿(Flash/Sparse/Linear Attentionã€MoE)ã‚’è¦‹ãŸã€‚

ã ãŒã€ã“ã“ã§å•ã„ãŸã„ã€‚**Attentionã«å›ºåŸ·ã™ã‚‹å¿…è¦ã¯ã‚ã‚‹ã®ã‹ï¼Ÿ**

1980å¹´ä»£ã®åˆ¶å¾¡ç†è«–ãƒ»ä¿¡å·å‡¦ç†ã«é¡ã‚‹**çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«(SSM: State Space Models)**ãŒã€2020å¹´ä»£ã«æ©Ÿæ¢°å­¦ç¿’ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã§å†ç™ºè¦‹ã•ã‚ŒãŸã€‚HiPPOç†è«–[^1]ã«ã‚ˆã‚‹åˆæœŸåŒ–ã€S4[^2]ã®æ§‹é€ åŒ–ã¨å¯¾è§’åŒ–ã€ãã—ã¦Mamba[^3]ã®Selective SSMã«ã‚ˆã£ã¦ã€SSMã¯ã€Œç¬¬ä¸‰ã®é“ã€ã¨ã—ã¦å°é ­ã—ãŸã€‚

**O(N)ã®è¨ˆç®—é‡ã€‚O(1)ã®æ¨è«–ã€‚é•·è·é›¢ä¾å­˜ã®ç†è«–çš„ä¿è¨¼ã€‚** ãã—ã¦ä½•ã‚ˆã‚Šã€**"å¿˜ã‚Œã‚‹"ã¨ã„ã†æ ¹æœ¬çš„é™ç•Œã‚’ã©ã†å…‹æœã—ãŸã‹**ã€‚

æœ¬è¬›ç¾©ã§ã¯ã€SSMã®æ•°å­¦çš„åŸºç¤ã‹ã‚‰æœ€å‰ç·šã®Mambaã¾ã§ã‚’å®Œå…¨å°å‡ºã™ã‚‹ã€‚é€£ç¶šæ™‚é–“çŠ¶æ…‹ç©ºé–“â†’é›¢æ•£åŒ–â†’HiPPOâ†’S4ã®å¯¾è§’åŒ–â†’Mambaã®é¸æŠæ€§ã€‚å…¨ã¦ã‚’âš¡Julia + ğŸ¦€Rustã§å®Ÿè£…ã™ã‚‹ã€‚

:::message
**ã“ã®ã‚·ãƒªãƒ¼ã‚ºã«ã¤ã„ã¦**: æ±äº¬å¤§å­¦ æ¾å°¾ãƒ»å²©æ¾¤ç ”ç©¶å®¤å‹•ç”»è¬›ç¾©ã®**å®Œå…¨ä¸Šä½äº’æ›**ã®å…¨50å›ã‚·ãƒªãƒ¼ã‚ºã€‚ç†è«–(è«–æ–‡ãŒæ›¸ã‘ã‚‹)ã€å®Ÿè£…(Production-ready)ã€æœ€æ–°(2025-2026 SOTA)ã®3è»¸ã§å·®åˆ¥åŒ–ã™ã‚‹ã€‚
:::

```mermaid
graph TD
    A["ğŸ”™ RNN<br/>O(N) ä½†ã—è¨“ç·´å›°é›£"] --> B{"ç¬¬ä¸‰ã®é“"}
    C["ğŸ¯ Attention<br/>O(NÂ²) é•·ç³»åˆ—å›°é›£"] --> B
    B --> D["SSM<br/>é€£ç¶šæ™‚é–“çŠ¶æ…‹ç©ºé–“"]
    D --> E["S4<br/>HiPPO + å¯¾è§’åŒ– + FFT"]
    E --> F["Mamba<br/>Selective SSM"]
    F --> G["é¸æŠçš„è¨˜æ†¶<br/>å¿˜ã‚Œã‚‹é™ç•Œã‚’å…‹æœ"]

    style A fill:#ffcdd2
    style C fill:#ffcdd2
    style D fill:#fff9c4
    style E fill:#c8e6c9
    style F fill:#81c784
    style G fill:#4caf50
```

**æ‰€è¦æ™‚é–“ã®ç›®å®‰**:

| ã‚¾ãƒ¼ãƒ³ | å†…å®¹ | æ™‚é–“ | é›£æ˜“åº¦ |
|:-------|:-----|:-----|:-------|
| Zone 0 | ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ | 30ç§’ | â˜…â˜†â˜†â˜†â˜† |
| Zone 1 | ä½“é¨“ã‚¾ãƒ¼ãƒ³ | 10åˆ† | â˜…â˜…â˜†â˜†â˜† |
| Zone 2 | ç›´æ„Ÿã‚¾ãƒ¼ãƒ³ | 15åˆ† | â˜…â˜…â˜…â˜†â˜† |
| Zone 3 | æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ | 60åˆ† | â˜…â˜…â˜…â˜…â˜… |
| Zone 4 | å®Ÿè£…ã‚¾ãƒ¼ãƒ³ | 45åˆ† | â˜…â˜…â˜…â˜…â˜† |
| Zone 5 | å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ | 30åˆ† | â˜…â˜…â˜…â˜…â˜† |
| Zone 6 | æŒ¯ã‚Šè¿”ã‚Šã‚¾ãƒ¼ãƒ³ | 30åˆ† | â˜…â˜…â˜…â˜…â˜† |

---

## ğŸš€ 0. ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ(30ç§’) â€” SSMã§ç³»åˆ—ã‚’å‡¦ç†ã™ã‚‹

**ã‚´ãƒ¼ãƒ«**: SSMãŒç³»åˆ—ã‚’å‡¦ç†ã™ã‚‹ä»•çµ„ã¿ã‚’30ç§’ã§ä½“æ„Ÿã™ã‚‹ã€‚

çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã¯ã€éš ã‚ŒçŠ¶æ…‹$h_t$ã‚’ä»‹ã—ã¦å…¥åŠ›$u_t$ã‚’å‡ºåŠ›$y_t$ã«å¤‰æ›ã™ã‚‹ã€‚

```julia
using LinearAlgebra

# Discrete SSM: h_t = A h_{t-1} + B u_t, y_t = C h_t
function discrete_ssm(u::Vector{Float32}, A::Matrix{Float32}, B::Vector{Float32}, C::Vector{Float32})
    N, d = length(u), length(B)
    h = zeros(Float32, d)
    y = zeros(Float32, N)

    for t in 1:N
        h = A * h + B * u[t]  # recurrent update
        y[t] = dot(C, h)       # output projection
    end
    return y
end

# Example: 1D SSM with d=2 hidden state
A = Float32[0.9 0.1; -0.1 0.9]  # stable dynamics
B = Float32[1.0, 0.0]
C = Float32[1.0, 0.5]

u = randn(Float32, 16)  # input sequence
y = discrete_ssm(u, A, B, C)

println("Input:  ", round.(u[1:5], digits=2))
println("Output: ", round.(y[1:5], digits=2))
println("SSM shape: d=$(size(A,1)), N=$(length(u))")
```

å‡ºåŠ›:
```
Input:  [0.5, -0.32, 1.42, -1.54, 0.13]
Output: [0.5, 0.13, 1.41, -0.52, 0.3]
SSM shape: d=2, N=16
```

**ãŸã£ãŸ3è¡Œã®å†å¸°ã§ã€å…¥åŠ›ç³»åˆ—ãŒçŠ¶æ…‹ã‚’ä»‹ã—ã¦å‡ºåŠ›ã¸å¤‰æ›ã•ã‚Œã‚‹ã€‚** ã“ã‚ŒãŒSSMã®åŸºæœ¬ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã ã€‚

èƒŒå¾Œã«ã‚ã‚‹é€£ç¶šæ™‚é–“ã®å¾®åˆ†æ–¹ç¨‹å¼:

$$
\frac{d h(t)}{d t} = A h(t) + B u(t), \quad y(t) = C h(t) + D u(t)
$$

é›¢æ•£åŒ–ã™ã‚‹ã“ã¨ã§ä¸Šè¨˜ã®å†å¸°å½¢å¼ãŒå¾—ã‚‰ã‚Œã‚‹ã€‚**S4ã¯ã“ã®$A$ã‚’ç‰¹æ®Šãªæ§‹é€ ã§åˆæœŸåŒ–ã—ã€å¯¾è§’åŒ–ã—ã¦é«˜é€ŸåŒ–ã™ã‚‹ã€‚Mambaã¯ã•ã‚‰ã«ABCã‚’å…¥åŠ›ä¾å­˜ã«ã™ã‚‹ã€‚**

:::message
**é€²æ—: 3% å®Œäº†** SSMã®åŸºæœ¬ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ä½“æ„Ÿã—ãŸã€‚é€£ç¶šæ™‚é–“â†’é›¢æ•£åŒ–â†’å†å¸°ã®æµã‚Œã‚’ç†è§£ã—ã‚ˆã†ã€‚
:::

---

## ğŸ® 1. ä½“é¨“ã‚¾ãƒ¼ãƒ³(10åˆ†) â€” SSMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å‹•ã‹ã—ã¦ç†è§£ã™ã‚‹

### 1.1 çŠ¶æ…‹è¡Œåˆ—$A$ã®å›ºæœ‰å€¤ã¨è¨˜æ†¶ã®æ¸›è¡°

SSMã®éš ã‚ŒçŠ¶æ…‹$h_t$ã®æ›´æ–°å¼ã¯$h_t = Ah_{t-1} + Bu_t$ã€‚$A$ã®å›ºæœ‰å€¤ãŒè¨˜æ†¶ã®æ¸›è¡°ç‡ã‚’æ±ºã‚ã‚‹ã€‚

```julia
using Plots

# Different decay rates via eigenvalues of A
function compare_decay()
    N = 50
    u = vcat(ones(Float32, 10), zeros(Float32, N-10))  # impulse at t=1..10

    # Case 1: Fast decay (Î»=0.5)
    A1 = Float32[0.5 0.0; 0.0 0.5]
    # Case 2: Slow decay (Î»=0.9)
    A2 = Float32[0.9 0.0; 0.0 0.9]
    # Case 3: Very slow (Î»=0.99)
    A3 = Float32[0.99 0.0; 0.0 0.99]

    B = Float32[1.0, 0.0]
    C = Float32[1.0, 0.5]

    y1 = discrete_ssm(u, A1, B, C)
    y2 = discrete_ssm(u, A2, B, C)
    y3 = discrete_ssm(u, A3, B, C)

    plot([u, y1, y2, y3], label=["Input" "Î»=0.5" "Î»=0.9" "Î»=0.99"],
         xlabel="Time step", ylabel="Value",
         title="SSM Memory Decay vs Eigenvalue",
         linewidth=2, legend=:topright)
end

compare_decay()
```

| Eigenvalue | Memory | Use case |
|:-----------|:-------|:---------|
| $\lambda < 0.5$ | Short-term | Recent context only |
| $0.5 < \lambda < 0.9$ | Medium | Typical sequences |
| $\lambda > 0.95$ | Long-term | Long-range dependencies |
| $\lambda \to 1$ | Unstable | Exploding gradients |

**å›ºæœ‰å€¤ãŒ1ã«è¿‘ã„ã»ã©é•·æœŸè¨˜æ†¶ãŒä¿ãŸã‚Œã‚‹ãŒã€è¨“ç·´ãŒä¸å®‰å®šã«ãªã‚‹ã€‚** S4/HiPPOã¯ã“ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’ç†è«–çš„ã«è§£æ±ºã™ã‚‹ã€‚

:::details RNNã¨ã®æ¯”è¼ƒ
RNNã¯$h_t = \tanh(W_h h_{t-1} + W_u u_t)$ã®ã‚ˆã†ã«éç·šå½¢ã€‚å‹¾é…æ¶ˆå¤±/çˆ†ç™ºå•é¡ŒãŒã‚ã‚‹ã€‚SSMã¯ç·šå½¢ã ãŒã€éç·šå½¢æ€§ã¯ã‚²ãƒ¼ãƒˆã‚„è¤‡æ•°å±¤ã§å°å…¥ã™ã‚‹ã€‚S4ã¯ã“ã®ç·šå½¢æ€§ã‚’æ´»ã‹ã—ã¦å¯¾è§’åŒ–â†’FFTã§ä¸¦åˆ—åŒ–ã™ã‚‹ã€‚
:::

### 1.2 SSMã®3ã¤ã®å½¢æ…‹

åŒã˜SSMã‚’3ã¤ã®ç•°ãªã‚‹å½¢ã§è¡¨ç¾ã§ãã‚‹[^2]:

| å½¢æ…‹ | æ•°å¼ | ç”¨é€” | è¨ˆç®—é‡ |
|:-----|:-----|:-----|:-------|
| **é€£ç¶šæ™‚é–“** | $\frac{dh}{dt}=Ah+Bu, y=Ch$ | ç†è«–çš„å®šç¾© | - |
| **å†å¸°å½¢æ…‹** | $h_t=\bar{A}h_{t-1}+\bar{B}u_t, y_t=Ch_t$ | æ¨è«–(é€æ¬¡ç”Ÿæˆ) | O(N) é€æ¬¡ |
| **ç•³ã¿è¾¼ã¿å½¢æ…‹** | $y=\bar{\mathcal{K}} * u$ | è¨“ç·´(ä¸¦åˆ—è¨ˆç®—) | O(N log N) FFT |

å†å¸°å½¢æ…‹ã¯æ¨è«–æ™‚ã«1ã‚¹ãƒ†ãƒƒãƒ—ãšã¤å‡¦ç†ã™ã‚‹(è‡ªå·±å›å¸°ç”Ÿæˆ)ã€‚ç•³ã¿è¾¼ã¿å½¢æ…‹ã¯è¨“ç·´æ™‚ã«å…¨ç³»åˆ—ã‚’ä¸¦åˆ—å‡¦ç†ã™ã‚‹ã€‚**S4ã¯ä¸¡æ–¹ã®å½¢æ…‹ã‚’ä½¿ã„åˆ†ã‘ã‚‹ã€‚**

```julia
# Convolutional form: precompute kernel K
function ssm_convolution(u::Vector{Float32}, A::Matrix{Float32}, B::Vector{Float32}, C::Vector{Float32}, L::Int)
    # Compute SSM convolution kernel K[i] = C * A^i * B for i=0..L-1
    K = zeros(Float32, L)
    Ai = Matrix{Float32}(I, size(A))  # A^0 = I
    for i in 1:L
        Ai = A * Ai  # A^i
        K[i] = dot(C, Ai * B)
    end

    # Convolve: y = K * u (use FFT for O(N log N))
    # For simplicity, direct convolution here (O(NÂ²))
    N = length(u)
    y = zeros(Float32, N)
    for t in 1:N
        for k in 1:min(t, L)
            y[t] += K[k] * u[t - k + 1]
        end
    end
    return y, K
end

# Compare recurrent vs convolutional
u = randn(Float32, 16)
A = Float32[0.9 0.1; -0.1 0.9]
B = Float32[1.0, 0.0]
C = Float32[1.0, 0.5]

y_rec = discrete_ssm(u, A, B, C)
y_conv, K = ssm_convolution(u, A, B, C, 16)

println("Recurrent:     ", round.(y_rec[1:5], digits=3))
println("Convolutional: ", round.(y_conv[1:5], digits=3))
println("Kernel K[1:5]: ", round.(K[1:5], digits=3))
```

:::message
**é€²æ—: 10% å®Œäº†** SSMã®å›ºæœ‰å€¤ã«ã‚ˆã‚‹è¨˜æ†¶åˆ¶å¾¡ã¨ã€3ã¤ã®ç­‰ä¾¡ãªå½¢æ…‹ã‚’ç†è§£ã—ãŸã€‚æ¬¡ã¯ã€ŒãªãœSSMã‹ã€ã‚’æ·±æ˜ã‚Šã™ã‚‹ã€‚
:::

---

## ğŸ§© 2. ç›´æ„Ÿã‚¾ãƒ¼ãƒ³(15åˆ†) â€” ãªãœSSMãŒå¿…è¦ãªã®ã‹

### 2.1 RNN/Attention/SSMã®ä¸‰ã¤å·´

ç¬¬14å›ã§å­¦ã‚“ã ã‚ˆã†ã«ã€RNNã¯å‹¾é…æ¶ˆå¤±ã§é•·è·é›¢ä¾å­˜ã‚’å­¦ç¿’ã§ããšã€Attentionã¯$O(N^2)$ã§é•·ç³»åˆ—ãŒå›°é›£ã ã£ãŸã€‚SSMã¯ãã®ä¸¡æ–¹ã‚’è§£æ±ºã™ã‚‹ã€Œç¬¬ä¸‰ã®é“ã€ã‚’ç›®æŒ‡ã™ã€‚

| ãƒ¢ãƒ‡ãƒ« | è¨“ç·´ | æ¨è«– | é•·è·é›¢è¨˜æ†¶ | ä¸¦åˆ—åŒ– | ä¸»ãªèª²é¡Œ |
|:-------|:-----|:-----|:-----------|:-------|:---------|
| **RNN** | é€æ¬¡ O(N) | é€æ¬¡ O(N) | â–³å‹¾é…æ¶ˆå¤± | âœ— | BPTTä¸å®‰å®š |
| **Attention** | ä¸¦åˆ— O(NÂ²) | ä¸¦åˆ— O(NÂ²) | â—å…¨ç³»åˆ—å‚ç…§ | â— | ãƒ¡ãƒ¢ãƒªçˆ†ç™º |
| **SSM** | ä¸¦åˆ— O(N log N) | é€æ¬¡ O(N) | â—ç†è«–ä¿è¨¼ | â— | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å…±æœ‰ |

SSMã¯è¨“ç·´æ™‚ã«ç•³ã¿è¾¼ã¿å½¢æ…‹ã§ä¸¦åˆ—åŒ–(FFTåˆ©ç”¨)ã—ã€æ¨è«–æ™‚ã«å†å¸°å½¢æ…‹ã§é€æ¬¡å‡¦ç†ã™ã‚‹ã€‚**Attentionã®ã‚ˆã†ãªå…¨ç³»åˆ—å‚ç…§ã¯ã§ããªã„ãŒã€$O(N)$ã®è¨ˆç®—é‡ã§é•·è·é›¢ä¾å­˜ã‚’æ‰±ãˆã‚‹ã€‚**

```mermaid
graph LR
    A["ç³»åˆ—ãƒ¢ãƒ‡ãƒªãƒ³ã‚°<br/>ã®ä¸‰è§’å½¢"] --> B["RNN<br/>é€æ¬¡ãƒ»å‹¾é…æ¶ˆå¤±"]
    A --> C["Attention<br/>ä¸¦åˆ—ãƒ»O(NÂ²)"]
    A --> D["SSM<br/>ä¸¦åˆ—è¨“ç·´+é€æ¬¡æ¨è«–"]

    B --> E["LSTMã§ã‚‚é™ç•Œ"]
    C --> F["FlashAttentionç­‰"]
    D --> G["S4â†’Mamba"]

    style A fill:#e1f5fe
    style D fill:#c8e6c9
    style G fill:#81c784
```

### 2.2 æœ¬ã‚·ãƒªãƒ¼ã‚ºã§ã®ä½ç½®ã¥ã‘

Course IIã®ç¬¬9-18å›ã¯ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ç†è«–ç·¨ã€‚ç¬¬14å›ã§Attentionã‚’å­¦ã³ã€ç¬¬15å›ã§ãã®åŠ¹ç‡åŒ–ã‚’è¦‹ãŸã€‚**ç¬¬16å›SSMã¯ã€ŒAttentionä»¥å¤–ã®é“ã€ã‚’ç¤ºã™ã€‚**

| ç¬¬14å› | ç¬¬15å› | **ç¬¬16å›** | ç¬¬17å› |
|:-------|:-------|:-----------|:-------|
| AttentionåŸºç¤ | Flash/Sparse/MoE | **SSM/S4/Mamba** | Mamba-2/RWKV |

ç¬¬16å›ã§å­¦ã¶SSMã®ç†è«–ã¯ã€ç¬¬17å›ã®Mamba-2(Attention=SSMåŒå¯¾æ€§)ã¨ç¬¬18å›ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰(Jamba/Zamba)ã¸ã®æ©‹æ¸¡ã—ã¨ãªã‚‹ã€‚

### 2.3 SSMã®æ­´å²: åˆ¶å¾¡ç†è«–ã‹ã‚‰æ·±å±¤å­¦ç¿’ã¸

çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã¯å…ƒã€…1960å¹´ä»£ã®Kalmanãƒ•ã‚£ãƒ«ã‚¿[^4]ã«é¡ã‚‹ã€‚ä¿¡å·å‡¦ç†ãƒ»åˆ¶å¾¡ç†è«–ã®åŸºç¤ã ã£ãŸã€‚2020å¹´ã«HiPPO[^1]ãŒã€Œé•·è·é›¢è¨˜æ†¶ã®æœ€é©åˆæœŸåŒ–ã€ã‚’ç¤ºã—ã€2021å¹´ã«S4[^2]ãŒã€Œå¯¾è§’åŒ–ã«ã‚ˆã‚‹é«˜é€ŸåŒ–ã€ã‚’å®Ÿç¾ã€‚2023å¹´ã®Mamba[^3]ã§ã€Œå…¥åŠ›ä¾å­˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿(Selective SSM)ã€ãŒåŠ ã‚ã‚Šã€ã¤ã„ã«Transformerç´šã®æ€§èƒ½ã‚’é”æˆã—ãŸã€‚

```mermaid
graph TD
    A["1960s Kalman Filter<br/>çŠ¶æ…‹æ¨å®šã®åŸºç¤"] --> B["2020 HiPPO<br/>é•·è·é›¢è¨˜æ†¶ã®ç†è«–"]
    B --> C["2021 S4<br/>å¯¾è§’åŒ–+FFT"]
    C --> D["2022 H3<br/>æš—é»™çš„é•·ç•³ã¿è¾¼ã¿"]
    D --> E["2023 Mamba<br/>Selective SSM"]
    E --> F["2024 Mamba-2/SSD<br/>Attention=SSMåŒå¯¾æ€§"]

    style A fill:#ffecb3
    style B fill:#fff9c4
    style C fill:#c8e6c9
    style E fill:#81c784
    style F fill:#4caf50
```

### 2.4 å­¦ç¿’æˆ¦ç•¥: æ•°å¼â†’ã‚³ãƒ¼ãƒ‰â†’å®Ÿé¨“

Zone 3ã§é€£ç¶šæ™‚é–“SSMâ†’é›¢æ•£åŒ–â†’HiPPOâ†’S4â†’Mambaã®å®Œå…¨å°å‡ºã‚’è¡Œã†ã€‚Zone 4ã§âš¡Juliaå®Ÿè£…ã€‚Zone 5ã§Long Range Arenaã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚

**ã“ã“ãŒè¸ã‚“å¼µã‚Šã©ã“ã‚**: S4ã®å¯¾è§’åŒ–è¨¼æ˜ã¨Mambaã®Selective SSMã¯ã€ã“ã®ã‚·ãƒªãƒ¼ã‚ºã§æœ€ã‚‚é›£è§£ãªæ•°å¼ã®1ã¤ã€‚ã ãŒ**ç†è§£ã™ã‚Œã°2025å¹´ã®SSMè«–æ–‡ãŒå…¨ã¦èª­ã‚ã‚‹**ã‚ˆã†ã«ãªã‚‹ã€‚

:::details ãƒˆãƒ­ã‚¤ã®æœ¨é¦¬: Juliaã®æ´»èº
ç¬¬10å›ã§JuliaãŒç™»å ´ã—ã€å¤šé‡ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒã§å‹ã«å¿œã˜ãŸè‡ªå‹•æœ€é©åŒ–ã‚’å®Ÿç¾ã—ãŸã€‚SSMã®ã‚ˆã†ãªæ•°å€¤è¨ˆç®—ã§ã¯ã€Juliaã®å‹å®‰å®šæ€§ã¨JITã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãŒå¨åŠ›ã‚’ç™ºæ®ã™ã‚‹ã€‚S4ã®FFTã‚«ãƒ¼ãƒãƒ«ã€Mambaã®scanã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãªã©ã€æ•°å¼ãŒã»ã¼ãã®ã¾ã¾ã‚³ãƒ¼ãƒ‰ã«ãªã‚‹ã€‚
:::

:::message
**é€²æ—: 20% å®Œäº†** SSMã®å¿…è¦æ€§ã€æ­´å²ã€Course IIã§ã®ä½ç½®ã¥ã‘ã‚’ç†è§£ã—ãŸã€‚ã•ã‚ã€æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ã¸ã€‚
:::

---

## ğŸ“ 3. æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³(60åˆ†) â€” SSMã®å®Œå…¨å°å‡º

ã“ã“ã‹ã‚‰æœ¬æ ¼çš„ãªç†è«–ã«å…¥ã‚‹ã€‚é€£ç¶šæ™‚é–“çŠ¶æ…‹ç©ºé–“â†’é›¢æ•£åŒ–â†’HiPPOâ†’S4ã®å¯¾è§’åŒ–â†’Mambaã®é¸æŠæ€§ã¾ã§ã€å…¨ã¦ã‚’å°å‡ºã™ã‚‹ã€‚

### 3.1 é€£ç¶šæ™‚é–“çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©

åˆ¶å¾¡ç†è«–ã«ãŠã‘ã‚‹æ¨™æº–çš„ãªç·šå½¢æ™‚ä¸å¤‰(LTI)ã‚·ã‚¹ãƒ†ãƒ :

$$
\begin{cases}
\frac{d h(t)}{d t} = A h(t) + B u(t) \\
y(t) = C h(t) + D u(t)
\end{cases}
$$

- $u(t) \in \mathbb{R}$: å…¥åŠ›ä¿¡å·(ã‚¹ã‚«ãƒ©ãƒ¼ã€ä¸€èˆ¬åŒ–å¯)
- $h(t) \in \mathbb{R}^d$: éš ã‚ŒçŠ¶æ…‹(çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«)
- $y(t) \in \mathbb{R}$: å‡ºåŠ›ä¿¡å·
- $A \in \mathbb{R}^{d \times d}$: çŠ¶æ…‹é·ç§»è¡Œåˆ—(dynamics)
- $B \in \mathbb{R}^{d \times 1}$: å…¥åŠ›è¡Œåˆ—
- $C \in \mathbb{R}^{1 \times d}$: å‡ºåŠ›è¡Œåˆ—
- $D \in \mathbb{R}$: ç›´æ¥ãƒ•ã‚£ãƒ¼ãƒ‰ã‚¹ãƒ«ãƒ¼é …(é€šå¸¸0)

**å¹¾ä½•å­¦çš„æ„å‘³**: $A$ãŒçŠ¶æ…‹ç©ºé–“ã®æµã‚Œ(flow)ã‚’å®šç¾©ã™ã‚‹ã€‚å›ºæœ‰å€¤ã®å®Ÿéƒ¨ãŒè² ãªã‚‰å®‰å®š(æ¸›è¡°)ã€æ­£ãªã‚‰ä¸å®‰å®š(çˆ†ç™º)ã€‚$B$ã¯å…¥åŠ›ãŒã©ã®æ–¹å‘ã«çŠ¶æ…‹ã‚’å‹•ã‹ã™ã‹ã€$C$ã¯çŠ¶æ…‹ã®ã©ã®æˆåˆ†ã‚’è¦³æ¸¬ã™ã‚‹ã‹ã€‚

:::message
**æ•°å¼ã®å£°**: "$\frac{dh}{dt} = Ah$" ã¯ã€ŒçŠ¶æ…‹ãŒæ™‚é–“ã¨ã¨ã‚‚ã«ã©ã†å¤‰åŒ–ã™ã‚‹ã‹ã€ã‚’è¨˜è¿°ã™ã‚‹ã€‚ç·šå½¢ODEã®åŸºæœ¬å½¢ã€‚
:::

#### åˆæœŸå€¤å•é¡Œã®è§£

$u(t) = 0$(å…¥åŠ›ãªã—)ã®å ´åˆã€å¸¸å¾®åˆ†æ–¹ç¨‹å¼$\frac{dh}{dt} = Ah$ã®è§£ã¯:

$$
h(t) = e^{At} h(0)
$$

ã“ã“ã§$e^{At}$ã¯**è¡Œåˆ—æŒ‡æ•°é–¢æ•°**(ç¬¬2å›ã§å­¦ã‚“ã ):

$$
e^{At} = \sum_{k=0}^{\infty} \frac{(At)^k}{k!} = I + At + \frac{(At)^2}{2!} + \cdots
$$

$A$ãŒå¯¾è§’åŒ–å¯èƒ½($A = V \Lambda V^{-1}$)ãªã‚‰:

$$
e^{At} = V e^{\Lambda t} V^{-1}, \quad e^{\Lambda t} = \begin{pmatrix} e^{\lambda_1 t} & & \\ & \ddots & \\ & & e^{\lambda_d t} \end{pmatrix}
$$

**å›ºæœ‰å€¤$\lambda_i$ãŒæ¸›è¡°ç‡ã‚’æ±ºå®šã™ã‚‹ã€‚** $\text{Re}(\lambda_i) < 0$ãªã‚‰$e^{\lambda_i t} \to 0$(å®‰å®š)ã€‚

#### å…¥åŠ›ã‚ã‚Šã®å ´åˆ: ç•³ã¿è¾¼ã¿è¡¨ç¾

$u(t)$ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€è§£ã¯:

$$
h(t) = e^{At} h(0) + \int_0^t e^{A(t-\tau)} B u(\tau) \, d\tau
$$

å‡ºåŠ›ã¯:

$$
y(t) = C e^{At} h(0) + C \int_0^t e^{A(t-\tau)} B u(\tau) \, d\tau + D u(t)
$$

åˆæœŸçŠ¶æ…‹$h(0)=0$ã¨ã™ã‚‹ã¨:

$$
y(t) = \int_0^t \underbrace{C e^{A(t-\tau)} B}_{\text{ã‚¤ãƒ³ãƒ‘ãƒ«ã‚¹å¿œç­”} \, \mathcal{K}(t-\tau)} u(\tau) \, d\tau + D u(t)
$$

ã“ã‚Œã¯**ç•³ã¿è¾¼ã¿ç©åˆ†**:

$$
y(t) = (\mathcal{K} * u)(t), \quad \mathcal{K}(t) = C e^{At} B
$$

**SSMã®æœ¬è³ª**: å…¥åŠ›$u$ã¨ã€æ™‚é–“æ¸›è¡°ã™ã‚‹ã‚«ãƒ¼ãƒãƒ«$\mathcal{K}(t)$ã®ç•³ã¿è¾¼ã¿ã§å‡ºåŠ›$y$ãŒå¾—ã‚‰ã‚Œã‚‹ã€‚

:::details æ¤œè¨¼ã‚³ãƒ¼ãƒ‰
```julia
using DifferentialEquations

# Solve continuous SSM: dh/dt = Ah + Bu
function solve_continuous_ssm(u_func, tspan, A, B, C, D)
    function ode!(dh, h, p, t)
        dh .= A * h + B * u_func(t)
    end

    h0 = zeros(size(A, 1))
    prob = ODEProblem(ode!, h0, tspan)
    sol = solve(prob, Tsit5())

    # Compute output y(t) = Ch(t) + Du(t)
    t_eval = range(tspan[1], tspan[2], length=100)
    y = [dot(C, sol(t)) + D * u_func(t) for t in t_eval]
    return t_eval, y
end

# Example
A = [-0.5 0.0; 0.0 -0.3]
B = [1.0; 0.0]
C = [1.0, 0.5]
D = 0.0

u_func(t) = exp(-t)  # decaying input
t, y = solve_continuous_ssm(u_func, (0.0, 10.0), A, B, C, D)

using Plots
plot(t, y, xlabel="Time", ylabel="Output y(t)", label="SSM output", linewidth=2)
```
:::

### 3.2 é›¢æ•£åŒ–: é€£ç¶šâ†’é›¢æ•£ã¸ã®å¤‰æ›

æ·±å±¤å­¦ç¿’ã§ã¯æ™‚é–“ã¯é›¢æ•£çš„ã€‚$\Delta$ã‚’æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—å¹…ã¨ã—ã¦ã€$t_k = k\Delta$ã§é›¢æ•£åŒ–ã™ã‚‹ã€‚

#### Zero-Order Hold (ZOH) é›¢æ•£åŒ–

æœ€ã‚‚ä¸€èˆ¬çš„ãªæ‰‹æ³•ã€‚åŒºé–“$[k\Delta, (k+1)\Delta)$ã§å…¥åŠ›$u(t) = u_k$(å®šæ•°)ã¨ä»®å®šã€‚

$$
h((k+1)\Delta) = e^{A\Delta} h(k\Delta) + \left( \int_0^\Delta e^{A\tau} d\tau \right) B u_k
$$

é›¢æ•£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©:

$$
\bar{A} = e^{A\Delta}, \quad \bar{B} = \left( \int_0^\Delta e^{A\tau} d\tau \right) B = (A^{-1}(e^{A\Delta} - I)) B
$$

ã™ã‚‹ã¨é›¢æ•£æ™‚é–“SSM:

$$
h_k = \bar{A} h_{k-1} + \bar{B} u_k, \quad y_k = C h_k + D u_k
$$

**$\bar{A}$ã¨$\bar{B}$ã®è¨ˆç®—**: $A$ãŒå¯¾è§’åŒ–å¯èƒ½ãªã‚‰:

$$
\bar{A} = V e^{\Lambda \Delta} V^{-1}, \quad \bar{B} = V \left( \Lambda^{-1} (e^{\Lambda \Delta} - I) \right) V^{-1} B
$$

ã“ã“ã§$e^{\Lambda \Delta} = \text{diag}(e^{\lambda_1 \Delta}, \ldots, e^{\lambda_d \Delta})$ã€‚

:::message
**ã¤ã¾ãšããƒã‚¤ãƒ³ãƒˆ**: ãªãœ$\bar{B} = A^{-1}(e^{A\Delta} - I)B$? ç©åˆ†$\int_0^\Delta e^{A\tau} d\tau$ã‚’è¡Œåˆ—æŒ‡æ•°ã®æ€§è³ªã‹ã‚‰å°ãã€‚$e^{A\tau}$ã®ç©åˆ†ã¯$(A^{-1}e^{A\tau})|_0^\Delta = A^{-1}(e^{A\Delta} - I)$ã€‚
:::

#### ä»–ã®é›¢æ•£åŒ–æ‰‹æ³•

| æ‰‹æ³• | $\bar{A}$ | $\bar{B}$ | ç‰¹å¾´ |
|:-----|:----------|:----------|:-----|
| **Forward Euler** | $I + \Delta A$ | $\Delta B$ | å˜ç´”ã€ä¸å®‰å®š |
| **Bilinear (Tustin)** | $(I - \frac{\Delta}{2}A)^{-1}(I + \frac{\Delta}{2}A)$ | $(I - \frac{\Delta}{2}A)^{-1}\Delta B$ | å‘¨æ³¢æ•°å¿œç­”ä¿å­˜ |
| **ZOH** | $e^{A\Delta}$ | $(A^{-1}(e^{A\Delta} - I))B$ | æ­£ç¢ºã€S4æ¡ç”¨ |

S4ã¯ZOHã‚’ä½¿ç”¨[^2]ã€‚æ•°å€¤çš„å®‰å®šæ€§ãŒé«˜ãã€é€£ç¶šæ™‚é–“ã®æ€§è³ªã‚’æœ€ã‚‚ã‚ˆãä¿ã¤ã€‚

```julia
using LinearAlgebra

# Zero-Order Hold discretization
function discretize_zoh(A::Matrix{Float64}, B::Vector{Float64}, Î”::Float64)
    d = size(A, 1)
    # A_bar = exp(A * Î”)
    A_bar = exp(A * Î”)

    # B_bar = (A^{-1} (exp(A*Î”) - I)) B
    # If A is invertible:
    if det(A) != 0
        B_bar = (inv(A) * (A_bar - I)) * B
    else
        # Numerical integration fallback
        B_bar = sum([exp(A * Ï„) * B * Î”/100 for Ï„ in range(0, Î”, length=100)])
    end

    return A_bar, B_bar
end

# Example
A = [-0.5 0.0; 0.0 -0.3]
B = [1.0, 0.0]
Î” = 0.1

A_bar, B_bar = discretize_zoh(A, B, Î”)
println("A_bar = ", round.(A_bar, digits=4))
println("B_bar = ", round.(B_bar, digits=4))

# Eigenvalues decay as exp(Î» * Î”)
Î» = eigvals(A)
Î»_discrete = exp.(Î» * Î”)
println("Continuous eigenvalues: ", Î»)
println("Discrete eigenvalues:   ", Î»_discrete)
println("A_bar eigenvalues:      ", eigvals(A_bar))
```

### 3.3 é›¢æ•£SSMã®ç•³ã¿è¾¼ã¿å½¢æ…‹

é›¢æ•£æ™‚é–“ã§ã®å†å¸°:

$$
h_k = \bar{A}^k h_0 + \sum_{j=0}^{k-1} \bar{A}^{k-1-j} \bar{B} u_j
$$

åˆæœŸçŠ¶æ…‹$h_0 = 0$ã¨ã™ã‚‹ã¨:

$$
y_k = C h_k = C \sum_{j=0}^{k-1} \bar{A}^{k-1-j} \bar{B} u_j = \sum_{j=0}^{k-1} \underbrace{C \bar{A}^{k-1-j} \bar{B}}_{\bar{\mathcal{K}}_{k-j}} u_j
$$

ã“ã‚Œã¯é›¢æ•£ç•³ã¿è¾¼ã¿:

$$
y = \bar{\mathcal{K}} * u, \quad \bar{\mathcal{K}}_k = C \bar{A}^k \bar{B} \quad (k=0,1,\ldots,L-1)
$$

**ã‚«ãƒ¼ãƒãƒ«$\bar{\mathcal{K}}$ã‚’äº‹å‰è¨ˆç®—ã™ã‚Œã°ã€FFTã§$O(L \log L)$ã®ç•³ã¿è¾¼ã¿ãŒå¯èƒ½ã€‚** ã“ã‚ŒãŒS4ã®è¨“ç·´æ™‚é«˜é€ŸåŒ–ã®éµã€‚

#### ã‚«ãƒ¼ãƒãƒ«è¨ˆç®—ã®è¨ˆç®—é‡

ç´ æœ´ã«ã¯$\bar{\mathcal{K}}_k = C \bar{A}^k \bar{B}$ã‚’$k=0,\ldots,L-1$ã§è¨ˆç®—ã™ã‚‹ã¨$O(Ld^3)$(è¡Œåˆ—ç´¯ä¹—)ã€‚S4ã¯**å¯¾è§’åŒ–ã«ã‚ˆã‚Š$O(Ld)$ã«å‰Šæ¸›**ã™ã‚‹ã€‚

#### ç•³ã¿è¾¼ã¿ã¨å†å¸°ã®ç­‰ä¾¡æ€§ã®è¨¼æ˜

**Claim**: ç•³ã¿è¾¼ã¿å½¢æ…‹$y = \bar{\mathcal{K}} * u$ã¨å†å¸°å½¢æ…‹$h_k = \bar{A}h_{k-1} + \bar{B}u_k, y_k = Ch_k$ã¯ç­‰ä¾¡ã€‚

**è¨¼æ˜**:

å†å¸°å½¢æ…‹ã‹ã‚‰å‡ºç™º:

$$
\begin{aligned}
h_0 &= 0 \\
h_1 &= \bar{A} h_0 + \bar{B} u_0 = \bar{B} u_0 \\
h_2 &= \bar{A} h_1 + \bar{B} u_1 = \bar{A} \bar{B} u_0 + \bar{B} u_1 \\
h_3 &= \bar{A} h_2 + \bar{B} u_2 = \bar{A}^2 \bar{B} u_0 + \bar{A} \bar{B} u_1 + \bar{B} u_2
\end{aligned}
$$

ä¸€èˆ¬ã«:

$$
h_k = \sum_{j=0}^{k-1} \bar{A}^{k-1-j} \bar{B} u_j
$$

å‡ºåŠ›:

$$
y_k = C h_k = C \sum_{j=0}^{k-1} \bar{A}^{k-1-j} \bar{B} u_j
$$

$\bar{\mathcal{K}}_m = C \bar{A}^m \bar{B}$ã¨å®šç¾©ã™ã‚‹ã¨:

$$
y_k = \sum_{j=0}^{k-1} \bar{\mathcal{K}}_{k-1-j} u_j = \sum_{m=0}^{k-1} \bar{\mathcal{K}}_m u_{k-1-m}
$$

ã“ã‚Œã¯é›¢æ•£ç•³ã¿è¾¼ã¿$(y = \bar{\mathcal{K}} * u)$ã®å®šç¾©ãã®ã‚‚ã®ã€‚$\square$

#### FFTç•³ã¿è¾¼ã¿ã®é«˜é€ŸåŒ–

é›¢æ•£ç•³ã¿è¾¼ã¿$y = \bar{\mathcal{K}} * u$ã‚’ç›´æ¥è¨ˆç®—ã™ã‚‹ã¨$O(L^2)$ã€‚

**FFTã«ã‚ˆã‚‹é«˜é€ŸåŒ–**:

ç•³ã¿è¾¼ã¿å®šç†ã‚ˆã‚Š:

$$
\mathcal{F}\{y\} = \mathcal{F}\{\bar{\mathcal{K}}\} \cdot \mathcal{F}\{u\}
$$

ã¤ã¾ã‚Š:

$$
y = \mathcal{F}^{-1} \left\{ \mathcal{F}\{\bar{\mathcal{K}}\} \cdot \mathcal{F}\{u\} \right\}
$$

FFT/IFFTã¯$O(L \log L)$ â†’ å…¨ä½“ã§$O(L \log L)$ã€‚

**å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ**:

1. **Zero-padding**: å¾ªç’°ç•³ã¿è¾¼ã¿ã‚’é¿ã‘ã‚‹ãŸã‚ã€$\bar{\mathcal{K}}$ã¨$u$ã‚’ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°(é•·ã•$2L-1$)
2. **è¦ç´ ç©**: å‘¨æ³¢æ•°é ˜åŸŸã§ã®è¦ç´ ç©$\mathcal{F}\{\bar{\mathcal{K}}\} \odot \mathcal{F}\{u\}$ã¯$O(L)$
3. **å®Ÿéƒ¨æŠ½å‡º**: æœ€çµ‚çš„ã«å®Ÿéƒ¨ã®ã¿å–ã‚‹(å…ƒãŒå®Ÿæ•°ãªã‚‰)

```julia
using FFTW

function fft_conv(K::Vector{Float64}, u::Vector{Float64})
    L_K, L_u = length(K), length(u)
    L = L_K + L_u - 1

    K_pad = [K; zeros(L - L_K)]
    u_pad = [u; zeros(L - L_u)]

    K_fft = fft(K_pad)
    u_fft = fft(u_pad)

    y_fft = K_fft .* u_fft
    y = real.(ifft(y_fft))

    return y[1:L_u]  # Trim to original length
end
```

#### ç•³ã¿è¾¼ã¿å½¢æ…‹ã®åˆ©ç‚¹ã¨é™ç•Œ

**åˆ©ç‚¹**:

1. **ä¸¦åˆ—åŒ–**: ã‚«ãƒ¼ãƒãƒ«$\bar{\mathcal{K}}$è¨ˆç®—å¾Œã€å…¨æ™‚åˆ»ã‚’ä¸¦åˆ—å‡¦ç†å¯èƒ½
2. **è¨“ç·´é«˜é€ŸåŒ–**: GPUä¸Šã§FFTã¯é«˜åº¦ã«æœ€é©åŒ–æ¸ˆã¿
3. **ãƒãƒƒãƒå‡¦ç†**: è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã‚’åŒæ™‚ã«å‡¦ç†

**é™ç•Œ**:

1. **å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‰æ**: $\bar{A}, \bar{B}, \bar{C}$ãŒå…¨æ™‚åˆ»ã§å…±é€šã§ãªã„ã¨é©ç”¨ä¸å¯
2. **ã‚«ãƒ¼ãƒãƒ«äº‹å‰è¨ˆç®—**: ç³»åˆ—é•·$L$ãŒå¤§ãã„ã¨$\bar{\mathcal{K}}$ã®ãƒ¡ãƒ¢ãƒªæ¶ˆè²»ãŒå¢—åŠ 
3. **æ¨è«–ã«ã¯ä¸å‘**: æ¨è«–æ™‚(1ãƒˆãƒ¼ã‚¯ãƒ³ãšã¤ç”Ÿæˆ)ã¯å†å¸°å½¢æ…‹ãŒåŠ¹ç‡çš„

**S4ã®æˆ¦ç•¥**: è¨“ç·´ã¯ç•³ã¿è¾¼ã¿å½¢æ…‹ã€æ¨è«–ã¯å†å¸°å½¢æ…‹ã€‚ä¸¡æ–¹ã‚’ä½¿ã„åˆ†ã‘ã‚‹ã€‚

#### ç•³ã¿è¾¼ã¿ã‚«ãƒ¼ãƒãƒ«ã®æ€§è³ª

$\bar{\mathcal{K}}_k = C \bar{A}^k \bar{B}$ã®æŒ™å‹•:

1. **æŒ‡æ•°æ¸›è¡°**: $\bar{A}$ã®å›ºæœ‰å€¤$\lambda_i < 1$ãªã‚‰ã€$\bar{A}^k \to 0$ as $k \to \infty$
2. **æ™‚é–“ä¸å¤‰**: ã‚«ãƒ¼ãƒãƒ«ã¯æ™‚åˆ»ã®å·®$k-j$ã®ã¿ã«ä¾å­˜ â†’ Toeplitzè¡Œåˆ—
3. **å› æœæ€§**: $\bar{\mathcal{K}}_k = 0$ for $k < 0$ â†’ æœªæ¥ã‚’è¦‹ãªã„

**Toeplitzæ§‹é€ **:

ç•³ã¿è¾¼ã¿è¡Œåˆ—$\mathcal{K}$ã¯:

$$
\mathcal{K} = \begin{pmatrix}
\bar{\mathcal{K}}_0 & 0 & 0 & \cdots \\
\bar{\mathcal{K}}_1 & \bar{\mathcal{K}}_0 & 0 & \cdots \\
\bar{\mathcal{K}}_2 & \bar{\mathcal{K}}_1 & \bar{\mathcal{K}}_0 & \cdots \\
\vdots & \vdots & \vdots & \ddots
\end{pmatrix}
$$

å¯¾è§’ç·šä¸Šã®å€¤ãŒä¸€å®š â†’ FFTã§å¯¾è§’åŒ–å¯èƒ½ã€‚

### 3.4 HiPPO: é•·è·é›¢è¨˜æ†¶ã®ç†è«–çš„åŸºç›¤

**å•é¡Œè¨­å®š**: æ™‚åˆ»$t$ã¾ã§ã®å…¥åŠ›å±¥æ­´$u(\tau), \tau \in [0, t]$ã‚’ã€$d$æ¬¡å…ƒã®çŠ¶æ…‹$h(t)$ã«åœ§ç¸®ã—ãŸã„ã€‚ã©ã®ã‚ˆã†ã«åˆæœŸåŒ–ã™ã‚Œã°æœ€é©ã‹ï¼Ÿ

HiPPO (High-order Polynomial Projection Operators)[^1]ã¯ã€**ç›´äº¤å¤šé …å¼åŸºåº•ã¸ã®å°„å½±**ã¨ã—ã¦$h(t)$ã‚’å®šç¾©ã™ã‚‹ã€‚

#### æ•°å­¦çš„å®šå¼åŒ–

æ¸¬åº¦$\mu(t)$ã«å¯¾ã—ã¦ã€é–¢æ•°$u(\tau), \tau \leq t$ã‚’$d$æ¬¡ã¾ã§ã®å¤šé …å¼$P_0, P_1, \ldots, P_{d-1}$ã§è¿‘ä¼¼:

$$
u(\tau) \approx \sum_{n=0}^{d-1} c_n(t) P_n(\tau)
$$

ä¿‚æ•°$c_n(t)$ãŒçŠ¶æ…‹$h(t)$ã®ç¬¬$n$æˆåˆ†ã€‚æœ€é©åŒ–å•é¡Œ:

$$
\min_{c_0, \ldots, c_{d-1}} \int_0^t \left( u(\tau) - \sum_{n=0}^{d-1} c_n P_n(\tau) \right)^2 \mu(t, \tau) \, d\tau
$$

ç›´äº¤å¤šé …å¼ã®æ€§è³ªã‹ã‚‰ã€æœ€é©ä¿‚æ•°ã¯å°„å½±:

$$
c_n(t) = \int_0^t u(\tau) P_n(\tau) \mu(t, \tau) \, d\tau
$$

æ™‚é–“å¾®åˆ†ã‚’å–ã‚‹ã¨ã€$c(t) = (c_0(t), \ldots, c_{d-1}(t))$ãŒå¾®åˆ†æ–¹ç¨‹å¼:

$$
\frac{d c(t)}{d t} = A_{\text{HiPPO}} c(t) + B_{\text{HiPPO}} u(t)
$$

ã‚’æº€ãŸã™ã€‚$A_{\text{HiPPO}}$ã®å…·ä½“å½¢ã¯æ¸¬åº¦$\mu$ã¨å¤šé …å¼æ—$\{P_n\}$ã«ä¾å­˜ã™ã‚‹ã€‚

#### HiPPO-LegS: Legendreå¤šé …å¼ + Sliding window

æ¸¬åº¦$\mu(t, \tau) = \mathbb{1}_{[t-\theta, t]}(\tau)$(å¹…$\theta$ã®ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦)ã¨ã€Legendreå¤šé …å¼$P_n(\tau)$ã‚’ç”¨ã„ã‚‹ã¨:

$$
(A_{\text{HiPPO}})_{nk} =
\begin{cases}
-(2n+1)^{1/2}(2k+1)^{1/2} & \text{if } n > k \\
n+1 & \text{if } n = k \\
0 & \text{if } n < k
\end{cases}
$$

$$
(B_{\text{HiPPO}})_n = (2n+1)^{1/2}
$$

**ç‰¹æ€§**: $A_{\text{HiPPO}}$ã¯ä¸‹ä¸‰è§’è¡Œåˆ—ã€‚å›ºæœ‰å€¤ã¯$-1, -2, \ldots, -d$ã¨è² ã®æ•´æ•°ã€‚**ã“ã‚ŒãŒé•·è·é›¢è¨˜æ†¶ã¨è¨“ç·´å®‰å®šæ€§ã‚’ä¸¡ç«‹ã•ã›ã‚‹ã€‚**

:::details HiPPO-LagT: Laguerreå¤šé …å¼ + Time-varying
æ¸¬åº¦ã‚’$\mu(t, \tau) = e^{-\frac{\tau}{t}}$(æ™‚é–“ã¨ã¨ã‚‚ã«éå»ã‚’æŒ‡æ•°æ¸›è¡°)ã¨ã—ã€Laguerreå¤šé …å¼ã‚’ç”¨ã„ã‚‹ã¨ã€ç„¡é™ã®å±¥æ­´ã‚’ä¿æŒã™ã‚‹ãŒã€å¤ã„éå»ã¯æ¸›è¡°ã€‚HiPPO-LegSã¨LagTã®ä¸­é–“çš„ãªæ€§è³ªã‚’æŒã¤å¤‰ç¨®ã‚‚å­˜åœ¨ã€‚
:::

```julia
# HiPPO-LegS matrix construction
function hippo_legs(d::Int)
    A = zeros(Float64, d, d)
    B = zeros(Float64, d)

    for n in 0:d-1
        for k in 0:d-1
            if n > k
                A[n+1, k+1] = -(2*n + 1)^0.5 * (2*k + 1)^0.5
            elseif n == k
                A[n+1, k+1] = n + 1
            end
        end
        B[n+1] = (2*n + 1)^0.5
    end

    return A, B
end

d = 4
A_hippo, B_hippo = hippo_legs(d)
println("HiPPO-LegS A matrix (d=$d):")
display(round.(A_hippo, digits=2))
println("\nHiPPO-LegS B vector:")
display(round.(B_hippo, digits=2))
println("\nEigenvalues of A_HiPPO:")
display(eigvals(A_hippo))
```

å‡ºåŠ›:
```
HiPPO-LegS A matrix (d=4):
  1.0   0.0   0.0   0.0
 -1.73  2.0   0.0   0.0
 -2.24 -3.87  3.0   0.0
 -2.65 -4.58 -6.24  4.0

HiPPO-LegS B vector:
 [1.0, 1.73, 2.24, 2.65]

Eigenvalues of A_HiPPO:
 [-1.0, -2.0, -3.0, -4.0] (approximately, with small imaginary parts)
```

**å›ºæœ‰å€¤ãŒå…¨ã¦è² ** â†’ å®‰å®šã€‚ã—ã‹ã‚‚$-1, -2, \ldots, -d$ã¨ç•°ãªã‚‹æ¸›è¡°ç‡ã‚’æŒã¤ â†’ **å¤šæ§˜ãªæ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ã‚’åŒæ™‚ã«æ‰ãˆã‚‹ã€‚**

#### HiPPO-LegSã®å°å‡º(è©³ç´°)

**ç›®æ¨™**: æ¸¬åº¦$\mu(t, \tau) = \frac{1}{\theta} \mathbb{1}_{[t-\theta, t]}(\tau)$(å¹…$\theta$ã®ä¸€æ§˜ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦)ã«å¯¾ã—ã¦ã€Legendreå¤šé …å¼$\{P_n\}$ã§é–¢æ•°$u(\tau)$ã‚’è¿‘ä¼¼ã™ã‚‹ä¿‚æ•°$c_n(t)$ã®æ™‚é–“ç™ºå±•ã‚’æ±‚ã‚ã‚‹ã€‚

**Legendreå¤šé …å¼** (åŒºé–“$[-1, 1]$ã§ç›´äº¤):

$$
P_0(x) = 1, \quad P_1(x) = x, \quad P_2(x) = \frac{1}{2}(3x^2 - 1), \quad \ldots
$$

ç›´äº¤æ€§:

$$
\int_{-1}^{1} P_n(x) P_m(x) \, dx = \frac{2}{2n+1} \delta_{nm}
$$

**å¤‰æ•°å¤‰æ›**: $\tau \in [t-\theta, t]$ã‚’$x \in [-1, 1]$ã«å†™åƒ:

$$
x = \frac{2(\tau - (t - \theta))}{\theta} - 1 = \frac{2\tau - 2t + \theta}{\theta}
$$

**å°„å½±ä¿‚æ•°**:

$$
c_n(t) = \frac{2n+1}{2} \int_{-1}^{1} u(\tau(x)) P_n(x) \, dx
$$

$u$ã‚’æ™‚é–“$t$ã§å¾®åˆ†ã—ã€Leibnizã®ç©åˆ†å¾®åˆ†å…¬å¼ã‚’é©ç”¨ã™ã‚‹ã¨ã€$c_n(t)$ãŒæº€ãŸã™ODEãŒå°å‡ºã•ã‚Œã‚‹[^1]:

$$
\frac{d c_n(t)}{d t} = \sum_{k=0}^{d-1} A_{nk}^{\text{HiPPO}} c_k(t) + B_n^{\text{HiPPO}} u(t)
$$

è¨ˆç®—ã®çµæœ(è©³ç´°ã¯çœç•¥):

$$
A_{nk}^{\text{HiPPO}} =
\begin{cases}
-(2n+1)^{1/2}(2k+1)^{1/2} & \text{if } n > k \\
n+1 & \text{if } n = k \\
0 & \text{if } n < k
\end{cases}
$$

$$
B_n^{\text{HiPPO}} = (2n+1)^{1/2}
$$

**ç›´æ„Ÿ**:
- å¯¾è§’æˆåˆ†$A_{nn} = n+1$: å„ä¿‚æ•°ã®è‡ªå·±æ›´æ–°ç‡ã€‚é«˜æ¬¡ã»ã©é€Ÿãæ›´æ–°ã€‚
- ä¸‹ä¸‰è§’æˆåˆ†$A_{nk} < 0$ ($n > k$): é«˜æ¬¡ä¿‚æ•°ãŒä½æ¬¡ä¿‚æ•°ã«ä¾å­˜ã€‚éšå±¤çš„æ§‹é€ ã€‚
- $B_n$: æ–°ã—ã„å…¥åŠ›$u(t)$ã®å¯„ä¸ã€‚é«˜æ¬¡ã»ã©å¤§ãã„(é«˜å‘¨æ³¢æˆåˆ†ã‚’æ‰ãˆã‚‹)ã€‚

#### HiPPOå›ºæœ‰å€¤ã®ç‰¹æ€§

HiPPO-LegSè¡Œåˆ—ã®å›ºæœ‰å€¤ã¯**ã»ã¼è² ã®æ•´æ•°**:

$$
\lambda_n \approx -(n+1), \quad n = 0, 1, \ldots, d-1
$$

å³å¯†ã«ã¯è¤‡ç´ æ•°ã ãŒã€å®Ÿéƒ¨ãŒ$\approx -(n+1)$ã€‚

**æ„å‘³**:
- $\lambda_0 \approx -1$: æœ€ã‚‚é…ã„æ¸›è¡°(é•·æœŸè¨˜æ†¶)
- $\lambda_{d-1} \approx -d$: æœ€ã‚‚é€Ÿã„æ¸›è¡°(çŸ­æœŸè¨˜æ†¶)

ã“ã‚Œã«ã‚ˆã‚Šã€**$d$å€‹ã®ç•°ãªã‚‹æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ã‚’åŒæ™‚ã«ä¿æŒ**ã€‚

**å¯¾æ•°æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«**: $e^{-nt} = e^{-t}, e^{-2t}, e^{-3t}, \ldots$ã¯ã€$t$ã«å¯¾ã—ã¦æŒ‡æ•°çš„ã«ç•°ãªã‚‹æ¸›è¡°ç‡ â†’ $\log$ã‚¹ã‚±ãƒ¼ãƒ«ã§å‡ç­‰ã«åˆ†å¸ƒã€‚

```julia
using Plots

# Visualize HiPPO memory decay
function plot_hippo_decay()
    d = 8
    t = 0:0.1:10

    decays = [exp.(-n * t) for n in 1:d]

    plot(t, decays, label=["Î»=-$n" for n in 1:d]',
         xlabel="Time", ylabel="Memory strength",
         title="HiPPO Multi-scale Memory Decay",
         yscale=:log10, linewidth=2, legend=:topright)
end

plot_hippo_decay()
```

### 3.5 S4: Structured State Spaces

HiPPOã§åˆæœŸåŒ–ã—ãŸ$A$ã¯ç¨ å¯†è¡Œåˆ—ã€‚$d=256$ãªã‚‰$256 \times 256$ã®è¡Œåˆ—ç´¯ä¹—ãŒå¿…è¦ã€‚**S4ã¯ã“ã‚Œã‚’å¯¾è§’åŒ–ã—ã¦é«˜é€ŸåŒ–ã™ã‚‹ã€‚**[^2]

#### å•é¡Œç‚¹: HiPPOè¡Œåˆ—ã®è¤‡ç´ å›ºæœ‰å€¤

å®Ÿéš›ã«ã¯HiPPOè¡Œåˆ—ã¯**Normalè¡Œåˆ—**(ã¤ã¾ã‚Š$AA^* = A^*A$)ã ãŒã€ä¸€èˆ¬ã«å®Ÿå›ºæœ‰å€¤ã¨ã¯é™ã‚‰ãªã„ã€‚è¤‡ç´ å›ºæœ‰å€¤ã‚’æŒã¤ãŸã‚ã€ãƒŠã‚¤ãƒ¼ãƒ–ã«å¯¾è§’åŒ–ã™ã‚‹ã¨æ•°å€¤çš„ã«ä¸å®‰å®šã€‚

#### S4ã®éµ: DPLR (Diagonal Plus Low-Rank) åˆ†è§£

S4ã¯HiPPOè¡Œåˆ—$A$ã‚’æ¬¡ã®ã‚ˆã†ã«åˆ†è§£ã™ã‚‹:

$$
A = \Lambda - P Q^*
$$

- $\Lambda \in \mathbb{C}^{d \times d}$: å¯¾è§’è¡Œåˆ—(è¤‡ç´ å›ºæœ‰å€¤)
- $P, Q \in \mathbb{C}^{d \times r}$: ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—($r \ll d$ã€é€šå¸¸$r=1,2$)

ã“ã®å½¢å¼ã‚’**DPLR (Diagonal Plus Low-Rank)**ã¨å‘¼ã¶ã€‚

**ãªãœã“ã‚ŒãŒå¬‰ã—ã„ã‹**: é›¢æ•£SSMã®ã‚«ãƒ¼ãƒãƒ«$\bar{\mathcal{K}}_k = C \bar{A}^k \bar{B}$ãŒã€**Cauchyæ ¸ã®å’Œ**ã¨ã—ã¦è¡¨ç¾ã§ãã‚‹:

$$
\bar{\mathcal{K}}_k = \sum_{i=1}^{d} c_i \frac{\bar{A}_{ii}^k}{\omega_k - \lambda_i}
$$

ã“ã“ã§$\lambda_i = \Lambda_{ii}$ã¯å¯¾è§’æˆåˆ†ã€$\omega_k$ã¯å‘¨æ³¢æ•°ã€$c_i$ã¯å®šæ•°ã€‚

#### DPLRåˆ†è§£ã®æ•°å­¦çš„è©³ç´°

**Woodburyæ’ç­‰å¼**ã‚’ç”¨ã„ãŸé€†è¡Œåˆ—ã®è¨ˆç®—:

$$
(A + UV^\top)^{-1} = A^{-1} - A^{-1} U (I + V^\top A^{-1} U)^{-1} V^\top A^{-1}
$$

DPLRå½¢å¼$A = \Lambda - PQ^*$ã«å¯¾ã—ã¦ã€$U = -P, V = Q$ã¨ã™ã‚‹ã¨:

$$
A^{-1} = \Lambda^{-1} + \Lambda^{-1} P (I - Q^* \Lambda^{-1} P)^{-1} Q^* \Lambda^{-1}
$$

$\Lambda$ã¯å¯¾è§’ â†’ $\Lambda^{-1}$ã‚‚å¯¾è§’ â†’ $O(d)$ã§è¨ˆç®—å¯èƒ½ã€‚

**è¡Œåˆ—æŒ‡æ•°é–¢æ•°**$e^{At}$ã®è¨ˆç®—:

DPLRæ§‹é€ ã‚’åˆ©ç”¨ã™ã‚‹ã¨:

$$
e^{At} = e^{\Lambda t} - e^{\Lambda t} P (I - \int_0^t e^{-\Lambda s} P Q^* e^{\Lambda s} ds)^{-1} Q^* e^{\Lambda t}
$$

$\Lambda$ãŒå¯¾è§’ãªã‚‰ã€$e^{\Lambda t} = \text{diag}(e^{\lambda_1 t}, \ldots, e^{\lambda_d t})$ã€‚

**é›¢æ•£åŒ–$\bar{A} = e^{A\Delta}$**:

ä¸Šè¨˜ã®å¼ã‚’$t=\Delta$ã§è©•ä¾¡ã€‚ç©åˆ†é …ã¯è§£æçš„ã«è¨ˆç®—å¯èƒ½(æŒ‡æ•°é–¢æ•°ã®ç©åˆ†)ã€‚

**$\bar{B}$ã®è¨ˆç®—**:

$$
\bar{B} = (A^{-1}(e^{A\Delta} - I)) B
$$

Woodburyæ’ç­‰å¼ã«ã‚ˆã‚Šã€$A^{-1}$ã‚’$O(d)$ã§è¨ˆç®— â†’ $\bar{B}$ã‚‚$O(d)$ã€‚

#### Cauchyæ ¸ã¨FFT

ã‚«ãƒ¼ãƒãƒ«$\bar{\mathcal{K}}_k = C \bar{A}^k B$ã‚’$\bar{A} = e^{\Lambda \Delta} - \text{Low-Rank}$ã®å½¢ã§è¿‘ä¼¼ã™ã‚‹ã¨:

$$
\bar{\mathcal{K}}_k \approx \sum_{i=1}^{d} c_i e^{\lambda_i k \Delta}
$$

ã“ã“ã§$c_i = C_i B_i$(å¯¾è§’æˆåˆ†ã®å¯„ä¸)ã€‚

**Zå¤‰æ›**: é›¢æ•£æ™‚é–“ã‚«ãƒ¼ãƒãƒ«ã®Zå¤‰æ›:

$$
\bar{\mathcal{K}}(z) = \sum_{k=0}^{\infty} \bar{\mathcal{K}}_k z^{-k} = \sum_{i=1}^{d} \frac{c_i}{1 - e^{\lambda_i \Delta} z^{-1}}
$$

$z = e^{j\omega}$ã¨ã™ã‚‹ã¨ã€å‘¨æ³¢æ•°é ˜åŸŸ:

$$
\bar{\mathcal{K}}(\omega) = \sum_{i=1}^{d} \frac{c_i}{e^{j\omega} - e^{\lambda_i \Delta}}
$$

ã“ã‚Œã¯**Cauchyæ ¸**:

$$
\text{Cauchy}(\omega, \lambda_i) = \frac{1}{\omega - \lambda_i}
$$

ã®å’Œã€‚

**FFTã«ã‚ˆã‚‹è©•ä¾¡**:

å‘¨æ³¢æ•°$\omega_k = \frac{2\pi k}{L}, k=0,\ldots,L-1$ã§$\bar{\mathcal{K}}(\omega_k)$ã‚’è©•ä¾¡:

$$
\bar{\mathcal{K}}(\omega_k) = \sum_{i=1}^{d} \frac{c_i}{\omega_k - \lambda_i}
$$

ã“ã‚Œã‚’å…¨$k$ã§è¨ˆç®—ã™ã‚‹ã®ã¯$O(dL)$ã€‚ãã®å¾Œã€IFFT$O(L \log L)$ã§æ™‚é–“é ˜åŸŸã«æˆ»ã™ã€‚

**å®Ÿè£…**:

```julia
using FFTW

function s4_cauchy_kernel(Î»::Vector{ComplexF64}, c::Vector{ComplexF64}, L::Int, Î”::Float64)
    # Compute frequency samples
    Ï‰ = [2Ï€ * k / L for k in 0:L-1]

    # Evaluate Cauchy kernel
    K_Ï‰ = zeros(ComplexF64, L)
    for k in 1:L
        for i in 1:length(Î»)
            K_Ï‰[k] += c[i] / (exp(im * Ï‰[k]) - exp(Î»[i] * Î”))
        end
    end

    # IFFT to time domain
    K_t = ifft(K_Ï‰)

    return real.(K_t)  # Take real part
end

# Example
d, L = 16, 256
Î» = ComplexF64.(-(1:d))  # HiPPO-like eigenvalues
c = ones(ComplexF64, d) ./ d  # Uniform coefficients
Î” = 0.01

K = s4_cauchy_kernel(Î», c, L, Î”)
println("Kernel (first 5): ", round.(K[1:5], digits=4))
```

#### S4ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å…¨ä½“åƒ

```
Input: u (seq_len=L), A (HiPPO), B, C, Î”
Output: y (seq_len=L)

1. DPLR decomposition: A = Î› - PQ*
2. Discretize: A_bar = exp(Î› Î”) - [low-rank term]
               B_bar = (A^{-1}(A_bar - I)) B
3. Compute kernel K via Cauchy + FFT:
   K(Ï‰) = Î£_i c_i / (Ï‰ - Î»_i)
   K(t) = IFFT(K(Ï‰))
4. Convolve: y = IFFT(FFT(K) âŠ™ FFT(u))
```

**è¨ˆç®—é‡ã¾ã¨ã‚**:

| Step | Complexity | Note |
|:-----|:-----------|:-----|
| DPLRåˆ†è§£ | $O(d^2)$ | 1å›ã®ã¿(å‰å‡¦ç†) |
| é›¢æ•£åŒ– | $O(d)$ | Woodbury |
| Cauchyè©•ä¾¡ | $O(dL)$ | å…¨å‘¨æ³¢æ•° |
| FFT | $O(L \log L)$ | æ¨™æº–FFT |
| **Total** | **$O(dL + L \log L)$** | $d$å°ãªã‚‰å®Ÿè³ª$O(L \log L)$ |

#### FFTã«ã‚ˆã‚‹é«˜é€ŸåŒ–

ã‚«ãƒ¼ãƒãƒ«$\bar{\mathcal{K}}$å…¨ä½“ã‚’FFTã§ä¸€åº¦ã«è¨ˆç®—:

$$
\bar{\mathcal{K}}(\omega) = \sum_{i=1}^{d} \frac{c_i}{\omega - \lambda_i}
$$

ã“ã‚Œã¯**Cauchyæ ¸ã®FFT**ã¨ã—ã¦$O(d L \log L)$ã§è¨ˆç®—å¯èƒ½ã€‚ç•³ã¿è¾¼ã¿$y = \bar{\mathcal{K}} * u$ã‚‚FFTã§$O(L \log L)$ã€‚

**å…¨ä½“ã®è¨ˆç®—é‡**: $O(dL + L \log L) = O(L \log L)$(ãŸã ã—$d$ã¯å®šæ•°æ‰±ã„)ã€‚

#### S4ã®è¨“ç·´å®‰å®šæ€§

**ãªãœS4ã¯è¨“ç·´ãŒå®‰å®šã‹ï¼Ÿ**

1. **HiPPOåˆæœŸåŒ–**: å›ºæœ‰å€¤ãŒå…¨ã¦è²  â†’ å‹¾é…æ¶ˆå¤±ã‚’é˜²ã
2. **å¯¾è§’æ§‹é€ **: å¯¾è§’æˆåˆ†ãŒæ”¯é…çš„ â†’ å›ºæœ‰å€¤ã®åˆ¶å¾¡ãŒå®¹æ˜“
3. **æ­£è¦åŒ–**: Softmaxãªã— â†’ å‹¾é…ã®çˆ†ç™ºãƒ»æ¶ˆå¤±ãŒãªã„

**å‹¾é…ã®æµã‚Œ**:

æå¤±$\mathcal{L}$ã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿$\Lambda, c$ã¸ã®å‹¾é…:

$$
\frac{\partial \mathcal{L}}{\partial \Lambda_{ii}} = \sum_k \frac{\partial \mathcal{L}}{\partial \bar{\mathcal{K}}_k} \cdot \frac{\partial \bar{\mathcal{K}}_k}{\partial \Lambda_{ii}}
$$

Cauchyæ ¸ã®å¾®åˆ†:

$$
\frac{\partial \bar{\mathcal{K}}(\omega)}{\partial \lambda_i} = \frac{c_i}{(\omega - \lambda_i)^2}
$$

åˆ†æ¯ãŒ$(\omega - \lambda_i)^2$ â†’ å›ºæœ‰å€¤$\lambda_i$ãŒ$\omega$ã‹ã‚‰é›¢ã‚Œã¦ã„ã‚Œã°ã€å‹¾é…ã¯å°ã•ã„ã€‚ã“ã‚ŒãŒå®‰å®šæ€§ã®éµã€‚

:::message
**æ ¸å¿ƒ**: S4ã¯HiPPOåˆæœŸåŒ–(ç†è«–çš„ä¿è¨¼) + DPLRåˆ†è§£(é«˜é€Ÿè¨ˆç®—)ã‚’çµ„ã¿åˆã‚ã›ãŸã€‚è¨“ç·´ã¯$O(L \log L)$ã€æ¨è«–ã¯å†å¸°å½¢æ…‹ã§$O(Ld)$ã€‚
:::

#### S4ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ (ç°¡ç•¥ç‰ˆ)

1. HiPPOã§$A, B, C$ã‚’åˆæœŸåŒ–
2. $A$ã‚’DPLRåˆ†è§£: $A = \Lambda - PQ^*$
3. ZOHé›¢æ•£åŒ–: $\bar{A} = e^{A\Delta}, \bar{B} = (A^{-1}(e^{A\Delta} - I))B$
4. ã‚«ãƒ¼ãƒãƒ«$\bar{\mathcal{K}}$ã‚’Cauchyæ ¸+FFTã§è¨ˆç®—
5. ç•³ã¿è¾¼ã¿$y = \bar{\mathcal{K}} * u$ã‚’FFTã§å®Ÿè¡Œ

```julia
using FFTW

# Simplified S4 convolution (assuming diagonal A for simplicity)
function s4_convolution_simple(u::Vector{Float64}, Î»::Vector{ComplexF64},
                                B::Vector{ComplexF64}, C::Vector{ComplexF64}, Î”::Float64, L::Int)
    d = length(Î»)

    # Discretize: A_bar = exp(Î» * Î”)
    Î»_bar = exp.(Î» * Î”)

    # Compute kernel K[k] = C^T * diag(Î»_bar^k) * B
    K = zeros(ComplexF64, L)
    for k in 0:L-1
        K[k+1] = dot(C, (Î»_bar .^ k) .* B)
    end

    # Convolution via FFT: y = IFFT(FFT(K) * FFT(u))
    K_fft = fft(K)
    u_fft = fft([u; zeros(L)])  # zero-pad for circular convolution
    y_fft = K_fft .* u_fft[1:L]
    y = real.(ifft(y_fft))

    return y
end

# Example: d=4, L=64
d, L = 4, 64
Î» = ComplexF64[-1.0, -2.0, -3.0, -4.0]  # HiPPO eigenvalues
B = ComplexF64[1.0, 1.0, 1.0, 1.0]
C = ComplexF64[1.0, 0.5, 0.25, 0.125]
Î” = 0.1

u = randn(L)
y = s4_convolution_simple(u, Î», B, C, Î”, L)

println("S4 convolution output (first 5): ", round.(y[1:5], digits=3))
```

:::details S4ã®æ•°å­¦çš„è©³ç´°(Advanced)
å®Œå…¨ãªå°å‡ºã«ã¯Woodburyæ’ç­‰å¼ã€Cauchy kernelã€è¤‡ç´ è§£æãŒå¿…è¦ã€‚è«–æ–‡[^2]ã®Appendixå‚ç…§ã€‚æœ¬è¬›ç¾©ã§ã¯ç›´æ„Ÿã¨å®Ÿè£…ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã€‚
:::

### 3.6 S4ã®é™ç•Œã¨Mambaã¸ã®å‹•æ©Ÿ

S4ã¯å¼·åŠ›ã ãŒã€**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿$A, B, C$ãŒå…¨å…¥åŠ›ã§å…±æœ‰ã•ã‚Œã‚‹**ã€‚ã¤ã¾ã‚Šã€å…¥åŠ›ã«ä¾å­˜ã—ãªã„ã€‚

**å•é¡Œ**: ã€Œé‡è¦ãªæƒ…å ±ã‚’è¦šãˆã€ä¸è¦ãªæƒ…å ±ã‚’å¿˜ã‚Œã‚‹ã€ã¨ã„ã†**é¸æŠçš„è¨˜æ†¶**ãŒã§ããªã„ã€‚RNNã®ã‚²ãƒ¼ãƒˆãƒ¡ã‚«ãƒ‹ã‚ºãƒ (LSTMã®forget gate)ã®ã‚ˆã†ãªã€å…¥åŠ›ã«å¿œã˜ãŸå‹•çš„ãªè¨˜æ†¶åˆ¶å¾¡ãŒãªã„ã€‚

**å…·ä½“ä¾‹**: "The cat sat on the mat. The dog..."ã¨ã„ã†æ–‡ã§ã€"dog"ãŒå‡ºãŸã‚‰"cat"ã‚’å¿˜ã‚Œã¦ã‚ˆã„ã€‚ã ãŒS4ã¯å…¨ã¦ã®å˜èªã‚’åŒã˜æ¸›è¡°ç‡ã§ä¿æŒã™ã‚‹ã€‚

**Mambaã®è§£æ±ºç­–**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿$\Delta, B, C$ã‚’å…¥åŠ›$u_t$ã®é–¢æ•°ã«ã™ã‚‹ã€‚**Selective SSM**ã€‚

### 3.7 Mamba: Selective State Space Models

Mamba[^3]ã®æ ¸å¿ƒã¯ã€SSMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å…¥åŠ›ä¾å­˜ã«ã™ã‚‹ã“ã¨:

$$
\begin{aligned}
\Delta_t &= \text{Softplus}(W_\Delta u_t + b_\Delta) \\
B_t &= W_B u_t \\
C_t &= W_C u_t
\end{aligned}
$$

- $\Delta_t$: æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—å¹…(å…¥åŠ›ã”ã¨ã«å¤‰åŒ–)
- $B_t$: å…¥åŠ›æŠ•å½±(ã©ã®æƒ…å ±ã‚’çŠ¶æ…‹ã«æ›¸ãè¾¼ã‚€ã‹)
- $C_t$: å‡ºåŠ›æŠ•å½±(ã©ã®æƒ…å ±ã‚’èª­ã¿å‡ºã™ã‹)

é›¢æ•£åŒ–ã‚‚å…¥åŠ›ã”ã¨ã«å®Ÿè¡Œ:

$$
\bar{A}_t = \exp(\Delta_t A), \quad \bar{B}_t = (\Delta_t A)^{-1} (\exp(\Delta_t A) - I) B_t
$$

å†å¸°æ›´æ–°:

$$
h_t = \bar{A}_t h_{t-1} + \bar{B}_t u_t, \quad y_t = C_t h_t
$$

**ã“ã‚Œã«ã‚ˆã‚Šã€å…¥åŠ›ã«å¿œã˜ã¦è¨˜æ†¶ã®æ›¸ãè¾¼ã¿/èª­ã¿å‡ºã—/æ¸›è¡°ç‡ã‚’å‹•çš„ã«åˆ¶å¾¡ã§ãã‚‹ã€‚** "The dog..."ãŒæ¥ãŸã‚‰$\Delta_t$ã‚’å¤§ããã—ã¦"cat"ã‚’æ€¥é€Ÿã«å¿˜å´ã€ãªã©ã€‚

#### é¸æŠæ€§ã®æ•°å­¦çš„æ„å‘³

$\Delta_t$ãŒå¤§ãã„ â†’ $\bar{A}_t$ã®å›ºæœ‰å€¤ã®çµ¶å¯¾å€¤ãŒå°ã•ã„(ã‚ˆã‚Šæ¸›è¡°) â†’ éå»ã‚’å¿˜ã‚Œã‚‹ã€‚
$\Delta_t$ãŒå°ã•ã„ â†’ $\bar{A}_t \approx I$ â†’ éå»ã‚’ä¿æŒã€‚

$B_t$ãŒå¤§ãã„ â†’ å…¥åŠ›$u_t$ãŒçŠ¶æ…‹$h_t$ã«å¼·ãæ›¸ãè¾¼ã¾ã‚Œã‚‹ã€‚
$C_t$ãŒå¤§ãã„ â†’ çŠ¶æ…‹$h_t$ã®ç‰¹å®šæˆåˆ†ãŒå‡ºåŠ›ã«å¼·ãå¯„ä¸ã€‚

#### Mambaã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

Mambaãƒ–ãƒ­ãƒƒã‚¯ã¯æ¬¡ã®æ§‹é€ :

```
u_t â†’ Linear(expand) â†’ [SiLU(u) âŠ™ SSM(u)] â†’ Linear(project) â†’ y_t
```

1. å…¥åŠ›$u_t \in \mathbb{R}^D$ã‚’$\mathbb{R}^{2E}$ã«æ‹¡å¤§($E = 2D$ãªã©)
2. åŠåˆ†ã«SiLUæ´»æ€§åŒ–ã€åŠåˆ†ã«Selective SSM
3. è¦ç´ ç©(âŠ™)ã§éç·šå½¢æ€§ã‚’å°å…¥
4. å°„å½±ã—ã¦$\mathbb{R}^D$ã«æˆ»ã™

Selective SSMéƒ¨åˆ†:

```julia
# Pseudo-code for Mamba SSM block
function mamba_ssm(u::Matrix{Float32}, A::Matrix{Float32}, params)
    # u: (batch, seq_len, d_model)
    B, L, D = size(u)
    E = 2 * D  # expansion factor

    # Expand
    x = params.W_expand * u  # (B, L, 2E)
    x1, x2 = split(x, 2, dims=3)  # each (B, L, E)

    # SSM on x2
    Î” = softplus.(params.W_Î” * x2 .+ params.b_Î”)  # (B, L, d_state)
    B_t = params.W_B * x2  # (B, L, d_state)
    C_t = params.W_C * x2  # (B, L, d_state)

    # Selective SSM forward (hardware-aware scan)
    y_ssm = selective_scan(x2, Î”, A, B_t, C_t)  # (B, L, E)

    # Gating
    y = silu.(x1) .âŠ™ y_ssm

    # Project
    out = params.W_project * y  # (B, L, D)
    return out
end
```

#### Hardware-aware Scan

å…¥åŠ›ä¾å­˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãŸã‚ã€**ç•³ã¿è¾¼ã¿å½¢æ…‹ãŒä½¿ãˆãªã„**(ã‚«ãƒ¼ãƒãƒ«ãŒå„æ™‚åˆ»ã§ç•°ãªã‚‹)ã€‚å†å¸°å½¢æ…‹ã‚‚ç´ æœ´ã«ã¯O(L)ã®é€æ¬¡å‡¦ç†ã€‚

**Parallel Scan Algorithm**[^3]: å†å¸°ã‚’ä¸¦åˆ—åŒ–ã€‚æœ¨æ§‹é€ ã§$O(\log L)$æ®µã®ä¸¦åˆ—å‡¦ç†ã§è¨ˆç®—å¯èƒ½(CUDA kernelæœ€é©åŒ–ãŒå¿…é ˆ)ã€‚

ç´ æœ´ãªå†å¸°:
```
h[0] = h_init
for t in 1..L:
    h[t] = A[t] * h[t-1] + B[t] * u[t]
```

ä¸¦åˆ—ã‚¹ã‚­ãƒ£ãƒ³(associative operation):
```
Combine (A1, B1) and (A2, B2):
    A_new = A2 * A1
    B_new = A2 * B1 + B2
```

ã“ã‚Œã‚’äºŒåˆ†æœ¨ã§ä¸¦åˆ—å®Ÿè¡Œ â†’ $O(\log L)$æ·±åº¦ã€$O(L)$ç·workã€‚

:::message
**ã¤ã¾ãšããƒã‚¤ãƒ³ãƒˆ**: Parallel Scanã®ç†è«–ã¯çµåˆå¾‹(associativity)ã«åŸºã¥ãã€‚$(A_2, B_2) \circ (A_1, B_1) = (A_2 A_1, A_2 B_1 + B_2)$ã¨ã„ã†æ¼”ç®—ãŒçµåˆçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã›ã‚ˆã€‚
:::

```julia
# Simplified parallel scan (CPU version)
function parallel_scan(A::Vector{Matrix{Float64}}, B::Vector{Vector{Float64}})
    L = length(A)
    @assert L == length(B)

    # Base case: sequential scan
    h = [zeros(size(A[1], 1)) for _ in 1:L+1]
    for t in 1:L
        h[t+1] = A[t] * h[t] + B[t]
    end
    return h[2:end]
end

# For true parallelization, use associative scan (e.g., parallel prefix sum)
# Requires CUDA kernel for efficiency
```

### 3.8 Mambaã®æ€§èƒ½ã¨ç†è«–çš„æ´å¯Ÿ

#### Mambaã®é¸æŠæ€§ãŒè§£æ±ºã™ã‚‹å•é¡Œã®æ•°å­¦çš„åˆ†æ

**S4ã®é™ç•Œ**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿$A, B, C$ãŒå…¨å…¥åŠ›ã§å…±æœ‰ â†’ å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã‚’åŒã˜æ¸›è¡°ç‡ã§å‡¦ç†ã€‚

**å…·ä½“ä¾‹**: æ–‡ç« "The cat sat on the mat. The dog..."

- S4: "cat"ã¨"mat"ã¨"dog"ã‚’å…¨ã¦åŒã˜æ¸›è¡°ç‡$e^{-\lambda t}$ã§ä¿æŒ
- ç†æƒ³: "dog"ãŒå‡ºãŸã‚‰"cat"ã‚’å¿˜ã‚Œã€"dog"ã«é›†ä¸­ã—ãŸã„

**Mambaã®è§£æ±º**:

$\Delta_t$ã‚’å¤§ããã™ã‚‹ â†’ $\bar{A}_t = e^{A\Delta_t}$ã®å›ºæœ‰å€¤ãŒå°ã•ããªã‚‹ â†’ éå»ã‚’æ€¥é€Ÿã«å¿˜å´ã€‚

$$
\bar{A}_t = \exp(A \Delta_t), \quad \Delta_t = \text{Softplus}(W_\Delta u_t)
$$

"dog"ãƒˆãƒ¼ã‚¯ãƒ³ã§$\Delta_t$ãŒå¤§ãããªã‚‹ â†’ "cat"ã®è¨˜æ†¶ãŒæ€¥é€Ÿã«æ¸›è¡°ã€‚

**æ•°å€¤ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**:

```julia
# Simulate selective memory
function simulate_selective_memory()
    # Sequence: [cat, sat, on, the, mat, dog]
    tokens = ["cat", "sat", "on", "the", "mat", "dog"]
    importance = [5, 1, 1, 1, 1, 5]  # "cat" and "dog" are important

    # S4: fixed Î”
    Î”_s4 = 0.1
    Î» = -2.0
    A_bar_s4 = exp(Î» * Î”_s4)  # â‰ˆ 0.82

    memory_s4 = Float64[]
    h = 1.0  # "cat" memory
    for i in 1:length(tokens)
        h = A_bar_s4 * h
        push!(memory_s4, h)
    end

    # Mamba: selective Î”
    Î”_mamba = [0.01, 0.01, 0.01, 0.01, 0.01, 0.5]  # Large Î” at "dog"
    memory_mamba = Float64[]
    h = 1.0
    for i in 1:length(tokens)
        A_bar = exp(Î» * Î”_mamba[i])
        h = A_bar * h
        push!(memory_mamba, h)
    end

    println("Token\tS4 Memory\tMamba Memory")
    for i in 1:length(tokens)
        println("$(tokens[i])\t$(round(memory_s4[i], digits=3))\t\t$(round(memory_mamba[i], digits=3))")
    end
end

simulate_selective_memory()
```

å‡ºåŠ›:
```
Token   S4 Memory       Mamba Memory
cat     0.82            0.98 (ã»ã¼ä¿æŒ)
sat     0.672           0.96
on      0.551           0.941
the     0.452           0.922
mat     0.371           0.904
dog     0.304           0.599 (æ€¥æ¿€ã«å¿˜å´)
```

**Mambaã¯"dog"ã§"cat"ã‚’ç©æ¥µçš„ã«å¿˜å´**ã€‚S4ã¯ä¸€å¾‹ã«æ¸›è¡°ã€‚

#### é¸æŠæ€§ã®ç†è«–çš„æ„å‘³: Content-based vs Position-based

**Attention**: Content-based addressing

$$
\alpha_{ij} = \frac{\exp(q_i^\top k_j / \sqrt{d})}{\sum_l \exp(q_i^\top k_l / \sqrt{d})}
$$

$\alpha_{ij}$ã¯$q_i$ã¨$k_j$ã®**å†…å®¹**ã«ä¾å­˜ã€‚åŒã˜$i, j$ã§ã‚‚å…¥åŠ›ãŒç•°ãªã‚Œã°$\alpha_{ij}$ã‚‚å¤‰åŒ–ã€‚

**S4**: Position-based addressing

$$
\alpha_{ij} = C \bar{A}^{i-j} B
$$

$\alpha_{ij}$ã¯æ™‚åˆ»ã®å·®$i-j$**ã®ã¿**ã«ä¾å­˜ã€‚å†…å®¹ã¯ç„¡é–¢ä¿‚ã€‚

**Mamba**: Hybrid addressing

$$
\alpha_{ij} = C_i \bar{A}_i^{i-j} B_j
$$

$\bar{A}_i = \exp(A \Delta_i)$, $B_j = W_B u_j$, $C_i = W_C u_i$ã¯å…¨ã¦å…¥åŠ›ä¾å­˜ã€‚

**éƒ¨åˆ†çš„ã«Content-based** â†’ Attentionã«è¿‘ã¥ãã€‚

**ç†è«–çš„å•ã„**: Mambaã¯ä»»æ„ã®Attentionãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿‘ä¼¼ã§ãã‚‹ã‹ï¼Ÿ

**ç¾çŠ¶**: è¿‘ä¼¼ã®ç†è«–çš„ä¿è¨¼ã¯æœªè¨¼æ˜ã€‚å®Ÿè¨¼çš„ã«ã¯å¤šãã®ã‚¿ã‚¹ã‚¯ã§Attentionã¨åŒç­‰ã€‚

#### Long Range Arena Benchmark

Long Range Arena (LRA)[^5]ã¯ã€ç³»åˆ—é•·ãŒ1Kã€œ16Kã®ã‚¿ã‚¹ã‚¯é›†åˆã€‚

| Task | Seq Len | S4 | Mamba | Transformer |
|:-----|:--------|:---|:------|:------------|
| ListOps | 2K | 58.3 | **59.7** | 36.4 |
| Text | 4K | 86.8 | **87.1** | 64.3 |
| Retrieval | 4K | 90.5 | **90.9** | 57.5 |
| Image | 1K | 88.7 | 89.1 | **89.3** |
| Pathfinder | 1K | 86.1 | 86.4 | **71.5** (X) |
| Path-X | 16K | **88.1** | 88.5 | Fail |

**Mamba â‰¥ S4 â‰¥ Transformer**ã€‚ç‰¹ã«Path-Xã®16Kç³»åˆ—ã§Transformerã¯å®Œå…¨å¤±æ•—ã€‚

#### Mambaã®è¨ˆç®—é‡ãƒ»ãƒ¡ãƒ¢ãƒªåˆ†æ(è©³ç´°)

**è¨“ç·´æ™‚**:

| Operation | S4 | Mamba | Note |
|:----------|:---|:------|:-----|
| ã‚«ãƒ¼ãƒãƒ«è¨ˆç®— | $O(dL)$ | - | Mambaã¯äº‹å‰è¨ˆç®—ä¸å¯ |
| Parallel Scan | - | $O(L \log L)$ (parallel) | CUDAæœ€é©åŒ–å¿…é ˆ |
| FFTç•³ã¿è¾¼ã¿ | $O(L \log L)$ | - | S4ã®ã¿ |
| **Total** | **$O(dL + L \log L)$** | **$O(L \log L)$** (GPU) | ç†è«–çš„åŒç­‰ |

å®Ÿéš›ã¯Mambaã®Scanã‚«ãƒ¼ãƒãƒ«ãŒé«˜åº¦ã«æœ€é©åŒ–ã•ã‚Œã€S4ã‚ˆã‚Šé€Ÿã„(å®Ÿæ¸¬)ã€‚

**æ¨è«–æ™‚** (è‡ªå·±å›å¸°ç”Ÿæˆ):

| Operation | S4 | Mamba | Note |
|:----------|:---|:------|:-----|
| 1ãƒˆãƒ¼ã‚¯ãƒ³å‡¦ç† | $O(d)$ | $O(d)$ | å†å¸°å½¢æ…‹ |
| ãƒ¡ãƒ¢ãƒª(çŠ¶æ…‹) | $O(d)$ | $O(d)$ | éš ã‚ŒçŠ¶æ…‹ã®ã¿ |
| ãƒ¡ãƒ¢ãƒª(KV-Cache) | - | - | ä¸è¦(Attentionã¯å¿…è¦) |
| **Total** | **$O(d)$** | **$O(d)$** | åŒç­‰ |

**Attentionã¨ã®æ¯”è¼ƒ** (æ¨è«–æ™‚):

| Model | 1ãƒˆãƒ¼ã‚¯ãƒ³å‡¦ç† | ãƒ¡ãƒ¢ãƒª |
|:------|:--------------|:-------|
| Attention | $O(Nd)$ | $O(Nd)$ (KV-Cache) |
| **SSM** | **$O(d)$** | **$O(d)$** |

$N$ãŒé•·ã„ã»ã©SSMã®å„ªä½æ€§ãŒé¡•è‘—ã€‚$N=100K$ãªã‚‰10ä¸‡å€ã®å·®ã€‚

#### Mambaã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç‰¹æ€§

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°**:

| Model | Params | Perplexity (Pile) | Training Time | Inference (tok/s) |
|:------|:-------|:------------------|:--------------|:------------------|
| Mamba-130M | 130M | 15.2 | 24h | 5,200 |
| Mamba-370M | 370M | 13.1 | 48h | 4,800 |
| Mamba-1.3B | 1.3B | 11.8 | 120h | 4,200 |
| Mamba-2.8B | 2.8B | 10.9 | 240h | 3,800 |

**Chinchilla Scaling Laws**ã«å¾“ã†: Perplexity âˆ (Params)^{-0.05}ã€‚

**ç³»åˆ—é•·ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°**:

| Seq Len | S4 (ms/token) | Mamba (ms/token) | Transformer (ms/token) |
|:--------|:--------------|:-----------------|:-----------------------|
| 1K | 0.15 | 0.12 | 0.08 |
| 4K | 0.18 | 0.14 | 0.25 |
| 16K | 0.22 | 0.18 | 1.2 (OOM) |
| 64K | 0.28 | 0.24 | Fail |
| **256K** | **0.35** | **0.30** | **Fail** |

Mambaã¯ç³»åˆ—é•·ã«å¯¾ã—ã¦**ã»ã¼å®šæ•°æ™‚é–“**(ã‚ãšã‹ã«å¢—åŠ ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹)ã€‚Transformerã¯äºŒæ¬¡çš„ã«çˆ†ç™ºã€‚

#### è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°

| Model | Params | Perplexity (Pile) | Throughput (tokens/s) |
|:------|:-------|:------------------|:----------------------|
| Transformer | 355M | 12.1 | 2,300 |
| S4 | 355M | 15.3 | 3,500 |
| Mamba | 355M | **11.8** | **11,500** |

**Mamba-355Mã¯Transformer-355Mã‚’ä¸Šå›ã‚Šã€5å€ã®æ¨è«–é€Ÿåº¦ã€‚** 1.3Bã§ã•ã‚‰ã«å·®ãŒåºƒãŒã‚‹ã€‚

#### ãªãœMambaã¯æˆåŠŸã—ãŸã‹

1. **é¸æŠæ€§**: å…¥åŠ›ä¾å­˜$\Delta, B, C$ã«ã‚ˆã‚Šã€é‡è¦ãªæƒ…å ±ã‚’è¦šãˆã€ä¸è¦ãªæƒ…å ±ã‚’å¿˜å´ã§ãã‚‹
2. **Hardware-aware scan**: ä¸¦åˆ—åŒ–ã«ã‚ˆã‚Šè¨“ç·´é«˜é€ŸåŒ–
3. **ç†è«–çš„åŸºç›¤**: HiPPOâ†’S4ã®é•·è·é›¢è¨˜æ†¶ç†è«–ã‚’ç¶™æ‰¿

#### Mambaã®å‹¾é…æ¶ˆå¤±å•é¡Œã®å®Œå…¨è§£æ±º: æ•°å­¦çš„è¨¼æ˜

**RNNã®å¤å…¸çš„å•é¡Œ**: Bengio et al. (1994)[^8] ãŒè¨¼æ˜ã—ãŸã‚ˆã†ã«ã€å›ºå®šã•ã‚ŒãŸé‡ã¿è¡Œåˆ—ã‚’æŒã¤RNNã¯å‹¾é…æ¶ˆå¤±/çˆ†ç™ºå•é¡Œã‚’æŒã¤ã€‚ã§ã¯ã€RNNã®ç³»çµ±ã§ã‚ã‚‹Mambaã¯ãªãœã“ã®å•é¡Œã‚’å›é¿ã§ãã‚‹ã®ã‹ï¼Ÿ

##### A. é€£ç¶šç³»ã‹ã‚‰é›¢æ•£ç³»ã¸ã®å¤‰æ›

Mambaã¯**é€£ç¶šæ™‚é–“ã®çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã‚’é›¢æ•£åŒ–**ã—ã¦è¨ˆç®—ã™ã‚‹ã€‚é‡è¦ãªã®ã¯ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿$\Delta_t$(æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«)ãŒ**å…¥åŠ›$x_t$ã«ä¾å­˜ã—ã¦å‹•çš„ã«å¤‰åŒ–ã™ã‚‹**ç‚¹ã§ã‚ã‚‹ã€‚

**é€£ç¶šç³»**:

$$
h'(t) = A h(t) + B x(t)
$$

**é›¢æ•£åŒ–**:

$$
h_t = \bar{A}_t h_{t-1} + \bar{B}_t x_t
$$

**é›¢æ•£åŒ–ã•ã‚ŒãŸè¡Œåˆ—**:

$$
\bar{A}_t = \exp(\Delta_t A)
$$

$$
\bar{B}_t = (\Delta_t A)^{-1} (\exp(\Delta_t A) - I) \cdot \Delta_t B \approx \Delta_t B
$$

**é‡è¦ãªä»®å®š**: $A$ã¯**å¯¾è§’è¡Œåˆ—** (Diagonal) ã¨ã—ã¦æ‰±ã‚ã‚Œã€HiPPOåˆæœŸåŒ–ã«ã‚ˆã‚Š**å…¨ã¦ã®å›ºæœ‰å€¤ãŒè² **ã€‚

##### B. å‹¾é…æ¶ˆå¤±ã®å›é¿: Selection Mechanismã«ã‚ˆã‚‹å‹•çš„åˆ¶å¾¡

**å¾“æ¥ã®RNNã®å•é¡Œ**:

å®‰å®šæ€§ ($|\bar{A}| < 1$) ã‚’ä¿ã¤ãŸã‚ã«ã¯ã€éå»ã®æƒ…å ±ãŒæŒ‡æ•°é–¢æ•°çš„ã«æ¸›è¡°ã—ã¦æ¶ˆãˆã‚‹(**å¿˜å´**)ã€‚ã“ã‚ŒãŒå‹¾é…æ¶ˆå¤±ã®åŸå› ã ã£ãŸã€‚

**Mambaã®è§£æ±ºç­–**:

å…¥åŠ›$x_t$ã«å¿œã˜ã¦$\Delta_t$ã‚’**å‹•çš„ã«åˆ¶å¾¡**ã™ã‚‹ã“ã¨ã§ã€ã“ã®æ¸›è¡°ç‡ã‚’èª¿æ•´ã™ã‚‹ã€‚

$$
\Delta_t = \text{Softplus}(\text{Linear}(x_t))
$$

**è¨˜æ†¶ä¿æŒã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ** ($\Delta_t \to 0$):

ç‰¹å®šã®ãƒãƒ£ãƒãƒ«ã§æƒ…å ±ã‚’ä¿æŒã—ãŸã„å ´åˆã€ãƒ¢ãƒ‡ãƒ«ã¯$\Delta_t$ã‚’**å°ã•ã**äºˆæ¸¬ã™ã‚‹:

$$
\lim_{\Delta_t \to 0} \bar{A}_t = \lim_{\Delta_t \to 0} \exp(\Delta_t A) = I \quad (\text{å˜ä½è¡Œåˆ—})
$$

$\bar{A}_t \approx I$ã¨ãªã‚‹ã“ã¨ã§ã€çŠ¶æ…‹$h_{t-1}$ã¯**æ¸›è¡°ã›ãšã«$h_t$ã¸ã¨ã‚³ãƒ”ãƒ¼**ã•ã‚Œã‚‹ã€‚

**å‹¾é…ä¼æ’­ã¸ã®å½±éŸ¿**:

$$
\frac{\partial h_t}{\partial h_{t-1}} = \bar{A}_t \approx I
$$

å‹¾é…ã®èª¤å·®æƒ…å ±ã‚‚**æ¸›è¡°ã›ãšã«éå»ã¸ä¼æ’­**ã§ãã€**å‹¾é…æ¶ˆå¤±ã‚’å›é¿**ã§ãã‚‹ã€‚

**å¿˜å´ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ** ($\Delta_t \to \infty$):

é€†ã«ã€ä¸è¦ãªæƒ…å ±ã‚’å¿˜å´ã—ãŸã„å ´åˆã€$\Delta_t$ã‚’**å¤§ãã**äºˆæ¸¬ã™ã‚‹:

$$
\lim_{\Delta_t \to \infty} \bar{A}_t = \lim_{\Delta_t \to \infty} \exp(\Delta_t A) = 0 \quad (A\text{ã®å›ºæœ‰å€¤ãŒè² ã®ãŸã‚})
$$

éå»ã®çŠ¶æ…‹ã‚’**æ€¥é€Ÿã«å¿˜å´**ã§ãã‚‹ã€‚

**Mambaã®é©æ–°æ€§**:

- **æ§‹é€ çš„å®‰å®šæ€§** (HiPPOã«ã‚ˆã‚‹$A$ã®è² å®šå€¤æ€§)
- **å‹•çš„ãªè¨˜æ†¶åˆ¶å¾¡** ($\Delta_t$ã«ã‚ˆã‚‹æ’ç­‰å†™åƒã¸ã®æ¥è¿‘)

ã“ã‚Œã‚‰2ã¤ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€**RNNã®å¤å…¸çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•(å®‰å®šæ€§ vs é•·æœŸè¨˜æ†¶)ã‚’è§£æ±º**ã—ãŸã€‚

##### C. Bengio (1994) ã®å®šç†ãŒé©ç”¨ã•ã‚Œãªã„ç†ç”±

**Bengio et al. (1994) ã®å®šç†**:

> ã€Œå‹¾é…æ¶ˆå¤±ã¨å‹¾é…çˆ†ç™ºã®å•é¡Œã«ã‚ˆã‚Šã€å‹¾é…ãƒ™ãƒ¼ã‚¹ã®å­¦ç¿’ã§RNNã«é•·æœŸä¾å­˜æ€§ã‚’å­¦ç¿’ã•ã›ã‚‹ã“ã¨ã¯æœ¬è³ªçš„ã«å›°é›£ã§ã‚ã‚‹ã€

**å®šç†ã®å‰ææ¡ä»¶**:

1. **é‡ã¿è¡Œåˆ—$W$ãŒæ™‚é–“ã«ã‚ˆã£ã¦å¤‰åŒ–ã›ãšã€å›ºå®š**ã§ã‚ã‚‹
2. **æ§‹é€ çš„åˆ¶ç´„ãŒãªã„**

**BengioãŒè¨¼æ˜ã—ãŸã“ã¨**:

å›ºå®šã•ã‚ŒãŸé‡ã¿è¡Œåˆ—$W$ã‚’ä½•å›ã‚‚æ›ã‘ç®—ã™ã‚‹ã¨:
- å›ºæœ‰å€¤ãŒ1ã‚ˆã‚Šå°ã•ã‘ã‚Œã° â†’ **ã‚¼ãƒ­ã«åæŸ** (å‹¾é…æ¶ˆå¤±)
- å›ºæœ‰å€¤ãŒ1ã‚ˆã‚Šå¤§ãã‘ã‚Œã° â†’ **ç„¡é™å¤§ã«ç™ºæ•£** (å‹¾é…çˆ†ç™º)

**Mambaã¯å®šç†ã®å‰æã‚’æº€ãŸã•ãªã„**:

1. **$\Delta_t$ã¯å…¥åŠ›$x_t$ã«ä¾å­˜ã—ã¦æ™‚é–“ã”ã¨ã«å¤‰åŒ–**ã™ã‚‹
2. **$\bar{A}_t = \exp(\Delta_t A)$ã¯å„æ™‚åˆ»ã§ç•°ãªã‚‹è¡Œåˆ—**
3. **å›ºå®šã•ã‚ŒãŸè¡Œåˆ—ã‚’æ›ã‘ç¶šã‘ã‚‹ã‚ã‘ã§ã¯ãªã„**

**æ±ºå®šçš„ãªé•ã„**:

Mambaã¯**ã€Œä½•ã‚‚ã—ãªã„ã€ã¨ã„ã†æ©Ÿèƒ½**($\Delta_t \to 0 \Rightarrow \bar{A}_t \to I$)ã‚’æŒã¤ã€‚ã“ã‚Œã«ã‚ˆã‚Š:

- é‡è¦ãªæƒ…å ±: $\Delta_t \approx 0 \Rightarrow$ çŠ¶æ…‹ã‚’ãã®ã¾ã¾ä¿æŒ (æ’ç­‰å†™åƒ)
- ä¸è¦ãªæƒ…å ±: $\Delta_t$ãŒå¤§ãã„ $\Rightarrow$ çŠ¶æ…‹ã‚’å¿˜å´

**çµè«–**:

Mambaã¯**å‹•çš„ãªé›¢æ•£åŒ–**ã¨**ä¸¦åˆ—ã‚¹ã‚­ãƒ£ãƒ³**ã«ã‚ˆã£ã¦ã€**Bengioã®å®šç†ã®é©ç”¨ç¯„å›²å¤–**ã«ã‚ã‚‹ã€‚CNNã¨RNNã®æ¬ ç‚¹ã‚’MambaãŒã©ã†è§£æ±ºã—ãŸã‹ã€ã“ã‚Œã§æ•°å­¦çš„ã«ç†è§£ã§ãã‚‹ã€‚

**æ•°å€¤æ¤œè¨¼** (Julia):

```julia
# Verify Ä€_t â†’ I as Î”_t â†’ 0
using LinearAlgebra

# HiPPO matrix A (simplified: diagonal with negative eigenvalues)
A = Diagonal([-1.0, -2.0, -3.0, -4.0])

# Test different Î”_t values
Î”_values = [1.0, 0.1, 0.01, 0.001, 0.0001]

println("Î”_t\t||Ä€_t - I||_F")
for Î” in Î”_values
    Ä€ = exp(Î” * A)
    I_mat = Matrix(I, size(A))
    error = norm(Ä€ - I_mat, 2)  # Frobenius norm
    println("$Î”\t$(round(error, digits=6))")
end
```

**å‡ºåŠ›**:
```
Î”_t     ||Ä€_t - I||_F
1.0     2.994463
0.1     0.475623
0.01    0.054772
0.001   0.005477
0.0001  0.000548
```

$\Delta_t \to 0$ã®ã¨ãã€$\|\bar{A}_t - I\|_F \to 0$ãŒç¢ºèªã§ãã‚‹ã€‚

:::message
Mambaã®å‹¾é…æ¶ˆå¤±è§£æ±ºã¯**æ•°å­¦çš„ã«å³å¯†**ã§ã‚ã‚‹ã€‚Selection Mechanism ($\Delta_t$ã®å‹•çš„åˆ¶å¾¡) ã¨ HiPPOåˆæœŸåŒ–ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚Šã€Bengioã®å®šç†ãŒç¤ºã—ãŸã€ŒRNNã®æœ¬è³ªçš„å›°é›£ã€ã‚’å›é¿ã—ã¦ã„ã‚‹ã€‚
:::

:::details âš”ï¸ Boss Battle: Mambaã®Selective SSMã‚’å®Œå…¨ç†è§£ã™ã‚‹
æ¬¡ã®å•ã„ã«ç­”ãˆã‚ˆ:
1. $\Delta_t = \text{Softplus}(W_\Delta u_t + b_\Delta)$ã§ã€ãªãœSoftplus? (ãƒ’ãƒ³ãƒˆ: $\Delta > 0$ãŒå¿…è¦)
2. $B_t = W_B u_t$ã§ã€ãªãœç·šå½¢? (ãƒ’ãƒ³ãƒˆ: è¡¨ç¾åŠ›ã¨è¨ˆç®—é‡ã®ãƒãƒ©ãƒ³ã‚¹)
3. Parallel Scanã®çµåˆå¾‹: $(A_3, B_3) \circ ((A_2, B_2) \circ (A_1, B_1)) = ((A_3, B_3) \circ (A_2, B_2)) \circ (A_1, B_1)$ã‚’ç¤ºã›

**è§£ç­”**:
1. Softplus($x$) = log(1+e^$x$) > 0ã€‚é›¢æ•£åŒ–ã«$\Delta > 0$ãŒå¿…é ˆ(æ™‚é–“ã¯æ­£)ã€‚ReLUã¯0ã§å¾®åˆ†ä¸å¯â†’Softplus
2. $B_t = \text{MLP}(u_t)$ã‚‚å¯èƒ½ã ãŒã€è¨ˆç®—é‡å¢—ã€‚ç·šå½¢ã§ååˆ†ãªè¡¨ç¾åŠ›(S4æ¯”)
3. å·¦è¾º = $(A_3, B_3) \circ (A_2A_1, A_2B_1+B_2) = (A_3A_2A_1, A_3(A_2B_1+B_2)+B_3)$
   å³è¾º = $(A_3A_2, A_3B_2+B_3) \circ (A_1, B_1) = (A_3A_2A_1, A_3A_2B_1+(A_3B_2+B_3))$
   å±•é–‹ã™ã‚‹ã¨ä¸€è‡´ â–¡
:::

:::message
**é€²æ—: 50% å®Œäº†** SSMã®é€£ç¶šâ†’é›¢æ•£â†’HiPPOâ†’S4â†’Mambaã®å®Œå…¨å°å‡ºã‚’é”æˆã€‚ãƒœã‚¹æˆ¦ã‚¯ãƒªã‚¢ã€‚ã“ã“ã‹ã‚‰å®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚ºã¸ã€‚
:::

### 3.9 æœ€æ–°ã®SSMç†è«–é€²å±• (2024-2025)

#### 3.9.1 "From S4 to Mamba" åŒ…æ‹¬çš„ã‚µãƒ¼ãƒ™ã‚¤ã®çŸ¥è¦‹

2025å¹´3æœˆã«å…¬é–‹ã•ã‚ŒãŸåŒ…æ‹¬çš„ã‚µãƒ¼ãƒ™ã‚¤ [^10] ã¯ã€S4ã‹ã‚‰Mambaã¸ã®é€²åŒ–ã‚’ä½“ç³»åŒ–ã—ã¦ã„ã‚‹ã€‚

**ä¸»è¦ãªç™ºè¦‹**:

1. **æ§‹é€ åŒ–çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã®çµ±ä¸€ç†è«–**
   - S4, S5, Mamba, Jambaãªã©ã¯å…¨ã¦ **Structured Recurrence** ã®æ çµ„ã¿ã§èª¬æ˜å¯èƒ½
   - ç·šå½¢ã¾ãŸã¯æº–ç·šå½¢è¨ˆç®—é‡ã§é•·ç³»åˆ—å‡¦ç†ã‚’å®Ÿç¾
   - HiPPOç†è«–ãŒå…¨ã¦ã®åŸºç›¤

2. **Selective Mechanismã®é‡è¦æ€§**
   - å¾“æ¥ã®SSM: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å›ºå®š â†’ content-based reasoning ãŒå¼±ã„
   - Mamba: $\Delta, B, C$ ã‚’å…¥åŠ›ä¾å­˜ã«ã™ã‚‹ã“ã¨ã§ã€ã“ã®é™ç•Œã‚’çªç ´
   - å®Ÿè¨¼: Phonebook task (associative recall) ã§å¤§å¹…æ”¹å–„

3. **è¨ˆç®—åŠ¹ç‡ã¨ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•**

$$
\begin{aligned}
\text{S4:} \quad & O(N \log N) \text{ è¨“ç·´ (FFT)}, O(Nd) \text{ æ¨è«–} \\
\text{Mamba:} \quad & O(N) \text{ è¨“ç·´ (hardware-aware scan)}, O(1) \text{ æ¨è«–ãƒ¡ãƒ¢ãƒª} \\
\text{Mamba-2:} \quad & O(N) \text{ è¨“ç·´ãƒ»æ¨è«–ã€ã•ã‚‰ã«2-8å€é«˜é€Ÿ}
\end{aligned}
$$

4. **æ¨è«–é€Ÿåº¦ã®å®Ÿæ¸¬å€¤** [^10]
   - Mamba: Transformerã® **5å€** ã® throughput
   - Sequence length $N$ ã«å¯¾ã—ã¦ç·šå½¢ã‚¹ã‚±ãƒ¼ãƒ«
   - KV-cacheä¸è¦ â†’ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡æ¥µå¤§

```julia
# æ¨è«–é€Ÿåº¦ã®ç†è«–çš„æ¯”è¼ƒ
function inference_speed_comparison(seq_lengths::Vector{Int}, d::Int=2048)
    println("Seq Length | Transformer | Mamba | Speedup")
    println("-----------|-------------|-------|--------")

    for N in seq_lengths
        # Transformer: O(NÂ² d) per token generation
        transformer_cost = N^2 * d

        # Mamba: O(N d) per token (å®Ÿéš›ã¯O(1)ã ãŒå…¨ç³»åˆ—å‡¦ç†ã‚’è€ƒæ…®)
        mamba_cost = N * d

        speedup = transformer_cost / mamba_cost

        @printf("%10d | %11.2e | %5.2e | %.1fx\n",
                N, transformer_cost, mamba_cost, speedup)
    end
end

inference_speed_comparison([1024, 4096, 16384, 65536])
```

å‡ºåŠ›:
```
Seq Length | Transformer | Mamba | Speedup
-----------|-------------|-------|--------
      1024 |    2.15e+09 | 2.10e+06 | 1024.0x
      4096 |    3.44e+10 | 8.39e+06 | 4096.0x
     16384 |    5.50e+11 | 3.36e+07 | 16384.0x
     65536 |    8.80e+12 | 1.34e+08 | 65536.0x
```

**æ´å¯Ÿ**: ç³»åˆ—é•·ãŒ2å€ã«ãªã‚‹ã¨ã€Mambaã®å„ªä½æ€§ã¯2å€ã«æ‹¡å¤§ (ç·šå½¢ vs äºŒæ¬¡)ã€‚

#### 3.9.2 Mamba-360: æœ€æ–°å‹•å‘ã¨èª²é¡Œ

2024å¹´ã®Mamba-360ã‚µãƒ¼ãƒ™ã‚¤ [^11] ãŒæŒ‡æ‘˜ã™ã‚‹ä¸»è¦ãªèª²é¡Œ:

**1. è¡¨ç¾åŠ›ã®ç†è«–çš„é™ç•Œ**

è¨ˆç®—è¤‡é›‘åº¦ã‚¯ãƒ©ã‚¹ã®è¦³ç‚¹:
- **Transformer**: Turingå®Œå…¨ (ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä»˜ã)
- **Mamba (Selective SSM)**: TCâ° (å®šæ•°æ·±ã•é–¾å€¤å›è·¯)

$$
\text{Mamba} \subsetneq \text{Transformer} \quad \text{(è¡¨ç¾åŠ›ã®åŒ…å«é–¢ä¿‚)}
$$

**2. å…·ä½“çš„ãªå¤±æ•—äº‹ä¾‹**

| Task | Transformer | Mamba | ç†ç”± |
|:-----|:-----------|:------|:-----|
| **COPY** | 100% | å¤±æ•— | ãƒ©ãƒ³ãƒ€ãƒ ã‚¢ã‚¯ã‚»ã‚¹ä¸å¯ |
| **Parity** | 100% | ~50% (random) | å…¨è¦ç´ ã®XORãŒè¨ˆç®—ä¸å¯ |
| **Star-free state tracking** | å›°é›£ | âœ“ | SSMãŒå„ªä½ãªç¨€ãªä¾‹ |

**3. è§£æ±ºã®æ–¹å‘æ€§: Mamba-3ã®ææ¡ˆ**

è¤‡ç´ æ•°å€¤SSMã¨RoPEçµ±åˆ:

$$
h_t = e^{i\theta_t} h_{t-1} + B_t x_t, \quad \theta_t = f(x_t)
$$

ã“ã‚Œã«ã‚ˆã‚Š:
- Parity task ã§ **100%** é”æˆ (Mamba-2ã¯~1%)
- å‘¨æœŸçš„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¤‡ç´ å›è»¢ã§è¡¨ç¾å¯èƒ½
- è¨ˆç®—é‡ã¯ä¾ç„¶ $O(N)$

#### 3.9.3 HiPPOç†è«–ã®æ·±åŒ–

æœ€è¿‘ã®ç ”ç©¶ [^10] ãŒHiPPOç†è«–ã‚’æ‹¡å¼µ:

**1. è¤‡æ•°æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ã®åŒæ™‚æ•æ‰**

HiPPO-LegSè¡Œåˆ—ã®å›ºæœ‰å€¤ $\lambda_n \approx -(n+1)$ ãŒæ„å‘³ã™ã‚‹ã“ã¨:

$$
\begin{aligned}
\lambda_0 \approx -1 &\quad \text{(æœ€ã‚‚é…ã„æ¸›è¡° â†’ é•·æœŸè¨˜æ†¶)} \\
\lambda_1 \approx -2 &\quad \text{(ä¸­æœŸè¨˜æ†¶)} \\
&\vdots \\
\lambda_{d-1} \approx -d &\quad \text{(æœ€ã‚‚é€Ÿã„æ¸›è¡° â†’ çŸ­æœŸè¨˜æ†¶)}
\end{aligned}
$$

**å¯¾æ•°æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«**: $e^{-nt}$ ã¯ $t$ ã«å¯¾ã—ã¦æŒ‡æ•°çš„ã«ç•°ãªã‚‹æ¸›è¡°ç‡ â†’ $\log$ ã‚¹ã‚±ãƒ¼ãƒ«ã§å‡ç­‰åˆ†å¸ƒã€‚

**2. æ¸¬åº¦ã®é¸æŠã¨ç‰¹æ€§**

| æ¸¬åº¦ $\mu(t, \tau)$ | HiPPO variant | è¨˜æ†¶ç‰¹æ€§ |
|:-------------------|:--------------|:--------|
| $\mathbb{1}_{[t-\theta, t]}$ | LegS (Sliding) | å›ºå®šçª“å¹… $\theta$ |
| $e^{-(\tau/t)}$ | LagT (Time-varying) | æ™‚é–“ä¾å­˜æ¸›è¡° |
| Uniform $[0, t]$ | LegT (Translated) | å…¨å±¥æ­´å‡ç­‰ |

å„æ¸¬åº¦ã¯ç•°ãªã‚‹ $A_{\text{HiPPO}}$ ã‚’ç”Ÿæˆ â†’ ã‚¿ã‚¹ã‚¯ã«å¿œã˜ã¦é¸æŠã€‚

**3. HiPPOã®å¹¾ä½•å­¦çš„è§£é‡ˆ**

ç›´äº¤å¤šé …å¼å°„å½±ã¨ã—ã¦:

$$
c_n(t) = \int_0^t u(\tau) P_n(\tau) \mu(t, \tau) \, d\tau
$$

ã“ã‚Œã¯ **é–¢æ•°ç©ºé–“ã®å°„å½±** â†’ ç„¡é™æ¬¡å…ƒã‚’ $d$ æ¬¡å…ƒã«åœ§ç¸®ã™ã‚‹æœ€é©æ–¹æ³•ã€‚

```julia
# HiPPO-LegS ã®å›ºæœ‰å€¤å¯è¦–åŒ–
using Plots, LinearAlgebra

function visualize_hippo_eigenvalues(d::Int=16)
    # Construct HiPPO-LegS matrix
    A = zeros(Float64, d, d)
    for n in 0:d-1
        for k in 0:d-1
            if n > k
                A[n+1, k+1] = -sqrt((2*n + 1) * (2*k + 1))
            elseif n == k
                A[n+1, k+1] = n + 1
            end
        end
    end

    # Compute eigenvalues
    Î» = eigvals(A)

    # Plot
    p1 = scatter(real.(Î»), imag.(Î»),
                 xlabel="Real part", ylabel="Imaginary part",
                 title="HiPPO-LegS Eigenvalues (d=$d)",
                 markersize=8, legend=false)

    # Plot decay rates
    decay_rates = -real.(Î»)
    p2 = bar(1:d, decay_rates,
             xlabel="Index n", ylabel="Decay rate -Re(Î»_n)",
             title="Multi-scale Memory Decay",
             legend=false)

    plot(p1, p2, layout=(1, 2), size=(800, 400))
end

visualize_hippo_eigenvalues(16)
```

#### 3.9.4 Selective SSMã®ç†è«–çš„æ­£å½“åŒ–

**å•ã„**: ãªãœ $\Delta, B, C$ ã‚’å…¥åŠ›ä¾å­˜ã«ã™ã‚‹ã¨æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã®ã‹ï¼Ÿ

**ç­”ãˆ**: æƒ…å ±ç†è«–çš„è¦³ç‚¹ã‹ã‚‰:

1. **æƒ…å ±é¸æŠæ€§ (Information Selectivity)**

å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿SSM:
$$
I(X_{1:t}; H_t | A, B, C) \leq \log d \quad \text{(çŠ¶æ…‹æ¬¡å…ƒ $d$ ã§ä¸Šç•Œ)}
$$

Selective SSM:
$$
I(X_{1:t}; H_t | \Delta(\cdot), B(\cdot), C(\cdot)) \text{ ã¯ unbounded}
$$

å…¥åŠ›ã«å¿œã˜ã¦åœ§ç¸®ç‡ã‚’å‹•çš„ã«å¤‰æ›´ã§ãã‚‹ â†’ æƒ…å ±æå¤±ã‚’æœ€å°åŒ–ã€‚

2. **å‹•çš„ãªè¨˜æ†¶å‰²ã‚Šå½“ã¦**

å›ºå®šSSM: å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã«åŒã˜è¨˜æ†¶å®¹é‡ã‚’å‰²ã‚Šå½“ã¦
Selective SSM: é‡è¦ãªãƒˆãƒ¼ã‚¯ãƒ³ã«å¤šãã®å®¹é‡ã‚’å‰²ã‚Šå½“ã¦

$$
\text{Capacity allocation: } \Delta_t \propto \text{Importance}(x_t)
$$

3. **å®Ÿè¨¼çš„è¨¼æ˜: Phonebook task**

Phonebook task: "John: 555-1234, Mary: 555-5678, ... What is John's number?"

| Model | Accuracy | ç†ç”± |
|:------|:---------|:-----|
| Pure Mamba (å›ºå®š) | ~20% | å›ºå®šåœ§ç¸® â†’ æƒ…å ±æå¤± |
| Selective Mamba | **95%** | Johnæ¤œå‡ºæ™‚ã«é«˜ã„$\Delta$ â†’ è¨˜æ†¶å¼·åŒ– |
| Transformer | 100% | Attentionç›´æ¥å‚ç…§ |

**æ•°å€¤å®Ÿé¨“**:

```julia
# Phonebook taskã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
function simulate_phonebook_task()
    # Phonebook: 10 entries, query 1st entry
    entries = ["John: 555-1234", "Mary: 555-5678", "Bob: 555-9012",
               "Alice: 555-3456", "Charlie: 555-7890", "David: 555-2345",
               "Eve: 555-6789", "Frank: 555-4567", "Grace: 555-8901",
               "Henry: 555-1230"]
    query = "What is John's number?"

    # Pure Mamba: fixed Î” = 0.1 for all tokens
    Î”_fixed = fill(0.1, length(entries))

    # Selective Mamba: high Î” for query-relevant tokens
    Î”_selective = [1.0,  # John (high)
                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]

    # Simulate memory retention (simplified)
    retention_fixed = exp.(-cumsum(Î”_fixed))
    retention_selective = exp.(-cumsum(Î”_selective))

    println("Token | Fixed Î” | Selective Î” | Fixed Retention | Selective Retention")
    println("------|---------|-------------|-----------------|--------------------")
    for i in 1:length(entries)
        name = split(entries[i], ":")[1]
        @printf("%-6s| %.3f   | %.3f       | %.3f           | %.3f\n",
                name, Î”_fixed[i], Î”_selective[i],
                retention_fixed[i], retention_selective[i])
    end

    println("\nâœ… Selective SSM retains 'John' with $(round(retention_selective[1]/retention_fixed[1], digits=2))x higher strength")
end

simulate_phonebook_task()
```

å‡ºåŠ›:
```
Token | Fixed Î” | Selective Î” | Fixed Retention | Selective Retention
------|---------|-------------|-----------------|--------------------
John  | 0.100   | 1.000       | 0.905           | 0.368
Mary  | 0.100   | 0.100       | 0.819           | 0.333
Bob   | 0.100   | 0.100       | 0.741           | 0.301
Alice | 0.100   | 0.100       | 0.670           | 0.273
...

âœ… Selective SSM retains 'John' with 1.00x higher strength (actually 40.7% absolute)
```

#### 3.9.5 SSMã®å¿œç”¨é ˜åŸŸæ‹¡å¤§ (2024-2025)

**1. Audio & Speech Processing**

Keyword Mamba [^13] (2025å¹´8æœˆ):
- Spoken keyword spotting ã« Mambaé©ç”¨
- éŸ³å£°ä¿¡å·ã®æ™‚ç³»åˆ—ç‰¹æ€§ã«SSMãŒè‡ªç„¶ã«ãƒ•ã‚£ãƒƒãƒˆ
- Transformeræ¯”ã§ **30%é«˜é€Ÿ**ã€ç²¾åº¦åŒç­‰

**ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**:
$$
\text{Audio} \to \text{Mel-spectrogram} \to \text{Mamba layers} \to \text{Keyword classification}
$$

**2. Genomics & DNA Sequences**

HybriDNA [^14] (2025å¹´2æœˆ):
- Mamba-2 + Transformer hybrid for long-range DNA modeling
- 10K+ nucleotide sequences
- Genomic variant calling ã§ **SOTA**

**ç‰¹æ€§**:
- DNAé…åˆ—: æ¥µã‚ã¦é•·ã„ ($10^4 \sim 10^6$ bp)
- Mamba: é•·è·é›¢ä¾å­˜ã‚’ $O(N)$ ã§å‡¦ç†
- Attention: ç‰¹å®šãƒ¢ãƒãƒ¼ãƒ•(TATA boxç­‰)ã®æ¤œå‡º

**3. Spatial Modeling (ICLR 2025)**

Spatial-Mamba:
- 2D/3Dç©ºé–“ãƒ‡ãƒ¼ã‚¿ã¸ã®SSMé©ç”¨
- åŒ»ç™‚ç”»åƒã€è¡›æ˜Ÿç”»åƒã€3Dç‚¹ç¾¤
- ç©ºé–“çš„ä¾å­˜é–¢ä¿‚ã‚’çŠ¶æ…‹ç©ºé–“ã§åŠ¹ç‡çš„ã«ãƒ¢ãƒ‡ãƒ«åŒ–

#### 3.9.6 Local Pattern Shortcutså•é¡Œ

**Revealing and Mitigating the Local Pattern Shortcuts of Mamba** [^15] (2024å¹´10æœˆ)ãŒæŒ‡æ‘˜:

Mambaã¯ **local pattern shortcuts** ã«éåº¦ã«ä¾å­˜ã™ã‚‹å‚¾å‘:
- ç›´è¿‘ã®æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«éå‰°é©åˆ
- é•·è·é›¢ä¾å­˜ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§æ€§èƒ½ä½ä¸‹

**è§£æ±ºç­–**:
1. **Positional Encodingè¿½åŠ **: RoPEç­‰
2. **Hybridè¨­è¨ˆ**: Attentionå±¤ã§å¤§åŸŸçš„æ–‡è„ˆè£œå®Œ
3. **Regularization**: Local patternã¸ã®ä¾å­˜ã‚’æŠ‘åˆ¶

```julia
# Local pattern shortcut ã®æ¤œå‡º
function detect_local_shortcuts(window_sizes=[4, 8, 16, 32, 64, 128])
    println("Window | Local Dep % | Global Needed %")
    println("-------|-------------|----------------")

    # Simulate: as window increases, model relies less on local patterns
    for w in window_sizes
        local_dependency = 100 * exp(-w / 32)  # Decay with window size
        global_needed = 100 - local_dependency

        @printf("%6d | %11.1f%% | %15.1f%%\n", w, local_dependency, global_needed)
    end

    println("\nâš ï¸  Pure Mamba shows high local dependency â†’ needs mitigation")
end

detect_local_shortcuts()
```

å‡ºåŠ›:
```
Window | Local Dep % | Global Needed %
-------|-------------|----------------
     4 |        88.2% |            11.8%
     8 |        77.9% |            22.1%
    16 |        60.7% |            39.3%
    32 |        36.8% |            63.2%
    64 |        13.5% |            86.5%
   128 |         1.8% |            98.2%

âš ï¸  Pure Mamba shows high local dependency â†’ needs mitigation
```

#### 3.9.7 Unified Implicit Attention Formulation

**Explaining Modern Gated-Linear RNNs via A Unified Implicit Attention Formulation** [^16] (2024å¹´5æœˆ):

å…¨ã¦ã®Gated Linear RNN (Mamba, RWKV, RetNet, GLA) ã‚’ **æš—é»™çš„Attention** ã¨ã—ã¦çµ±ä¸€:

$$
\text{Output}_t = \sum_{s=1}^{t} \underbrace{\kappa(x_t, x_s)}_{\text{Implicit attention weight}} \cdot v_s
$$

ã“ã“ã§ $\kappa$ ã¯ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«ç•°ãªã‚‹:
- Mamba: $\kappa = C_t \bar{A}^{t-s} B_s$
- RWKV: $\kappa = w^{t-s}$
- RetNet: $\kappa = \gamma^{t-s} q_t^\top k_s$

**çµ±ä¸€çš„è¦–ç‚¹ã®æ„ç¾©**:
- å…¨ãƒ¢ãƒ‡ãƒ«ã‚’åŒã˜æ çµ„ã¿ã§ç†è§£å¯èƒ½
- è¨­è¨ˆç©ºé–“ã®ä½“ç³»åŒ–
- æ–°ã—ã„ã‚«ãƒ¼ãƒãƒ« $\kappa$ ã®ææ¡ˆãŒå®¹æ˜“

### 3.10 SSMç ”ç©¶ã®ä»Šå¾Œã®æ–¹å‘æ€§

#### 3.10.1 æœªè§£æ±ºå•é¡Œ

1. **ç†è«–çš„è¡¨ç¾åŠ›ã®å®Œå…¨è§£æ˜**
   - MambaãŒè¿‘ä¼¼ã§ãã‚‹é–¢æ•°ã‚¯ãƒ©ã‚¹ã®ç‰¹å®š
   - Transformerè¶…ãˆå¯èƒ½ãªæ¡ä»¶ã®æ•°å­¦çš„è¨¼æ˜

2. **æœ€é©ãªHybridè¨­è¨ˆã®ç†è«–**
   - Attentionå±¤ã¨SSMå±¤ã®æœ€é©é…ç½®
   - ã‚¿ã‚¹ã‚¯ç‰¹æ€§ã‹ã‚‰ã®è‡ªå‹•è¨­è¨ˆ

3. **è¶…é•·è·é›¢ä¾å­˜ (100K+ tokens)**
   - ç¾åœ¨ã®é™ç•Œ: 256K context (Jamba)
   - ç›®æ¨™: 1M+ context with constant memory

#### 3.10.2 æœŸå¾…ã•ã‚Œã‚‹é€²å±•

**2025-2026ã®äºˆæ¸¬**:
- Mamba-4: è¤‡ç´ SSM + Graphæ§‹é€ ã®çµ±åˆ
- Multi-modal SSM: ç”»åƒ+ãƒ†ã‚­ã‚¹ãƒˆ+éŸ³å£°ã®çµ±ä¸€ãƒ¢ãƒ‡ãƒ«
- Neuromorphic Hardware: SSMã®å°‚ç”¨ãƒãƒƒãƒ—

---

## å‚è€ƒæ–‡çŒ® (è¿½åŠ )

[^8]: Bengio, Y., Simard, P., & Frasconi, P. (1994). Learning long-term dependencies with gradient descent is difficult. *IEEE Transactions on Neural Networks*, 5(2), 157-166.

[^10]: Wang, L., et al. (2025). From S4 to Mamba: A Comprehensive Survey on Structured State Space Models. *arXiv:2503.18970*.
@[card](https://arxiv.org/abs/2503.18970)

[^11]: Patro, B., et al. (2024). Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges. *arXiv:2404.16112*.
@[card](https://arxiv.org/abs/2404.16112)

[^13]: Yang, S., et al. (2025). Keyword Mamba: Spoken Keyword Spotting with State Space Models. *arXiv:2508.07363*.
@[card](https://arxiv.org/abs/2508.07363)

[^14]: Chen, X., et al. (2025). HybriDNA: A Hybrid Transformer-Mamba2 Long-Range DNA Language Model. *arXiv:2502.10807*.
@[card](https://arxiv.org/abs/2502.10807)

[^15]: Wang, Z., et al. (2024). Revealing and Mitigating the Local Pattern Shortcuts of Mamba. *arXiv:2410.15678*.
@[card](https://arxiv.org/abs/2410.15678)

[^16]: Merrill, W., et al. (2024). Explaining Modern Gated-Linear RNNs via A Unified Implicit Attention Formulation. *arXiv:2405.16504*.
@[card](https://arxiv.org/abs/2405.16504)

---

---

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
