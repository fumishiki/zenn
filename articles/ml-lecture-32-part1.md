---
title: "ç¬¬32å›: Productionçµ±åˆã€å‰ç·¨ã€‘ç†è«–ç·¨: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œ""
emoji: "ğŸ”„"
type: "tech"
topics: ["machinelearning"]
published: true
slug: "ml-lecture-32-part1"
---
---

# ç¬¬32å›: Production & ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ— + çµ±åˆPJ ğŸ†

:::message
**å‰æçŸ¥è­˜**: ç¬¬31å›ã§MLOpsåŸºç›¤ã‚’æ•´ãˆãŸã€‚ã“ã®ç¬¬32å›ã¯Course IIIæœ€çµ‚å› â€” 14å›ã®å…¨æŠ€è¡“ã‚’çµ±åˆã—ã¦E2Eã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
:::

## ğŸš€ 0. ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆ30ç§’ï¼‰â€” 3è¡Œã§E2Eã‚·ã‚¹ãƒ†ãƒ ã‚’ä½“æ„Ÿ

ç¬¬31å›ã§MLOpsãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ãŸã€‚æœ€çµ‚å›ã®ä»Šå›ã€**å…¨ã¦ã‚’çµ±åˆã—ãŸProduction E2Eã‚·ã‚¹ãƒ†ãƒ **ã‚’3è¡Œã®ã‚³ãƒ¼ãƒ‰ã§ä½“æ„Ÿã—ã‚ˆã†ã€‚

```julia
# SmolVLM2-256Mæ¨è«– â†’ Elixir API â†’ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›† â†’ Juliaå†è¨“ç·´
using SmolVLM2Inference, ElixirGateway, FeedbackLoop
result = deploy_e2e_system("models/smolvlm2-256m.onnx", port=4000)
# => "E2E system deployed: Juliaè¨“ç·´â†’Rustæ¨è«–â†’Elixiré…ä¿¡â†’Feedbackâ†’å†è¨“ç·´"
```

**å‡ºåŠ›**:
```
ğŸ¯ E2E System Status:
  âš¡ Julia Training Pipeline: Ready (SmolVLM2-256M, VAE, GANçµ±åˆ)
  ğŸ¦€ Rust Inference Server: Running on port 8080 (Axum, ONNX Runtime)
  ğŸ”® Elixir API Gateway: Running on port 4000 (Phoenix, JWT auth, Rate limit)
  ğŸ“Š Monitoring: Prometheus metrics at :9090
  ğŸ”„ Feedback Loop: Active (implicit+explicit feedback collected)

âœ… System Health: All components operational
ğŸ“ˆ Current throughput: 1,247 req/s (95th %ile latency: 12ms)
```

**ã“ã®è£ã«ã‚ã‚‹æ•°å¼**: ç¬¬19å›ã‹ã‚‰ç¬¬31å›ã§å­¦ã‚“ã **å…¨ã¦ã®æŠ€è¡“ãŒçµ±åˆã•ã‚Œã¦ã„ã‚‹**:

$$
\text{Production System} = \underbrace{\text{Train}_{\text{Julia}}}_{\text{ç¬¬20,23å›}} \xrightarrow{\text{Export}_{\text{ONNX}}} \underbrace{\text{Infer}_{\text{Rust}}}_{\text{ç¬¬26å›}} \xrightarrow{\text{Serve}_{\text{Elixir}}} \underbrace{\text{Feedback}}_{\text{ç¬¬32å›}} \circlearrowleft
$$

ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã®æ•°å¼:

$$
\theta_{t+1} \leftarrow \theta_t - \eta \nabla_\theta \mathcal{L}(\theta_t; \mathcal{D}_{\text{feedback}})
$$

3è¡Œã®ã‚³ãƒ¼ãƒ‰ã®è£ã§ã€**Juliaè¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ãŒVAE/GAN/GPTã‚’è¨“ç·´ã—ã€**Rustæ¨è«–ã‚µãƒ¼ãƒãƒ¼**ãŒONNXãƒ¢ãƒ‡ãƒ«ã‚’é«˜é€Ÿæ¨è«–ã€**Elixir APIã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤**ãŒåˆ†æ•£é…ä¿¡ã¨èªè¨¼ã‚’æ‹…å½“ã€**ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—**ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è©•ä¾¡ã‚’åé›†ã—ã¦å†è¨“ç·´ã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã™ã‚‹ â€” å…¨ã¦ãŒè‡ªå‹•çš„ã«å‹•ä½œã™ã‚‹ã€‚

**ã“ã‚ŒãŒCourse III 14å›ã®é›†å¤§æˆã ã€‚**

:::message
**é€²æ—: 3%å®Œäº†ï¼** ç¬¬32å›ã®ã‚´ãƒ¼ãƒ«ã¯ã€ŒProduction E2Eã‚·ã‚¹ãƒ†ãƒ ã‚’è‡ªåŠ›ã§æ§‹ç¯‰ãƒ»é‹ç”¨ã§ãã‚‹ã€ã“ã¨ã€‚
:::

---

## ğŸ® 1. ä½“é¨“ã‚¾ãƒ¼ãƒ³ï¼ˆ10åˆ†ï¼‰â€” AIã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆ & ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è§¦ã‚‹

### 1.1 AIã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã®è¨­è¨ˆ

AIã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã®æœ¬è³ªã¯**å•ã„åˆã‚ã›ã®è‡ªå‹•åˆ†é¡**ã¨**äººé–“ã¸ã®ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥**ã ã€‚

```julia
using CustomerSupport, Embeddings

# å•ã„åˆã‚ã›ã‚’è‡ªå‹•åˆ†é¡
inquiry = "å•†å“ãŒå±Šã‹ãªã„ã€‚æ³¨æ–‡ç•ªå·ã¯12345ã§ã™ã€‚"
category, confidence = classify_inquiry(inquiry)
# => ("é…é€å•é¡Œ", 0.92)

if confidence < 0.7
    escalate_to_human(inquiry, reason="ä½ä¿¡é ¼åº¦")
elseif category == "è¿”é‡‘è¦æ±‚"
    escalate_to_human(inquiry, reason="é«˜ãƒªã‚¹ã‚¯")
else
    auto_response = generate_faq_response(category, inquiry)
    send_response(auto_response)
end
```

**æ•°å¼**: å•ã„åˆã‚ã›åˆ†é¡ã¯Softmaxåˆ†é¡

$$
p(c_i | \mathbf{x}) = \frac{\exp(\mathbf{w}_i^\top \mathbf{x})}{\sum_{j=1}^C \exp(\mathbf{w}_j^\top \mathbf{x})}
$$

ã“ã“ã§ $\mathbf{x}$ ã¯å•ã„åˆã‚ã›ã®Embeddingã€$\mathbf{w}_i$ ã¯ã‚«ãƒ†ã‚´ãƒª $c_i$ ã®é‡ã¿ãƒ™ã‚¯ãƒˆãƒ«ã€‚

**ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥**:

| æ¡ä»¶ | ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ | ç†ç”± |
|:-----|:----------|:-----|
| `confidence < 0.7` | äººé–“ã«ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ | ãƒ¢ãƒ‡ãƒ«ãŒè‡ªä¿¡ã‚’æŒã¦ãªã„ |
| `category == "è¿”é‡‘"` | äººé–“ã«ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ | é«˜ãƒªã‚¹ã‚¯ãƒ»é«˜ã‚³ã‚¹ãƒˆåˆ¤æ–­ |
| `sentiment < -0.5` | äººé–“ã«ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ | æ€’ã£ã¦ã„ã‚‹é¡§å®¢ |
| ãã®ä»– | è‡ªå‹•å¿œç­” | æ¨™æº–çš„ãªå•ã„åˆã‚ã› |

### 1.2 ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†: æš—é»™çš„ vs æ˜ç¤ºçš„

ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«ã¯**æš—é»™çš„**ã¨**æ˜ç¤ºçš„**ã®2ç¨®é¡ãŒã‚ã‚‹ã€‚

```julia
# æš—é»™çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: ã‚¯ãƒªãƒƒã‚¯ãƒ»æ»åœ¨æ™‚é–“ãƒ»ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«æ·±åº¦
implicit_feedback = collect_implicit_feedback(
    click_through=true,
    dwell_time=45.3,  # ç§’
    scroll_depth=0.78  # 78%ã¾ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
)
# => ImplicitFeedback(positive_signal=0.82)

# æ˜ç¤ºçš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: è©•ä¾¡ãƒœã‚¿ãƒ³ãƒ»ã‚³ãƒ¡ãƒ³ãƒˆãƒ»NPS
explicit_feedback = collect_explicit_feedback(
    rating=4,  # 1-5 stars
    comment="å›ç­”ã¯å½¹ç«‹ã£ãŸãŒã€ã‚‚ã†å°‘ã—å…·ä½“ä¾‹ãŒæ¬²ã—ã‹ã£ãŸ",
    nps=8      # Net Promoter Score (0-10)
)
# => ExplicitFeedback(sentiment=0.65, topics=["å…·ä½“ä¾‹ä¸è¶³"])
```

**æ•°å¼**: æš—é»™çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ã‚¹ã‚³ã‚¢é–¢æ•°

$$
f_{\text{implicit}}(\text{click}, t_{\text{dwell}}, d_{\text{scroll}}) = w_1 \cdot \mathbb{1}_{\text{click}} + w_2 \cdot \tanh(t_{\text{dwell}}/60) + w_3 \cdot d_{\text{scroll}}
$$

ã“ã“ã§ $\mathbb{1}_{\text{click}}$ ã¯ã‚¯ãƒªãƒƒã‚¯ã®æœ‰ç„¡ï¼ˆ0 or 1ï¼‰ã€$w_1, w_2, w_3$ ã¯é‡ã¿ï¼ˆä¾‹: $w_1=0.4, w_2=0.4, w_3=0.2$ï¼‰ã€‚

**æ˜ç¤ºçš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æ**:

$$
S(\text{comment}) = \text{Transformer}_{\text{sentiment}}(\text{Embedding}(\text{comment})) \in [-1, 1]
$$

### 1.3 ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æ: ãƒˆãƒ”ãƒƒã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°

åé›†ã—ãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚³ãƒ¡ãƒ³ãƒˆã‚’**ãƒˆãƒ”ãƒƒã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°**ã—ã¦æ ¹æœ¬åŸå› ã‚’åˆ†æã™ã‚‹ã€‚

```julia
using UMAP, HDBSCAN

# 1,000ä»¶ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
comments = load_feedback_comments(n=1000)
embeddings = embed_comments(comments)  # (1000, 384) Embedding

# UMAPæ¬¡å…ƒå‰Šæ¸› â†’ HDBSCAN ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
umap_emb = umap(embeddings, n_components=2)
clusters = hdbscan(umap_emb, min_cluster_size=20)

# ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ä»£è¡¨çš„ãªã‚³ãƒ¡ãƒ³ãƒˆ
for (cluster_id, representative_comments) in clusters
    println("Cluster $cluster_id:")
    println("  ", join(representative_comments[1:3], "\n  "))
end
```

**å‡ºåŠ›ä¾‹**:
```
Cluster 1: "é…é€ãŒé…ã„"ç³»
  "å•†å“ãŒå±Šã‹ãªã„"
  "é…é€çŠ¶æ³ãŒæ›´æ–°ã•ã‚Œãªã„"
  "é…é€æ¥­è€…ã«é€£çµ¡ãŒã¤ã‹ãªã„"

Cluster 2: "å…·ä½“ä¾‹ä¸è¶³"ç³»
  "ã‚‚ã£ã¨å…·ä½“çš„ãªæ‰‹é †ãŒæ¬²ã—ã„"
  "ç”»åƒä»˜ãã§èª¬æ˜ã—ã¦æ¬²ã—ã„"
  "ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ãŒæ¬²ã—ã„"
```

**æ•°å¼**: UMAPæ¬¡å…ƒå‰Šæ¸›

$$
\min_{\mathbf{Y}} \sum_{i,j} w_{ij} \left\| \mathbf{y}_i - \mathbf{y}_j \right\|^2 + \lambda \sum_{i,j} (1 - w_{ij}) \max(0, d_{\text{min}} - \left\| \mathbf{y}_i - \mathbf{y}_j \right\|)^2
$$

ã“ã“ã§ $\mathbf{Y} \in \mathbb{R}^{n \times 2}$ ã¯2æ¬¡å…ƒåŸ‹ã‚è¾¼ã¿ã€$w_{ij}$ ã¯é«˜æ¬¡å…ƒç©ºé–“ã§ã®è¿‘å‚é‡ã¿ã€‚

### 1.4 PyTorchã¨ã®å¯¾å¿œ â€” ãƒ¢ãƒ‡ãƒ«è¨“ç·´

```python
import torch
import torch.nn as nn

# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä½¿ã£ãŸFine-tuning
class FeedbackClassifier(nn.Module):
    def __init__(self, embedding_dim=384, num_classes=10):
        super().__init__()
        self.classifier = nn.Linear(embedding_dim, num_classes)

    def forward(self, x):
        return self.classifier(x)

model = FeedbackClassifier()
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
criterion = nn.CrossEntropyLoss()

# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´
for epoch in range(10):
    for batch in feedback_dataloader:
        embeddings, labels = batch
        logits = model(embeddings)
        loss = criterion(logits, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

**Juliaå¯¾å¿œ** (æ•°å¼ â†” ã‚³ãƒ¼ãƒ‰ 1:1):

```julia
using Lux, Optimisers, Zygote

# Lux.jl ã§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†é¡å™¨
struct FeedbackClassifier <: Lux.AbstractExplicitLayer
    embedding_dim::Int
    num_classes::Int
end

function (m::FeedbackClassifier)(x, ps, st)
    W = ps.W  # (num_classes, embedding_dim)
    b = ps.b  # (num_classes,)
    return W * x .+ b, st
end

# è¨“ç·´ãƒ«ãƒ¼ãƒ—
model = FeedbackClassifier(384, 10)
ps, st = Lux.setup(rng, model)
opt_state = Optimisers.setup(AdamW(1e-4), ps)

for epoch in 1:10
    for (embeddings, labels) in feedback_dataloader
        # Forward + Backward
        loss, grads = Zygote.withgradient(ps) do p
            logits, _ = model(embeddings, p, st)
            cross_entropy_loss(logits, labels)
        end

        # Update
        opt_state, ps = Optimisers.update(opt_state, ps, grads[1])
    end
end
```

**æ¥ç¶šå›³**:

```mermaid
graph LR
    A[ãƒ¦ãƒ¼ã‚¶ãƒ¼å•ã„åˆã‚ã›] --> B[Embedding]
    B --> C[åˆ†é¡ãƒ¢ãƒ‡ãƒ«]
    C --> D{ä¿¡é ¼åº¦ > 0.7?}
    D -->|Yes| E[è‡ªå‹•å¿œç­”]
    D -->|No| F[äººé–“ã«ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³]
    E --> G[ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†]
    F --> G
    G --> H[ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æ]
    H --> I[ãƒ¢ãƒ‡ãƒ«æ”¹å–„]
    I --> C
```

:::message
**é€²æ—: 10%å®Œäº†ï¼** AIã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã®è¨­è¨ˆã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†ã®åŸºç¤ã‚’ä½“é¨“ã—ãŸã€‚
:::

---

## ğŸ§© 2. ç›´æ„Ÿã‚¾ãƒ¼ãƒ³ï¼ˆ15åˆ†ï¼‰â€” ãªãœProductionã‚·ã‚¹ãƒ†ãƒ ãŒå¿…è¦ã‹

### 2.1 Course IIIã®åœ°å›³: ç¬¬19-32å›ã®æŒ¯ã‚Šè¿”ã‚Š

Course IIIã¯**ç†è«–ã‚’å‹•ãã‚·ã‚¹ãƒ†ãƒ ã«å¤‰ãˆã‚‹14å›**ã ã£ãŸã€‚å„è¬›ç¾©ã‚’æŒ¯ã‚Šè¿”ã‚ã†ã€‚

| å› | ã‚¿ã‚¤ãƒˆãƒ« | ç²å¾—ã—ãŸæ­¦å™¨ | è¨€èª |
|:---|:---------|:-------------|:-----|
| ç¬¬19å› | ç’°å¢ƒæ§‹ç¯‰ & FFI | FFIå¢ƒç•Œè¨­è¨ˆ / C-ABIçµ±ä¸€ç†è«– | ğŸ¦€âš¡ğŸ”® |
| ç¬¬20å› | å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ | VAE/GAN/Transformerå®Ÿè£…ã®å‹ | âš¡ğŸ¦€ |
| ç¬¬21å› | ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ | ETL/ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°/å¯è¦–åŒ– | âš¡ |
| ç¬¬22å› | ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ« | VLM/ç”»åƒ-ãƒ†ã‚­ã‚¹ãƒˆçµ±åˆ | âš¡ğŸ¦€ |
| ç¬¬23å› | Fine-tuning & PEFT | LoRA/QLoRA/AdaLoRA | âš¡ğŸ¦€ |
| ç¬¬24å› | çµ±è¨ˆå­¦ | ä»®èª¬æ¤œå®š/A/Bãƒ†ã‚¹ãƒˆ/ä¿¡é ¼åŒºé–“ | âš¡ |
| ç¬¬25å› | å› æœæ¨è«– | RCT/DID/IV/å‚¾å‘ã‚¹ã‚³ã‚¢ | âš¡ |
| ç¬¬26å› | æ¨è«–æœ€é©åŒ– | é‡å­åŒ–/è’¸ç•™/ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚° | ğŸ¦€âš¡ |
| ç¬¬27å› | è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ | FID/CLIP Score/Human Eval | âš¡ |
| ç¬¬28å› | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ | Few-shot/CoT/ReAct/Self-Consistency | âš¡ |
| ç¬¬29å› | RAG | Retrieval/Rerank/Hybrid Search | âš¡ğŸ¦€ |
| ç¬¬30å› | ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ | ReAct/Tool Use/Multi-Agent | ğŸ”®âš¡ |
| ç¬¬31å› | MLOps | CI/CD/Monitoring/A/Bãƒ†ã‚¹ãƒˆ | ğŸ¦€âš¡ğŸ”® |
| **ç¬¬32å›** | **Productionçµ±åˆ** | **E2Eã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰** | **ğŸ¦€âš¡ğŸ”®** |

**å…¨ã¦ã‚’çµ±åˆã—ãŸã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**:

```mermaid
graph TD
    A[ãƒ‡ãƒ¼ã‚¿åé›†] --> B[âš¡ Juliaè¨“ç·´PL]
    B --> C[ãƒ¢ãƒ‡ãƒ«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ ONNX]
    C --> D[ğŸ¦€ Rustæ¨è«–ã‚µãƒ¼ãƒãƒ¼]
    D --> E[ğŸ”® Elixir APIã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤]
    E --> F[ãƒ¦ãƒ¼ã‚¶ãƒ¼]
    F --> G[ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†]
    G --> H[ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æ]
    H --> A
    D --> I[ğŸ“Š Monitoring Prometheus]
    E --> I
    I --> J[ã‚¢ãƒ©ãƒ¼ãƒˆ & ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰]
```

### 2.2 Productionã®æœ¬è³ª: Trainâ†’Feedbacké–‰ãƒ«ãƒ¼ãƒ—

Productionã‚·ã‚¹ãƒ†ãƒ ã®æœ¬è³ªã¯**é–‰ãƒ«ãƒ¼ãƒ—**ã ã€‚

**å¾“æ¥ã®MLé–‹ç™º** (é–‹ãƒ«ãƒ¼ãƒ—):
```
ãƒ‡ãƒ¼ã‚¿åé›† â†’ è¨“ç·´ â†’ è©•ä¾¡ â†’ ãƒ‡ãƒ—ãƒ­ã‚¤ â†’ [çµ‚äº†]
```

**Productionã‚·ã‚¹ãƒ†ãƒ ** (é–‰ãƒ«ãƒ¼ãƒ—):
```
ãƒ‡ãƒ¼ã‚¿åé›† â†’ è¨“ç·´ â†’ è©•ä¾¡ â†’ ãƒ‡ãƒ—ãƒ­ã‚¤ â†’ Feedbackåé›† â†º
                                          â†“
                                      åˆ†æ & æ”¹å–„
```

**é–‰ãƒ«ãƒ¼ãƒ—ã®æ•°å¼**:

$$
\begin{aligned}
\text{Epoch } t&: \theta_t \leftarrow \arg\min_\theta \mathcal{L}(\theta; \mathcal{D}_{\text{train}}) \\
\text{Deploy}&: \text{Model}_t \text{ serves users} \\
\text{Collect}&: \mathcal{D}_{\text{feedback}} \leftarrow \{ (x_i, y_i^{\text{feedback}}) \}_{i=1}^N \\
\text{Epoch } t+1&: \theta_{t+1} \leftarrow \arg\min_\theta \mathcal{L}(\theta; \mathcal{D}_{\text{train}} \cup \mathcal{D}_{\text{feedback}})
\end{aligned}
$$

**ãªãœé–‰ãƒ«ãƒ¼ãƒ—ãŒå¿…è¦ã‹ï¼Ÿ**

1. **ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¡Œå‹•ã¯æ™‚é–“ã¨ã¨ã‚‚ã«å¤‰åŒ–ã™ã‚‹
2. **åˆ†å¸ƒã‚·ãƒ•ãƒˆ**: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨æœ¬ç•ªãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒãŒç•°ãªã‚‹
3. **ç¶™ç¶šçš„æ”¹å–„**: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ´»ç”¨ã—ã¦æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹

### 2.3 æ¾å°¾ç ”ã¨ã®å¯¾æ¯”

| é …ç›® | æ¾å°¾ç ” (æ•™ç§‘æ›¸ãƒ¬ãƒ™ãƒ«) | æœ¬ã‚·ãƒªãƒ¼ã‚º Course III |
|:-----|:---------------------|:---------------------|
| **è¨“ç·´** | PyTorchã§è¨“ç·´ | âš¡ Juliaé«˜é€Ÿè¨“ç·´ (ç¬¬20å›) |
| **æ¨è«–** | Pythonã§æ¨è«– | ğŸ¦€ Rusté«˜é€Ÿæ¨è«– (ç¬¬26å›) |
| **é…ä¿¡** | Flask/FastAPI | ğŸ”® Elixiråˆ†æ•£é…ä¿¡ (ç¬¬30å›) |
| **ç›£è¦–** | ãªã— | Prometheus/Grafana (ç¬¬31å›) |
| **ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯** | ãªã— | **Active Learning + HITL** (ç¬¬32å›) |
| **E2Eçµ±åˆ** | ãªã— | **å…¨è¨€èªçµ±åˆã‚·ã‚¹ãƒ†ãƒ ** (ç¬¬32å›) |

**æ¾å°¾ç ”ãŒæ•™ãˆãªã„ã“ã¨**:
- 3è¨€èªçµ±åˆ (ğŸ¦€âš¡ğŸ”®)
- Productionå“è³ªè¨­è¨ˆ (ç¬¬26å›ã®æ¨è«–æœ€é©åŒ–, ç¬¬31å›ã®MLOps)
- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ— (ç¬¬32å›)
- E2Eã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ (ç¬¬32å›)

### 2.4 3ã¤ã®æ¯”å–©ã§æ‰ãˆã‚‹ã€ŒProductionã€

**æ¯”å–©1: ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³çµŒå–¶**
- è¨“ç·´ = ãƒ¬ã‚·ãƒ”é–‹ç™º
- æ¨è«– = æ–™ç†æä¾›
- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ = é¡§å®¢ãƒ¬ãƒ“ãƒ¥ãƒ¼
- æ”¹å–„ = ãƒ¬ã‚·ãƒ”æ”¹è‰¯

**æ¯”å–©2: è‡ªå‹•è»Šè£½é€ **
- è¨“ç·´ = è©¦ä½œè»Šé–‹ç™º
- æ¨è«– = é‡ç”£ãƒ©ã‚¤ãƒ³
- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ = å“è³ªæ¤œæŸ» + é¡§å®¢ã‚¯ãƒ¬ãƒ¼ãƒ 
- æ”¹å–„ = è¨­è¨ˆå¤‰æ›´

**æ¯”å–©3: ç”Ÿæ…‹ç³»**
- è¨“ç·´ = ç¨®ã®é€²åŒ–
- æ¨è«– = å€‹ä½“ã®ç”Ÿå­˜
- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ = è‡ªç„¶é¸æŠ
- æ”¹å–„ = é©å¿œé€²åŒ–

**Productionã®3æ¯”å–©ãŒç¤ºã™ã“ã¨**:
1. **ç¶™ç¶šçš„ãƒ—ãƒ­ã‚»ã‚¹**: ä¸€åº¦ä½œã£ã¦çµ‚ã‚ã‚Šã§ã¯ãªã„
2. **ç’°å¢ƒé©å¿œ**: å¤–éƒ¨ç’°å¢ƒã®å¤‰åŒ–ã«å¯¾å¿œã™ã‚‹
3. **ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é§†å‹•**: ãƒ‡ãƒ¼ã‚¿ãŒæ”¹å–„ã‚’å°ã

### 2.5 Trojan Horse: ğŸâ†’ğŸ¦€â†’âš¡â†’ğŸ”® å®Œå…¨çµ±åˆ

ç¬¬9å›ã§RustãŒç™»å ´ã—ã€ç¬¬10å›ã§JuliaãŒç™»å ´ã—ã€ç¬¬19å›ã§ElixirãŒç™»å ´ã—ãŸã€‚**3è¨€èªãŒæƒã£ãŸä»Šã€ãã‚Œãã‚Œã®å½¹å‰²ãŒæ˜ç¢ºã«ãªã£ãŸ**ã€‚

| è¨€èª | å½¹å‰² | ç†ç”± | ç™»å ´å› |
|:-----|:-----|:-----|:-------|
| ğŸ¦€ Rust | æ¨è«–ãƒ»ã‚¤ãƒ³ãƒ•ãƒ©ãƒ»æœ¬ç•ª | ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ / å‹å®‰å…¨ / é«˜é€Ÿ | ç¬¬9å› |
| âš¡ Julia | ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒ»è¨“ç·´ | æ•°å¼â†”ã‚³ãƒ¼ãƒ‰1:1 / å¤šé‡ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒ | ç¬¬10å› |
| ğŸ”® Elixir | åˆ†æ•£é…ä¿¡ãƒ»è€éšœå®³æ€§ | OTP / Actor / let it crash | ç¬¬19å› |
| ğŸ Python | æŸ»èª­ç”¨ (èª­ã‚€ã ã‘) | ç ”ç©¶è€…ã®ã‚³ãƒ¼ãƒ‰ç†è§£ | ç¬¬1å› |

**ç¬¬32å›ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**: **Pythonã¯å’æ¥­ã—ãŸ**ã€‚Productionç’°å¢ƒã§ã¯ğŸ¦€âš¡ğŸ”®ãŒå½“ãŸã‚Šå‰ã€‚

:::message
**é€²æ—: 20%å®Œäº†ï¼** Productionã‚·ã‚¹ãƒ†ãƒ ã®å…¨ä½“åƒã¨Course IIIã®ä½ç½®ã¥ã‘ã‚’ç†è§£ã—ãŸã€‚
:::

---

## ğŸ“ 3. æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ï¼ˆ60åˆ†ï¼‰â€” ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ— & Active Learningç†è«–

### 3.1 ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã®æ•°å¼åŒ–

#### 3.1.1 æš—é»™çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®å®šå¼åŒ–

æš—é»™çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯**ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¡Œå‹•ã‹ã‚‰é–“æ¥çš„ã«å“è³ªã‚’æ¨å®š**ã™ã‚‹ã€‚

**å®šç¾©**: ã‚¯ãƒªãƒƒã‚¯ã‚¹ãƒ«ãƒ¼ç‡ (CTR) ã®è¨ˆç®—

$$
\text{CTR} = \frac{\text{ã‚¯ãƒªãƒƒã‚¯æ•°}}{\text{è¡¨ç¤ºå›æ•°}}
$$

**æ»åœ¨æ™‚é–“ãƒ¢ãƒ‡ãƒ«**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ $t$ ç§’æ»åœ¨ã—ãŸå ´åˆã®æº€è¶³åº¦

$$
s_{\text{dwell}}(t) = 1 - \exp(-\lambda t)
$$

ã“ã“ã§ $\lambda > 0$ ã¯æ¸›è¡°ç‡ã€‚$t \to \infty$ ã§ $s \to 1$ã€$t=0$ ã§ $s=0$ã€‚

**ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«æ·±åº¦ãƒ¢ãƒ‡ãƒ«**: ãƒšãƒ¼ã‚¸ã® $d \in [0,1]$ ã¾ã§è¦‹ãŸå ´åˆã®æº€è¶³åº¦

$$
s_{\text{scroll}}(d) = d
$$

**çµ±åˆã‚¹ã‚³ã‚¢**: 3ã¤ã®æŒ‡æ¨™ã‚’é‡ã¿ä»˜ãå’Œã§çµåˆ

$$
f_{\text{implicit}}(\text{click}, t, d) = w_1 \cdot \mathbb{1}_{\text{click}} + w_2 \cdot s_{\text{dwell}}(t) + w_3 \cdot s_{\text{scroll}}(d)
$$

å…¸å‹çš„ãªé‡ã¿: $w_1=0.4, w_2=0.4, w_3=0.2$ã€‚

**æ•°å€¤æ¤œè¨¼** (Julia):

```julia
Î» = 0.05  # 20ç§’ã§ s â‰ˆ 0.63
s_dwell(t) = 1 - exp(-Î» * t)

# æ»åœ¨æ™‚é–“45.3ç§’ã€ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«78%ã€ã‚¯ãƒªãƒƒã‚¯ã‚ã‚Š
t = 45.3
d = 0.78
click = 1

s_t = s_dwell(t)  # â‰ˆ 0.90
score = 0.4 * click + 0.4 * s_t + 0.2 * d
# => 0.4 + 0.36 + 0.156 = 0.916
```

#### 3.1.2 æ˜ç¤ºçš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®å®šå¼åŒ–

æ˜ç¤ºçš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯**ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç›´æ¥è©•ä¾¡ã‚’å…¥åŠ›**ã™ã‚‹ã€‚

**è©•ä¾¡ã‚¹ã‚³ã‚¢æ­£è¦åŒ–**:

$$
r_{\text{norm}} = \frac{r - r_{\min}}{r_{\max} - r_{\min}}
$$

5æ®µéšè©•ä¾¡ (1-5) ã®å ´åˆ: $r_{\text{norm}} = (r-1)/4$ã€‚

**ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æ**: ã‚³ãƒ¡ãƒ³ãƒˆ $c$ ã‹ã‚‰æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ $S(c) \in [-1, 1]$ ã‚’æŠ½å‡º

$$
S(c) = \text{Classifier}_{\text{sentiment}}(\text{Embedding}(c))
$$

Transformerãƒ™ãƒ¼ã‚¹ã®ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†é¡å™¨ã‚’ä½¿ç”¨ã€‚

**Net Promoter Score (NPS)**: é¡§å®¢ãƒ­ã‚¤ãƒ¤ãƒ«ãƒ†ã‚£æŒ‡æ¨™

$$
\text{NPS} = \frac{\text{æ¨å¥¨è€… (9-10ç‚¹)} - \text{æ‰¹åˆ¤è€… (0-6ç‚¹)}}{\text{ç·å›ç­”æ•°}} \times 100
$$

**çµ±åˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¹ã‚³ã‚¢**:

$$
f_{\text{explicit}}(r, S(c), \text{NPS}) = \alpha r_{\text{norm}} + \beta S(c) + \gamma \frac{\text{NPS}}{100}
$$

å…¸å‹çš„ãªé‡ã¿: $\alpha=0.5, \beta=0.3, \gamma=0.2$ã€‚

#### 3.1.3 ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é§†å‹•ã®ç¶™ç¶šå­¦ç¿’

ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä½¿ã£ãŸãƒ¢ãƒ‡ãƒ«æ›´æ–°ã®æ•°å¼ã€‚

**ç›®çš„é–¢æ•°**: å…ƒã®è¨“ç·´æå¤±ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æå¤±ã®é‡ã¿ä»˜ãå’Œ

$$
\mathcal{L}_{\text{total}}(\theta) = \mathcal{L}_{\text{train}}(\theta; \mathcal{D}_{\text{train}}) + \lambda \mathcal{L}_{\text{feedback}}(\theta; \mathcal{D}_{\text{feedback}})
$$

ã“ã“ã§ $\lambda > 0$ ã¯ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®é‡è¦åº¦ã€‚

**ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æå¤±**: ãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡ã¨ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã®å·®

$$
\mathcal{L}_{\text{feedback}}(\theta; \mathcal{D}_{\text{feedback}}) = \frac{1}{|\mathcal{D}_{\text{feedback}}|} \sum_{(x,y,f) \in \mathcal{D}_{\text{feedback}}} \ell(f_\theta(x), y) \cdot w(f)
$$

ã“ã“ã§:
- $f_\theta(x)$ ã¯ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬
- $y$ ã¯æ­£è§£ãƒ©ãƒ™ãƒ«
- $f$ ã¯ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¹ã‚³ã‚¢
- $w(f)$ ã¯ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ãé‡ã¿: $w(f) = f$ (é«˜è©•ä¾¡ã»ã©é‡è¦–)

**å‹¾é…é™ä¸‹æ›´æ–°**:

$$
\theta_{t+1} \leftarrow \theta_t - \eta \nabla_\theta \mathcal{L}_{\text{total}}(\theta_t)
$$

### 3.2 Active Learningå®Œå…¨ç‰ˆ

#### 3.2.1 ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®ç†è«–

Active Learningã®ç›®æ¨™: **æœ€å°ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ã‚¹ãƒˆã§æœ€å¤§ã®æ€§èƒ½å‘ä¸Š**ã‚’é”æˆã™ã‚‹ã€‚

**ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°**: ãƒ¢ãƒ‡ãƒ«ãŒæœ€ã‚‚è‡ªä¿¡ã‚’æŒã¦ãªã„ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠ

$$
x^* = \arg\max_{x \in \mathcal{U}} U(x; \theta)
$$

ã“ã“ã§ $\mathcal{U}$ ã¯ãƒ©ãƒ™ãƒ«ãªã—ãƒ‡ãƒ¼ã‚¿ã€$U(x; \theta)$ ã¯ä¸ç¢ºå®Ÿæ€§æŒ‡æ¨™ã€‚

**3ã¤ã®ä¸ç¢ºå®Ÿæ€§æŒ‡æ¨™**:

1. **Least Confidence**: æœ€å¤§ç¢ºç‡ãŒä½ã„ã‚µãƒ³ãƒ—ãƒ«

$$
U_{\text{LC}}(x; \theta) = 1 - \max_c p_\theta(c | x)
$$

2. **Margin Sampling**: ä¸Šä½2ã‚¯ãƒ©ã‚¹ã®ç¢ºç‡å·®ãŒå°ã•ã„ã‚µãƒ³ãƒ—ãƒ«

$$
U_{\text{M}}(x; \theta) = - \left( p_\theta(c_1 | x) - p_\theta(c_2 | x) \right)
$$

ã“ã“ã§ $c_1, c_2$ ã¯ç¢ºç‡ä¸Šä½2ã‚¯ãƒ©ã‚¹ã€‚

3. **Entropy**: ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒæœ€å¤§ã®ã‚µãƒ³ãƒ—ãƒ«

$$
U_{\text{Ent}}(x; \theta) = H(p_\theta(\cdot | x)) = - \sum_{c=1}^C p_\theta(c | x) \log p_\theta(c | x)
$$

**ã©ã‚Œã‚’ä½¿ã†ã¹ãã‹ï¼Ÿ**

| æŒ‡æ¨™ | é•·æ‰€ | çŸ­æ‰€ | é©ç”¨å ´é¢ |
|:-----|:-----|:-----|:---------|
| Least Confidence | è¨ˆç®—ãŒè»½ã„ | 2ç•ªç›®ã®ç¢ºç‡ã‚’ç„¡è¦– | 2ã‚¯ãƒ©ã‚¹åˆ†é¡ |
| Margin | æ±ºå®šå¢ƒç•Œã‚’é‡è¦– | å¤šã‚¯ãƒ©ã‚¹ã§æƒ…å ±æå¤± | 2ã‚¯ãƒ©ã‚¹ or ãƒãƒ©ãƒ³ã‚¹è‰¯å¥½ |
| Entropy | å…¨ã‚¯ãƒ©ã‚¹ã®æƒ…å ±ã‚’ä½¿ã† | è¨ˆç®—ã‚³ã‚¹ãƒˆã‚„ã‚„é«˜ | å¤šã‚¯ãƒ©ã‚¹åˆ†é¡ |

**æ•°å€¤æ¤œè¨¼** (Julia):

```julia
# 3ã‚¯ãƒ©ã‚¹åˆ†é¡ã®ä¾‹
p = [0.6, 0.3, 0.1]  # ã‚¯ãƒ©ã‚¹ç¢ºç‡

# Least Confidence
U_LC = 1 - maximum(p)  # => 0.4

# Margin
p_sorted = sort(p, rev=true)
U_M = -(p_sorted[1] - p_sorted[2])  # => -(0.6 - 0.3) = -0.3

# Entropy
H(p) = -sum(p .* log.(p .+ 1e-10))
U_Ent = H(p)  # => 0.897

println("LC: $U_LC, Margin: $U_M, Entropy: $U_Ent")
```

#### 3.2.2 MSAL (Maximally Separated Active Learning)

arXiv:2411.17444 "Maximally Separated Active Learning" (Nov 2024)[^1] ã§ææ¡ˆã•ã‚ŒãŸæ‰‹æ³•ã€‚

**èª²é¡Œ**: å¾“æ¥ã®ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¯**é¡ä¼¼ã—ãŸã‚µãƒ³ãƒ—ãƒ«ã°ã‹ã‚Šé¸ã‚“ã§ã—ã¾ã†** (sampling bias)ã€‚

**è§£æ±ºç­–**: ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«**å¤šæ§˜æ€§åˆ¶ç´„**ã‚’è¿½åŠ ã€‚

**MSALç›®çš„é–¢æ•°**:

$$
x^* = \arg\max_{x \in \mathcal{U}} \left[ U(x; \theta) + \alpha \cdot D(x; \mathcal{L}) \right]
$$

ã“ã“ã§:
- $U(x; \theta)$ ã¯ä¸ç¢ºå®Ÿæ€§ã‚¹ã‚³ã‚¢
- $D(x; \mathcal{L})$ ã¯æ—¢ã«ãƒ©ãƒ™ãƒ«ä»˜ã‘ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ $\mathcal{L}$ ã¨ã®å¤šæ§˜æ€§
- $\alpha > 0$ ã¯å¤šæ§˜æ€§ã®é‡è¦åº¦

**å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢**: æœ€è¿‘å‚ã¨ã®è·é›¢

$$
D(x; \mathcal{L}) = \min_{x' \in \mathcal{L}} \left\| \phi(x) - \phi(x') \right\|_2
$$

ã“ã“ã§ $\phi(x)$ ã¯Embedding (ä¾‹: BERTæœ€çµ‚å±¤)ã€‚

**Equiangular Prototypes**: MSALã¯å„ã‚¯ãƒ©ã‚¹ã®**ç­‰è§’è¶…çƒé¢ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—**ã‚’ä½¿ã†ã€‚

$C$ ã‚¯ãƒ©ã‚¹ã®å ´åˆã€$d$ æ¬¡å…ƒçƒé¢ä¸Šã« $C$ å€‹ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’ç­‰é–“éš”é…ç½®:

$$
\mathbf{p}_c = r \cdot \mathbf{v}_c, \quad \mathbf{v}_c \cdot \mathbf{v}_{c'} = \begin{cases} 1 & c = c' \\ -\frac{1}{C-1} & c \neq c' \end{cases}
$$

**ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **:

```julia
function msal_select_batch(model, unlabeled_pool, labeled_data, batch_size, Î±=0.5)
    selected = []

    for _ in 1:batch_size
        scores = []
        for x in unlabeled_pool
            # ä¸ç¢ºå®Ÿæ€§ã‚¹ã‚³ã‚¢
            U = entropy(model(x))

            # å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢: æ—¢é¸æŠã‚µãƒ³ãƒ—ãƒ«ã¨ã®æœ€å°è·é›¢
            Ï†_x = embedding(x)
            D = minimum([norm(Ï†_x - embedding(x')) for x' in labeled_data âˆª selected])

            # çµ±åˆã‚¹ã‚³ã‚¢
            score = U + Î± * D
            push!(scores, (x, score))
        end

        # æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’é¸æŠ
        x_best = argmax(s -> s[2], scores)[1]
        push!(selected, x_best)
        unlabeled_pool = filter(x -> x != x_best, unlabeled_pool)
    end

    return selected
end
```

#### 3.2.3 Human-in-the-Loop (HITL) è¨­è¨ˆ

arXiv:2409.09467 "Keeping Humans in the Loop" (Sep 2024)[^2] ã§è­°è«–ã•ã‚ŒãŸãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã€‚

**HITLã®3åŸå‰‡**:

1. **Selective Annotation**: äººé–“ã¯é›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã®ã¿ã‚¢ãƒãƒ†ãƒ¼ãƒˆ
2. **Quality Control**: è¤‡æ•°ã‚¢ãƒãƒ†ãƒ¼ã‚¿ãƒ¼é–“ã®ä¸€è‡´åº¦ã‚’æ¸¬å®š
3. **Feedback Integration**: ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å³åº§ã«è¨“ç·´ã«åæ˜ 

**ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å“è³ªã®å®šé‡åŒ–**: Cohen's Kappa

$$
\kappa = \frac{p_o - p_e}{1 - p_e}
$$

ã“ã“ã§:
- $p_o$ ã¯è¦³æ¸¬ä¸€è‡´ç‡
- $p_e$ ã¯å¶ç„¶ã®ä¸€è‡´ç‡

$\kappa > 0.6$ ã§ã€Œå®Ÿè³ªçš„ãªä¸€è‡´ã€ã€$\kappa > 0.8$ ã§ã€Œã»ã¼å®Œå…¨ãªä¸€è‡´ã€ã€‚

**Disagreement Resolution**: 2äººã®ã‚¢ãƒãƒ†ãƒ¼ã‚¿ãƒ¼ãŒç•°ãªã‚‹ãƒ©ãƒ™ãƒ«ã‚’ä»˜ã‘ãŸå ´åˆ

```julia
function resolve_disagreement(x, label_A, label_B, model)
    if label_A == label_B
        return label_A  # ä¸€è‡´
    else
        # ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’å‚è€ƒã«å°‚é–€å®¶ãŒåˆ¤æ–­
        pred = model(x)
        println("Disagreement: A=$label_A, B=$label_B, Model=$pred")
        return expert_review(x, label_A, label_B, pred)
    end
end
```

**å°‚é–€å®¶ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°**:

| æ¡ä»¶ | ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ |
|:-----|:----------|
| $\kappa < 0.6$ | å…¨ã‚µãƒ³ãƒ—ãƒ«ã‚’å°‚é–€å®¶ãƒ¬ãƒ“ãƒ¥ãƒ¼ |
| $0.6 \leq \kappa < 0.8$ | Disagreementã®ã¿ãƒ¬ãƒ“ãƒ¥ãƒ¼ |
| $\kappa \geq 0.8$ | ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸è¦ |

#### 3.2.4 âš”ï¸ Boss Battle: Active LearningåæŸä¿è¨¼

arXiv:2110.15784 "Convergence of Uncertainty Sampling" (Oct 2021)[^3] ã®å®šç†ã‚’å®Œå…¨ç†è§£ã™ã‚‹ã€‚

**å®šç† (Simplified)**: ã‚ã‚‹æ¡ä»¶ä¸‹ã§ã€ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¯**æœ€é©æ±ºå®šå¢ƒç•Œã«åæŸ**ã™ã‚‹ã€‚

**ä»®å®š**:
1. ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ $p(x, y)$ ã¯å›ºå®š
2. ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹ $\mathcal{F}$ ã¯ååˆ†ãªè¡¨ç¾åŠ›ã‚’æŒã¤ (VCæ¬¡å…ƒ $d_{VC} < \infty$)
3. ã‚µãƒ³ãƒ—ãƒ«é¸æŠã¯æ±ºå®šå¢ƒç•Œä»˜è¿‘ã«é›†ä¸­

**åæŸãƒ¬ãƒ¼ãƒˆ**: $T$ ãƒ©ã‚¦ãƒ³ãƒ‰å¾Œã®èª¤å·®

$$
\mathbb{E}[\text{Error}(\theta_T)] \leq \mathcal{O}\left( \frac{d_{VC}}{T} \log T \right)
$$

ã“ã“ã§ $d_{VC}$ ã¯VCæ¬¡å…ƒã€‚

**è¨¼æ˜ã®ã‚¹ã‚±ãƒƒãƒ**:

1. **æ±ºå®šå¢ƒç•Œã®å®šç¾©**: $\{ x : p_\theta(c_1 | x) = p_\theta(c_2 | x) \}$
2. **ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®æ€§è³ª**: Entropyæœ€å¤§ = æ±ºå®šå¢ƒç•Œä¸Š
3. **PACå­¦ç¿’ç†è«–**: $N$ ã‚µãƒ³ãƒ—ãƒ«ã§èª¤å·® $\epsilon$ ä»¥ä¸‹ã«ãªã‚‹ç¢ºç‡

$$
P(\text{Error}(\theta) > \epsilon) \leq 2 \mathcal{M}(\mathcal{F}, N) e^{-N \epsilon^2 / 8}
$$

ã“ã“ã§ $\mathcal{M}(\mathcal{F}, N)$ ã¯æˆé•·é–¢æ•°ã€‚

4. **VCæ¬¡å…ƒã¨ã®é–¢ä¿‚**: $\mathcal{M}(\mathcal{F}, N) \leq N^{d_{VC}}$
5. **çµè«–**: $N = \mathcal{O}(d_{VC} / \epsilon^2 \log(1/\delta))$ ã‚µãƒ³ãƒ—ãƒ«ã§ååˆ†

**æ•°å€¤æ¤œè¨¼** (Julia):

```julia
# ç·šå½¢åˆ†é¡å™¨ (VCæ¬¡å…ƒ = d+1)
d = 10  # ç‰¹å¾´é‡æ¬¡å…ƒ
d_VC = d + 1

# ç›®æ¨™èª¤å·® Îµ = 0.01, ç¢ºç‡ Î´ = 0.05
Îµ = 0.01
Î´ = 0.05

# å¿…è¦ã‚µãƒ³ãƒ—ãƒ«æ•°
N_required = ceil(Int, d_VC / Îµ^2 * log(1/Î´))
# => ç´„ 32,919 ã‚µãƒ³ãƒ—ãƒ«

println("VCæ¬¡å…ƒ: $d_VC")
println("å¿…è¦ã‚µãƒ³ãƒ—ãƒ«æ•°: $N_required")
```

**ãƒœã‚¹æ’ƒç ´ã®è¨¼**: ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®åæŸãƒ¬ãƒ¼ãƒˆ $\mathcal{O}(d_{VC}/T \log T)$ ã‚’å°å‡ºã—ã€æ•°å€¤æ¤œè¨¼ã§ç¢ºèªã—ãŸã€‚

### 3.3 ãƒ¢ãƒ‡ãƒ«æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ã®æ•°å¼

#### 3.3.1 Continuous Learning (ç¶™ç¶šå­¦ç¿’)

**å®šç¾©**: æœ¬ç•ªç’°å¢ƒã§ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä½¿ã£ã¦**ãƒ¢ãƒ‡ãƒ«ã‚’ç¶™ç¶šçš„ã«æ›´æ–°**ã™ã‚‹ã€‚

**Naive Approach** (ç ´æ»…çš„å¿˜å´):

$$
\theta_{t+1} \leftarrow \arg\min_\theta \mathcal{L}(\theta; \mathcal{D}_{\text{new}})
$$

å•é¡Œ: å¤ã„ãƒ‡ãƒ¼ã‚¿ $\mathcal{D}_{\text{old}}$ ã®æ€§èƒ½ãŒåŠ£åŒ– (Catastrophic Forgetting)ã€‚

**Elastic Weight Consolidation (EWC)**: é‡è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¤‰åŒ–ã‚’æŠ‘åˆ¶

$$
\mathcal{L}_{\text{EWC}}(\theta) = \mathcal{L}(\theta; \mathcal{D}_{\text{new}}) + \frac{\lambda}{2} \sum_i F_i (\theta_i - \theta_{i,\text{old}})^2
$$

ã“ã“ã§:
- $F_i$ ã¯Fisheræƒ…å ±é‡: $F_i = \mathbb{E}_{x \sim \mathcal{D}_{\text{old}}} \left[ \left( \frac{\partial \log p_{\theta_{\text{old}}}(y|x)}{\partial \theta_i} \right)^2 \right]$
- $\lambda > 0$ ã¯æ­£å‰‡åŒ–å¼·åº¦

**Experience Replay**: å¤ã„ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒãƒ•ã‚¡ã‚’ä¿æŒ

$$
\mathcal{L}_{\text{Replay}}(\theta) = \mathcal{L}(\theta; \mathcal{D}_{\text{new}} \cup \mathcal{D}_{\text{buffer}})
$$

ã“ã“ã§ $\mathcal{D}_{\text{buffer}}$ ã¯å¤ã„ãƒ‡ãƒ¼ã‚¿ã®ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒ«ã€‚

**ã©ã¡ã‚‰ã‚’ä½¿ã†ã¹ãã‹ï¼Ÿ**

| æ‰‹æ³• | ãƒ¡ãƒ¢ãƒª | è¨ˆç®—é‡ | æ€§èƒ½ | é©ç”¨å ´é¢ |
|:-----|:------|:-------|:-----|:---------|
| EWC | å° (Fisheræƒ…å ±é‡ã®ã¿) | ä¸­ | ä¸­ | ãƒ¡ãƒ¢ãƒªåˆ¶ç´„ |
| Replay | å¤§ (ãƒãƒƒãƒ•ã‚¡ä¿æŒ) | å¤§ | é«˜ | é«˜æ€§èƒ½å„ªå…ˆ |

#### 3.3.2 Hidden Feedback Loop Effect

arXiv:2405.02726 "Mathematical Model of the Hidden Feedback Loop Effect"[^4] ã§è­°è«–ã•ã‚ŒãŸå•é¡Œã€‚

**å•é¡Œ**: ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ãŒæ¬¡ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹**éš ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—**ã€‚

**æ•°å¼ãƒ¢ãƒ‡ãƒ«**: æ™‚åˆ» $t$ ã§ã®ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ $p_t(x, y)$ ãŒå‰å›ã®ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã«ä¾å­˜

$$
p_{t+1}(x, y) = (1 - \alpha) p_{\text{true}}(x, y) + \alpha \cdot \delta_{y = \hat{y}_t(x)} p_t(x)
$$

ã“ã“ã§:
- $p_{\text{true}}(x, y)$ ã¯çœŸã®åˆ†å¸ƒ
- $\hat{y}_t(x)$ ã¯æ™‚åˆ» $t$ ã®ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬
- $\alpha \in [0, 1]$ ã¯ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å¼·åº¦

**çµæœ**: $\alpha > 0.5$ ã§ãƒ¢ãƒ‡ãƒ«ãŒ**è‡ªå·±å¼·åŒ–ãƒã‚¤ã‚¢ã‚¹**ã«é™¥ã‚‹ã€‚

**æ•°å€¤ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³** (Julia):

```julia
# 2ã‚¯ãƒ©ã‚¹åˆ†é¡ã®ä¾‹
p_true = [0.5, 0.5]  # çœŸã®åˆ†å¸ƒ
Î± = 0.6  # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å¼·åº¦

p_t = copy(p_true)
for t in 1:10
    # ãƒ¢ãƒ‡ãƒ«ã¯å¸¸ã«ã‚¯ãƒ©ã‚¹1ã‚’äºˆæ¸¬ (simplified)
    y_pred = 1

    # æ¬¡ã®åˆ†å¸ƒ: ã‚¯ãƒ©ã‚¹1ãŒå¢—ãˆã‚‹
    p_t = (1 - Î±) .* p_true + Î± .* [y_pred == 1 ? 1.0 : 0.0, y_pred == 2 ? 1.0 : 0.0]

    println("t=$t: p(y=1)=$(p_t[1])")
end
# => t=10: p(y=1) â‰ˆ 0.94 (å¤§ããåã‚‹)
```

**å¯¾ç­–**: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å¼·åº¦ $\alpha$ ã‚’åˆ¶å¾¡ or ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§çœŸã®åˆ†å¸ƒã‚’ä¿æŒã€‚

#### 3.3.3 RLHF (Reinforcement Learning from Human Feedback)

arXiv:2504.12501 "RLHF" (2025)[^5] ã§ä½“ç³»åŒ–ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é§†å‹•è¨“ç·´ã€‚

**3ã‚¹ãƒ†ãƒƒãƒ—**:

1. **Supervised Fine-tuning (SFT)**: äººé–“ã®ä¾‹ã§äº‹å‰è¨“ç·´

$$
\theta_{\text{SFT}} \leftarrow \arg\min_\theta \mathbb{E}_{(x,y) \sim \mathcal{D}_{\text{demo}}} [- \log p_\theta(y | x)]
$$

2. **Reward Model Training**: äººé–“ã®å¥½ã¿ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–

$$
r_\phi(x, y) = \mathbb{E}_{\text{human}}[\text{preference}(x, y)]
$$

è¨“ç·´ãƒ‡ãƒ¼ã‚¿: $(x, y_w, y_l)$ (win/lose pair)

$$
\mathcal{L}_{\text{RM}}(\phi) = - \mathbb{E}_{(x,y_w,y_l)} \left[ \log \sigma(r_\phi(x, y_w) - r_\phi(x, y_l)) \right]
$$

3. **RL Fine-tuning**: Rewardæœ€å¤§åŒ–

$$
\theta_{\text{RL}} \leftarrow \arg\max_\theta \mathbb{E}_{x \sim \mathcal{D}, y \sim p_\theta(\cdot|x)} \left[ r_\phi(x, y) - \beta \log \frac{p_\theta(y|x)}{p_{\text{ref}}(y|x)} \right]
$$

ã“ã“ã§ $\beta > 0$ ã¯KLæ­£å‰‡åŒ–ä¿‚æ•°ã€$p_{\text{ref}}$ ã¯å‚ç…§ãƒ¢ãƒ‡ãƒ« (SFT)ã€‚

**PPO (Proximal Policy Optimization)** ã§RLã‚’å®‰å®šåŒ–:

$$
\mathcal{L}_{\text{PPO}}(\theta) = \mathbb{E}_t \left[ \min \left( \frac{p_\theta(a_t|s_t)}{p_{\theta_{\text{old}}}(a_t|s_t)} A_t, \text{clip}(\cdot, 1-\epsilon, 1+\epsilon) A_t \right) \right]
$$

ã“ã“ã§ $A_t$ ã¯Advantageã€$\epsilon=0.2$ ã¯å…¸å‹å€¤ã€‚

### 3.4 E2Eã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ç†è«–

#### 3.4.1 ã‚µãƒ¼ãƒ“ã‚¹é–“é€šä¿¡ã®æ•°å¼

**REST API**: ãƒªã‚¯ã‚¨ã‚¹ãƒˆ $r$ ã«å¯¾ã™ã‚‹ãƒ¬ã‚¹ãƒãƒ³ã‚¹ $s$

$$
s = f_{\text{API}}(r; \theta)
$$

**ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·**: å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å‡¦ç†æ™‚é–“ã®å’Œ

$$
t_{\text{total}} = t_{\text{gateway}} + t_{\text{inference}} + t_{\text{postprocess}}
$$

**ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**: å˜ä½æ™‚é–“ã‚ãŸã‚Šã®å‡¦ç†æ•°

$$
\text{Throughput} = \frac{1}{t_{\text{total}} + t_{\text{queue}}}
$$

ã“ã“ã§ $t_{\text{queue}}$ ã¯ã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°æ™‚é–“ã€‚

**Little's Law**: å¹³å‡ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•° $L$ã€å¹³å‡åˆ°ç€ç‡ $\lambda$ã€å¹³å‡å‡¦ç†æ™‚é–“ $W$

$$
L = \lambda W
$$

ä¾‹: $\lambda = 100$ req/sã€$W = 0.05$ s â†’ $L = 5$ ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆã€‚

#### 3.4.2 Circuit Breakerç†è«–

**çŠ¶æ…‹é·ç§»**:

```
Closed â†’ (å¤±æ•—ç‡ > threshold) â†’ Open â†’ (timeoutçµŒé) â†’ Half-Open â†’ (æˆåŠŸ) â†’ Closed
```

**æ•°å¼ãƒ¢ãƒ‡ãƒ«**: å¤±æ•—ç‡ $p_{\text{fail}}$ã€é–¾å€¤ $\theta_{\text{CB}}$

$$
\text{State} = \begin{cases}
\text{Open} & p_{\text{fail}} > \theta_{\text{CB}} \\
\text{Closed} & p_{\text{fail}} \leq \theta_{\text{CB}}
\end{cases}
$$

**Exponential Backoff**: OpençŠ¶æ…‹ã‹ã‚‰ã®å¾©å¸°æ™‚é–“

$$
t_{\text{wait}} = t_0 \cdot 2^n
$$

ã“ã“ã§ $n$ ã¯å¤±æ•—å›æ•°ã€$t_0$ ã¯åˆæœŸå¾…ã¡æ™‚é–“ã€‚

#### 3.4.3 Rate Limiting (Token Bucket)

**Token Bucket Algorithm**: å®¹é‡ $B$ã€è£œå……ãƒ¬ãƒ¼ãƒˆ $r$

$$
\text{tokens}(t) = \min(B, \text{tokens}(t-1) + r \Delta t - c)
$$

ã“ã“ã§ $c$ ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§æ¶ˆè²»ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°ã€‚

**è¨±å¯æ¡ä»¶**:

$$
\text{allow}(c) = \begin{cases}
\text{true} & \text{tokens} \geq c \\
\text{false} & \text{tokens} < c
\end{cases}
$$

**æ•°å€¤ä¾‹**:

```julia
# Token Bucket ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
B = 100  # ãƒã‚±ãƒƒãƒˆå®¹é‡
r = 10   # è£œå……ãƒ¬ãƒ¼ãƒˆ (tokens/sec)

tokens = B
t = 0

for i in 1:15
    # 1ç§’ã”ã¨ã«7ãƒˆãƒ¼ã‚¯ãƒ³è¦æ±‚
    t += 1
    tokens = min(B, tokens + r * 1 - 7)

    println("t=$t: tokens=$tokens")
end
# => t=15: tokens=145 - 105 = 40 (ãƒã‚±ãƒƒãƒˆå®¹é‡ã§ã‚­ãƒ£ãƒƒãƒ—)
```

:::message
**é€²æ—: 50%å®Œäº†ï¼** ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—æ•°å¼ã¨Active Learningç†è«–ã‚’ç¿’å¾—ã—ãŸã€‚æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ã‚¯ãƒªã‚¢ï¼
:::

---


## è¨˜æ³•è¦ç´„

### æ•°å­¦è¨˜æ³•

| è¨˜å· | æ„å‘³ | ä¾‹ |
|------|------|-----|
| $\theta$ | ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | $\theta \in \mathbb{R}^d$ |
| $\mathcal{L}$ | æå¤±é–¢æ•° | $\mathcal{L}(\theta) = \text{MSE}$ |
| $\nabla_\theta$ | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹å‹¾é… | $\nabla_\theta \mathcal{L}$ |
| $\mathbb{E}_{x \sim p}$ | åˆ†å¸ƒ$p$ã«é–¢ã™ã‚‹æœŸå¾…å€¤ | $\mathbb{E}_{x \sim \mathcal{D}}[f(x)]$ |
| $\mathcal{D}_{\text{pool}}$ | ãƒ©ãƒ™ãƒ«ãªã—ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¼ãƒ« | Active Learningç”¨ |
| $x^{(i)}$ | $i$ç•ªç›®ã®ã‚µãƒ³ãƒ—ãƒ« | $(x^{(1)}, y^{(1)}), \ldots$ |
| $\mathcal{H}$ | ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ | $\mathcal{H}(p) = -\sum p \log p$ |
| $\text{MI}(X;Y)$ | ç›¸äº’æƒ…å ±é‡ | $\text{MI}(y;\theta \mid x, \mathcal{D})$ |

### ã‚³ãƒ¼ãƒ‰è¦ç´„

**Julia**:
```julia
# é–¢æ•°å: snake_case
function train_model(data::Matrix, labels::Vector)
    # ...
end

# å‹å: PascalCase
struct TrainingPipeline
    model::Lux.AbstractExplicitLayer
end

# å®šæ•°: UPPER_CASE
const BATCH_SIZE = 32
```

**Rust**:
```rust
// é–¢æ•°å: snake_case
pub fn run_inference(input: &[f32]) -> Vec<f32> {
    // ...
}

// å‹å: PascalCase
pub struct InferenceEngine {
    session: Session,
}

// å®šæ•°: SCREAMING_SNAKE_CASE
const MAX_BATCH_SIZE: usize = 128;
```

**Elixir**:
```elixir
# é–¢æ•°å: snake_case
def process_request(request) do
  # ...
end

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å: PascalCase
defmodule FeedbackCollector do
  # ...
end

# ã‚¢ãƒˆãƒ : lowercase
:ok, :error, :rate_limited
```

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³è¨˜æ³•

```mermaid
graph LR
    A[Component A] -->|REST API| B[Component B]
    B -->|gRPC| C[Component C]
    C -.->|Async| D[(Database)]

    style A fill:#4ecdc4,stroke:#1a535c
    style B fill:#ffe66d,stroke:#ff6b6b
    style C fill:#95e1d3,stroke:#38ada9
    style D fill:#f38181,stroke:#aa4465
```

- **å®Ÿç·š**: åŒæœŸé€šä¿¡ (REST, gRPC)
- **ç‚¹ç·š**: éåŒæœŸé€šä¿¡ (Message Queue, Event)
- **å††æŸ±**: ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ (DB, Cache)
- **è‰²**: è¨€èªåˆ¥ (ğŸ¦€ Rust=é’, âš¡ Julia=é»„, ğŸ”® Elixir=ç·‘)

---

:::message
**ğŸ“ Course IIIå®Œå…¨åˆ¶è¦‡ãŠã‚ã§ã¨ã†ï¼**

ã‚ãªãŸã¯ä»Šã€ä»¥ä¸‹ã®ã‚¹ã‚­ãƒ«ã‚’ç²å¾—ã—ãŸ:
1. âœ… ç†è«–ï¼ˆCourse I-IIï¼‰â†’ å®Ÿè£…ï¼ˆCourse IIIï¼‰ã®å®Œå…¨æ©‹æ¸¡ã—
2. âœ… Julia/Rust/Elixir 3è¨€èªã§ã®Production E2Eã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰åŠ›
3. âœ… è¨“ç·´â†’æ¨è«–â†’é…ä¿¡â†’ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯â†’ç¶™ç¶šå­¦ç¿’ã®å®Ÿè£…
4. âœ… è² è·ãƒ†ã‚¹ãƒˆãƒ»Chaos Engineeringãƒ»MLOpsã®å®Ÿè·µçŸ¥è­˜

**ã“ã“ã‹ã‚‰2ã¤ã®ãƒ«ãƒ¼ãƒˆãŒåˆ†å²ã™ã‚‹**:

**ğŸŒŠ Course IV: æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ç†è«–æ·±åŒ–ï¼ˆç¬¬33-42å›ã€å…¨10å›ï¼‰**
- Normalizing Flows â†’ EBM â†’ Score Matching â†’ DDPM â†’ SDE â†’ Flow Matching â†’ LDM â†’ Consistency Models â†’ World Models â†’ çµ±ä¸€ç†è«–
- ã€Œæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«è«–æ–‡ã®ç†è«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå°å‡ºã§ãã‚‹ã€æ•°å­¦åŠ›ã‚’ç²å¾—
- å¯†åº¦ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®è«–ç†çš„ãƒã‚§ãƒ¼ãƒ³ã‚’å®Œå…¨è¸ç ´

**ğŸ¨ Course V: ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å¿œç”¨ï¼ˆç¬¬43-50å›ã€å…¨8å›ï¼‰**
- Visionãƒ»Audioãƒ»RLãƒ»Proteinãƒ»Moleculeãƒ»Climateãƒ»Robotãƒ»Simulation
- å„ãƒ‰ãƒ¡ã‚¤ãƒ³ã®æœ€æ–°SOTAæŠ€è¡“ã‚’å®Ÿè£…
- å®Ÿä¸–ç•Œå•é¡Œã¸ã®é©ç”¨åŠ›ã‚’é›ãˆã‚‹

**Course IVã¨Vã¯ç‹¬ç«‹** â€” ã©ã¡ã‚‰ã‹ã‚‰å§‹ã‚ã¦ã‚‚è‰¯ã„ã€‚ä¸¡æ–¹å±¥ä¿®ã§å…¨50å›å®Œå…¨åˆ¶è¦‡ã€‚

**æ¬¡å›äºˆå‘Š: ç¬¬33å› Normalizing Flows â€” å¯é€†å¤‰æ›ã§å³å¯†å°¤åº¦ã‚’æ‰‹ã«å…¥ã‚Œã‚‹**
:::

---

---

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
