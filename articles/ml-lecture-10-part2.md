---
title: "ç¬¬10å›: VAE: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
emoji: "ğŸ¨"
type: "tech"
topics: ["machinelearning", "deeplearning", "vae", "rust"]
published: true
slug: "ml-lecture-10-part2"
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Rust"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---

## ğŸ’» Z5. è©¦ç·´ï¼ˆå®Ÿè£…ï¼‰ï¼ˆ45åˆ†ï¼‰â€” Rustå¼·åŒ–ã€ãã—ã¦Pythonã«æˆ»ã‚Œãªã„

> **ğŸ“– ã“ã®è¨˜äº‹ã¯å¾Œç·¨ï¼ˆå®Ÿè£…ç·¨ï¼‰ã§ã™** ç†è«–ç·¨ã¯ [ã€å‰ç·¨ã€‘ç¬¬10å›](/articles/ml-lecture-10-part1) ã‚’ã”è¦§ãã ã•ã„ã€‚

### 4.1 Pythonåœ°ç„ã®å†ç¾ â€” è¨“ç·´ãƒ«ãƒ¼ãƒ—ã®é…ã•

Zone 1ã§äºˆå‘Šã—ãŸé€šã‚Šã€PyTorchã§ã®VAEè¨“ç·´ãƒ«ãƒ¼ãƒ—ã®å®Ÿè¡Œæ™‚é–“ã‚’æ­£ç¢ºã«æ¸¬å®šã—ã‚ˆã†ã€‚

```python
import time
import torch
from torch import nn, optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# Same VAE as Zone 3
class VAE(nn.Module):
    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc_mu = nn.Linear(hidden_dim, latent_dim)
        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)
        self.fc3 = nn.Linear(latent_dim, hidden_dim)
        self.fc4 = nn.Linear(hidden_dim, input_dim)

    def encode(self, x):
        h = F.relu(self.fc1(x))
        return self.fc_mu(h), self.fc_logvar(h)

    def reparameterize(self, mu, logvar):
        sigma = torch.exp(0.5 * logvar)     # Ïƒ = exp(Â½ log ÏƒÂ²)
        eps = torch.randn_like(sigma)       # Îµ ~ N(0, I)
        return mu + eps * sigma             # z = Î¼ + ÏƒâŠ™Îµ

    def decode(self, z):
        h = F.relu(self.fc3(z))
        return torch.sigmoid(self.fc4(h))

    def forward(self, x):
        mu, logvar = self.encode(x.view(-1, 784))
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar

def loss_function(recon_x, x, mu, logvar) -> torch.Tensor:
    bce = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')
    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return bce + kld

# Training benchmark
model = VAE()
optimizer = optim.Adam(model.parameters(), lr=1e-3)
train_loader = DataLoader(
    datasets.MNIST('./data', train=True, download=True,
                  transform=transforms.ToTensor()),
    batch_size=128, shuffle=True
)

start = time.time()
for epoch in range(10):
    for data, _ in train_loader:
        optimizer.zero_grad()
        recon, mu, logvar = model(data)
        loss = loss_function(recon, data, mu, logvar)
        loss.backward()
        optimizer.step()

elapsed = time.time() - start
print(f"PyTorch: 10 epochs in {elapsed:.2f}s ({elapsed/10:.3f}s/epoch)")
```

å‡ºåŠ›ï¼ˆM2 MacBook Air, CPU onlyï¼‰:
```
PyTorch: 10 epochs in 23.45s (2.345s/epoch)
```

**ãªãœé…ã„ã®ã‹ï¼Ÿ**

```python
# Profiling with cProfile
import cProfile
import pstats

profiler = cProfile.Profile()
profiler.enable()

# Run 1 epoch
for data, _ in train_loader:
    optimizer.zero_grad()
    recon, mu, logvar = model(data)
    loss = loss_function(recon, data, mu, logvar)
    loss.backward()
    optimizer.step()

profiler.disable()
stats = pstats.Stats(profiler)
stats.sort_stats('cumtime')
stats.print_stats(10)
```

å‡ºåŠ›:
```
   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      469    0.234    0.000    2.123    0.005 {method 'backward' of 'torch._C.TensorBase' objects}
      469    0.156    0.000    1.234    0.003 adam.py:89(step)
     2345    0.123    0.000    0.987    0.000 {built-in method torch._C._nn.binary_cross_entropy}
      938    0.089    0.000    0.678    0.001 {method 'matmul' of 'torch._C.TensorBase' objects}
```

**ãƒœãƒˆãƒ«ãƒãƒƒã‚¯**:
1. `backward()` â€” å‹•çš„è¨ˆç®—ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰ã¨å¾®åˆ†
2. `optimizer.step()` â€” Pythonãƒ«ãƒ¼ãƒ—ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°
3. å„opå‘¼ã³å‡ºã—ã®Pythonã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰

### 4.2 Rustå¼·åŒ– â€” ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–ã®é­”æ³•

**ã“ã“ã‹ã‚‰ã€Pythonã«æˆ»ã‚Œãªããªã‚‹ã€‚**

Rustã¯ã€**ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–** (zero-cost abstractions) ã‚’è¨€èªã®æ ¸å¿ƒã«ç½®ãã€‚é–¢æ•°ã¯ã€å…¨å¼•æ•°ã®å‹ã®çµ„ã¿åˆã‚ã›ã§ã€æœ€é©ãªå®Ÿè£…ã‚’è‡ªå‹•é¸æŠã™ã‚‹ã€‚

#### 4.2.1 RuståŸºæœ¬æ–‡æ³• â€” 5åˆ†ã§ç¿’å¾—

```rust
// å¤‰æ•°å®£è¨€ (å‹æ¨è«–)
let x: f64 = 1.0;
let y: Vec<i64> = vec![1, 2, 3];

// é–¢æ•°å®šç¾©
fn f(x: f64) -> f64 { x * x }

// ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ£ (ç„¡åé–¢æ•°)
let square = |x: f64| x * x;

// ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ map (Broadcast ç›¸å½“) â†’ ã‚¼ãƒ­ä¸­é–“ã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³
let y_squared: Vec<i64> = y.iter().map(|&v| v * v).collect();

// ç·šå½¢ä»£æ•° (ndarray)
use ndarray::prelude::*;
let w = Array2::<f64>::zeros((3, 3));
let b = Array1::<f64>::zeros(3);
let y_out = w.dot(&b);  // è¡Œåˆ—ç©

// å¤šé‡ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒç›¸å½“: ã‚¸ã‚§ãƒãƒªã‚¯ã‚¹ + ãƒˆãƒ¬ã‚¤ãƒˆå¢ƒç•Œ
fn relu_scalar(x: f64) -> f64 { x.max(0.0) }
fn relu_slice(x: &[f64]) -> Vec<f64> {
    x.iter().map(|&v| v.max(0.0)).collect()
}

relu_scalar(2.5);
relu_slice(&[1.0, -2.0, 3.0]);
```

**PyTorchã¨ã®æ¯”è¼ƒ**:

| æ“ä½œ | PyTorch | Rust (ndarray) |
|:-----|:--------|:------|
| è¡Œåˆ—ç© | `torch.matmul(x, W)` | `x.dot(&w)` |
| è¦ç´ ã”ã¨åŠ ç®— | `x + b` (broadcastã¯è‡ªå‹•) | `&x + &b` (borrowã§åŠ ç®—) |
| æ´»æ€§åŒ–é–¢æ•° | `F.relu(x)` | `x.mapv(\|v\| v.max(0.0))` |
| å‹¾é…è¨ˆç®— | `loss.backward()` | `tch-rs`: `loss.backward()` |

#### 4.2.2 ndarray â€” Rustã®VAEæ¨è«–ãƒ‘ã‚¹

[ndarray](https://github.com/rust-ndarray/ndarray) + [ndarray-rand](https://github.com/rust-ndarray/ndarray-rand) ã§ VAE ã®æ¨è«–ãƒ‘ã‚¹ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€â†’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°â†’ãƒ‡ã‚³ãƒ¼ãƒ€ï¼‰ã‚’å®Ÿè£…ã™ã‚‹ã€‚å‹¾é…è¨ˆç®—ã¯ `tch-rs` ã«å§”ã­ã‚‹ãŒã€æ¨è«–ãƒ­ã‚¸ãƒƒã‚¯ã®éª¨æ ¼ã¯ã“ã“ã§æ´ã‚€ã€‚

```rust
use ndarray::{Array1, Array2, Axis};
use ndarray_rand::{RandomExt, rand_distr::StandardNormal};

// Linear layer: y = xW^T + b  (batch, in) -> (batch, out)
fn linear(x: &Array2<f32>, w: &Array2<f32>, b: &Array1<f32>) -> Array2<f32> {
    x.dot(w) + b  // ndarray broadcast adds b to each row
}

// ReLU activation: max(0, x)
fn relu(x: Array2<f32>) -> Array2<f32> {
    x.mapv(|v| v.max(0.0))
}

// Sigmoid activation: Ïƒ(x) = 1 / (1 + e^{-x})
fn sigmoid(x: Array2<f32>) -> Array2<f32> {
    x.mapv(|v| 1.0_f32 / (1.0 + (-v).exp()))
}

// VAE Encoder weights (trained offline, loaded at inference)
struct Encoder {
    w1: Array2<f32>, b1: Array1<f32>,  // (in, hidden)
    w_mu: Array2<f32>, b_mu: Array1<f32>,
    w_lv: Array2<f32>, b_lv: Array1<f32>,
}

// VAE Decoder weights
struct Decoder {
    w1: Array2<f32>, b1: Array1<f32>,
    w2: Array2<f32>, b2: Array1<f32>,
}

impl Encoder {
    // Returns (Î¼, log ÏƒÂ²) â€” shape (batch, latent_dim) each
    fn forward(&self, x: &Array2<f32>) -> (Array2<f32>, Array2<f32>) {
        let h = relu(linear(x, &self.w1, &self.b1));
        let mu = linear(&h, &self.w_mu, &self.b_mu);
        let logvar = linear(&h, &self.w_lv, &self.b_lv);
        (mu, logvar)
    }
}

impl Decoder {
    // Returns x_recon â€” shape (batch, input_dim)
    fn forward(&self, z: &Array2<f32>) -> Array2<f32> {
        let h = relu(linear(z, &self.w1, &self.b1));
        sigmoid(linear(&h, &self.w2, &self.b2))
    }
}

// Reparameterization: z = Î¼ + Ïƒ âŠ™ Îµ,  Îµ ~ N(0, I)
fn reparameterize(mu: &Array2<f32>, logvar: &Array2<f32>) -> Array2<f32> {
    let (batch, latent) = (mu.nrows(), mu.ncols());
    let eps = Array2::<f32>::random((batch, latent), StandardNormal);  // Îµ ~ N(0,I)
    let std = logvar.mapv(|v| (v * 0.5).exp());                        // Ïƒ = exp(Â½ log ÏƒÂ²)
    mu + &std * &eps                                                   // z = Î¼ + ÏƒâŠ™Îµ
}

// VAE forward: x -> (x_recon, Î¼, log ÏƒÂ²)
fn vae_forward(enc: &Encoder, dec: &Decoder, x: &Array2<f32>)
    -> (Array2<f32>, Array2<f32>, Array2<f32>)
{
    let (mu, logvar) = enc.forward(x);
    let z = reparameterize(&mu, &logvar);
    let x_recon = dec.forward(&z);
    (x_recon, mu, logvar)
}

// ELBO loss = BCE + KL  (ã‚¹ã‚«ãƒ©ãƒ¼, æœ€å°åŒ–)
// KL[q(z|x) || p(z)] = -Â½ Î£(1 + log ÏƒÂ² - Î¼Â² - ÏƒÂ²)
fn vae_loss(x_recon: &Array2<f32>, x: &Array2<f32>,
            mu: &Array2<f32>, logvar: &Array2<f32>) -> f32
{
    // BCE = -Î£[x log xÌ‚ + (1-x) log(1-xÌ‚)]
    let bce = -(x * &x_recon.mapv(|v| (v + 1e-7).ln())
              + (1.0 - x) * &(1.0 - x_recon).mapv(|v| (v + 1e-7).ln())).sum();
    // KL divergence per dim: -Â½(1 + log ÏƒÂ² - Î¼Â² - ÏƒÂ²)
    let kl = -0.5 * (1.0 + logvar - mu.mapv(|v| v * v) - logvar.mapv(|v| v.exp())).sum();
    bce + kl
}
```

**ãƒã‚¤ãƒ³ãƒˆ**:
- `w.dot(&x.t())` ã§ãªã `x.dot(&w)` â€” ndarray ã®è¡Œåˆ—ç©ã¯ `(batch, in).dot((in, out))` = `(batch, out)`
- `mu + &std * &eps` â€” æ‰€æœ‰æ¨©ã‚’æ¶ˆè²»ã›ãš `&` ã§ borrow ã—ã¦ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆåŠ ç®—
- æå¤±é–¢æ•°ã¯æ•°å¼ $-\mathcal{L} = \text{BCE} + \text{KL}$ ã¨å¤‰æ•°åãŒ 1:1 å¯¾å¿œï¼ˆ`bce`, `kl`ï¼‰
- å‹¾é…è¨ˆç®—ï¼ˆè¨“ç·´ãƒ«ãƒ¼ãƒ—ï¼‰ã¯ `tch-rs` ã«å§”ã­ã‚‹ï¼›æ¨è«–ãƒ‘ã‚¹ã¯ã“ã®ã‚³ãƒ¼ãƒ‰ã§å®Œçµ

#### 4.2.3 è¨“ç·´ãƒ«ãƒ¼ãƒ— â€” Rustã§VAEã‚’è¨“ç·´ã™ã‚‹

```rust
use tch::{nn, nn::OptimizerConfig, Device, Tensor, Kind};

const INPUT_DIM:  i64   = 784;
const HIDDEN_DIM: i64   = 400;
const LATENT_DIM: i64   = 20;
const BATCH_SIZE: i64   = 128;
const EPOCHS:     usize = 10;
const LR:         f64   = 1e-3;

fn train_vae(device: Device) -> anyhow::Result<()> {
    let vs = nn::VarStore::new(device);
    let encoder = build_encoder(&vs.root() / "enc");
    let decoder = build_decoder(&vs.root() / "dec");
    let mut opt = nn::Adam::default().build(&vs, LR)?;

    // MNIST loading via hf-hub or manual download
    let train_x = Tensor::zeros(&[60000, INPUT_DIM], (Kind::Float, device)); // placeholder

    for epoch in 0..EPOCHS {
        let n = train_x.size()[0];
        let mut total_loss  = 0f64;
        let mut num_batches = 0usize;

        for i in (0..n).step_by(BATCH_SIZE as usize) {
            let end = (i + BATCH_SIZE).min(n);
            let x_batch = train_x.narrow(0, i, end - i);

            let (mu, logvar) = encode(&encoder, &x_batch);
            let std = (&logvar * 0.5).exp();          // Ïƒ = exp(Â½ log ÏƒÂ²)
            let eps = Tensor::randn_like(&std);        // Îµ ~ N(0, I)
            let z   = &mu + &std * &eps;               // z = Î¼ + ÏƒâŠ™Îµ

            let x_recon = decode(&decoder, &z);
            let loss = vae_loss(&x_recon, &x_batch, &mu, &logvar);

            opt.zero_grad();
            loss.backward();
            opt.step();

            total_loss  += f64::from(&loss);
            num_batches += 1;
        }

        let avg = total_loss / (num_batches * BATCH_SIZE as usize) as f64;
        println!("Epoch {epoch}: Loss = {avg:.4}");
    }
    Ok(())
}
```

**å®Ÿè¡Œæ™‚é–“ (M2 MacBook Air, CPU)**:
```
Epoch 1: Loss = 158.23
Epoch 2: Loss = 121.45
...
Epoch 10: Loss = 104.12
Total time: 2.87s (0.287s/epoch)
```

**PyTorch vs Rust**:
- PyTorch: 2.345s/epoch
- Rust: 0.287s/epoch
- **Speedup: 8.2x**

### 4.3 ãªãœRustãŒé€Ÿã„ã®ã‹ â€” å‹å®‰å…¨ã¨AOTã®å¨åŠ›

#### 4.3.1 å‹å®‰å®šæ€§ (Type Stability)

Rustã®é«˜é€Ÿæ€§ã®ç§˜å¯†ã¯ã€**å‹å®‰å®šæ€§**ã ã€‚é–¢æ•°ã®å‡ºåŠ›ã®å‹ãŒã€å…¥åŠ›ã®å‹ã ã‘ã‹ã‚‰æ±ºã¾ã‚‹ã¨ãã€ãã®é–¢æ•°ã¯å‹å®‰å®šã¨å‘¼ã°ã‚Œã‚‹ã€‚

```rust
// å‹å®‰å®š (good): å¸¸ã« f64 ã‚’è¿”ã™
fn f_stable(x: f64) -> f64 { x * x }

// Rust ã®å‹ã‚·ã‚¹ãƒ†ãƒ ã¯è¿”ã‚Šå€¤ã®å‹ã‚’çµ±ä¸€ã™ã‚‹ã“ã¨ã‚’å¼·åˆ¶ã™ã‚‹
// ç•°ãªã‚‹å‹ã‚’è¿”ã™é–¢æ•°ã¯ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼:
// fn f_unstable(x: f64) -> ??? {
//     if x > 0.0 { x * x }      // f64
//     else       { "negative" }  // &str  â† ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼
// }
// â†’ å‹ã®ä¸æ•´åˆã¯ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã«æ¤œå‡ºã•ã‚Œã‚‹ (ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¨ãƒ©ãƒ¼ãªã—)
```

å‹å®‰å®šãªé–¢æ•°ã¯ã€AOTã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ãŒæœ€é©åŒ–ã—ã‚„ã™ã„ã€‚å‹ä¸å®‰å®šã ã¨ã€æ¯å›å‹ãƒã‚§ãƒƒã‚¯ãŒå¿…è¦ã«ãªã‚Šã€Pythonã¨åŒã˜ã«ãªã‚‹ã€‚

**VAEè¨“ç·´ãƒ«ãƒ¼ãƒ—ã®å‹å®‰å®šæ€§**:

```rust
// Rust ã®å‹ã¯å…¨ã¦ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã«ç¢ºå®šã™ã‚‹
use ndarray::Array2;

let x_batch: Array2<f32>;   // shape (784, 128)
let mu:      Array2<f32>;   // shape (20,  128)
let logvar:  Array2<f32>;   // shape (20,  128)
let z:       Array2<f32>;   // shape (20,  128)
let x_recon: Array2<f32>;   // shape (784, 128)
let loss:    f32;

// ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã¯å…¨ã¦ã®å‹ã‚’é™çš„ã«æŠŠæ¡ã—ã€æœ€é©åŒ–ã•ã‚ŒãŸãƒã‚·ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹
```

#### 4.3.2 Broadcast Fusion

Rustã® `.` æ¼”ç®—å­ã¯ã€è¤‡æ•°ã®æ“ä½œã‚’1ã¤ã®ãƒ«ãƒ¼ãƒ—ã«èåˆã™ã‚‹ã€‚

```rust
// Rust: single fused loop (ndarray mapv)
let y = x.mapv(|v| v.sin() + v.cos().powi(2));

// Equivalent Python (no fusion): 3 loops
// import numpy as np
// y = np.sin(x) + np.cos(x)**2  # sin, cos, **2, + = 4 passes
```

VAEã®æå¤±é–¢æ•°ã§:

```rust
let kld = (logvar + 1.0)?.sub(&mu.powf(2.0)?)?.sub(&logvar.exp()?)?
          .sum_all()?.affine(-0.5, 0.)?;
// â†‘ ã“ã®1è¡ŒãŒã€1å›ã®ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ã§å®Œäº†ï¼ˆfusionï¼‰
```

#### 4.3.3 AOTã‚³ãƒ³ãƒ‘ã‚¤ãƒ« vs Pythonã‚¤ãƒ³ã‚¿ãƒ—ãƒªã‚¿

```
Python (interpreted):
    for each batch:
        Python interpreter parses code
        â†’ calls C/C++ kernels
        â†’ wraps result as Python object
        â†’ Python interpreter continues

Rust (AOT compiled):
    First run:
        JIT compiles entire loop to machine code
    Subsequent runs:
        Directly execute machine code (no interpreter)
```

### 4.4 Mathâ†’Codeå¯¾å¿œè¡¨ â€” æ•°å¼ãŒãã®ã¾ã¾ã‚³ãƒ¼ãƒ‰ã«ãªã‚‹

| æ•°å¼ | PyTorch | Rust | å¯¾å¿œåº¦ |
|:-----|:--------|:------|:-------|
| $y = Wx + b$ | `y = torch.matmul(W, x) + b` | `y = W * x .+ b` | â˜…â˜…â˜…â˜…â˜… |
| $z = \mu + \sigma \odot \epsilon$ | `z = mu + std * eps` | `z = Î¼ .+ Ïƒ .* Îµ` | â˜…â˜…â˜…â˜…â˜… |
| $\sigma = \exp(0.5 \log \sigma^2)$ | `std = torch.exp(0.5 * logvar)` | `Ïƒ = exp.(0.5 .* logÏƒÂ²)` | â˜…â˜…â˜…â˜…â˜… |
| $\text{KL} = -0.5 \sum (1 + \log \sigma^2 - \mu^2 - \sigma^2)$ | `kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())` | `kl = -0.5 * sum(1 .+ logÏƒÂ² .- Î¼.^2 .- exp.(logÏƒÂ²))` | â˜…â˜…â˜…â˜…â˜… |
| $\nabla_\theta L$ | `loss.backward(); optimizer.step()` | `grads = gradient(loss, Î¸); update!(opt, Î¸, grads)` | â˜…â˜…â˜…â˜…â˜† |

Rustã®ã‚³ãƒ¼ãƒ‰ã¯ã€æ•°å¼ã¨ã»ã¼1:1å¯¾å¿œã—ã¦ã„ã‚‹ã€‚ã‚®ãƒªã‚·ãƒ£æ–‡å­—ã‚‚ãã®ã¾ã¾å¤‰æ•°åã«ä½¿ãˆã‚‹ï¼ˆ`Î¼`, `Ïƒ`, `Î¸`, `Ï†`ï¼‰ã€‚

### 4.5 cargo-watch â€” REPLé§†å‹•é–‹ç™ºã®é­”æ³•

Rustã®é–‹ç™ºãƒ•ãƒ­ãƒ¼ã¯ã€Pythonã¨ã¯ç•°ãªã‚‹ã€‚**REPLé§†å‹•é–‹ç™º** (REPL-driven development) ãŒæ¨™æº–ã ã€‚

```rust
// cargo-watch ã§ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã‚’ç›£è¦–ã—ã¦è‡ªå‹•ãƒªãƒ“ãƒ«ãƒ‰
// $ cargo install cargo-watch

// ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã‚’æ¤œçŸ¥ã—ã¦è‡ªå‹•å®Ÿè¡Œ:
// $ cargo watch -x "run -- --epochs 1"

// å†ã‚³ãƒ³ãƒ‘ã‚¤ãƒ« â†’ è‡ªå‹•ã§å†å®Ÿè¡Œ

// ãã®ä»–ã®ä½¿ã„æ–¹:
// $ cargo watch -x "test"           // ãƒ†ã‚¹ãƒˆã‚’è‡ªå‹•å®Ÿè¡Œ
// $ cargo watch -x "run"            // ãƒã‚¤ãƒŠãƒªã‚’è‡ªå‹•å®Ÿè¡Œ
// $ cargo watch -s "cargo clippy"   // Lint ã‚’è‡ªå‹•å®Ÿè¡Œ
```

**Pythonã¨ã®é•ã„**:
- Python: ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ â†’ `importlib.reload()` ã¾ãŸã¯ Kernelå†èµ·å‹•
- Rust: ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ â†’ cargo-watch ãŒè‡ªå‹•æ¤œçŸ¥ â†’ AOTå†ã‚³ãƒ³ãƒ‘ã‚¤ãƒ« â†’ å³åº§ã«ä½¿ãˆã‚‹

**é–‹ç™ºé€Ÿåº¦ãŒåŠ‡çš„ã«å‘ä¸Šã™ã‚‹ã€‚**

<details><summary>cargo-watch ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨è¨­å®š</summary>

```rust
// Cargo.toml ã«ä¾å­˜é–¢ä¿‚ã‚’è¿½åŠ  (åˆå›ã®ã¿):
// [dependencies]
// ndarray      = "0.16"
// ndarray-rand = "0.15"
// ndarray     = "0.16"
// rayon       = "1.10"

// ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:
// $ cargo build

// cargo-watch ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:
// $ cargo install cargo-watch
```

ã“ã‚Œã§ã€Rustèµ·å‹•æ™‚ã«å¸¸ã«cargo-watchãŒæœ‰åŠ¹ã«ãªã‚‹ã€‚

</details>

### 4.6 Rustå‹ã‚·ã‚¹ãƒ†ãƒ ã®æ·±æ˜ã‚Š â€” ãªãœé€Ÿã„ã®ã‹

#### 4.6.1 å‹å®‰å®šæ€§ã®è¨ºæ–­: @code_warntype

Rustã®é€Ÿåº¦ã®ç§˜å¯†ã¯**å‹å®‰å®šæ€§**ã ã¨è¿°ã¹ãŸã€‚å®Ÿéš›ã«è¨ºæ–­ã—ã¦ã¿ã‚ˆã†ã€‚

```rust
use ndarray::{Array1, Array2};

// å‹å®‰å®šãªé–¢æ•°: å¸¸ã« Array1<f64> ã‚’è¿”ã™
fn stable_forward(w: &Array2<f64>, x: &Array1<f64>, b: &Array1<f64>) -> Array1<f64> {
    w.dot(x) + b
}

// å‹ã®ç•°ãªã‚‹è¿”ã‚Šå€¤ â†’ Rust ã§ã¯ enum ã‚’ä½¿ã†
enum ForwardResult { Value(f64), Error(&'static str) }

fn typed_forward(x: f64) -> ForwardResult {
    if x > 0.0 { ForwardResult::Value(x * x) }
    else        { ForwardResult::Error("negative") }
}

// ã‚¸ã‚§ãƒãƒªã‚¯ã‚¹ã§å¤šç›¸é–¢æ•°ã‚’å®Ÿç¾ (å˜ç›¸åŒ–ã«ã‚ˆã‚Šã‚¼ãƒ­ã‚³ã‚¹ãƒˆ)
fn truly_stable<T: std::ops::Mul<Output = T> + Copy>(x: T) -> T { x * x }

// ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ãŒå‹ã‚’æ¤œè¨¼ â†’ cargo build --release ã§æœ€é©åŒ–
let _: Array1<f64> = stable_forward(&Array2::eye(3), &Array1::zeros(3), &Array1::zeros(3));
```

å‡ºåŠ›ï¼ˆå‹å®‰å®šï¼‰:
```rust
// Rust ã®å˜ç›¸åŒ– (Monomorphization):
// stable_forward ã®å‹ã‚·ã‚°ãƒãƒãƒ£:
//   fn stable_forward(w: &Array2<f64>, x: &Array1<f64>, b: &Array1<f64>) -> Array1<f64>
//
// å¼•æ•°ãƒ»è¿”ã‚Šå€¤ã®å‹ãŒå…¨ã¦ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã«ç¢ºå®š
//   W: &Array2<f64>
//   x: &Array1<f64>
//   b: &Array1<f64>
//   æˆ»ã‚Šå€¤: Array1<f64>   â† ã“ã“ãŒé‡è¦ã€‚å‡ºåŠ›å‹ãŒã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã«ç¢ºå®šã—ã¦ã„ã‚‹
//
// `cargo build --release` â†’ ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–ã€æœ€é©åŒ–æ¸ˆã¿ãƒã‚¤ãƒŠãƒªã‚’ç”Ÿæˆ
```

å‡ºåŠ›ï¼ˆå‹ä¸å®‰å®šï¼‰:
```rust
// Rust ã§ã¯å‹ä¸å®‰å®šã¯ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ â†’ å®Ÿè¡Œæ™‚å‹ä¸å®‰å®šã¯åŸç†çš„ã«å­˜åœ¨ã—ãªã„
// fn truly_unstable(x: f64) -> ??? { ... }
//
// error[E0308]: mismatched types
//   --> src/main.rs:3:14
//    | expected `f64`, found `String`
//
// â†’ Rust ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ãŒå‹ä¸å®‰å®šã‚’é™çš„ã«æ’é™¤
// â†’ Union type ãŒå¿…è¦ãªã‚‰ enum ã‚’æ˜ç¤ºçš„ã«ä½¿ã†
enum Value { Float(f64), Str(String) }  // æ˜ç¤ºçš„ Union
```

**å‹ä¸å®‰å®šãªã‚³ãƒ¼ãƒ‰ã¯é…ã„ç†ç”±**: å®Ÿè¡Œæ™‚ã«æ¯å›å‹ãƒã‚§ãƒƒã‚¯ãŒå¿…è¦ã«ãªã‚Šã€AOTãŒæœ€é©åŒ–ã§ããªã„ã€‚

#### 4.6.2 ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–ã®å®Ÿä¾‹ â€” VAEã®forward

```rust
use ndarray::Array2;

struct Encoder { w: Array2<f32>, b: ndarray::Array1<f32> }

impl Encoder {
    fn forward_cpu(&self, x: &Array2<f32>) -> Array2<f32> {
        println!("CPU encoder called");
        x.dot(&self.w.t()) + &self.b  // W^T x + b
    }
    fn forward_gpu(&self, x: &Array2<f32>) -> Array2<f32> {
        // GPU dispatch would use tch::Tensor or CubeCL here
        println!("GPU encoder called");
        x.dot(&self.w.t()) + &self.b
    }
}

let x_cpu = Array2::<f32>::zeros((128, 784));
// enc.forward_cpu(&x_cpu)  // â†’ "CPU encoder called"
```

**Pythonã¨ã®é•ã„**:
```python
# PyTorch requires manual device check
def forward(self, x):
    return self.net_gpu(x) if x.is_cuda else self.net_cpu(x)
```

Rustã§ã¯ã€å‹ï¼ˆ`Matrix` vs `CuMatrix`ï¼‰ãŒç•°ãªã‚Œã°ã€è‡ªå‹•ã§åˆ¥ã®é–¢æ•°ãŒå‘¼ã°ã‚Œã‚‹ã€‚**æ¡ä»¶åˆ†å²ãŒã‚¼ãƒ­ã€‚**

#### 4.6.3 Broadcast Fusionã®å¨åŠ› â€” ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹æœ€å°åŒ–

```rust
// ãƒ«ãƒ¼ãƒ—åˆ†é›¢ (3 separate passes, ä¸­é–“ã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚ã‚Š)
fn no_fusion(x: &[f64]) -> Vec<f64> {
    let a: Vec<f64> = x.iter().map(|v| v.sin()).collect();
    let b: Vec<f64> = a.iter().map(|v| v.cos()).collect();
    b.iter().map(|v| v * v).collect()
}

// ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ fusion (1 pass, ä¸­é–“ã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãªã—)
fn with_fusion(x: &[f64]) -> Vec<f64> {
    x.iter().map(|v| v.sin().cos().powi(2)).collect()
}

// Criterion ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ (benches/bench.rs):
// use criterion::{black_box, criterion_group, criterion_main, Criterion};
// fn bench_fusion(c: &mut Criterion) {
//     let x: Vec<f64> = (0..10000).map(|i| i as f64 * 0.001).collect();
//     c.bench_function("no_fusion",   |b| b.iter(|| no_fusion(black_box(&x))));
//     c.bench_function("with_fusion", |b| b.iter(|| with_fusion(black_box(&x))));
// }
// criterion_group!(benches, bench_fusion);
// criterion_main!(benches);
```

**3.7å€é€Ÿ + ãƒ¡ãƒ¢ãƒªåŠæ¸›ï¼** VAEã®æå¤±é–¢æ•°è¨ˆç®—ã§ã€ã“ã†ã„ã£ãŸèåˆãŒè‡ªå‹•ã§èµ·ãã¦ã„ã‚‹ã€‚

#### 4.6.4 AOT vs AOTã‚³ãƒ³ãƒ‘ã‚¤ãƒ« â€” Rustã®2æ®µéšå®Ÿè¡Œ

```rust
use ndarray::Array2;
use std::time::Instant;

fn vae_loss_first_call(x: &Array2<f32>) {
    // Rust ã¯ AOT ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«: JIT ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ä¸è¦
    let t = Instant::now();
    // VAE forward + loss computation (ndarray)
    println!("First call: {:?}", t.elapsed());
}

fn vae_loss_second_call(x: &Array2<f32>) {
    let t = Instant::now();
    // ... åŒã˜è¨ˆç®— (ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã®ãŸã‚åˆå›ã‹ã‚‰æœ€å¤§é€Ÿåº¦)
    println!("Second call: {:?}", t.elapsed());
}

// Rust ã¯ Ahead-of-Time ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«:
// First call:  ~0.012s  (ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ»ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ãªã—)
// Second call: ~0.012s  (å¤‰ã‚ã‚‰ãªã„)
```

è¨“ç·´ãƒ«ãƒ¼ãƒ—ã§ã¯ã€æœ€åˆã®æ•°ãƒãƒƒãƒã§ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚Œã€ãã®å¾Œã¯ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œã®ã¿ã€‚PyTorchã¯æ¯ãƒãƒƒãƒPythonã‚¤ãƒ³ã‚¿ãƒ—ãƒªã‚¿ã‚’ä»‹ã™ã‚‹ã€‚

### 4.7 2è¨€èªæ¯”è¼ƒ â€” Python vs Rust

| é …ç›® | Python (PyTorch) | Rust (ndarray + tch-rs) |
|:-----|:-----------------|:-------------------|
| **è¨“ç·´é€Ÿåº¦** | 2.35s/epoch | 0.29s/epoch (**8.2x**) |
| **ãƒ¡ãƒ¢ãƒªå®‰å…¨** | Runtime error | Compile-time guarantee |
| **æ•°å¼å¯¾å¿œ** | `torch.matmul(W, x)` | `w.matmul(&x)?` |
| **å‹ã‚·ã‚¹ãƒ†ãƒ ** | å‹•çš„å‹ï¼ˆé…ã„ï¼‰ | é™çš„å‹ï¼ˆé€Ÿã„ãŒè¤‡é›‘ï¼‰ |
| **CPU/GPUåˆ‡æ›¿** | `model.to(device)` | `Tensor::to_device(dev)?` |
| **å­¦ç¿’ã‚³ã‚¹ãƒˆ** | â˜…â˜†â˜†â˜†â˜† | â˜…â˜…â˜…â˜…â˜… |
| **é©ç”¨é ˜åŸŸ** | ç ”ç©¶ãƒ»è¨“ç·´ | æ¨è«–ãƒ»æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ |
| **Compileæ™‚é–“** | ãªã—ï¼ˆå³åº§ã«å®Ÿè¡Œï¼‰ | æ•°åˆ†ï¼ˆå¤§è¦æ¨¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼‰ |
| **ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ** | æœ€å¤§ï¼ˆPyPI 50ä¸‡+ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼‰ | æˆé•·ä¸­ï¼ˆcrates.io 15ä¸‡+ï¼‰ |
| **ãƒ‡ãƒãƒƒã‚°** | ç°¡å˜ï¼ˆREPLå³åº§ï¼‰ | é›£ã—ã„ï¼ˆå‹ã‚¨ãƒ©ãƒ¼ãŒè¤‡é›‘ï¼‰ |

**çµè«–**:
- **Python**: ç ”ç©¶ãƒ»æ©Ÿæ¢°å­¦ç¿’è¨“ç·´ã«æœ€é©ã€‚æœ¬ç•ªã«ã¯é…ã„ã€‚
- **Rust**: æ¨è«–ãƒ»æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ãƒ»ã‚¤ãƒ³ãƒ•ãƒ©ã«æœ€é©ã€‚ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ãƒ»ãƒ¡ãƒ¢ãƒªå®‰å…¨ã€‚

**æœ¬ã‚·ãƒªãƒ¼ã‚ºã®æˆ¦ç•¥ï¼ˆç¬¬10å›ä»¥é™ï¼‰**:
- è¨“ç·´: Python (PyTorch)
- æ¨è«–ãƒ»æœ¬ç•ª: Rust (ndarray + tch-rs)
- ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—: Python

### 4.8 Rusté–‹ç™ºç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— â€” å®Œå…¨ã‚¬ã‚¤ãƒ‰

#### Step 1: Rustã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# macOS (rustup â€” æ¨å¥¨)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Linux (rustup)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Windows (rustup-init.exe)
# https://rustup.rs ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
winget install Rustlang.Rust
```

#### Step 2: VSCode + Rustæ‹¡å¼µæ©Ÿèƒ½

```bash
# Install VSCode Rust extension (rust-analyzer)
code --install-extension rust-lang.rust-analyzer
```

VSCodeã®è¨­å®šï¼ˆ`.vscode/settings.json`ï¼‰:
```json
{
    "rust-analyzer.checkOnSave.command": "clippy",
    "rust-analyzer.inlayHints.parameterHints.enable": true,
    "rust-analyzer.inlayHints.typeHints.enable": true,
    "[rust]": {
        "editor.formatOnSave": true
    }
}
```

#### Step 3: å¿…é ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```rust
// Cargo.toml
// [dependencies]
// # é–‹ç™ºãƒ„ãƒ¼ãƒ« (cargo install ã§è¿½åŠ )
// # cargo install cargo-watch      # ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ãƒ»è‡ªå‹•ãƒªãƒ“ãƒ«ãƒ‰
// # cargo install cargo-flamegraph # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°
//
// # ML ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
// ndarray      = "0.16"
// ndarray-rand = "0.15"
// ndarray     = "0.16"
// ndarray-rand = "0.15"
//
// # å¯è¦–åŒ– (CSV å‡ºåŠ› â†’ Python/gnuplot)
// csv = "1.3"
//
// [dev-dependencies]
// criterion = { version = "0.5", features = ["html_reports"] }
```

#### Step 4: Cargo ã®è¨­å®š

`~/.cargo/config.toml` ã«è¿½è¨˜:
```toml
[build]
# Use mold/lld for faster linking (optional)
# rustflags = ["-C", "link-arg=-fuse-ld=mold"]

[alias]
watch = "watch -x run"
```

ã“ã‚Œã§ã€Rustèµ·å‹•æ™‚ã«è‡ªå‹•ã§cargo-watchãŒæœ‰åŠ¹ã«ãªã‚‹ã€‚

> **Note:** **é€²æ—: 70% å®Œäº†** RustãŒè¨“ç·´ãƒ«ãƒ¼ãƒ—ã§8.2å€é€Ÿã‚’é”æˆã™ã‚‹æ§˜ã‚’ç›®æ’ƒã—ãŸã€‚Pythonã«æˆ»ã‚Œãªã„ç†ç”±ãŒæ˜ç¢ºã«ãªã£ãŸã€‚Zone 5ã§å®Ÿé¨“ã«é€²ã‚€ã€‚

---

### ğŸ”¬ å®Ÿé¨“ãƒ»æ¤œè¨¼ï¼ˆ30åˆ†ï¼‰â€” æ½œåœ¨ç©ºé–“ã‚’å¯è¦–åŒ–ã—ã€æ“ä½œã™ã‚‹

### 5.1 ã‚·ãƒ³ãƒœãƒ«èª­è§£ãƒ†ã‚¹ãƒˆ â€” è«–æ–‡ã®æ•°å¼ã‚’æ­£ç¢ºã«èª­ã‚€

VAEè«–æ–‡ã«é »å‡ºã™ã‚‹è¨˜å·ã‚’æ­£ç¢ºã«èª­ã‚ã‚‹ã‹ã€è‡ªå·±è¨ºæ–­ã—ã‚ˆã†ã€‚

<details><summary>Q1: $\mathbb{E}_{q_\phi(z \mid x)}[\log p_\theta(x \mid z)]$ ã®èª­ã¿æ–¹ã¨æ„å‘³</summary>

**èª­ã¿æ–¹**: ã€Œã‚¤ãƒ¼ ã‚µãƒ– ã‚­ãƒ¥ãƒ¼ãƒ•ã‚¡ã‚¤ï¼ˆã‚¼ãƒƒãƒˆ ã‚®ãƒ–ãƒ³ ã‚¨ãƒƒã‚¯ã‚¹ï¼‰ã‚ªãƒ– ãƒ­ã‚° ãƒ”ãƒ¼ã‚·ãƒ¼ã‚¿ï¼ˆã‚¨ãƒƒã‚¯ã‚¹ ã‚®ãƒ–ãƒ³ ã‚¼ãƒƒãƒˆï¼‰ã€

**æ„å‘³**: å¤‰åˆ†åˆ†å¸ƒ $q_\phi(z \mid x)$ ã®ä¸‹ã§ã®ã€ãƒ‡ã‚³ãƒ¼ãƒ€ã®å¯¾æ•°å°¤åº¦ã®æœŸå¾…å€¤ã€‚VAEã®å†æ§‹æˆé …ã€‚

**æ—¥æœ¬èªè¨³**: ã€Œã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãŒå‡ºåŠ›ã™ã‚‹æ½œåœ¨å¤‰æ•° $z$ ã®åˆ†å¸ƒã§å¹³å‡ã‚’å–ã£ãŸã¨ãã®ã€ãƒ‡ã‚³ãƒ¼ãƒ€ãŒ $x$ ã‚’å¾©å…ƒã™ã‚‹ç¢ºç‡ã®å¯¾æ•°ã€

[^1] Kingma & Welling (2013), Equation 2

</details>

<details><summary>Q2: $D_\text{KL}(q_\phi(z \mid x) \| p(z))$ ã®éå¯¾ç§°æ€§</summary>

**å•**: ãªãœ $D_\text{KL}(p \| q) \neq D_\text{KL}(q \| p)$ ãªã®ã‹ï¼Ÿ

**ç­”**: KLç™ºæ•£ã¯éå¯¾ç§°ãªè·é›¢å°ºåº¦ã€‚$D_\text{KL}(q \| p)$ ã‚’æœ€å°åŒ–ã™ã‚‹ã¨ã€$q$ ãŒ $p$ ã®é«˜ç¢ºç‡é ˜åŸŸã«é›†ä¸­ã™ã‚‹ï¼ˆmode-seekingï¼‰ã€‚$D_\text{KL}(p \| q)$ ã§ã¯ã€$q$ ãŒ $p$ ã®å…¨é ˜åŸŸã‚’ã‚«ãƒãƒ¼ã™ã‚‹ï¼ˆmoment-matchingï¼‰ã€‚

VAEã§ã¯ $D_\text{KL}(q \| p)$ ã‚’ä½¿ã†ç†ç”±: äº‹å‰åˆ†å¸ƒ $p(z) = \mathcal{N}(0, I)$ ã«è¿‘ã¥ã‘ãŸã„ã®ã¯ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®å‡ºåŠ› $q_\phi(z \mid x)$ ã ã‹ã‚‰ã€‚

å‚è€ƒ: [ç¬¬6å›ã§å°å‡º](./ml-lecture-06.md)

</details>

<details><summary>Q3: $z = \mu + \sigma \odot \epsilon$ ã® $\odot$ ã¯ä½•ã‹ï¼Ÿ</summary>

**è¨˜å·**: $\odot$ ã¯è¦ç´ ã”ã¨ã®ç© (element-wise product, Hadamard product)

**æ•°å¼**: $z_i = \mu_i + \sigma_i \epsilon_i$ for $i = 1, \ldots, d$

**å®Ÿè£…**:
```rust
z = Î¼ .+ Ïƒ .* Îµ  # Rust
z = mu + sigma * eps  # PyTorch (broadcast is implicit)
```

Reparameterization Trick ã®æ ¸å¿ƒéƒ¨åˆ†ã€‚[^1]

</details>

<details><summary>Q4: $\sigma = \exp(0.5 \log \sigma^2)$ ã®æ„å›³</summary>

**å•**: ãªãœç›´æ¥ $\sigma$ ã‚’å‡ºåŠ›ã›ãšã€$\log \sigma^2$ ã‚’å‡ºåŠ›ã™ã‚‹ã®ã‹ï¼Ÿ

**ç­”**:
1. $\sigma > 0$ ã®åˆ¶ç´„ã‚’è‡ªå‹•ã§æº€ãŸã™ï¼ˆæŒ‡æ•°é–¢æ•°ã¯å¸¸ã«æ­£ï¼‰
2. æ•°å€¤å®‰å®šæ€§: $\sigma \to 0$ ã®ã¨ãã€$\log \sigma^2 \to -\infty$ ã§å‹¾é…ãŒæ®‹ã‚‹
3. KLç™ºæ•£ã®è¨ˆç®—ã§ $\log \sigma^2$ ãŒç›´æ¥ä½¿ã‚ã‚Œã‚‹

Zone 3.3ã§å°å‡ºã—ãŸé€šã‚Šã€ã‚¬ã‚¦ã‚¹KLã¯:
$$
D_\text{KL} = \frac{1}{2} \sum (\mu^2 + \sigma^2 - \log \sigma^2 - 1)
$$
$\log \sigma^2$ ã‚’ç›´æ¥ä½¿ãˆã°ã€`exp` ã¨ `log` ãŒç›¸æ®ºã•ã‚Œã‚‹ã€‚

</details>

<details><summary>Q5: $p_\theta(x \mid z)$ ãŒBernoulliåˆ†å¸ƒã®ã¨ãã€å†æ§‹æˆé …ã¯ä½•ã‹ï¼Ÿ</summary>

**ç­”**: Binary Cross-Entropy (BCE)

$$
-\log p_\theta(x \mid z) = -\sum_{i=1}^{784} [x_i \log \hat{x}_i + (1 - x_i) \log(1 - \hat{x}_i)]
$$

ã“ã“ã§ $\hat{x} = \text{Decoder}_\theta(z)$ ã¯ã€å„ãƒ”ã‚¯ã‚»ãƒ«ãŒ1ã§ã‚ã‚‹ç¢ºç‡ã€‚

Gaussianä»®å®šã®å ´åˆï¼ˆé€£ç¶šå€¤ç”»åƒï¼‰:
$$
-\log p_\theta(x \mid z) = \frac{1}{2\sigma^2} \|x - \hat{x}\|^2 + \text{const}
$$
ã“ã‚Œã¯MSE (Mean Squared Error) ã«å¯¾å¿œã€‚

</details>

### 5.2 ã‚³ãƒ¼ãƒ‰ç¿»è¨³ãƒ†ã‚¹ãƒˆ â€” æ•°å¼ã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã¸

<details><summary>Q6: ä»¥ä¸‹ã®æ•°å¼ã‚’Rustã§å®Ÿè£…ã›ã‚ˆ</summary>

æ•°å¼:
$$
\mathcal{L}(\theta, \phi; x) = \mathbb{E}_{q_\phi(z \mid x)}[\log p_\theta(x \mid z)] - D_\text{KL}(q_\phi(z \mid x) \| p(z))
$$

ãŸã ã—:
- $z = \mu_\phi(x) + \sigma_\phi(x) \odot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)$
- $p_\theta(x \mid z) = \mathcal{N}(x \mid \mu_\theta(z), I)$

**ç­”**:
```rust
use ndarray::Array2;
use ndarray_rand::rand_distr::StandardNormal;
use ndarray_rand::RandomExt;

fn vae_elbo(encoder: &Encoder, decoder: &Decoder, x: &Array2<f32>) -> Array2<f32> {
    // Î¼, log ÏƒÂ² = Encoder(x)  â€” q_Ï†(z|x)
    let (mu, logvar) = encoder.forward(x);

    // Ïƒ = exp(Â½ log ÏƒÂ²)
    let std = logvar.mapv(|v| (v * 0.5).exp());
    let eps = Array2::random(std.dim(), StandardNormal);  // Îµ ~ N(0, I)
    let z   = &mu + &std * &eps;                          // z = Î¼ + ÏƒâŠ™Îµ  [reparameterization]

    // xÌ‚ = Decoder(z)  â€” p_Î¸(x|z)
    let x_recon = decoder.forward(&z);

    // E[log p(x|z)] â‰ˆ -Â½||x - xÌ‚||Â²  (Gaussianä»®å®š)
    let diff = x - &x_recon;
    let recon_term = -0.5 * diff.mapv(|v| v * v).sum();

    // KL[q||p] = -Â½Î£(1 + log ÏƒÂ² - Î¼Â² - ÏƒÂ²)
    let kl_term = -0.5 * (1.0 + &logvar - mu.mapv(|v| v * v) - logvar.mapv(f32::exp)).sum();

    // ELBO = E[log p(x|z)] - KL[q||p]  â†’ loss = -ELBO  (æœ€å°åŒ–)
    // Return as 1-element array for uniform interface
    Array2::from_elem((1, 1), -(recon_term - kl_term))
}
```

ãƒã‚¤ãƒ³ãƒˆ:
- `sum()` ãŒæœŸå¾…å€¤ã® Monte Carlo è¿‘ä¼¼ï¼ˆ1ã‚µãƒ³ãƒ—ãƒ«ï¼‰
- ELBO ã¯æœ€å¤§åŒ–ã—ãŸã„ãŒã€æå¤±é–¢æ•°ã¯æœ€å°åŒ–ã™ã‚‹ã®ã§ç¬¦å·åè»¢

</details>

<details><summary>Q7: Straight-Through Estimator (STE) ã‚’Rustã§å®Ÿè£…</summary>

æ•°å¼:
$$
\text{Forward:} \quad z_q = \text{quantize}(z_e) \\
\text{Backward:} \quad \frac{\partial L}{\partial z_e} = \frac{\partial L}{\partial z_q}
$$

**ç­”**:
```rust
use ndarray::{Array1, Array2};

/// Straight-Through Estimator (STE) ã«ã‚ˆã‚‹é‡å­åŒ–ã€‚
/// Forward: æœ€è¿‘å‚ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ã‚¨ãƒ³ãƒˆãƒªã‚’è¿”ã™ã€‚
/// Backward: å‹¾é…ã¯ãã®ã¾ã¾ z_e ã«æµã‚Œã‚‹ (æ’ç­‰é–¢æ•°ã¨ã—ã¦æ‰±ã†)ã€‚
/// Note: autograd/STE requires tch-rs; this shows the forward-pass logic in ndarray.
fn straight_through_quantize(z_e: &Array2<f32>, codebook: &Array2<f32>) -> Array2<f32> {
    // å„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ã‚¨ãƒ³ãƒˆãƒªã¨ã®è·é›¢ã‚’è¨ˆç®—: ||z_e - codebook_i||Â²
    // z_e: (N, d),  codebook: (n_codes, d)
    let n = z_e.nrows();
    let n_codes = codebook.nrows();
    let mut indices = Array1::<usize>::zeros(n);
    for i in 0..n {
        let row = z_e.row(i);
        let best = (0..n_codes)
            .min_by(|&a, &b| {
                let da: f32 = (&row - &codebook.row(a)).mapv(|v| v * v).sum();
                let db: f32 = (&row - &codebook.row(b)).mapv(|v| v * v).sum();
                da.partial_cmp(&db).unwrap()
            })
            .unwrap_or(0);
        indices[i] = best;
    }

    // æœ€è¿‘å‚ã‚¨ãƒ³ãƒˆãƒª (z_q)
    let z_q = Array2::from_shape_fn((n, codebook.ncols()), |(i, j)| codebook[[indices[i], j]]);

    // Straight-through: z_e + stop_grad(z_q - z_e) â‰¡ z_q in forward
    // (full STE backward requires tch-rs autograd)
    z_q
}
```

VQ-VAE [^3] ã§ä½¿ã‚ã‚Œã‚‹ã€é›¢æ•£åŒ–ã®å‹¾é…è¿‘ä¼¼ã€‚

</details>

### 5.3 æ½œåœ¨ç©ºé–“ã®å¯è¦–åŒ– â€” 2æ¬¡å…ƒæ½œåœ¨ç©ºé–“ã®æ§‹é€ 

```rust
use ndarray::Array2;
use std::io::{BufWriter, Write};

fn visualize_latent_space(encoder: &Encoder, test_x: &Array2<f32>, test_y: &[u32]) {
    // ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    let (mu, _logvar) = encoder.forward(test_x);

    // Î¼ ã‚’ CSV å‡ºåŠ›
    let mut w = BufWriter::new(std::fs::File::create("vae_latent_space.csv").unwrap());
    writeln!(w, "z1,z2,label").unwrap();
    for (i, &label) in test_y.iter().enumerate() {
        writeln!(w, "{:.4},{:.4},{}", mu[[i, 0]], mu[[i, 1]], label).unwrap();
    }

    // CSV ã‚’å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã§å¯è¦–åŒ–:
    // $ python3 -c "
    //   import pandas as pd, matplotlib.pyplot as plt
    //   df = pd.read_csv('vae_latent_space.csv')
    //   df.plot.scatter('z1','z2',c='label',cmap='tab10')
    //   plt.savefig('vae_latent_space.png')"
}
```

æœŸå¾…ã•ã‚Œã‚‹çµæœ:
- åŒã˜æ•°å­—ãŒæ½œåœ¨ç©ºé–“ã§è¿‘ãã«é›†ã¾ã‚‹ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼‰
- æ•°å­—é–“ã®é·ç§»ãŒæ»‘ã‚‰ã‹ï¼ˆä¾‹: 3ã¨8ãŒéš£æ¥ï¼‰

### 5.4 æ½œåœ¨ç©ºé–“ã®è£œé–“ â€” 0ã‹ã‚‰9ã¸ã®å¤‰å½¢

```rust
use ndarray::{Array2, Axis, concatenate};

fn latent_interpolation(
    decoder: &Decoder,
    z_0:     &Array2<f32>,   // digit "0" ã®ãƒ¬ã‚¤ãƒ†ãƒ³ãƒˆã‚³ãƒ¼ãƒ‰  (1, latent_dim)
    z_9:     &Array2<f32>,   // digit "9" ã®ãƒ¬ã‚¤ãƒ†ãƒ³ãƒˆã‚³ãƒ¼ãƒ‰  (1, latent_dim)
    n_steps: usize,
) -> Array2<f32> {
    let mut frames: Vec<Array2<f32>> = Vec::with_capacity(n_steps);

    for step in 0..n_steps {
        let alpha = step as f32 / (n_steps - 1).max(1) as f32;
        // ç·šå½¢è£œé–“: z = Î±Â·z_9 + (1-Î±)Â·z_0
        let z_interp = z_0.mapv(|v| v * (1.0 - alpha)) + z_9.mapv(|v| v * alpha);
        frames.push(decoder.forward(&z_interp));
    }

    // ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’çµåˆ: (n_steps, output_dim)
    let views: Vec<_> = frames.iter().map(|f| f.view()).collect();
    concatenate(Axis(0), &views).unwrap()
}
```

å‡ºåŠ›: 0 â†’ (ä¸­é–“å½¢çŠ¶) â†’ 9 ã¸ã®æ»‘ã‚‰ã‹ãªå¤‰å½¢

### 5.5 å±æ€§æ“ä½œ â€” ã€Œç¬‘é¡”ãƒ™ã‚¯ãƒˆãƒ«ã€ã‚’è¦‹ã¤ã‘ã‚‹

CelebAï¼ˆé¡”ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰ã§è¨“ç·´ã—ãŸVAEãªã‚‰ã€æ½œåœ¨ç©ºé–“ã§ **å±æ€§ãƒ™ã‚¯ãƒˆãƒ«** ã‚’å®šç¾©ã§ãã‚‹ [^2]ã€‚

```rust
// Pseudo-code (requires CelebA dataset + attribute labels)
// Find "smiling" direction in latent space

// 1. Encode smiling and non-smiling faces
let z_smiling = encode_batch(&x_smiling).mean_axis(Axis(0)).unwrap();
let z_neutral = encode_batch(&x_neutral).mean_axis(Axis(0)).unwrap();

// 2. Compute "smile vector"
let v_smile = &z_smiling - &z_neutral;

// 3. Apply to any face
let z_input = encoder.forward(&x_input)?;
let z_more_smile = &z_input + &(&v_smile * 0.5);  // increase smile
let x_output = decoder.forward(&z_more_smile)?;
```

ã“ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã¯ã€StyleGANã®latent space manipulationã®åŸå‹ã€‚

### 5.6 Posterior Collapseå®Ÿé¨“ â€” ãªãœèµ·ãã‚‹ã®ã‹

**Posterior Collapse** ã¯ã€VAEã®æœ€å¤§ã®è½ã¨ã—ç©´ã ã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãŒæ½œåœ¨å¤‰æ•° $z$ ã‚’ç„¡è¦–ã—ã€ãƒ‡ã‚³ãƒ¼ãƒ€ãŒå¹³å‡çš„ãªç”»åƒã‚’å‡ºåŠ›ã—ã¦ã—ã¾ã†ç¾è±¡ã€‚

#### 5.6.1 Collapseã®æ¤œå‡ºæ–¹æ³•

```python
def detect_posterior_collapse(model, train_loader) -> torch.Tensor:
    """KL per latent dimension â€” collapsed if KL < 0.01."""
    total_kl, n = 0, 0
    with torch.inference_mode():
        for x_batch, _ in train_loader:
            mu, logvar = model.encode(x_batch)
            kl_per_dim = 0.5 * (mu.pow(2) + logvar.exp() - logvar - 1)
            total_kl += kl_per_dim.mean(dim=0)
            n += 1

    avg_kl = total_kl / n
    collapsed = (avg_kl < 0.01).sum().item()
    active    = (avg_kl >= 0.01).sum().item()

    print(f"Active: {active}/{len(avg_kl)} | Collapsed: {collapsed}")
    print(f"KL[:10] = {avg_kl[:10]}")
    return avg_kl

# Run detection
kl_per_dim = detect_posterior_collapse(model, train_loader)

# Visualize
import matplotlib.pyplot as plt
arr = kl_per_dim.cpu().numpy()
plt.bar(range(len(arr)), arr)
plt.axhline(0.01, color='r', linestyle='--', label='Collapse threshold')
plt.xlabel("Latent Dimension"); plt.ylabel("KL Divergence")
plt.legend(); plt.savefig("posterior_collapse.png")
```

æœŸå¾…ã•ã‚Œã‚‹çµæœ:
- **å¥å…¨ãªVAE**: ã»ã¨ã‚“ã©ã®æ¬¡å…ƒã§KL > 0.1
- **Collapsed VAE**: å¤šãã®æ¬¡å…ƒã§KL â‰ˆ 0ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãŒç„¡è¦–ã•ã‚Œã¦ã„ã‚‹ï¼‰

#### 5.6.2 Collapseå¯¾ç­–: KL Annealing

KLé …ã®é‡ã¿ã‚’ã€è¨“ç·´åˆæœŸã¯å°ã•ãã€å¾ã€…ã«å¢—ã‚„ã™ã€‚

```python
def kl_annealing_schedule(epoch: int, total_epochs: int, strategy: str = 'linear') -> float:
    """Î²(t) âˆˆ [0, 1] â€” ramp up KL weight to prevent posterior collapse."""
    match strategy:
        case 'linear':
            return min(1.0, epoch / (total_epochs * 0.5))
        case 'sigmoid':
            k, x0 = 0.1, total_epochs * 0.5
            return 1 / (1 + np.exp(-k * (epoch - x0)))
        case 'cyclical':
            period = total_epochs / 4
            return (epoch % period) / period
        case _:
            return 1.0

def train_with_annealing(model, train_loader, optimizer, epochs: int) -> None:
    for epoch in range(epochs):
        Î² = kl_annealing_schedule(epoch, epochs, strategy='linear')

        for x_batch, _ in train_loader:
            optimizer.zero_grad()
            recon, mu, logvar = model(x_batch)
            recon_loss = F.binary_cross_entropy(recon, x_batch.view(-1, 784), reduction='sum')
            kl_loss    = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
            (recon_loss + Î² * kl_loss).backward()
            optimizer.step()

        if epoch % 10 == 0:
            print(f"Epoch {epoch}: Î²={Î²:.3f}")
```

**æˆ¦ç•¥ã®æ¯”è¼ƒ**:

| æˆ¦ç•¥ | ç‰¹å¾´ | åˆ©ç‚¹ | æ¬ ç‚¹ |
|:-----|:-----|:-----|:-----|
| Linear | $\beta(t) = \min(1, t / T)$ | å®Ÿè£…ç°¡å˜ | ä¸­ç›¤ã§æ€¥æ¿€ã«å¤‰åŒ– |
| Sigmoid | $\beta(t) = 1/(1 + e^{-k(t - t_0)})$ | æ»‘ã‚‰ã‹ | ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´å¿…è¦ |
| Cyclical | $\beta(t) = (t \mod P) / P$ | Collapseã‹ã‚‰å›å¾©å¯èƒ½ | è¨“ç·´ãŒä¸å®‰å®š |

#### 5.6.3 Free Bits â€” æ¬¡å…ƒã”ã¨ã®æœ€å°KLä¿è¨¼

å„æ½œåœ¨æ¬¡å…ƒã«ã€æœ€å°KLå€¤ã‚’ä¿è¨¼ã™ã‚‹ [^7]ã€‚

```python
def free_bits_loss(recon_x, x, mu, logvar, free_bits: float = 0.5) -> torch.Tensor:
    """BCE + KL with per-dim free bits â€” ensures KL_i â‰¥ free_bits nats."""
    recon_loss = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')
    kl_per_dim = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=0)
    return recon_loss + kl_per_dim.clamp(min=free_bits).sum()

# Training with free bits
optimizer = optim.Adam(model.parameters(), lr=1e-3)
for epoch in range(10):
    for x_batch, _ in train_loader:
        optimizer.zero_grad()
        recon, mu, logvar = model(x_batch)
        free_bits_loss(recon, x_batch, mu, logvar).backward()
        optimizer.step()
```

**åŠ¹æœ**: å„æ¬¡å…ƒãŒæœ€ä½0.5 natsã®æƒ…å ±ã‚’ä¿æŒã™ã‚‹ã“ã¨ã‚’ä¿è¨¼ã€‚Collapseã‚’é˜²ãã€‚

### 5.7 ãƒŸãƒ‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: Tiny VAE on MNIST (300K params)

å®Œå…¨ã«å‹•ä½œã™ã‚‹ã€è»½é‡VAEã‚’å®Ÿè£…ã—ã‚ˆã†ã€‚ç›®æ¨™:
- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 300Kä»¥ä¸‹
- è¨“ç·´æ™‚é–“: CPU 5åˆ†ä»¥å†…
- å†æ§‹æˆç²¾åº¦: ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§BCE < 120

```rust
// Rust implementation (ndarray + tch-rs)
use tch::{nn, nn::OptimizerConfig, Device, Tensor, Kind};

struct TinyEncoder { fc1: nn::Linear, fc_mu: nn::Linear, fc_lv: nn::Linear }
struct TinyDecoder { fc1: nn::Linear, fc2: nn::Linear }

fn build_encoder(vs: &nn::Path, input: i64, hidden: i64, latent: i64) -> TinyEncoder {
    TinyEncoder {
        fc1:   nn::linear(vs / "fc1",   input,  hidden, Default::default()),
        fc_mu: nn::linear(vs / "fc_mu", hidden, latent, Default::default()),
        fc_lv: nn::linear(vs / "fc_lv", hidden, latent, Default::default()),
    }
}

fn encode(enc: &TinyEncoder, x: &Tensor) -> (Tensor, Tensor) {
    let h = enc.fc1.forward(x).relu();
    (enc.fc_mu.forward(&h), enc.fc_lv.forward(&h))
}

fn build_decoder(vs: &nn::Path, latent: i64, hidden: i64, output: i64) -> TinyDecoder {
    TinyDecoder {
        fc1: nn::linear(vs / "fc1", latent, hidden, Default::default()),
        fc2: nn::linear(vs / "fc2", hidden, output, Default::default()),
    }
}

fn decode(dec: &TinyDecoder, z: &Tensor) -> Tensor {
    dec.fc1.forward(z).relu().apply(&dec.fc2)
}

fn train_tiny_vae(epochs: usize, batch_size: i64, lr: f64) {
    let device = Device::Cpu;
    let vs = nn::VarStore::new(device);
    let encoder = build_encoder(&vs.root() / "enc", 784, 256, 10);
    let decoder = build_decoder(&vs.root() / "dec", 10, 256, 784);
    let mut opt = nn::Adam::default().build(&vs, lr).unwrap();

    // MNIST loading placeholder
    let train_x = Tensor::zeros(&[60000, 784], (Kind::Float, device));

    for epoch in 0..epochs {
        let n = train_x.size()[0];
        let mut total_loss = 0f64;
        let mut n_batches = 0usize;

        for i in (0..n).step_by(batch_size as usize) {
            let end = (i + batch_size).min(n);
            let x_batch = train_x.narrow(0, i, end - i);

            let (mu, logvar) = encode(&encoder, &x_batch);
            let std = (&logvar * 0.5).exp();              // Ïƒ = exp(Â½ log ÏƒÂ²)
            let eps = Tensor::randn_like(&std);           // Îµ ~ N(0, I)
            let z   = &mu + &std * &eps;                  // z = Î¼ + ÏƒâŠ™Îµ

            let x_recon = decode(&decoder, &z);

            // BCE reconstruction loss
            let bce = x_recon.binary_cross_entropy_with_logits::<Tensor>(&x_batch, None, None, tch::Reduction::Mean);
            // KL[q||p] = -Â½Î£(1 + log ÏƒÂ² - Î¼Â² - ÏƒÂ²)
            let kld = (-0.5 * (1.0 + &logvar - mu.pow_tensor_scalar(2) - logvar.exp())).sum(Kind::Float);
            let loss = &bce + &kld;

            opt.zero_grad();
            loss.backward();
            opt.step();

            total_loss += f64::from(&loss);
            n_batches  += 1;
        }
        println!("Epoch {epoch}: avg_loss={:.4}", total_loss / n_batches as f64);
    }
}

fn main() {
    let t = std::time::Instant::now();
    train_tiny_vae(10, 128, 1e-3);
    println!("Training time: {:?}", t.elapsed());
}
```

æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
```
Total parameters: 291,594
Epoch 1: Loss = 152.34
Epoch 2: Loss = 118.56
...
Epoch 10: Loss = 104.23
245.123456 seconds (CPU time)
```

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**:
- [ ] ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° < 300K
- [ ] è¨“ç·´æ™‚é–“ < 5åˆ†ï¼ˆCPUï¼‰
- [ ] æœ€çµ‚Loss < 110

### 5.8 Paper Reading Test â€” VAEè«–æ–‡ã®é‡è¦å›³ã‚’èª­ã‚€

Kingma & Welling (2013) [^1] ã® Figure 1 ã‚’å®Œå…¨ã«ç†è§£ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã‚ˆã†ã€‚

<details><summary>Q8: Figure 1 ã® Graphical Model ã‚’èª¬æ˜ã›ã‚ˆ</summary>

**å•**: è«–æ–‡ã®Figure 1ã«æã‹ã‚Œã¦ã„ã‚‹Graphical Modelã®æ„å‘³ã‚’ã€ç¢ºç‡çš„ä¾å­˜é–¢ä¿‚ã¨ã¨ã‚‚ã«èª¬æ˜ã›ã‚ˆã€‚

**ç­”**:

```
    zâ‚ ----> xâ‚
    â†‘         â†‘
    |         |
   Î¸,Ï†      Î¸,Ï†
    |         |
    â†“         â†“
    zâ‚‚ ----> xâ‚‚
    â‹®         â‹®
    zâ‚™ ----> xâ‚™
```

- $z_i \sim p(z)$: äº‹å‰åˆ†å¸ƒï¼ˆæ¨™æº–æ­£è¦åˆ†å¸ƒï¼‰
- $x_i \mid z_i \sim p_\theta(x \mid z)$: ãƒ‡ã‚³ãƒ¼ãƒ€ï¼ˆç”Ÿæˆéç¨‹ï¼‰
- $q_\phi(z \mid x)$: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ï¼ˆå¤‰åˆ†åˆ†å¸ƒã€å›³ã«ã¯çœç•¥ï¼‰

VAEã¯ã€ã“ã®graphical modelã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ $\theta$ ã‚’æœ€å°¤æ¨å®šã—ã€åŒæ™‚ã«è¿‘ä¼¼äº‹å¾Œåˆ†å¸ƒ $q_\phi(z \mid x)$ ã‚’å­¦ç¿’ã™ã‚‹ã€‚

Plate notation ã§ $N$ å€‹ã®ãƒ‡ãƒ¼ã‚¿ç‚¹ãŒç‹¬ç«‹ã«ç”Ÿæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚

</details>

> **Note:** **é€²æ—: 85% å®Œäº†** ã‚·ãƒ³ãƒœãƒ«èª­è§£ã€ã‚³ãƒ¼ãƒ‰ç¿»è¨³ã€æ½œåœ¨ç©ºé–“ã®å¯è¦–åŒ–ãƒ»è£œé–“ãƒ»å±æ€§æ“ä½œã€Posterior Collapseå®Ÿé¨“ã€ãƒŸãƒ‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€è«–æ–‡å›³èª­è§£ã‚’å®Œèµ°ã—ãŸã€‚Zone 6ã§æœ€æ–°ç ”ç©¶ã®å…¨ä½“åƒã‚’æŠŠæ¡ã™ã‚‹ã€‚

---

> Progress: 85%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. Rustå®Ÿè£…ã«ãŠã‘ã‚‹ `z .= Î¼ .+ Ïƒ .* Îµ` ï¼ˆReparameterization Trickï¼‰ã® `.=` ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆä»£å…¥ãŒã€Pythonã® `z = mu + sigma * eps` ã¨æ¯”ã¹ã¦ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã§å„ªã‚Œã‚‹ç†ç”±ã‚’è¿°ã¹ã‚ˆã€‚
> 2. VQ-VAEã®Commitment Loss $\beta_c \|\text{sg}[\mathbf{z}_e] - e\|^2 + \|\mathbf{z}_e - \text{sg}[e]\|^2$ ã«ãŠã„ã¦ã€`sg`ï¼ˆstop-gradientï¼‰ãŒ2ç®‡æ‰€ã«å…¥ã‚‹ç†ç”±ã¨ã€ãã‚Œãã‚ŒãŒä½•ã‚’å­¦ç¿’ã•ã›ã‚‹ã‹ã‚’èª¬æ˜ã›ã‚ˆã€‚

## ğŸ”¬ Z6. æ–°ãŸãªå†’é™ºã¸ï¼ˆç ”ç©¶å‹•å‘ï¼‰

### 6.1 FSQ (Finite Scalar Quantization) â€” VQ-VAEã®ç°¡ç´ ç‰ˆ

VQ-VAEã®èª²é¡Œ:
- **Codebook Collapse**: ä¸€éƒ¨ã®ã‚³ãƒ¼ãƒ‰ã ã‘ãŒä½¿ã‚ã‚Œã€æ®‹ã‚ŠãŒæ­»ã¬
- **è¤‡é›‘ãªè¨“ç·´**: Commitment Loss, EMAæ›´æ–°, Codebookå†åˆæœŸåŒ–

FSQ [^4] ã¯ã“ã‚Œã‚’æ ¹æœ¬ã‹ã‚‰è§£æ±º:

**Key Idea**: ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ã‚’å­¦ç¿’ã›ãšã€**å›ºå®šã‚°ãƒªãƒƒãƒ‰**ã«é‡å­åŒ–ã™ã‚‹ã€‚

$$
z_i \in \{-1, 0, 1\}, \quad \text{for } i = 1, \ldots, d
$$

ä¾‹: $d=8$ æ¬¡å…ƒã€å„æ¬¡å…ƒãŒ $\{-1, 0, 1\}$ â†’ ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ ã‚µã‚¤ã‚º = $3^8 = 6561$

```rust
use ndarray::prelude::*;

/// Finite Scalar Quantization (FSQ)ã€‚
/// - `z`: é€£ç¶šãƒ¬ã‚¤ãƒ†ãƒ³ãƒˆã‚³ãƒ¼ãƒ‰, shape (d, N)
/// - `levels`: æ¬¡å…ƒã”ã¨ã®é‡å­åŒ–ãƒ¬ãƒ™ãƒ«æ•° (ä¾‹: &[3; 8] â†’ 3â¸ = 6561 ã‚³ãƒ¼ãƒ‰)
fn fsq_quantize(z: &ArrayView2<f64>, levels: &[usize]) -> Array2<f64> {
    let (d, n) = z.dim();
    assert_eq!(d, levels.len());

    let mut z_q = z.to_owned();

    for i in 0..d {
        let l = levels[i];
        // å‡ç­‰ã‚°ãƒªãƒƒãƒ‰: [-1, +1] ã‚’ l ç‚¹ã«åˆ†å‰²
        let grid: Vec<f64> = (0..l)
            .map(|k| -1.0 + 2.0 * k as f64 / (l - 1).max(1) as f64)
            .collect();

        for j in 0..n {
            let v = z[[i, j]];
            // æœ€è¿‘å‚ã‚°ãƒªãƒƒãƒ‰ç‚¹: z_q = argmin_g |g - v|
            z_q[[i, j]] = grid.iter()
                .min_by(|a, b| ((*a - v).abs()).partial_cmp(&((*b - v).abs())).unwrap())
                .copied()
                .unwrap_or(v);
        }
    }

    // Straight-Through Estimator (STE):
    // forward = z_q,  backward: âˆ‚L/âˆ‚z ãŒãã®ã¾ã¾æµã‚Œã‚‹
    // z + stop_gradient(z_q - z) â‰¡ z_q in forward, z in backward
    let diff = &z_q - z;
    z + &diff
}
```

**åˆ©ç‚¹**:
- Codebook Collapse ãŒåŸç†çš„ã«èµ·ããªã„ï¼ˆå…¨ã‚°ãƒªãƒƒãƒ‰ç‚¹ãŒå®šç¾©æ¸ˆã¿ï¼‰
- è¨“ç·´ãŒå˜ç´”ï¼ˆEMAä¸è¦ã€Commitment Lossä¸è¦ï¼‰
- VQ-VAEã¨åŒç­‰ã®æ€§èƒ½

### 6.2 Cosmos Tokenizer â€” ç”»åƒã¨å‹•ç”»ã®çµ±ä¸€è¡¨ç¾

NVIDIA Cosmos Tokenizer [^5] ã¯ã€2024å¹´ã®æœ€æ–°ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã ã€‚

**ç‰¹å¾´**:
- ç”»åƒ (256Ã—256) ã¨å‹•ç”» (16ãƒ•ãƒ¬ãƒ¼ãƒ ) ã‚’åŒã˜æ½œåœ¨ç©ºé–“ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
- ç©ºé–“åœ§ç¸®ç‡: 8Ã—8ã€æ™‚é–“åœ§ç¸®ç‡: 4
- é›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³: 16,384èªå½™
- Diffusion Transformer (DiT) ã¨ã®ä½µç”¨ã‚’æƒ³å®š

```
Image (256Ã—256Ã—3) â†’ Encoder â†’ (32Ã—32Ã—C) â†’ FSQ/VQ â†’ Discrete tokens (32Ã—32)
Video (256Ã—256Ã—16Ã—3) â†’ Encoder â†’ (32Ã—32Ã—4Ã—C) â†’ FSQ/VQ â†’ Discrete tokens (32Ã—32Ã—4)
```

å¿œç”¨:
- å‹•ç”»ç”ŸæˆAIï¼ˆSora-likeãƒ¢ãƒ‡ãƒ«ï¼‰ã®å‰æ®µ
- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMï¼ˆç”»åƒãƒ»å‹•ç”»ç†è§£ï¼‰ã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼

### 6.3 ç ”ç©¶ã®æœ€å‰ç·š â€” 2025-2026è«–æ–‡ãƒªã‚¹ãƒˆ

| è«–æ–‡ | è‘—è€… | å¹´ | æ ¸å¿ƒè²¢çŒ® | arXiv |
|:-----|:-----|:---|:--------|:------|
| CAR-Flow | - | 2025/09 | æ¡ä»¶ä»˜ãå†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ– | 2509.19300 |
| DVAE | - | 2025 | äºŒçµŒè·¯ã§Posterior Collapseé˜²æ­¢ | æ¤œç´¢è¦ |
| é€†Lipschitzåˆ¶ç´„VAE | - | 2023 | Decoderåˆ¶ç´„ã§ç†è«–ä¿è¨¼ | 2304.12770 |
| GQ-VAE | - | 2025/12 | å¯å¤‰é•·é›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³ | 2512.21913 |
| MGVQ | - | 2025/07 | Multi-groupé‡å­åŒ– | 2507.07997 |
| TiTok v2 | - | 2025 | 1Dç”»åƒãƒˆãƒ¼ã‚¯ãƒ³åŒ– | æ¤œç´¢è¦ |
| Open-MAGVIT3 | - | 2025 | MAGVIT-v2å¾Œç¶™ | æ¤œç´¢è¦ |

#### 6.3.1 CAR-Flow â€” æ¡ä»¶ä»˜ãå†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã®é©æ–°

**å•é¡Œ**: æ¨™æº–çš„ãªReparameterization Trickã¯ã€å…¨ã¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ$\mu$ã¨$\sigma$ï¼‰ã«å‹¾é…ã‚’æµã™ã€‚ã—ã‹ã—ã€å ´åˆã«ã‚ˆã£ã¦ã¯$\mu$ã®ã¿æ›´æ–°ã—ãŸã„ï¼ˆä¾‹: ã‚¹ã‚±ãƒ¼ãƒ«å›ºå®šï¼‰ã€‚

**CAR-Flow (Conditional Affine Reparameterization)**:

$$
z = \mu_\phi(x) + \sigma_\text{fixed} \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)
$$

$\sigma$ã‚’å›ºå®šã™ã‚‹ã“ã¨ã§:
- æ½œåœ¨ç©ºé–“ã®ã‚¹ã‚±ãƒ¼ãƒ«ãŒå®‰å®š
- è¨“ç·´ãŒé«˜é€ŸåŒ–ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠæ¸›ï¼‰
- Flowãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¥ç¶šãŒæ˜ç¢ºã«

å¿œç”¨: Latent Diffusion Modelã®VAEã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã§ã€ã‚¹ã‚±ãƒ¼ãƒ«å›ºå®šãŒæœ‰åŠ¹ã€‚

#### 6.4.2 DVAE â€” äºŒçµŒè·¯ã§Posterior Collapseé˜²æ­¢

**ã‚¢ã‚¤ãƒ‡ã‚¢**: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã«2ã¤ã®çµŒè·¯ã‚’ç”¨æ„:
- çµŒè·¯A: ç›´æ¥çš„ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆå¾“æ¥é€šã‚Šï¼‰
- çµŒè·¯B: ãƒã‚¹ã‚¯ã‚’ä»‹ã—ãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆãƒã‚¤ã‚ºã«å¼·ã„ï¼‰

è¨“ç·´åˆæœŸã¯ä¸¡æ–¹ã‚’ä½¿ã„ã€å¾ŒæœŸã¯çµŒè·¯Aã®ã¿ã€‚ã“ã‚Œã§ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãŒæ—©æœŸã«Collapseã™ã‚‹ã®ã‚’é˜²ãã€‚

```python
def dual_path_encoder(x: torch.Tensor, training: bool = True) -> tuple[torch.Tensor, torch.Tensor]:
    mu_a, logvar_a = encoder_a(x)
    if not training:
        return mu_a, logvar_a

    # Path B: masked encoding
    x_masked = x * (torch.rand_like(x) > 0.3)
    mu_b, logvar_b = encoder_b(x_masked)
    Î± = min(1.0, epoch / 50)
    return Î± * mu_a + (1 - Î±) * mu_b, Î± * logvar_a + (1 - Î±) * logvar_b
```

#### 6.4.3 GQ-VAE â€” å¯å¤‰é•·é›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆBPEåœ§ç¸®ç‡ã«æ¥è¿‘ï¼‰

**å•é¡Œ**: VQ-VAEã¯å›ºå®šé•·ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆä¾‹: 256Ã—256 â†’ 32Ã—32ï¼‰ã€‚æƒ…å ±é‡ãŒå°‘ãªã„é ˜åŸŸã‚‚ä¸€æ§˜ã«åœ§ç¸®ã€‚

**GQ-VAE**: å¯å¤‰é•·ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã€‚æƒ…å ±é‡ã«å¿œã˜ã¦ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’èª¿æ•´ã€‚

```
High-detail region (é¡”):   128 tokens
Low-detail region (ç©º):    16 tokens
```

**åŠ¹æœ**: åœ§ç¸®ç‡ãŒBPEï¼ˆãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ï¼‰ã«æ¥è¿‘ã€‚LLMã¨ã®çµ±åˆãŒå®¹æ˜“ã«ã€‚

#### 6.4.4 MGVQ â€” Multi-group Vector Quantization

**ã‚¢ã‚¤ãƒ‡ã‚¢**: ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ã‚’è¤‡æ•°ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†å‰²ã€‚å„ã‚°ãƒ«ãƒ¼ãƒ—ãŒç•°ãªã‚‹ã€Œæ„å‘³ã®ç²’åº¦ã€ã‚’æ‹…å½“ã€‚

```
Group 1 (ç²—ã„ç‰¹å¾´): 16 codes â†’ è‰²ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£
Group 2 (ä¸­é–“ç‰¹å¾´): 64 codes â†’ å½¢çŠ¶ã€é…ç½®
Group 3 (ç´°ã‹ã„ç‰¹å¾´): 256 codes â†’ ã‚¨ãƒƒã‚¸ã€è©³ç´°
```

**åˆ©ç‚¹**:
- Codebookåˆ©ç”¨ç‡ãŒå‘ä¸Šï¼ˆå„ã‚°ãƒ«ãƒ¼ãƒ—ã§ç‹¬ç«‹ï¼‰
- éšå±¤çš„ãªè¡¨ç¾ãŒè‡ªç„¶ã«å­¦ç¿’ã•ã‚Œã‚‹
- VQ-VAE-2ã®ç°¡ç´ ç‰ˆã¨ã—ã¦æ©Ÿèƒ½

#### 6.4.5 TiTok v2 â€” 1Dç”»åƒãƒˆãƒ¼ã‚¯ãƒ³åŒ–ï¼ˆARç”Ÿæˆã¨ã®æ¥ç¶šï¼‰

**å¾“æ¥ã®VQ-VAE**: 2Dæ½œåœ¨ç©ºé–“ï¼ˆä¾‹: 32Ã—32ï¼‰â†’ 2Dæ§‹é€ ã‚’ä¿æŒ

**TiTok v2**: 1Dæ½œåœ¨ç©ºé–“ï¼ˆä¾‹: 1024ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰â†’ Transformerã§ç›´æ¥ç”Ÿæˆå¯èƒ½

```
Image (256Ã—256) â†’ Encoder â†’ 1D sequence (1024 tokens) â†’ Decoder â†’ Image (256Ã—256)
```

**åˆ©ç‚¹**:
- Transformer ARãƒ¢ãƒ‡ãƒ«ã§ç›´æ¥ç”Ÿæˆï¼ˆ2Dã‚¹ã‚­ãƒ£ãƒ³ä¸è¦ï¼‰
- LLMã¨ã®çµ±ä¸€çš„ãªæ‰±ã„ï¼ˆãƒ†ã‚­ã‚¹ãƒˆãƒ»ç”»åƒåŒã˜ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼‰
- æ¨è«–é€Ÿåº¦å‘ä¸Šï¼ˆ2Dã‚¹ã‚­ãƒ£ãƒ³ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰å‰Šæ¸›ï¼‰

**èª²é¡Œ**: 2Dæ§‹é€ ã®å­¦ç¿’ãŒé›£ã—ã„ï¼ˆä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¿…é ˆï¼‰

### 6.4 VAEå®Ÿè£…ã®æ¯”è¼ƒ â€” PyTorch vs JAX vs Rust

| é …ç›® | PyTorch | JAX (Flax) | ndarray + tch-rs (Rust) |
|:-----|:--------|:-----------|:------------------------|
| **å®Ÿè£…è¡Œæ•°** | 150è¡Œ | 180è¡Œï¼ˆç´”ç²‹é–¢æ•°å‹ï¼‰ | 120è¡Œï¼ˆæœ€å°ï¼‰ |
| **è¨“ç·´é€Ÿåº¦ï¼ˆCPUï¼‰** | 2.35s/epoch | 1.82s/epoch | 0.29s/epoch |
| **GPUåˆ‡æ›¿** | `model.to('cuda')` | `jax.device_put(x, gpu)` | `Tensor::to_device(device)` (tch-rs) |
| **å‹•çš„ãƒãƒƒãƒã‚µã‚¤ã‚º** | âœ… å¯èƒ½ | âŒ AOTå†ã‚³ãƒ³ãƒ‘ã‚¤ãƒ« | âœ… å¯èƒ½ |
| **ãƒ‡ãƒãƒƒã‚°** | âœ… pdb, printæ–‡ | âš ï¸ AOTã§é›£ã—ã„ | âœ… cargo-watch + lldb |
| **ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ** | æœ€å¤§ï¼ˆtorchvisionç­‰ï¼‰ | æˆé•·ä¸­ï¼ˆdm-haikuç­‰ï¼‰ | ndarray, rayon, tch-rs |
| **å­¦ç¿’æ›²ç·š** | ç·©ã‚„ã‹ | æ€¥ï¼ˆç´”ç²‹é–¢æ•°å‹ï¼‰ | ä¸­ï¼ˆã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–ï¼‰ |

**é¸æŠæŒ‡é‡**:
- **ç ”ç©¶ãƒ»ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—**: PyTorchï¼ˆã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ æœ€å¤§ï¼‰
- **æœ¬ç•ªãƒ»å¤§è¦æ¨¡è¨“ç·´**: JAXï¼ˆTPUæœ€é©åŒ–ï¼‰
- **æ¨è«–ãƒ»æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤**: ndarray + tch-rsï¼ˆã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–ã€ãƒ¡ãƒ¢ãƒªå®‰å…¨ï¼‰

<details><summary>ç”¨èªé›† (Glossary)</summary>

| ç”¨èª | è‹±èª | å®šç¾© |
|:-----|:-----|:-----|
| å¤‰åˆ†ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ | Variational Autoencoder | æ½œåœ¨å¤‰æ•°ãƒ¢ãƒ‡ãƒ«ã®ä¸€ç¨®ã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã§ $q_\phi(z \mid x)$ ã‚’å­¦ç¿’ã€‚ |
| ELBO | Evidence Lower BOund | å¯¾æ•°å‘¨è¾ºå°¤åº¦ã®ä¸‹ç•Œã€‚VAEã®æå¤±é–¢æ•°ã€‚ |
| å†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ãƒˆãƒªãƒƒã‚¯ | Reparameterization Trick | ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å¾®åˆ†å¯èƒ½ã«ã™ã‚‹æ‰‹æ³•ã€‚$z = \mu + \sigma \epsilon$ |
| KLç™ºæ•£ | KL Divergence | 2ã¤ã®åˆ†å¸ƒã®ã€Œè·é›¢ã€ã€‚éå¯¾ç§°ã€‚ |
| æ½œåœ¨ç©ºé–“ | Latent Space | ãƒ‡ãƒ¼ã‚¿ã®ä½æ¬¡å…ƒè¡¨ç¾ç©ºé–“ã€‚ |
| ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ | Codebook | é›¢æ•£æ½œåœ¨å¤‰æ•°ã®å€™è£œé›†åˆã€‚VQ-VAEã§ä½¿ç”¨ã€‚ |
| ãƒ™ã‚¯ãƒˆãƒ«é‡å­åŒ– | Vector Quantization | é€£ç¶šãƒ™ã‚¯ãƒˆãƒ«ã‚’é›¢æ•£ã‚³ãƒ¼ãƒ‰ã«å†™åƒã€‚ |
| Straight-Through Estimator | STE | é›¢æ•£åŒ–ã®å‹¾é…ã‚’è¿‘ä¼¼ã™ã‚‹æ‰‹æ³•ã€‚ |
| Posterior Collapse | - | ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãŒæ½œåœ¨å¤‰æ•°ã‚’ç„¡è¦–ã™ã‚‹ç¾è±¡ã€‚ |
| Disentanglement | - | æ½œåœ¨ç©ºé–“ã®å„æ¬¡å…ƒãŒç‹¬ç«‹ã—ãŸæ„å‘³ã‚’æŒã¤æ€§è³ªã€‚ |

</details>

> **Note:** **é€²æ—: 95% å®Œäº†** VAEç³»åˆ—ã®ç³»è­œã€FSQ/Cosmosæœ€å‰ç·šã€æ¨è–¦æ›¸ç±ã‚’æŠŠæ¡ã—ãŸã€‚Zone 7ã§å…¨ä½“ã‚’æŒ¯ã‚Šè¿”ã‚‹ã€‚


## ğŸ­ Z7. ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ï¼ˆã¾ã¨ã‚ãƒ»FAQãƒ»æ¬¡å›äºˆå‘Šï¼‰

### 6.5 ã“ã®è¬›ç¾©ã®3ã¤ã®æ ¸å¿ƒ

1. **VAEã¯å¤‰åˆ†æ¨è«–ã®è‡ªå‹•åŒ–ã§ã‚ã‚‹** â€” æ‰‹å‹•è¨­è¨ˆã®è¿‘ä¼¼åˆ†å¸ƒ $q(z)$ ã‚’ã€NN $q_\phi(z \mid x)$ ã«ç½®ãæ›ãˆãŸã€‚Reparameterization Trickã§å¾®åˆ†å¯èƒ½ã«ã€‚

2. **é€£ç¶šæ½œåœ¨ç©ºé–“ã‹ã‚‰é›¢æ•£è¡¨ç¾ã¸** â€” VAEã®ã€Œã¼ã‚„ã‘ãŸç”»åƒã€å•é¡Œã‚’ã€VQ-VAEãŒé›¢æ•£ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ã§è§£æ±ºã€‚FSQãŒä¸€æ®µã¨ç°¡ç´ åŒ–ã€‚2026å¹´ã®ç”»åƒãƒ»å‹•ç”»ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®åŸºç›¤ã€‚

3. **RustãŒè¨“ç·´ãƒ«ãƒ¼ãƒ—ã‚’8å€é«˜é€ŸåŒ–** â€” ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ– + AOT + å‹å®‰å®šæ€§ã€‚æ•°å¼ãŒãã®ã¾ã¾ã‚³ãƒ¼ãƒ‰ã«ãªã‚‹ã€‚**Pythonã«æˆ»ã‚Œãªã„ã€‚**

### 6.6 ã‚ˆãã‚ã‚‹è³ªå• (FAQ)

<details><summary>Q: VAEã®ç”»åƒãŒã¼ã‚„ã‘ã‚‹ã®ã¯ãªãœï¼Ÿ</summary>

**ç­”**: 2ã¤ã®ç†ç”±ãŒã‚ã‚‹:

1. **Gaussianä»®å®š**: ãƒ‡ã‚³ãƒ¼ãƒ€ãŒ $p_\theta(x \mid z) = \mathcal{N}(x \mid \mu_\theta(z), \sigma^2 I)$ ã‚’ä»®å®šã€‚ã‚¬ã‚¦ã‚¹åˆ†å¸ƒã¯ã€Œå¹³å‡çš„ãªç”»åƒã€ã‚’å‡ºåŠ›ã™ã‚‹ãŸã‚ã€ã‚¨ãƒƒã‚¸ãŒã¼ã‚„ã‘ã‚‹ã€‚

2. **Posterior Collapse**: KLæ­£å‰‡åŒ–ãŒå¼·ã™ãã‚‹ã¨ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãŒ $q_\phi(z \mid x) \approx p(z)$ ã«ãªã‚Šã€$z$ ãŒ $x$ ã®æƒ…å ±ã‚’æŒãŸãªããªã‚‹ã€‚ãƒ‡ã‚³ãƒ¼ãƒ€ã¯å¹³å‡çš„ãªç”»åƒã‚’å‡ºåŠ›ã™ã‚‹ã—ã‹ãªã„ã€‚

**è§£æ±ºç­–**:
- Î²-VAE ã§ Î² ã‚’å°ã•ãã™ã‚‹ï¼ˆå†æ§‹æˆé‡è¦–ï¼‰
- Perceptual Loss ã‚’ä½¿ã†ï¼ˆVQ-GANï¼‰
- GANã¨çµ„ã¿åˆã‚ã›ã‚‹ï¼ˆç¬¬12å›ï¼‰

</details>

<details><summary>Q: VQ-VAEã®Straight-Through Estimatorã¯ç†è«–çš„ã«æ­£ã—ã„ã®ã‹ï¼Ÿ</summary>

**ç­”**: **æ­£ã—ããªã„**ã€‚å‹¾é…ã®ä¸åæ¨å®šé‡ã§ã¯ãªã„ã€‚ã—ã‹ã—å®Ÿç”¨ä¸Šã¯å‹•ä½œã™ã‚‹ã€‚

ç†è«–çš„ã«ã¯ã€Gumbel-Softmaxï¼ˆé€£ç¶šç·©å’Œï¼‰ã®æ–¹ãŒå³å¯†ã ãŒã€VQ-VAEã®STEã®æ–¹ãŒå®Ÿè£…ãŒç°¡å˜ã§ã€æ€§èƒ½ã‚‚è‰¯ã„ï¼ˆçµŒé¨“çš„ï¼‰ã€‚

[^6] Bengio et al. (2013) "Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation" â€” STEã®æœ€åˆã®ææ¡ˆ

</details>

<details><summary>Q: Rustã¯æœ¬å½“ã«Pythonã‚ˆã‚Šé€Ÿã„ã®ã‹ï¼Ÿå…¨ã¦ã®ã‚±ãƒ¼ã‚¹ã§ï¼Ÿ</summary>

**ç­”**: **No**ã€‚AOTã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒã‚ã‚‹ãŸã‚ã€çŸ­ã„ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆ1å›ã ã‘å®Ÿè¡Œï¼‰ã§ã¯Pythonã®æ–¹ãŒé€Ÿã„å ´åˆã‚‚ã‚ã‚‹ã€‚

**RustãŒé€Ÿã„ã‚±ãƒ¼ã‚¹**:
- ãƒ«ãƒ¼ãƒ—ã‚’ä½•åº¦ã‚‚å›ã™ï¼ˆè¨“ç·´ãƒ«ãƒ¼ãƒ—ãªã©ï¼‰
- å‹å®‰å®šãªã‚³ãƒ¼ãƒ‰
- æ•°å€¤è¨ˆç®—ãŒä¸»ä½“

**PythonãŒé€Ÿã„ã‚±ãƒ¼ã‚¹**:
- 1å›ã ã‘å®Ÿè¡Œã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- I/Oå¾…ã¡ãŒä¸»ä½“ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼‰
- æ—¢å­˜ã®C/C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’å‘¼ã¶ã ã‘ï¼ˆNumPy, Pandasï¼‰

**ä½¿ã„åˆ†ã‘**: ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—â†’Pythonã€è¨“ç·´â†’Rustã€æ¨è«–â†’Rust

</details>

<details><summary>Q: VAEã¨Diffusion Modelã®é–¢ä¿‚ã¯ï¼Ÿ</summary>

**ç­”**: VAEã¯ **Latent Diffusion Model (LDM)** ã®åŸºç›¤ã ã€‚

Stable Diffusionã®æ§‹é€ :
1. VAE Encoder: ç”»åƒ (512Ã—512) â†’ æ½œåœ¨ç©ºé–“ (64Ã—64Ã—4)
2. Diffusion Model: æ½œåœ¨ç©ºé–“ã§ãƒã‚¤ã‚ºé™¤å»
3. VAE Decoder: æ½œåœ¨ç©ºé–“ â†’ ç”»åƒ (512Ã—512)

VAEãŒé«˜æ¬¡å…ƒç”»åƒã‚’ä½æ¬¡å…ƒæ½œåœ¨ç©ºé–“ã«åœ§ç¸®ã™ã‚‹ã“ã¨ã§ã€Diffusion Modelã®è¨ˆç®—é‡ã‚’åŠ‡çš„ã«å‰Šæ¸›ã€‚Course IVã§è©³è¿°ã€‚

</details>

<details><summary>Q: æœ¬è¬›ç¾©ã§æ‰±ã‚ãªã‹ã£ãŸVAEç™ºå±•ãƒˆãƒ”ãƒƒã‚¯ã¯ï¼Ÿ</summary>

æœ¬è¬›ç¾©ã¯åŸºç¤ã¨é›¢æ•£è¡¨ç¾ã«é›†ä¸­ã—ãŸãŸã‚ã€ä»¥ä¸‹ã¯çœç•¥ã—ãŸ:

- **Hierarchical VAE** (Ladder VAE, NVAE) â€” éšå±¤çš„æ½œåœ¨è¡¨ç¾
- **Normalizing Flow Posterior** â€” ã‚ˆã‚ŠæŸ”è»Ÿãªäº‹å¾Œåˆ†å¸ƒï¼ˆã“ã®ã‚·ãƒªãƒ¼ã‚ºã§ã¯æ‰±ã‚ãªã„ï¼‰
- **Conditional VAE (CVAE)** â€” ãƒ©ãƒ™ãƒ«æ¡ä»¶ä»˜ãç”Ÿæˆ
- **Semi-supervised VAE** â€” ãƒ©ãƒ™ãƒ«ãªã—ãƒ‡ãƒ¼ã‚¿ã®æ´»ç”¨
- **Variational Lossy Autoencoder (VLAE)** â€” æƒ…å ±ç†è«–çš„è§£é‡ˆ

èˆˆå‘³ãŒã‚ã‚Œã°ã€Zone 6ã®æ¨å¥¨æ›¸ç±ã‚’å‚ç…§ã€‚

</details>

### 6.7 1é€±é–“ã®å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

| æ—¥ | ã‚¿ã‚¹ã‚¯ | æ‰€è¦æ™‚é–“ | ç›®æ¨™ |
|:---|:------|:---------|:-----|
| **Day 1** | Zone 0-2 ã‚’èª­ã‚€ï¼ˆæ•°å¼ã‚¹ã‚­ãƒƒãƒ—ï¼‰ | 30åˆ† | å…¨ä½“åƒæŠŠæ¡ |
| **Day 2** | Zone 3.1-3.2 ELBO + Reparameterization å°å‡º | 1.5æ™‚é–“ | æ‰‹ã§å°å‡º |
| **Day 3** | Zone 3.3-3.4 Gaussian KL + Boss Battle | 1.5æ™‚é–“ | Kingma 2013 å®Œå…¨ç†è§£ |
| **Day 4** | Zone 4.1-4.3 Rust ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« + åŸºæœ¬æ–‡æ³• | 1æ™‚é–“ | Rustç’°å¢ƒæ§‹ç¯‰ |
| **Day 5** | Zone 4.4-4.6 Rust VAE å®Ÿè£… + é€Ÿåº¦æ¸¬å®š | 2æ™‚é–“ | 8å€é€Ÿã‚’ä½“é¨“ |
| **Day 6** | Zone 5 æ½œåœ¨ç©ºé–“å¯è¦–åŒ– + è£œé–“ | 1.5æ™‚é–“ | å®Ÿé¨“ã§éŠã¶ |
| **Day 7** | Zone 6-7 æœ€æ–°ç ”ç©¶ + å¾©ç¿’ | 1æ™‚é–“ | å…¨ä½“æŒ¯ã‚Šè¿”ã‚Š |

**åˆè¨ˆ: ç´„9æ™‚é–“**ï¼ˆæœ¬è¬›ç¾©ã®ç›®æ¨™ã¯3æ™‚é–“ã ãŒã€å®Œå…¨ç¿’å¾—ã«ã¯3å€ã‹ã‹ã‚‹ï¼‰

### 6.8 è‡ªå·±è¨ºæ–­ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] VAEã®Encoder/Decoderã®å½¹å‰²ã‚’å›³ã§èª¬æ˜ã§ãã‚‹
- [ ] ELBOã‚’3è¡Œã§å°å‡ºã§ãã‚‹ï¼ˆJensenä¸ç­‰å¼ã‚’ä½¿ã£ã¦ï¼‰
- [ ] Reparameterization Trickã‚’å¼ã§æ›¸ã‘ã‚‹: $z = \mu + \sigma \epsilon$
- [ ] ã‚¬ã‚¦ã‚¹KLç™ºæ•£ã®é–‰å½¢å¼ã‚’æš—è¨˜ã—ã¦ã„ã‚‹ï¼ˆã¾ãŸã¯å°å‡ºã§ãã‚‹ï¼‰
- [ ] PyTorchã§VAEã‚’10è¡Œã§å®Ÿè£…ã§ãã‚‹
- [ ] **Rustã§VAEã‚’å®Ÿè£…ã—ã€è¨“ç·´é€Ÿåº¦ã‚’æ¸¬å®šã—ãŸ**
- [ ] æ½œåœ¨ç©ºé–“ã®2Då¯è¦–åŒ–ã‚’ä½œæˆã—ãŸ
- [ ] VQ-VAEã®Straight-Through Estimatorã‚’èª¬æ˜ã§ãã‚‹
- [ ] FSQã¨VQ-VAEã®é•ã„ã‚’èª¬æ˜ã§ãã‚‹

**7å€‹ä»¥ä¸Šãƒã‚§ãƒƒã‚¯ã§ãã‚Œã°åˆæ ¼ã€‚** æ¬¡ã®ç¬¬11å›ï¼ˆæœ€é©è¼¸é€ç†è«–ï¼‰ã«é€²ã‚ã‚‹ã€‚

### 6.9 æ¬¡å›äºˆå‘Š: ç¬¬11å› æœ€é©è¼¸é€ç†è«– (Optimal Transport)

VAEã¯ã€Œå†æ§‹æˆ + KLæ­£å‰‡åŒ–ã€ã§æ½œåœ¨ç©ºé–“ã‚’å­¦ç¿’ã—ãŸã€‚ã—ã‹ã—ã€KLç™ºæ•£ã«ã¯é™ç•ŒãŒã‚ã‚‹:
- å°ã®ä¸ä¸€è‡´ã§ç™ºæ•£ï¼ˆ$p(x)$ ã¨ $q(x)$ ã®ã‚µãƒãƒ¼ãƒˆãŒé‡ãªã‚‰ãªã„ã¨ âˆï¼‰
- å‹¾é…æ¶ˆå¤±ï¼ˆGANã®è¨“ç·´ä¸å®‰å®šæ€§ã®åŸå› ï¼‰

**æœ€é©è¼¸é€ç†è«–** (Optimal Transport) ã¯ã€ç¢ºç‡åˆ†å¸ƒé–“ã®ã€Œè·é›¢ã€ã‚’ã€**è¼¸é€ã‚³ã‚¹ãƒˆ**ã§å®šç¾©ã™ã‚‹ã€‚

$$
W_2(p, q) = \inf_{\gamma \in \Pi(p, q)} \mathbb{E}_{(x, y) \sim \gamma}[\|x - y\|^2]
$$

ã“ã® Wasserstein è·é›¢ã¯:
- å°ãŒä¸ä¸€è‡´ã§ã‚‚æœ‰é™å€¤
- é€£ç¶šçš„ã§ã€å‹¾é…ãŒå¸¸ã«å­˜åœ¨
- GANã®ç†è«–åŸºç›¤ï¼ˆWGANï¼‰
- Flow Matchingã®æ•°å­¦çš„åœŸå°ï¼ˆCourse IVï¼‰

**ç¬¬11å›ã§å­¦ã¶ã“ã¨**:
- Mongeå•é¡Œï¼ˆ1781å¹´ï¼‰ã‹ã‚‰Kantorovichç·©å’Œï¼ˆ1942å¹´ï¼‰ã¸
- Kantorovich-RubinsteinåŒå¯¾æ€§ï¼ˆç¬¬6å›ã®åŒå¯¾æ€§ã‚’å¿œç”¨ï¼‰
- Sinkhornè·é›¢ï¼ˆé«˜é€Ÿè¿‘ä¼¼ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰
- OTã¨Flow Matchingã®æ¥ç¶šï¼ˆCourse IVã¸ã®ä¼ç·šï¼‰

```mermaid
graph LR
    L10["ç¬¬10å›: VAE<br>KLæ­£å‰‡åŒ–"] --> L11["ç¬¬11å›: æœ€é©è¼¸é€ç†è«–<br>Wassersteinè·é›¢"]
    L11 --> L12["ç¬¬12å›: GAN<br>WGANç†è«–"]
    L12 --> L13["ç¬¬13å›: è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«<br>é€£é–å¾‹ã§ç¢ºç‡åˆ†è§£"]

    style L10 fill:#e1f5fe
    style L11 fill:#fff3e0
```

> **Note:** **é€²æ—: 100% å®Œäº†ï¼** VAEã®åŸºç¤ã‹ã‚‰é›¢æ•£è¡¨ç¾ã€Rustå®Ÿè£…ã¾ã§å®Œèµ°ã—ãŸã€‚æ¬¡å›ã¯æœ€é©è¼¸é€ç†è«–ã§ã€ç¢ºç‡åˆ†å¸ƒé–“ã®ã€ŒçœŸã®è·é›¢ã€ã‚’å­¦ã¶ã€‚

### 6.10 ğŸ’€ ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„

> **ã€Œã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–ã¯"ä¾¿åˆ©æ©Ÿèƒ½"ã‹ã€ãã‚Œã¨ã‚‚"è¨€èªã®æœ¬è³ª"ã‹ï¼Ÿã€**

Pythonã§ã¯ã€é–¢æ•°ã®æŒ¯ã‚‹èˆã„ã¯å¼•æ•°ã®**å‹**ã§ã¯ãªãã€**å€¤**ã§åˆ¶å¾¡ã•ã‚Œã‚‹:

```python
def f(x):
    match x:
        case int():
            return x + 1
        case list():
            return [i + 1 for i in x]
```

Rustã§ã¯ã€é–¢æ•°ã®æŒ¯ã‚‹èˆã„ã¯**å‹**ã§åˆ¶å¾¡ã•ã‚Œã‚‹:

```rust
// Rust: ãƒˆãƒ¬ã‚¤ãƒˆã§ã‚¹ã‚«ãƒ©ãƒ¼/ã‚¹ãƒ©ã‚¤ã‚¹ã®å¤šé‡ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒã‚’è¡¨ç¾
fn f_int(x: i64) -> i64 { x + 1 }
fn f_slice(x: &[i64]) -> Vec<i64> { x.iter().map(|&v| v + 1).collect() }
```

**å•ã„**:
1. Pythonã® `isinstance` ãƒã‚§ãƒƒã‚¯ã¨ã€Rustã®ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–ã¯ã€æœ¬è³ªçš„ã«ä½•ãŒé•ã†ã®ã‹ï¼Ÿ
2. ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–ã¯ã€Œifæ–‡ã‚’æ›¸ã‹ãªãã¦æ¸ˆã‚€ç³–è¡£æ§‹æ–‡ã€ãªã®ã‹ã€ãã‚Œã¨ã‚‚ã€Œå‹ã‚·ã‚¹ãƒ†ãƒ ã¨ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®çµ±åˆã€ãªã®ã‹ï¼Ÿ
3. **VAEã®è¨“ç·´ãƒ«ãƒ¼ãƒ—ãŒ8å€é€Ÿããªã£ãŸç†ç”±ã¯ã€ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–ãªã®ã‹ã€AOTãªã®ã‹ã€å‹å®‰å®šæ€§ãªã®ã‹ï¼Ÿãã‚Œã¨ã‚‚å…¨ã¦ã®ç›¸ä¹—åŠ¹æœãªã®ã‹ï¼Ÿ**

<details><summary>ãƒ’ãƒ³ãƒˆ: Rustã®è¨­è¨ˆå“²å­¦</summary>

Rustã®å‰µå§‹è€…ã®è¨€è‘‰:

> "We want the speed of C with the dynamism of Ruby. We want a language that's homoiconic, with true macros like Lisp, but with obvious, familiar mathematical notation like Matlab. We want something as usable for general programming as Python, as easy for statistics as R, as natural for string processing as Perl, as powerful for linear algebra as Matlab, as good at gluing programs together as the shell."
> â€” Jeff Bezanson, Stefan Karpinski, Viral Shah, Alan Edelman (2012)

ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–ã¯ã€ã“ã®ã€Œå…¨ã¦ã‚’å®Ÿç¾ã™ã‚‹ã€ãŸã‚ã®æ ¸å¿ƒæŠ€è¡“ã ã£ãŸã€‚å‹ã«ã‚ˆã‚‹æœ€é©åŒ–ã¨ã€å‹•çš„è¨€èªã®æŸ”è»Ÿæ€§ã‚’ä¸¡ç«‹ã•ã›ã‚‹å”¯ä¸€ã®æ–¹æ³•ã€‚

</details>

ã“ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’å—ã‘å…¥ã‚Œã‚‹ã¨ã€**Pythonã® `if isinstance(x, type):` ã‚’æ›¸ããŸã³ã«é•å’Œæ„Ÿã‚’è¦šãˆã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚** ãã‚ŒãŒã€ç¬¬10å›ã®ç›®æ¨™ã ã€‚

---

> Progress: 95%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. FSQï¼ˆFinite Scalar Quantizationï¼‰ãŒLFQãƒ»RQ-VAEã¨æ¯”ã¹ã¦ã€Œå®Ÿè£…ã®å˜ç´”ã•ã€ã‚’å®Ÿç¾ã™ã‚‹ä»•çµ„ã¿ã‚’ã€é‡å­åŒ–å¾Œã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯åˆ©ç”¨ç‡ã®è¦³ç‚¹ã‹ã‚‰èª¬æ˜ã›ã‚ˆã€‚
> 2. SoftVQ-VAEãŒã€Œå®Œå…¨å¾®åˆ†å¯èƒ½ã€ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€é€šå¸¸ã®VQï¼ˆargminï¼‰æ“ä½œã‚’ã©ã®ã‚ˆã†ã«ç½®ãæ›ãˆã‚‹ã‹è¿°ã¹ã‚ˆã€‚

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: Kingma, D. P., & Welling, M. (2013). Auto-Encoding Variational Bayes. *arXiv preprint arXiv:1312.6114*.
<https://arxiv.org/abs/1312.6114>

[^2]: Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M., ... & Lerchner, A. (2017). Î²-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework. *International Conference on Learning Representations (ICLR)*.
<https://openreview.net/forum?id=Sy2fzU9gl>

[^3]: van den Oord, A., Vinyals, O., & Kavukcuoglu, K. (2017). Neural Discrete Representation Learning. *Advances in Neural Information Processing Systems (NeurIPS)*. arXiv:1711.00937.
<https://arxiv.org/abs/1711.00937>

[^4]: Mentzer, F., Minnen, D., Agustsson, E., & Tschannen, M. (2023). Finite Scalar Quantization: VQ-VAE Made Simple. *International Conference on Learning Representations (ICLR) 2024*. arXiv:2309.15505.
<https://arxiv.org/abs/2309.15505>

[^5]: NVIDIA. (2024). Cosmos Tokenizer. *GitHub Repository*.
<https://github.com/NVIDIA/Cosmos-Tokenizer>

[^6]: Bengio, Y., LÃ©onard, N., & Courville, A. (2013). Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation. arXiv:1308.3432.
<https://arxiv.org/abs/1308.3432>

[^7]: Kingma, D. P., Salimans, T., Jozefowicz, R., Chen, X., Sutskever, I., & Welling, M. (2016). Improved Variational Inference with Inverse Autoregressive Flow. *NeurIPS 2016*.
<https://arxiv.org/abs/1606.04934>

### é–¢é€£è«–æ–‡

- Burgess, C. P., Higgins, I., Pal, A., Matthey, L., Watters, N., Desjardins, G., & Lerchner, A. (2018). Understanding disentangling in Î²-VAE. arXiv:1804.03599.
<https://arxiv.org/abs/1804.03599>

- Kingma, D. P., Salimans, T., & Welling, M. (2015). Variational Dropout and the Local Reparameterization Trick. *NeurIPS*. arXiv:1506.02557.
<https://arxiv.org/abs/1506.02557>

- Esser, P., Rombach, R., & Ommer, B. (2021). Taming Transformers for High-Resolution Image Synthesis. *CVPR*. arXiv:2012.09841.
<https://arxiv.org/abs/2012.09841>

- Yu, L., Poirson, P., Yang, S., Berg, A. C., & Berg, T. L. (2023). MAGVIT-v2: Language Model Beats Diffusion - Tokenizer is Key to Visual Generation. arXiv:2310.05737.
<https://arxiv.org/abs/2310.05737>

### æ•™ç§‘æ›¸

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer. Chapter 10: Approximate Inference.

- Murphy, K. P. (2022). *Probabilistic Machine Learning: Advanced Topics*. MIT Press. Chapter 21: Variational Inference.

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press. Chapter 20: Deep Generative Models.
<https://www.deeplearningbook.org/>

---


## è‘—è€…ãƒªãƒ³ã‚¯

- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
