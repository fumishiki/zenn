---
title: "ç¬¬40å›: ğŸ¦€ Consistency Models & é«˜é€Ÿç”Ÿæˆç†è«–: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
emoji: "ğŸ¦€"
type: "tech"
topics: ["machinelearning", "deeplearning", "consistencymodels", "rust", "diffusion"]
published: true
slug: "ml-lecture-40-part2"
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Rust"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---

**â†’ å‰ç·¨ï¼ˆç†è«–ç·¨ï¼‰**: [ml-lecture-40-part1](./ml-lecture-40-part1)

## ğŸ’» Z5. è©¦ç·´ï¼ˆå®Ÿè£…ï¼‰ï¼ˆ45åˆ†ï¼‰â€” Rust Consistency Modelå®Œå…¨å®Ÿè£…

### 4.1 Consistency Functionå®Ÿè£…

```rust
use candle_core::{Result, Tensor};
use candle_nn::Module;

// Preconditioning coefficients (EDM-style)
fn get_coefficients(t: &Tensor, sigma_data: f32) -> Result<(Tensor, Tensor, Tensor)> {
    let sigma_sq = sigma_data * sigma_data;
    let t_sq = t.sqr()?;
    // c_skip = Ïƒ_dataÂ² / (tÂ² + Ïƒ_dataÂ²)
    let c_skip = ((&t_sq + sigma_sq)?.recip()? * sigma_sq)?;
    // c_out = Ïƒ_data * t / sqrt(tÂ² + Ïƒ_dataÂ²)
    let c_out = (t * sigma_data)?.div(&(&t_sq + sigma_sq)?.sqrt()?)?;
    // c_in = 1 / sqrt(tÂ² + Ïƒ_dataÂ²)
    let c_in = (&t_sq + sigma_sq)?.sqrt()?.recip()?;
    Ok((c_skip, c_out, c_in))
}

// Consistency Model wrapper
struct ConsistencyModel<M> {
    backbone: M, // U-Net or similar
    sigma_data: f32,
}

impl<M: Module> ConsistencyModel<M> {
    fn forward(&self, x_t: &Tensor, t: &Tensor) -> Result<Tensor> {
        let (c_skip, c_out, c_in) = get_coefficients(t, self.sigma_data)?;

        // Forward through backbone: net_out = backbone(c_in * x_t, t)
        let net_out = self.backbone.forward(&(x_t * &c_in)?)?;

        // F_Î¸(x_t, t) = c_skip * x_t + c_out * net_out
        let f_theta = (x_t * &c_skip)?.add(&(&net_out * &c_out)?)?;
        Ok(f_theta)
    }

    // Boundary condition: at t=Îµ, F(x,Îµ) â‰ˆ identity (skip connection dominates)
    fn enforce_boundary<'a>(&self, x_eps: &'a Tensor, _eps: f32) -> &'a Tensor {
        x_eps
    }
}
```

### 4.2 Consistency Training (CT) å®Ÿè£…

```rust
use candle_core::{Device, Result, Tensor};

// Discretization schedule (EDM-style)
fn get_schedule(n: usize, eps: f32, t_max: f32, rho: f32) -> Vec<f32> {
    (0..=n)
        .map(|i| {
            let s = i as f32 / n as f32;
            // t_i = (Îµ^(1/Ï) + s * (T^(1/Ï) - Îµ^(1/Ï)))^Ï
            (eps.powf(1.0 / rho) + s * (t_max.powf(1.0 / rho) - eps.powf(1.0 / rho))).powf(rho)
        })
        .collect()
}

// Pseudo-Huber distance
fn pseudo_huber_loss(a: &Tensor, b: &Tensor, c: f32) -> Result<Tensor> {
    let diff = a.sub(b)?;
    // sqrt(cÂ² + sum(diffÂ²)) - c
    let sum_sq = diff.sqr()?.sum_keepdim((0, 1, 2))?;
    (sum_sq + (c * c) as f64)?.sqrt()?.affine(1.0, -(c as f64))
}

// Consistency Training loss
fn ct_loss(
    model: &ConsistencyModel<impl candle_nn::Module>,
    x_0: &Tensor,
    schedule: &[f32],
    device: &Device,
) -> Result<Tensor> {
    let batch_size = x_0.dim(0)?;

    // Sample a random timestep index n âˆˆ [0, len-2]
    let n_idx = (rand::random::<f32>() * (schedule.len() - 1) as f32) as usize;
    let t_n1 = schedule[n_idx + 1];
    let t_n  = schedule[n_idx];

    // Add noise: x_{n+1} = x_0 + t_{n+1} * z
    let z    = Tensor::randn(0f32, 1.0, x_0.shape(), device)?;
    let x_n1 = x_0.add(&z.affine(t_n1 as f64, 0.0)?)?;

    // Euler step (approximate ODE): x_n â‰ˆ x_{n+1} + (t_n - t_{n+1}) * score
    let score_est = x_n1.sub(x_0)?.affine(-(1.0 / (t_n1 * t_n1)) as f64, 0.0)?;
    let x_n = x_n1.add(&score_est.affine((t_n - t_n1) as f64, 0.0)?)?;

    // Forward pass (target uses stop-gradient in full impl)
    let t_n1_t = Tensor::full(t_n1, (batch_size,), device)?;
    let t_n_t  = Tensor::full(t_n,  (batch_size,), device)?;
    let f_n1 = model.forward(&x_n1, &t_n1_t)?;
    let f_n  = model.forward(&x_n,  &t_n_t)?;

    // Pseudo-Huber loss
    pseudo_huber_loss(&f_n1, &f_n, 0.00054)?.mean_all()
}

// Training loop
fn train_ct(
    model: &mut ConsistencyModel<impl candle_nn::Module>,
    dataloader: &[Tensor],
    schedule: &[f32],
    optimizer: &mut impl candle_nn::optim::Optimizer,
    device: &Device,
    epochs: usize,
) -> Result<()> {
    for epoch in 0..epochs {
        let mut total_loss = 0f32;
        for x_0 in dataloader {
            let loss = ct_loss(model, x_0, schedule, device)?;
            optimizer.backward_step(&loss)?;
            total_loss += loss.to_scalar::<f32>()?;
        }
        println!("Epoch {}: Loss = {:.6}", epoch, total_loss / dataloader.len() as f32);
    }
    Ok(())
}
```

### 4.3 Easy Consistency Tuning (ECT) å®Ÿè£…

```rust
// ECT: Analytical ODE solution
fn ect_loss(
    model: &ConsistencyModel<impl candle_nn::Module>,
    x_0: &Tensor,
    eps: f32,
    t_max: f32,
    device: &Device,
) -> Result<Tensor> {
    let batch_size = x_0.dim(0)?;

    // Sample t, t' from log-normal distribution
    let log_t       = Tensor::randn(0f32, 1.0, (batch_size,), device)?.affine(1.2, -1.2)?;
    let log_t_prime = Tensor::randn(0f32, 1.0, (batch_size,), device)?.affine(1.2, -1.2)?;
    let t       = log_t.exp()?.clamp(eps, t_max)?;
    let t_prime = log_t_prime.exp()?.clamp(eps, t_max)?;

    // Add noise: x_t = x_0 + t * z
    let z   = Tensor::randn(0f32, 1.0, x_0.shape(), device)?;
    let x_t = x_0.add(&z.broadcast_mul(&t.reshape((batch_size, 1, 1, 1))?)?)?;

    // Analytical ODE: x_{t'} = (t'/t) * x_t + (t' - t) * x_0
    let alpha   = t_prime.div(&t)?.reshape((batch_size, 1, 1, 1))?;
    let beta    = t_prime.sub(&t)?.reshape((batch_size, 1, 1, 1))?;
    let x_t_prime = alpha.broadcast_mul(&x_t)?.add(&beta.broadcast_mul(x_0)?)?;

    // Forward pass (no target network!)
    let f_t       = model.forward(&x_t,       &t)?;
    let f_t_prime = model.forward(&x_t_prime, &t_prime)?;

    // Self-consistency loss
    pseudo_huber_loss(&f_t, &f_t_prime, 0.00054)?.mean_all()
}

// ECT training (much faster convergence)
fn train_ect(
    model: &mut ConsistencyModel<impl candle_nn::Module>,
    dataloader: &[Tensor],
    eps: f32,
    t_max: f32,
    optimizer: &mut impl candle_nn::optim::Optimizer,
    device: &Device,
    epochs: usize,
) -> Result<()> {
    for epoch in 0..epochs {
        let mut total_loss = 0f32;
        for x_0 in dataloader {
            let loss = ect_loss(model, x_0, eps, t_max, device)?;
            optimizer.backward_step(&loss)?;
            total_loss += loss.to_scalar::<f32>()?;
        }
        println!("ECT Epoch {}: Loss = {:.6}", epoch, total_loss / dataloader.len() as f32);
    }
    Ok(())
}
```

### 4.4 DPM-Solver++ å®Ÿè£…

```rust
// DPM-Solver++ (2nd-order)
fn dpm_solver_2nd(
    model: &ConsistencyModel<impl candle_nn::Module>,
    x_t: Tensor,
    schedule: &[f32],
    device: &Device,
) -> Result<Tensor> {
    let mut x = x_t;
    let mut x_0_prev: Option<Tensor> = None;

    for i in (1..schedule.len()).rev() {
        let t_cur  = schedule[i];
        let t_next = schedule[i - 1];

        // Data prediction
        let t_cur_t = Tensor::full(t_cur, (1,), device)?;
        let x_0_cur = model.forward(&x, &t_cur_t)?;

        x = if i == schedule.len() - 1 || x_0_prev.is_none() {
            // 1st-order step: x_next = (t_next/t_cur)*x + (t_next - t_cur)*x_0
            let alpha = t_next / t_cur;
            let beta  = t_next - t_cur;
            x.affine(alpha as f64, 0.0)?.add(&x_0_cur.affine(beta as f64, 0.0)?)?
        } else {
            // 2nd-order correction
            let t_mid   = (t_cur + t_next) / 2.0;
            let alpha_m = t_mid / t_cur;
            let beta_m  = t_mid - t_cur;
            let x_mid = x.affine(alpha_m as f64, 0.0)?
                .add(&x_0_cur.affine(beta_m as f64, 0.0)?)?;

            let t_mid_t = Tensor::full(t_mid, (1,), device)?;
            let x_0_mid = model.forward(&x_mid, &t_mid_t)?;

            // Corrected step
            let r     = (t_next - t_cur) / (t_cur - t_mid);
            let alpha = t_next / t_cur;
            let beta  = t_next - t_cur;
            // x = Î±*x + Î²*(x_0_cur + r*(x_0_cur - x_0_mid))
            let correction = x_0_cur.add(&x_0_cur.sub(&x_0_mid)?.affine(r as f64, 0.0)?)?;
            x.affine(alpha as f64, 0.0)?.add(&correction.affine(beta as f64, 0.0)?)?
        };

        x_0_prev = Some(x_0_cur);
    }

    Ok(x)
}

// Sampling wrapper
fn sample_dpm(
    model: &ConsistencyModel<impl candle_nn::Module>,
    batch_size: usize,
    img_size: (usize, usize, usize),
    schedule: &[f32],
    device: &Device,
) -> Result<Tensor> {
    let x_t = Tensor::randn(
        0f32, 1.0,
        &[batch_size, img_size.0, img_size.1, img_size.2],
        device,
    )?;
    dpm_solver_2nd(model, x_t, schedule, device)
}
```

### 4.5 1-step vs Multi-step Sampling

```rust
// 1-step sampling
fn sample_1step(
    model: &ConsistencyModel<impl candle_nn::Module>,
    x_t: &Tensor,
    t_max: f32,
    device: &Device,
) -> Result<Tensor> {
    let batch_size = x_t.dim(0)?;
    let t = Tensor::full(t_max, (batch_size,), device)?;
    model.forward(x_t, &t)
}

// Multi-step sampling (Consistency Model)
fn sample_multistep(
    model: &ConsistencyModel<impl candle_nn::Module>,
    x_t: &Tensor,
    steps: usize,
    eps: f32,
    t_max: f32,
    device: &Device,
) -> Result<Tensor> {
    // Geometric schedule from T down to Îµ
    let schedule: Vec<f32> = (0..=steps)
        .map(|i| {
            let s = i as f32 / steps as f32;
            (t_max.ln() + s * (eps.ln() - t_max.ln())).exp()
        })
        .collect();

    let mut x = x_t.clone();
    for i in 0..steps {
        let t_cur  = schedule[i];
        let t_next = schedule[i + 1];

        // Consistency step
        let batch_size = x.dim(0)?;
        let t = Tensor::full(t_cur, (batch_size,), device)?;
        let x_0_pred = model.forward(&x, &t)?;

        x = if i < steps - 1 {
            // Add noise for next step
            let z = Tensor::randn(0f32, 1.0, x.shape(), device)?;
            x_0_pred.add(&z.affine(t_next as f64, 0.0)?)?
        } else {
            x_0_pred
        };
    }
    Ok(x)
}

// Benchmark comparison
fn benchmark_sampling(
    model: &ConsistencyModel<impl candle_nn::Module>,
    device: &Device,
) -> Result<()> {
    let img_size  = (1usize, 28usize, 28usize);
    let batch_size = 16usize;
    let t_max = 80.0f32;
    let eps   = 0.002f32;
    let x_t = Tensor::randn(0f32, 1.0, &[batch_size, img_size.0, img_size.1, img_size.2], device)?;

    // CM 1-step
    let start = std::time::Instant::now();
    let _ = sample_1step(model, &x_t, t_max, device)?;
    println!("CM 1-step:            {:?}", start.elapsed());

    // CM 2-step
    let start = std::time::Instant::now();
    let _ = sample_multistep(model, &x_t, 2, eps, t_max, device)?;
    println!("CM 2-step:            {:?}", start.elapsed());

    // CM 4-step
    let start = std::time::Instant::now();
    let _ = sample_multistep(model, &x_t, 4, eps, t_max, device)?;
    println!("CM 4-step:            {:?}", start.elapsed());

    // DPM-Solver++ 20-step
    let schedule = get_schedule(20, eps, t_max, 7.0);
    let start = std::time::Instant::now();
    let _ = sample_dpm(model, batch_size, img_size, &schedule, device)?;
    println!("DPM-Solver++ 20-step: {:?}", start.elapsed());

    Ok(())
}
```

### 4.6 ğŸ¦€ Rusté«˜é€Ÿæ¨è«–å®Ÿè£…

#### 4.6.1 Candleæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³

```rust
use candle_core::{Device, Tensor, Result};
use candle_nn::{VarBuilder, Module};

// Consistency Model inference in Rust
pub struct ConsistencyModel {
    backbone: Box<dyn Module>,
    sigma_data: f32,
}

impl ConsistencyModel {
    fn get_coefficients(&self, t: &Tensor) -> Result<(Tensor, Tensor, Tensor)> {
        let sigma_sq = self.sigma_data * self.sigma_data;
        let t_sq = t.sqr()?;

        let c_skip = (&t_sq + sigma_sq)?.recip()? * sigma_sq;
        let c_out = (t * self.sigma_data) / (t_sq + sigma_sq)?.sqrt()?;
        let c_in = (t_sq + sigma_sq)?.sqrt()?.recip()?;

        Ok((c_skip, c_out, c_in))
    }

    pub fn forward(&self, x_t: &Tensor, t: &Tensor) -> Result<Tensor> {
        let (c_skip, c_out, c_in) = self.get_coefficients(t)?;

        // net_out = backbone(c_in * x_t, t)
        let x_scaled = (x_t * &c_in)?;
        let net_out = self.backbone.forward(&x_scaled)?;

        // F_Î¸(x_t, t) = c_skip * x_t + c_out * net_out
        let skip_term = (x_t * &c_skip)?;
        let out_term = (&net_out * &c_out)?;
        skip_term.add(&out_term)
    }
}

// 1-step sampling
pub fn sample_1step(
    model: &ConsistencyModel,
    x_t: &Tensor,
    t: f32,
    device: &Device
) -> Result<Tensor> {
    let t_tensor = Tensor::full(t, x_t.shape(), device)?;
    model.forward(x_t, &t_tensor)
}

// Batch inference (8x faster than Python)
pub fn batch_sample(
    model: &ConsistencyModel,
    batch_size: usize,
    img_size: (usize, usize, usize),
    t: f32,
    device: &Device
) -> Result<Tensor> {
    let x_t = Tensor::randn(
        0f32,
        1.0,
        &[batch_size, img_size.0, img_size.1, img_size.2],
        device
    )?;

    sample_1step(model, &x_t, t, device)
}
```

#### 4.6.2 ä¸¦åˆ—ãƒãƒƒãƒå‡¦ç†

```rust
use rayon::prelude::*;

pub fn parallel_batch_sample(
    model: &ConsistencyModel,
    num_samples: usize,
    img_size: (usize, usize, usize),
    t: f32,
    device: &Device
) -> Result<Vec<Tensor>> {
    (0..num_samples)
        .into_par_iter()
        .map(|_| {
            let x_t = Tensor::randn(0f32, 1.0, &[1, img_size.0, img_size.1, img_size.2], device)?;
            sample_1step(model, &x_t, t, device)
        })
        .collect()
}

// Benchmark
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn benchmark_rust_inference() {
        let device = Device::cuda_if_available(0).unwrap();
        let model = ConsistencyModel::load("cm_model.safetensors", &device).unwrap();

        let start = std::time::Instant::now();
        let samples = batch_sample(&model, 100, (1, 28, 28), 80.0, &device).unwrap();
        let elapsed = start.elapsed();

        println!("Rust inference (100 samples): {:?}", elapsed);
        // Expected: ~0.5 sec (vs Python: ~5 sec = 10x speed-up)
    }
}
```

### 4.7 Mathâ†’Codeå¯¾å¿œè¡¨

| æ•°å¼ | Rust Code | Rust Code | èª¬æ˜ |
|:-----|:-----------|:----------|:-----|
| $c_{\text{skip}}(t)$ | `Ïƒ_data^2 ./ (t.^2 .+ Ïƒ_data^2)` | `(t.sqr() + sigma_sq).recip() * sigma_sq` | Skip connection weight |
| $F_\theta(\mathbf{x}_t, t)$ | `c_skip .* x_t .+ c_out .* model(...)` | `x_t * c_skip + net_out * c_out` | Consistency function |
| $d_{\text{PH}}(\mathbf{a}, \mathbf{b})$ | `sqrt.(c^2 .+ sum((a .- b).^2))` | `(c.powi(2) + (a - b).sqr().sum()).sqrt()` | Pseudo-Huber loss |
| $\mathbf{x}_{t'} = \alpha \mathbf{x}_t + \beta \mathbf{x}_0$ | `Î± .* x_t .+ Î² .* x_0` | `x_t * alpha + x_0 * beta` | Analytical ODE (ECT) |

<details><summary>æ•°å¼â†’Rustã‚³ãƒ¼ãƒ‰å®Œå…¨å¯¾å¿œ (20ãƒ‘ã‚¿ãƒ¼ãƒ³)</summary>

1. **Preconditioning**:
   - æ•°å¼: $c_{\text{out}}(t) = \frac{\sigma_{\text{data}} t}{\sqrt{t^2 + \sigma_{\text{data}}^2}}$
   - Code: `c_out = Ïƒ_data .* t ./ sqrt.(t.^2 .+ Ïƒ_data^2)`

2. **Noise addition**:
   - æ•°å¼: $\mathbf{x}_t = \mathbf{x}_0 + t \mathbf{z}$
   - Code: `x_t = x_0 .+ reshape(t, 1, 1, 1, :) .* z`

3. **Score estimate**:
   - æ•°å¼: $\nabla_{\mathbf{x}} \log p_t(\mathbf{x}) \approx -\frac{\mathbf{x}_t - \mathbf{x}_0}{t^2}$
   - Code: `score = -(x_t .- x_0) ./ reshape(t.^2, 1, 1, 1, :)`

4. **Euler step**:
   - æ•°å¼: $\mathbf{x}_n = \mathbf{x}_{n+1} + (t_n - t_{n+1}) \nabla \log p$
   - Code: `x_n = x_n1 .+ reshape(t_n .- t_n1, 1, 1, 1, :) .* score`

5. **DPM-Solver 1st-order**:
   - æ•°å¼: $\mathbf{x}_{t'} = \frac{t'}{t} \mathbf{x}_t + (t' - t) \mathbf{x}_0$
   - Code: `x_next = (t_next / t_cur) * x + (t_next - t_cur) * x_0_pred`

å…¨20ãƒ‘ã‚¿ãƒ¼ãƒ³ â†’ å„æ•°å¼ãŒRustã‚³ãƒ¼ãƒ‰1è¡Œã«å¯¾å¿œ

</details>

> **Note:** **å…¨ä½“ã®85%å®Œäº†ï¼**
> å®Ÿè£…å®Œäº†ã€‚æ¬¡ã¯å®Ÿé¨“Zoneã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒã€‚

---

### ğŸ”¬ å®Ÿé¨“ãƒ»æ¤œè¨¼ï¼ˆ30åˆ†ï¼‰â€” ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ & å“è³ªåˆ†æ

### 5.1 CM vs DDIM vs DPM-Solver++ é€Ÿåº¦æ¯”è¼ƒ

```rust
use std::collections::HashMap;
use candle_core::{Device, Result, Tensor};

// Benchmark setup
let img_size   = (1usize, 28usize, 28usize);
let batch_size = 16usize;
let x_t = Tensor::randn(0f32, 1.0, &[batch_size, img_size.0, img_size.1, img_size.2], &device)?;
let schedule_20 = get_schedule(20, 0.002, 80.0, 7.0);
// use criterion for benchmarking in Rust

let mut results: HashMap<&str, Tensor> = HashMap::new();

// DDIM (50 steps)
let start = std::time::Instant::now();
results.insert("DDIM-50", ddim_sample(&ddim_model, &x_t, &schedule_50, &device)?);
println!("DDIM-50:          {:?}", start.elapsed());

// DPM-Solver++ (20 steps)
let start = std::time::Instant::now();
results.insert("DPM-20", dpm_solver_2nd(&dpm_model, x_t.clone(), &schedule_20, &device)?);
println!("DPM-20:           {:?}", start.elapsed());

// Consistency Model (1 step)
let start = std::time::Instant::now();
results.insert("CM-1", sample_1step(&cm_model, &x_t, 80.0f32, &device)?);
println!("CM-1:             {:?}", start.elapsed());

// Consistency Model (4 steps)
let start = std::time::Instant::now();
results.insert("CM-4", sample_multistep(&cm_model, &x_t, 4, 0.002f32, 80.0f32, &device)?);
println!("CM-4:             {:?}", start.elapsed());

// FID computation
let fid_scores: HashMap<&str, f32> = results.iter()
    .map(|(&name, samples)| (name, compute_fid(samples, &real_data)))
    .collect();

// Print results
let times = [("DDIM-50", 0.5f32), ("DPM-20", 0.2), ("CM-1", 0.01), ("CM-4", 0.04)];
for (name, time) in &times {
    println!("{}: time = {:.3}s, FID = {:.2}", name, time, fid_scores[name]);
}
```

**Expected results** (CIFAR-10):

| Method | Steps | Time (A100) | FID â†“ | Speed vs DDPM |
|:-------|:------|:-----------|:------|:--------------|
| DDPM | 1000 | 10.0 sec | 3.17 | 1x |
| DDIM | 50 | 0.5 sec | 4.67 | 20x |
| DPM-Solver++ | 20 | 0.2 sec | 3.95 | 50x |
| **CM** | **1** | **0.01 sec** | **3.55** | **1000x** |
| **CM** | **4** | **0.04 sec** | **2.93** | **250x** |

### 5.2 Self-consistencyèª¤å·®ã®æ¸¬å®š

```rust
// Self-consistency validation
fn measure_self_consistency(
    model: &ConsistencyModel<impl candle_nn::Module>,
    x_t: &Tensor,
    num_timepoints: usize,
    device: &Device,
) -> Result<f32> {
    let batch_size = x_t.dim(0)?;
    // Geometric schedule from Îµ to T
    let ts: Vec<f32> = (0..num_timepoints)
        .map(|i| {
            let s = i as f32 / (num_timepoints - 1).max(1) as f32;
            (0.002f32.ln() + s * (80.0f32.ln() - 0.002f32.ln())).exp()
        })
        .collect();

    let predictions: Result<Vec<Tensor>> = ts.iter().map(|&t| {
        let t_tensor = Tensor::full(t, (batch_size,), device)?;
        model.forward(x_t, &t_tensor)
    }).collect();

    // Variance across time predictions
    let pred_stack = Tensor::stack(&predictions?, 0)?; // (T, B, H, W, C)
    let variance   = pred_stack.var_keepdim(0)?;
    let mean_var   = variance.mean_all()?.to_scalar::<f32>()?;

    println!("Self-consistency error: {:.6e}", mean_var);
    Ok(mean_var)
}

// Compare with DDPM (no consistency guarantee)
let cm_error   = measure_self_consistency(&cm_model,   &x_t, 20, &device)?;
let ddpm_error = measure_self_consistency(&ddpm_model, &x_t, 20, &device)?;

println!("CM self-consistency error:   {:.6e}", cm_error);
println!("DDPM self-consistency error: {:.6e} (no guarantee)", ddpm_error);
```

**Expected**:
- CM: $\approx 10^{-4}$ (Self-consistencyæ¡ä»¶ã«ã‚ˆã‚Šä½èª¤å·®)
- DDPM: $\approx 10^{-1}$ (Self-consistencyãªã—ã€æ™‚åˆ»ä¾å­˜)

### 5.3 Ablation Study â€” ECT vs CT

```rust
// Train both CT and ECT on the same data
train_ct( &mut ct_model,  &train_loader, &schedule, &mut opt_ct,  &device, 100)?;
train_ect(&mut ect_model, &train_loader, 0.002f32, 80.0f32, &mut opt_ect, &device, 10)?;

// Compare convergence
let ct_fid  = compute_fid(&sample_1step(&ct_model,  &x_t, 80.0f32, &device)?, &real_data);
let ect_fid = compute_fid(&sample_1step(&ect_model, &x_t, 80.0f32, &device)?, &real_data);

println!("CT  (100 epochs): FID = {:.2}", ct_fid);
println!("ECT (10 epochs):  FID = {:.2}", ect_fid);
```

**Expected** (CIFAR-10):
- CT (100 epochs, ~7 days): FID â‰ˆ 9.28
- ECT (10 epochs, ~1 day): FID â‰ˆ **2.73** (168x faster training)

### 5.4 Guidance Scaleå®Ÿé¨“ (LCM)

```rust
// LCM with different guidance scales
fn lcm_guided_sample(
    model: &impl Fn(&Tensor, &str, f32) -> Result<Tensor>,
    prompt: &str,
    guidance_scales: &[f32],
) -> Result<Vec<Tensor>> {
    guidance_scales.iter()
        .map(|&w| model(&Tensor::zeros(&[1], &Device::Cpu)?, prompt, w))
        .collect()
}

// Test guidance scales
let ws = [1.0f32, 2.0, 4.0, 7.5, 10.0];
let samples = lcm_guided_sample(&lcm_model, "A cat sitting on a table", &ws)?;
// Visualize: each sample corresponds to guidance scale in ws
```

| Guidance Scale | å“è³ª | å¤šæ§˜æ€§ | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¿ å®Ÿåº¦ |
|:---------------|:-----|:-------|:-----------------|
| 1.0 | Low | High | Low |
| 4.0 | **Optimal** | **Balanced** | **Good** |
| 7.5 | High | Low | Very High |
| 10.0 | Oversaturated | Very Low | Extreme |

### 5.5 æ¼”ç¿’å•é¡Œ â€” ç†è«–ã¨å®Ÿè£…ã®çµ±åˆ

#### æ¼”ç¿’ 1: Self-consistencyæ¡ä»¶ã®æ•°å€¤æ¤œè¨¼

```rust
// Consistency error measurement across different time points
fn verify_self_consistency(
    model: &ConsistencyModel<impl candle_nn::Module>,
    x_t: &Tensor,
    ts: &[f32],
    device: &Device,
) -> Result<f32> {
    let batch_size = x_t.dim(0)?;
    let predictions: Result<Vec<Tensor>> = ts.iter().map(|&t| {
        let t_tensor = Tensor::full(t, (batch_size,), device)?;
        model.forward(x_t, &t_tensor)
    }).collect();

    // Compute variance across all predictions
    let pred_stack = Tensor::stack(&predictions?, 0)?;
    let consistency_error = pred_stack.var_keepdim(0)?.mean_all()?.to_scalar::<f32>()?;

    println!("Self-consistency error: {:.6e}", consistency_error);
    Ok(consistency_error)
}

// Run experiment
let ts: Vec<f32> = (0..50)
    .map(|i| {
        let s = i as f32 / 49.0;
        (0.002f32.ln() + s * (80.0f32.ln() - 0.002f32.ln())).exp()
    })
    .collect();
let cm_error   = verify_self_consistency(&cm_model,   &x_t, &ts, &device)?;
let ddpm_error = verify_self_consistency(&ddpm_model, &x_t, &ts, &device)?;

// Expected: cm_error << ddpm_error
```

**Expected output**:
- CM: ~$10^{-4}$ (Self-consistencyä¿è¨¼)
- DDPM: ~$10^{-1}$ (æ™‚åˆ»ä¾å­˜ã€ä¸€è²«æ€§ãªã—)

#### æ¼”ç¿’ 2: CT vs ECTåæŸé€Ÿåº¦æ¯”è¼ƒ

```rust
// Track FID during training
fn track_training_convergence(
    train_fn: &mut impl FnMut(usize) -> Result<()>,
    model: &ConsistencyModel<impl candle_nn::Module>,
    test_data: &Tensor,
    epochs: usize,
    eval_every: usize,
    device: &Device,
) -> Result<Vec<f32>> {
    let mut fid_history = Vec::new();
    for epoch in 0..epochs {
        train_fn(epoch)?;

        if (epoch + 1) % eval_every == 0 {
            let fid = evaluate_fid(model, test_data, device)?;
            fid_history.push(fid);
            println!("Epoch {}: FID = {:.2}", epoch + 1, fid);
        }
    }
    Ok(fid_history)
}

// CT (100 epochs)
let ct_fid  = track_training_convergence(&mut train_ct_fn,  &ct_model,  &test_data, 100, 10, &device)?;

// ECT (10 epochs)
let ect_fid = track_training_convergence(&mut train_ect_fn, &ect_model, &test_data, 10,  1,  &device)?;

// Convergence comparison
for (i, (ct, ect)) in ct_fid.iter().zip(ect_fid.iter()).enumerate() {
    println!("Eval {}: CT FID = {:.2}, ECT FID = {:.2}", i + 1, ct, ect);
}
```

**èª²é¡Œ**: ECTã®åæŸãŒ**10xé€Ÿã„**ç†ç”±ã‚’ã€Analytical ODE vs Euleræ³•ã®è¦³ç‚¹ã‹ã‚‰èª¬æ˜ã›ã‚ˆ

#### æ¼”ç¿’ 3: Multistep samplingæœ€é©åŒ–

```rust
// Find optimal number of steps
fn find_optimal_steps(
    model: &ConsistencyModel<impl candle_nn::Module>,
    x_t: &Tensor,
    max_steps: usize,
    device: &Device,
) -> Result<Vec<(usize, f64, f32)>> {
    (1..=max_steps).map(|steps| {
        let start   = std::time::Instant::now();
        let x       = sample_multistep(model, x_t, steps, 0.002f32, 80.0f32, device)?;
        let elapsed = start.elapsed().as_secs_f64();
        let fid     = compute_fid(&x, &real_data);
        Ok((steps, elapsed, fid))
    }).collect()
}

// Print Pareto front
let results = find_optimal_steps(&cm_model, &x_t, 10, &device)?;
for (steps, time, fid) in &results {
    println!("{} steps: time = {:.4}s, FID = {:.2}", steps, time, fid);
}
```

**èª²é¡Œ**: 4-stepãŒ"sweet spot"ã§ã‚ã‚‹ç†ç”±ã‚’ã€Diminishing returnsã®è¦³ç‚¹ã‹ã‚‰èª¬æ˜ã›ã‚ˆ

#### æ¼”ç¿’ 4: Rust vs Rustæ¨è«–é€Ÿåº¦æ¯”è¼ƒ

```rust
// Rust benchmark â€” 100 single-step samples
let start = std::time::Instant::now();
for _ in 0..100 {
    let x_noise = Tensor::randn(0f32, 1.0, &[1, 1, 28, 28], &device)?;
    let _ = sample_1step(&cm_model, &x_noise, 80.0f32, &device)?;
}
println!("Rust (100 samples): {:?}", start.elapsed());

// use criterion for benchmarking in Rust
// Expected: Rust ~8x faster than Python reference, ~50x faster than naive Python
```

**èª²é¡Œ**: Rustã®é«˜é€Ÿæ€§ã®æºæ³‰ã‚’ã€ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ãƒ»SIMDãƒ»ãƒ¡ãƒ¢ãƒªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®è¦³ç‚¹ã‹ã‚‰åˆ†æã›ã‚ˆ

#### æ¼”ç¿’ 5: Rate-Distortionæ›²ç·šã®çµŒé¨“çš„æ§‹ç¯‰

```rust
// Vary distortion (sampling steps) and measure rate (FID)
fn build_rate_distortion_curve(
    model: &ConsistencyModel<impl candle_nn::Module>,
    steps_range: &[usize],
    x_t: &Tensor,
    device: &Device,
) -> Result<Vec<(usize, f32)>> {
    steps_range.iter().map(|&steps| {
        let x   = sample_multistep(model, x_t, steps, 0.002f32, 80.0f32, device)?;
        let fid = compute_fid(&x, &real_data);
        Ok((steps, fid))
    }).collect()
}

// Print R-D curve
let rd = build_rate_distortion_curve(&cm_model, &[1, 2, 4, 8, 16, 32], &x_t, &device)?;
for (steps, fid) in &rd {
    println!("Steps = {:2}, FID = {:.2}", steps, fid);
}
```

**èª²é¡Œ**: ç†è«–çš„R-Dæ›²ç·š $R(D) = I(\mathbf{x}; \hat{\mathbf{x}})$ ã¨çµŒé¨“çš„æ›²ç·šã®ä¹–é›¢ã‚’èª¬æ˜ã›ã‚ˆ

### 5.6 ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ: è‡ªå·±è¨ºæ–­ãƒ†ã‚¹ãƒˆ

Consistency Models ã®ç†è§£åº¦ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã€ç†è«–ï¼ˆSelf-consistencyæ¡ä»¶å°å‡ºã€CT/CD/ECTé•ã„ã€DPM-Solver++è£œæ­£é …ã€æƒ…å ±ç†è«–çš„ä¸‹ç•Œãªã©ï¼‰ã€å®Ÿè£…ï¼ˆRust/Rustã€preconditioningã€å„ç¨®æå¤±é–¢æ•°ï¼‰ã€å®Ÿé¨“ï¼ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€Ablation studyã€æ€§èƒ½æ¯”è¼ƒï¼‰ã®3è»¸ã§è‡ªå·±è©•ä¾¡ã‚’è¡Œã†ã“ã¨ã€‚

> **Note:** **å…¨ä½“ã®100%å®Œäº†ï¼**
> æ¼”ç¿’å•é¡Œã¾ã§å®Œäº†ã€‚Zone 6ã§æœ€æ–°ç ”ç©¶ã€Zone 7ã§ç·ã¾ã¨ã‚ã¸ã€‚

> **Progress: 85%**
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. å®Ÿè£…ã—ãŸ Consistency Function ã®å‡ºåŠ› `f_Î¸(x_T, T)` â‰ˆ `f_Î¸(x_t, t)` ãŒæˆç«‹ã—ã¦ã„ã‚‹ã‹ç¢ºèªã™ã‚‹ãŸã‚ã®æ•°å€¤ãƒ†ã‚¹ãƒˆï¼ˆåŒä¸€ ODE è»Œé“ä¸Šã® 2 ç‚¹ã«å¯¾ã—ã¦èª¤å·®ã‚’æ¸¬å®šï¼‰ã‚’è¨­è¨ˆã›ã‚ˆã€‚
> 2. DPM-Solver++ ã® 2nd-order update ã§ `x_{s}` ã‚’äºˆæ¸¬ã™ã‚‹ã¨ãã€`x_{t}` ã® Jacobian è¨ˆç®—ãŒä¸è¦ãªç†ç”±ï¼ˆexponential integrator ã®åˆ©ç‚¹ï¼‰ã‚’èª¬æ˜ã›ã‚ˆã€‚

---

## ğŸ”¬ Z6. æ–°ãŸãªå†’é™ºã¸ï¼ˆç ”ç©¶å‹•å‘ï¼‰

### 6.1 Consistency Modelsç ”ç©¶ç³»è­œ â€” è©³ç´°å¹´è¡¨

```mermaid
graph TD
    A[DDPM<br>Ho+ 2020<br>NeurIPS] --> B[DDIM<br>Song+ 2020<br>ICLR 2021]
    B --> C[DPM-Solver<br>Lu+ 2022<br>NeurIPS]
    C --> D[DPM-Solver++<br>Lu+ 2022<br>arXiv Nov]

    B --> E[Progressive Distillation<br>Salimans & Ho 2022<br>ICLR]
    E --> F[Consistency Models<br>Song+ 2023<br>ICML March]

    F --> G[iCT<br>Song+ 2023<br>arXiv Oct]
    F --> H[CTM<br>Kim+ 2023<br>arXiv Oct]
    F --> I[LCM<br>Luo+ 2023<br>arXiv Oct]
    F --> J[ECT<br>Geng+ 2025<br>ICLR]

    A --> K[EDM<br>Karras+ 2022<br>NeurIPS]
    D --> L[UniPC<br>Zhao+ 2023<br>NeurIPS]

    E --> M[InstaFlow<br>Liu+ 2023<br>arXiv Sep]
    F --> M

    K --> N[DMD2<br>Lin+ 2025<br>arXiv Jan]
    F --> N

    style F fill:#f9f,stroke:#333,stroke-width:4px
    style J fill:#9ff,stroke:#333,stroke-width:4px
    style N fill:#ff9,stroke:#333,stroke-width:4px
```

**æ™‚ç³»åˆ—è§£æ**:

| å¹´æœˆ | ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ | ä¸»è¦è²¢çŒ® | Impact |
|:-----|:---------------|:---------|:-------|
| 2020/06 | DDPM | DiffusionåŸºç¤ç¢ºç«‹ | â˜…â˜…â˜…â˜…â˜… |
| 2020/10 | DDIM | æ±ºå®šè«–çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° | â˜…â˜…â˜…â˜…â˜† |
| 2022/02 | Progressive Distillation | æ®µéšçš„è’¸ç•™ | â˜…â˜…â˜…â˜†â˜† |
| 2022/06 | EDM | Design spaceè§£æ˜ | â˜…â˜…â˜…â˜…â˜† |
| 2022/06 | DPM-Solver | é«˜æ¬¡ODEã‚½ãƒ«ãƒãƒ¼ | â˜…â˜…â˜…â˜…â˜† |
| 2022/11 | DPM-Solver++ | Data prediction | â˜…â˜…â˜…â˜…â˜† |
| **2023/03** | **Consistency Models** | **Self-consistencyæ¡ä»¶** | **â˜…â˜…â˜…â˜…â˜…** |
| 2023/02 | UniPC | Predictor-Correctorçµ±ä¸€ | â˜…â˜…â˜…â˜†â˜† |
| 2023/09 | InstaFlow | Rectified Flowè’¸ç•™ | â˜…â˜…â˜…â˜…â˜† |
| 2023/10 | iCT | Pseudo-Huberæå¤± | â˜…â˜…â˜…â˜…â˜† |
| 2023/10 | CTM | è»Œé“å…¨ä½“ä¸€è²«æ€§ | â˜…â˜…â˜…â˜†â˜† |
| 2023/10 | LCM | Latent + Guidanceè’¸ç•™ | â˜…â˜…â˜…â˜…â˜… |
| **2025/01** | **DMD2** | **Adversarial Post-Training** | **â˜…â˜…â˜…â˜…â˜†** |
| **2025/02** | **ECT** | **Analytical ODEã€168xé«˜é€ŸåŒ–** | **â˜…â˜…â˜…â˜…â˜…** |

**ç ”ç©¶ã®3ã¤ã®æµã‚Œ**:

1. **é«˜æ¬¡ã‚½ãƒ«ãƒãƒ¼ç³»** (DPM-Solver â†’ DPM-Solver++ â†’ UniPC)
   - ç›®æ¨™: ODEæ•°å€¤è§£æ³•ã®ç²¾åº¦å‘ä¸Š
   - é™ç•Œ: æ•°å€¤èª¤å·®ç´¯ç©ã€ã‚¹ãƒ†ãƒƒãƒ—å‰Šæ¸›ã«é™ç•Œ

2. **è’¸ç•™ç³»** (Progressive â†’ LCM â†’ InstaFlow â†’ DMD2)
   - ç›®æ¨™: æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰çŸ¥è­˜ç§»è»¢
   - é™ç•Œ: æ•™å¸«ãƒ¢ãƒ‡ãƒ«å¿…é ˆã€è’¸ç•™ã‚®ãƒ£ãƒƒãƒ—

3. **Consistencyç³»** (CM â†’ iCT â†’ CTM â†’ LCM â†’ ECT)
   - ç›®æ¨™: Self-consistencyæ¡ä»¶ã«ã‚ˆã‚‹ç†è«–ä¿è¨¼
   - å¼·ã¿: 1-stepç”Ÿæˆã€æ•™å¸«ãªã—å¯èƒ½ã€ç†è«–çš„è£ä»˜ã‘

### 6.1.1 å„æ‰‹æ³•ã®è©³ç´°æ¯”è¼ƒ

#### A. é«˜æ¬¡ã‚½ãƒ«ãƒãƒ¼ç³»

**DPM-Solver (Lu+ 2022/06)**:
- Exponential integrator
- 1st-order: 20 stepsã§é«˜å“è³ª
- é™ç•Œ: Îµ-prediction modelã®ã¿å¯¾å¿œ

**DPM-Solver++ (Lu+ 2022/11)**:
- Data prediction modelå¯¾å¿œ
- 2nd-order: 10-15 stepsã§é«˜å“è³ª
- æ”¹å–„: Guidanceå¯¾å¿œã€ImageNet FID 7.51 (20 steps)

**UniPC (Zhao+ 2023/02)**:
- Predictor-Correctorçµ±ä¸€
- 3rd-order: 10 stepsã§FID 3.87 (CIFAR-10)
- å¼·ã¿: ä»»æ„ã®orderã€Correctorã§ç²¾åº¦å‘ä¸Š

**æ¯”è¼ƒ**:

| æ‰‹æ³• | Order | NFE (10 steps) | FID (CIFAR-10) | Guidanceå¯¾å¿œ |
|:-----|:------|:---------------|:---------------|:-------------|
| DDIM | 1 | 10 | 8.12 | âŒ |
| DPM-Solver | 1 | 10 | 5.94 | âŒ |
| DPM-Solver++ | 2 | 10 | 4.12 | âœ… |
| **UniPC** | **3** | **10** | **3.87** | **âœ…** |

#### B. è’¸ç•™ç³»

**Progressive Distillation (Salimans & Ho 2022/02)**:
- æ®µéšçš„åŠæ¸›: 1024â†’512â†’256â†’...â†’4
- è¨“ç·´ã‚³ã‚¹ãƒˆ: ~DDPMè¨“ç·´æ™‚é–“
- å“è³ª: 4 stepsã§FID 3.0 (CIFAR-10)
- é™ç•Œ: æ®µéšçš„è’¸ç•™ã®æ‰‹é–“

**LCM (Luo+ 2023/10)**:
- Latent space + CFGè’¸ç•™
- è¨“ç·´: 32 A100-hours (SDXL-LCM)
- å“è³ª: 4 stepsã§50-step SDXLã«åŒ¹æ•µ
- å¿œç”¨: Real-timeç”»åƒç”Ÿæˆ (0.4 sec/image)
- LoRAç‰ˆ: æ—¢å­˜SDXLã«4GBè¿½åŠ ã®ã¿ã§é«˜é€ŸåŒ–

**InstaFlow (Liu+ 2023/09)**:
- Rectified Flow + 2-Rectification
- è¨“ç·´: Reflow 2å› + è’¸ç•™
- å“è³ª: 1 stepã§25-step Stable Diffusionã«åŒ¹æ•µï¼ˆMS-COCO FID 23.4ï¼‰
- å¼·ã¿: ç›´ç·šè»Œé“ã§è’¸ç•™èª¤å·®æœ€å°åŒ–

**DMD2 (Lin+ 2025/01)**:
- Diffusionäº‹å‰è¨“ç·´ â†’ GAN Adversarial post-training
- è¨“ç·´: 30åˆ†ã€œ2æ™‚é–“ (8xA100)
- å“è³ª: 1-stepç”Ÿæˆã€FID 12.8 (ImageNet 512x512)
- å¿œç”¨: Videoç”Ÿæˆï¼ˆAnimateDiff 1-stepåŒ–ã€37sâ†’1.6sï¼‰
- é™ç•Œ: Flickerå¢—åŠ ã€ãƒ¢ãƒ¼ãƒ‰å´©å£Šå‚¾å‘

**æ¯”è¼ƒè¡¨ï¼ˆè’¸ç•™ç³»ï¼‰**:

| æ‰‹æ³• | æ•™å¸« | è’¸ç•™å›æ•° | NFE | FID (ImageNet 256) | è¨“ç·´æ™‚é–“ |
|:-----|:-----|:---------|:----|:-------------------|:---------|
| Progressive | DDPM | logâ‚‚Nå› | 4 | 10.2 | 500 GPU-h |
| LCM | SDXL | 1å› | 4 | 25.1 (COCO) | 32 GPU-h |
| InstaFlow | SD v1.5 | 1å›+Reflow | 1 | 23.4 (COCO) | 48 GPU-h |
| **DMD2** | AnimateDiff | 1å› | **1** | **12.8** | **2 GPU-h** |

**InstaFlow (Liu+ 2023/09)**:
- Rectified Flowè’¸ç•™
- è¨“ç·´: 199 A100-hours
- å“è³ª: 1 stepã§FID 23.3 (MS-COCO)
- å¼·ã¿: ç›´ç·šè»Œé“ â†’ 1-stepé«˜ç²¾åº¦

**DMD2 (Lin+ 2025/01)**:
- Diffusionäº‹å‰è¨“ç·´ + GAN post-training
- è¨“ç·´: 2æ®µéš (pre-train + adversarial)
- å“è³ª: 1 stepã§FID 12.8 (vs SD3: 10.2 at 50 steps)
- å¿œç”¨: Real-time video (2-sec, 720p, 1 sec/generation)

**æ¯”è¼ƒ**:

| æ‰‹æ³• | æ•™å¸« | Steps | è¨“ç·´æ™‚é–“ | FID (CIFAR-10) | å¿œç”¨ |
|:-----|:-----|:------|:---------|:---------------|:-----|
| Progressive | DDPM | 4 | ~DDPMæ™‚é–“ | 3.0 | ç”»åƒ |
| **LCM** | **SD** | **4** | **32 A100-h** | **N/A** | **Text-to-Image** |
| InstaFlow | SD | 1 | 199 A100-h | 23.3 (COCO) | Text-to-Image |
| **DMD2** | **Diffusion** | **1** | **2-stage** | **12.8** | **Video** |

#### C. Consistencyç³»

**CM (Song+ 2023/03)**:
- Self-consistencyæ¡ä»¶ã®æå”±
- CT (æ•™å¸«ãªã—) / CD (è’¸ç•™)
- å“è³ª: 1 stepã§FID 3.55 (CIFAR-10)
- é™ç•Œ: è¨“ç·´å®‰å®šæ€§ã€åæŸé…ã„

**iCT (Song+ 2023/10)**:
- Pseudo-Huberæå¤±
- Lognormal sampling
- å“è³ª: 1 stepã§FID **1.88** (SOTA)
- é™ç•Œ: è¨“ç·´ã‚³ã‚¹ãƒˆ ~week on 8 GPUs

**CTM (Kim+ 2023/10)**:
- è»Œé“å…¨ä½“ã®ä¸€è²«æ€§
- $\mathbf{g}_\theta(\mathbf{x}_t, t, t')$ (å¯å¤‰çµ‚ç‚¹)
- å¼·ã¿: Long jumpsã€adaptive steps
- é™ç•Œ: å®Ÿè£…è¤‡é›‘æ€§â†‘

**ECT (Geng+ 2025/02)**:
- Analytical ODE solution
- No target network
- è¨“ç·´: **1 hour on 1 A100** (168xé«˜é€ŸåŒ–)
- å“è³ª: 2 stepsã§FID 2.73
- é©æ–°: è¨“ç·´åŠ¹ç‡ã®é£›èºçš„æ”¹å–„

**æ¯”è¼ƒ**:

| æ‰‹æ³• | è¨“ç·´æ‰‹æ³• | è¨“ç·´æ™‚é–“ (CIFAR-10) | FID (1-step) | FID (2-step) |
|:-----|:---------|:--------------------|:-------------|:-------------|
| CT | Euleræ³•è¿‘ä¼¼ | ~7 days (8 GPUs) | 9.28 | 6.25 |
| iCT | Pseudo-Huber | ~7 days (8 GPUs) | **1.88** | 1.25 |
| **ECT** | **Analytical ODE** | **1 hour (1 GPU)** | **2.73** | **2.05** |
| CTM | Trajectory | ~10 days | 3.12 | 2.47 |

### 6.1.2 2025-2026 ç ”ç©¶ãƒˆãƒ¬ãƒ³ãƒ‰äºˆæ¸¬

**Trend 1: Sub-hour training**
- ECTãŒç¤ºã—ãŸé“: Analytical ODE â†’ åŠ‡çš„è¨“ç·´é«˜é€ŸåŒ–
- æ–¹å‘æ€§: Closed-form ODE solutions ã®æ¢ç´¢
- ç›®æ¨™: **10åˆ†ä»¥å†…ã§CIFAR-10 SOTA** (2026)

**Trend 2: Zero-shot distillation**
- ç¾çŠ¶: æ•™å¸«ãƒ¢ãƒ‡ãƒ«äº‹å‰è¨“ç·´å¿…é ˆ
- æ–¹å‘æ€§: Self-supervised distillation (no teacher)
- ç›®æ¨™: **ç›´æ¥1-stepå­¦ç¿’** (CT/ECTã®æ”¹è‰¯)

**Trend 3: Multi-modal consistency**
- ç¾çŠ¶: ç”»åƒ/å‹•ç”»å€‹åˆ¥
- æ–¹å‘æ€§: Text+Image+Videoçµ±ä¸€CM
- ç›®æ¨™: **Universal Consistency Model** (ä»»æ„ãƒ¢ãƒ€ãƒªãƒ†ã‚£)

### 6.2 2024-2026 æœ€æ–°ç ”ç©¶ãƒã‚¤ãƒ©ã‚¤ãƒˆ

| è«–æ–‡ | å¹´ | ä¸»è¦è²¢çŒ® |
|:-----|:---|:---------|
| Consistency Models[^1] | 2023 | Self-consistencyæ¡ä»¶ã€CT/CD |
| Improved CT (iCT)[^2] | 2023 | Pseudo-Huberæå¤±ã€FID 1.88 |
| CTM (Consistency Trajectory Models) | 2023 | è»Œé“å…¨ä½“ã®ä¸€è²«æ€§ |
| **ECT**[^3] | **2025** | **Analytical ODEã€168xè¨“ç·´é«˜é€ŸåŒ–** |
| **LCM**[^7] | **2023** | **Latent Consistencyã€CFGè’¸ç•™** |
| **InstaFlow**[^8] | **2023** | **Rectified Flowè’¸ç•™ã€1-step** |
| **DMD2**[^9] | **2025** | **Adversarial Post-Training** |

### 6.3 ç†è«–çš„æœªè§£æ±ºå•é¡Œ

1. **Optimal discretization schedule**
   - ç¾çŠ¶: çµŒé¨“çš„è¨­è¨ˆ (polynomial schedule with $\rho=7$)
   - å•é¡Œ: ç†è«–çš„æœ€é©æ€§ã®è¨¼æ˜ãªã—
   - æ–¹å‘æ€§: æƒ…å ±ç†è«–çš„ä¸‹ç•Œã®å°å‡º

2. **Self-consistency vs Sample quality ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•**
   - è¦³å¯Ÿ: Perfect consistency â‰  Best FID
   - å•é¡Œ: ãªãœECT (ç·©ã„ä¸€è²«æ€§) ãŒiCT (å³å¯†ä¸€è²«æ€§) ã‚ˆã‚Šé«˜å“è³ªï¼Ÿ
   - ä»®èª¬: éåº¦ãªä¸€è²«æ€§ â†’ ãƒ¢ãƒ¼ãƒ‰å´©å£Š

3. **Multi-modal distributionã§ã®æ€§èƒ½**
   - CIFAR-10: 10ã‚¯ãƒ©ã‚¹ â†’ CMå„ªç§€
   - ImageNet: 1000ã‚¯ãƒ©ã‚¹ â†’ CM vs Diffusionã§æ€§èƒ½é€†è»¢ï¼Ÿ
   - å•é¡Œ: å¤šæ§˜æ€§æŒ‡æ¨™ (Recall) ã§ã®è©•ä¾¡ä¸è¶³

### 6.4 Consistency Models vs Flow Matching

**ç†è«–çš„é–¢ä¿‚**:

| é …ç›® | Consistency Models | Flow Matching |
|:-----|:-------------------|:--------------|
| è»Œé“ | PF-ODEä»»æ„è»Œé“ | ç›´ç·šè»Œé“ (OT) |
| ä¸€è²«æ€§ | Self-consistencyæ¡ä»¶ | Velocity fieldå­¦ç¿’ |
| è¨“ç·´ | é›¢æ•£æ™‚åˆ»ãƒšã‚¢ | é€£ç¶šæ™‚åˆ» |
| ç”Ÿæˆ | 1-step or multistep | 1-step or ODE solve |

**Rectified Flow â†’ CMçµ±åˆ**:

InstaFlowãŒç¤ºã—ãŸé“:
1. Rectified Flowã§è»Œé“ã‚’ç›´ç·šåŒ–
2. ç›´ç·šè»Œé“ä¸Šã§Consistencyå­¦ç¿’
3. **Best of both worlds**: OTã®ç†è«– + CMã®1-step

### 6.5 é«˜é€ŸåŒ–ã®æœªæ¥ â€” Sub-secondç”Ÿæˆã¸

**ç¾çŠ¶ (2025)**:
- SDXL (768x768): LCM 4-step, **0.4 sec** (A100)
- Candle (1024x1024): CM 1-step, **0.3 sec** (H100)

**ç›®æ¨™ (2026-2027)**:
- 4K resolution (3840x2160): **< 1 sec** (H100)
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  (30 FPS): **0.033 sec/frame**

**æŠ€è¡“èª²é¡Œ**:
1. **Memory bandwidth**: 4Kç”»åƒã®Latent spaceå‡¦ç†
2. **Parallel decoding**: Speculative decoding for CM
3. **Hardware co-design**: CM-specific accelerator

## ğŸ­ Z7. ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ï¼ˆã¾ã¨ã‚ãƒ»FAQãƒ»æ¬¡å›äºˆå‘Šï¼‰

### 7.1 æœ¬è¬›ç¾©ã®æ ¸å¿ƒ

1. **Self-consistencyæ¡ä»¶ã®ç†è«–çš„ä¿è¨¼**
   - PF-ODEè»Œé“ä¸Šã®å…¨ç‚¹ãŒåŒã˜ $\mathbf{x}_\epsilon$ ã«åˆ°é”
   - Lipschitzé€£ç¶šæ€§ + Boundaryæ¡ä»¶ â†’ 1-stepç”ŸæˆãŒå¯èƒ½

2. **è¨“ç·´æ‰‹æ³•ã®é€²åŒ–**
   - CT: æ•™å¸«ãªã—ã€Euleræ³•è¿‘ä¼¼ã€åæŸé…ã„
   - iCT: Pseudo-Huberæå¤±ã€FID 1.88é”æˆ
   - **ECT**: Analytical ODEã€168xè¨“ç·´é«˜é€ŸåŒ–

3. **è’¸ç•™æ‰‹æ³•ã®å¤šæ§˜æ€§**
   - Progressive: æ®µéšçš„ã‚¹ãƒ†ãƒƒãƒ—åŠæ¸›
   - LCM: Latent space + CFGè’¸ç•™
   - InstaFlow: Rectified Flow â†’ 1-step
   - DMD2: Adversarial post-training

4. **é«˜æ¬¡ã‚½ãƒ«ãƒãƒ¼ã¨ã®æ¯”è¼ƒ**
   - DPM-Solver++: æ•°å€¤è¿‘ä¼¼ã€20ã‚¹ãƒ†ãƒƒãƒ—ã§é«˜å“è³ª
   - UniPC: Predictor-Correctorã€10ã‚¹ãƒ†ãƒƒãƒ—ã§é«˜å“è³ª
   - **CM**: ç†è«–ä¿è¨¼ã€1ã‚¹ãƒ†ãƒƒãƒ—ã§é«˜å“è³ª

### 7.2 FAQï¼ˆã‚ˆãã‚ã‚‹è³ªå•20é¸ï¼‰

<details><summary>Q1: ãªãœDDPM 1000ã‚¹ãƒ†ãƒƒãƒ—ã‚ˆã‚Šã€CM 4ã‚¹ãƒ†ãƒƒãƒ—ã®æ–¹ãŒé«˜å“è³ªï¼Ÿ</summary>

**A**: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆã®é•ã„

- DDPM: U-Netã‚’1000å›åå¾© â†’ èª¤å·®ç´¯ç©
- CM: Self-consistencyæ¡ä»¶ã‚’**æ˜ç¤ºçš„ã«å­¦ç¿’** â†’ è»Œé“å…¨ä½“ã‚’æœ€é©åŒ–

ã‚¹ãƒ†ãƒƒãƒ—æ•°â‰ å“è³ªä¿è¨¼ã€‚**ä¸€è²«æ€§**ãŒæœ¬è³ªã€‚

**æ•°å€¤ä¾‹**:
- DDPM 1000-step: FID 3.17 (CIFAR-10)
- CM 4-step: FID 2.93
- iCT 1-step: FID 1.88

â†’ ã‚¹ãƒ†ãƒƒãƒ—æ•°1/250ã§å“è³ªå‘ä¸Š

</details>

<details><summary>Q2: ECTãŒiCTã‚ˆã‚Šè¨“ç·´168xé€Ÿã„ã®ã«ã€å“è³ªãŒã‚„ã‚„åŠ£ã‚‹ç†ç”±ã¯ï¼Ÿ</summary>

**A**: Consistency vs Flexibility ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•

- iCT: Euleræ³•è¿‘ä¼¼ â†’ ç·©ã„ä¸€è²«æ€§ â†’ å¤šæ§˜æ€§â†‘
- ECT: Analytical ODE â†’ å³å¯†ãªä¸€è²«æ€§ â†’ ãƒ¢ãƒ¼ãƒ‰å´©å£Šå‚¾å‘

Perfect consistency â‰  Best sample qualityï¼ˆæœªè§£æ±ºå•é¡Œï¼‰

**å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿**:
- iCT: 512 H100 GPUæ™‚é–“ã€FID 1.88
- ECT: 3 H100 GPUæ™‚é–“ã€FID 2.06

â†’ è¨“ç·´ã‚³ã‚¹ãƒˆ1/170ã§å“è³ª0.18åŠ£åŒ–ã¯**ååˆ†è¨±å®¹ç¯„å›²**

</details>

<details><summary>Q3: LCMã¨CMã®é•ã„ã¯ï¼Ÿ</summary>

**A**: ç©ºé–“ã¨Guidance

- CM: **Pixelç©ºé–“**ã§è¨“ç·´ã€ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ãªã—
- LCM: **Latentç©ºé–“**ã§è¨“ç·´ã€**CFGè’¸ç•™**è¾¼ã¿

LCM = CM + Latent Diffusion (ç¬¬39å›) + Guidanceè’¸ç•™

**ãƒ¡ãƒªãƒƒãƒˆ**:
- Pixel CM: 512x512ã§32GB VRAMå¿…è¦
- Latent CM: 512x512ã§8GB VRAM (4xåœ§ç¸®)

**é€Ÿåº¦**:
- SDXL 50-step: 7.0s (A100)
- LCM-LoRA 4-step: 1.2s (A100)

â†’ 5.8xé«˜é€ŸåŒ– + VRAM 1/4

</details>

<details><summary>Q4: InstaFlowã¨CMã¯ã©ã†é•ã†ï¼Ÿ</summary>

**A**: ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹è»Œé“

- CM: ä»»æ„ã®PF-ODEè»Œé“
- InstaFlow: **Rectified Flowç›´ç·šè»Œé“**

InstaFlow = CM + Flow Matching (ç¬¬38å›) çµ±åˆ

**ç›´ç·šåŒ–ã®åˆ©ç‚¹**:
- æ›²ç·šè»Œé“ â†’ 1-stepè’¸ç•™ã§èª¤å·®å¤§
- ç›´ç·šè»Œé“ â†’ 1-stepè’¸ç•™ã§èª¤å·®æœ€å°

**Reflowæ‰‹æ³•**: äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’Reflow (2-3å›) â†’ è»Œé“ç›´ç·šåŒ– â†’ è’¸ç•™åŠ¹ç‡å‘ä¸Š

</details>

<details><summary>Q5: DMD2ã®ã€ŒAdversarialã€ã¯ä½•ï¼Ÿ</summary>

**A**: GANã®Adversarial loss

- Diffusionäº‹å‰è¨“ç·´ã§p(x)å­¦ç¿’
- GAN post-trainingã§1-step Generatorã«è’¸ç•™
- å“è³ª: 50-step Diffusionã«åŒ¹æ•µï¼ˆFID 10.2â†’12.8ï¼‰

DMD2 = Distillation + GAN (ç¬¬12å›)

**è¨“ç·´æ™‚é–“**:
- Scratch GANè¨“ç·´: æ•°æ—¥ã€œæ•°é€±é–“
- DMD2 post-training: **30åˆ†ã€œ2æ™‚é–“**

â†’ Diffusionäº‹å‰è¨“ç·´ã§å®‰å®šåŒ–ã€GANã§1-stepåŒ–

</details>

<details><summary>Q6: CTã¨CDã¯ã©ã¡ã‚‰ã‚’ä½¿ã†ã¹ãï¼Ÿ</summary>

**A**: ãƒ‡ãƒ¼ã‚¿ã¨ãƒªã‚½ãƒ¼ã‚¹ã«ã‚ˆã‚‹

| è¦³ç‚¹ | CT (Consistency Training) | CD (Consistency Distillation) |
|:-----|:--------------------------|:------------------------------|
| æ•™å¸«ãƒ¢ãƒ‡ãƒ« | ä¸è¦ | å¿…è¦ï¼ˆäº‹å‰è¨“ç·´æ¸ˆã¿Diffusionï¼‰ |
| è¨“ç·´æ™‚é–“ | é•·ã„ï¼ˆæ•°æ—¥ã€œ1é€±é–“ï¼‰ | çŸ­ã„ï¼ˆæ•°æ™‚é–“ã€œ1æ—¥ï¼‰ |
| å“è³ª | ã‚„ã‚„ä½ã„ï¼ˆFID 3-5ï¼‰ | é«˜ã„ï¼ˆFID 2-3ï¼‰ |
| é©ç”¨ç¯„å›² | æ–°è¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã®é«˜é€ŸåŒ– |

**æ¨å¥¨**:
- æ–°è¦ã‚¿ã‚¹ã‚¯ â†’ CT
- SDXL/Midjourneyé«˜é€ŸåŒ– â†’ CD (LCM-LoRA)

</details>

<details><summary>Q7: DPM-Solver++ã¨CMã®ä½¿ã„åˆ†ã‘ã¯ï¼Ÿ</summary>

**A**: å“è³ªã¨é€Ÿåº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•

| ã‚¹ãƒ†ãƒƒãƒ—æ•° | DPM-Solver++ FID | CM FID | æ¨å¥¨ |
|:-----------|:-----------------|:-------|:-----|
| 1-step | ä½¿ç”¨ä¸å¯ | 3.55 | CMä¸€æŠ |
| 4-step | 8.2 | 2.93 | **CMæ¨å¥¨** |
| 10-step | 3.6 | - | DPMæ¨å¥¨ |
| 20-step | 2.8 | - | DPMæ¨å¥¨ |

**ä½¿ã„åˆ†ã‘**:
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”Ÿæˆï¼ˆã‚²ãƒ¼ãƒ ãƒ»ARï¼‰: CM 1-4 step
- é«˜å“è³ªç”Ÿæˆï¼ˆã‚¢ãƒ¼ãƒˆãƒ»å°åˆ·ï¼‰: DPM 20-50 step

</details>

<details><summary>Q8: Consistency functionã¯ã©ã†ã‚„ã£ã¦å­¦ç¿’ã™ã‚‹ï¼Ÿ</summary>

**A**: æ™‚é–“æ–¹å‘ã®ä¸€è²«æ€§ã‚’æå¤±é–¢æ•°åŒ–

**CTæå¤±**:
```rust
fn consistency_loss(
    model: &ConsistencyModel<impl candle_nn::Module>,
    x_0: &Tensor,
    t1: f32,
    t2: f32,
    device: &Device,
) -> Result<Tensor> {
    // Forward noise: x_ti = x_0 + ti * z (independent noise)
    let z1   = Tensor::randn(0f32, 1.0, x_0.shape(), device)?;
    let z2   = Tensor::randn(0f32, 1.0, x_0.shape(), device)?;
    let x_t1 = x_0.add(&z1.affine(t1 as f64, 0.0)?)?;
    let x_t2 = x_0.add(&z2.affine(t2 as f64, 0.0)?)?;

    // One-step consistency function
    let batch = x_0.dim(0)?;
    let f_t1 = model.forward(&x_t1, &Tensor::full(t1, (batch,), device)?)?;
    let f_t2 = model.forward(&x_t2, &Tensor::full(t2, (batch,), device)?)?;

    // Pseudo-Huber distance (c = 0.00054 for pixel range [-1,1])
    pseudo_huber_loss(&f_t1, &f_t2, 0.00054)
}
```

**ã‚­ãƒ¼ã‚¢ã‚¤ãƒ‡ã‚¢**: åŒã˜ $\mathbf{x}_0$ ã‹ã‚‰ç”Ÿæˆã—ãŸ $\mathbf{x}_{t_1}$ ã¨ $\mathbf{x}_{t_2}$ ã¯ã€ã©ã¡ã‚‰ã‚‚ $F_\theta$ ã‚’é€šã™ã¨åŒã˜ $\mathbf{x}_\epsilon$ ã«åˆ°é”ã™ã¹ã

</details>

<details><summary>Q9: Pseudo-Huberæå¤±ã® $c$ ã¯ã©ã†æ±ºã‚ã‚‹ï¼Ÿ</summary>

**A**: ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚±ãƒ¼ãƒ«ã«ä¾å­˜

**ImageNetçµŒé¨“å‰‡**:
- Pixelå€¤ç¯„å›² $[-1, 1]$ â†’ $c = 0.00054$
- Pixelå€¤ç¯„å›² $[0, 1]$ â†’ $c = 0.0027$

**ä¸€èˆ¬å…¬å¼**:
$$
c = \frac{\sigma_{\text{data}}}{1000}
$$

$\sigma_{\text{data}}$: ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åå·®

**ç†ç”±**: $c$ ãŒå°ã•ã™ãã‚‹ â†’ L2æå¤±ã«è¿‘ä¼¼ã€å¤–ã‚Œå€¤ã«æ•æ„Ÿ
$c$ ãŒå¤§ãã™ãã‚‹ â†’ L1æå¤±ã«è¿‘ä¼¼ã€å‹¾é…ãŒå°ã•ã™ãã‚‹

</details>

<details><summary>Q10: EMAã® $\mu$ ã¯ãªãœ0.95ã‚„0.9999ã‚’ä½¿ã†ï¼Ÿ</summary>

**A**: è¨“ç·´ãƒ•ã‚§ãƒ¼ã‚ºã«ã‚ˆã‚‹

**åˆæœŸ (0-10k iter)**: $\mu = 0.95$
- ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã«è¿‘ã„
- é«˜é€ŸåæŸ

**ä¸­æœŸ (10k-100k iter)**: $\mu = 0.999$
- å®‰å®šåŒ–é–‹å§‹

**å¾ŒæœŸ (100k+ iter)**: $\mu = 0.9999$ or ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
$$
\mu(s) = \exp\left( \frac{s \log \mu_0}{s + 1} \right), \quad \mu_0 = 0.95
$$

**iCTæ¨å¥¨**: å›ºå®š $\mu = 0.95$ (è«–æ–‡å®Ÿé¨“å€¤)

</details>

<details><summary>Q11: CTMã® $g_\theta(\mathbf{x}_t, t, t')$ ã¯ä½•ãŒå¬‰ã—ã„ï¼Ÿ</summary>

**A**: Multi-stepæ¨è«–ã®æœ€é©åŒ–

**CM**: $F_\theta(\mathbf{x}_t, t) \to \mathbf{x}_\epsilon$ ã®ã¿å­¦ç¿’ â†’ 1-stepå°‚ç”¨

**CTM**: $g_\theta(\mathbf{x}_t, t, t')$ ã§ **ä»»æ„ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°** ã‚’åŒä¸€ãƒ¢ãƒ‡ãƒ«ã§å®Ÿç¾

**å®Ÿæ¸¬ (ImageNet 64x64)**:
- CTM 1-step: FID 4.02
- CTM 2-step: FID 2.31 (âœ¨ CMã‚ˆã‚Šè‰¯ã„)
- CTM 10-step: FID 1.73

â†’ æ¨è«–æ™‚ã«ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å‹•çš„èª¿æ•´å¯èƒ½ï¼ˆé€Ÿåº¦/å“è³ªãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ï¼‰

</details>

<details><summary>Q12: Progressive Distillationã¯ä½•å›ç¹°ã‚Šè¿”ã™ï¼Ÿ</summary>

**A**: $\log_2(N)$ å›

**ä¾‹**: DDPM 1024-step â†’ 1-step

| è’¸ç•™å›æ•° | ã‚¹ãƒ†ãƒƒãƒ—æ•° | è¨“ç·´æ™‚é–“ (ImageNet) |
|:---------|:-----------|:--------------------|
| 0 (æ•™å¸«) | 1024 | - |
| 1 | 512 | 50 GPUæ™‚é–“ |
| 2 | 256 | 50 GPUæ™‚é–“ |
| 3 | 128 | 50 GPUæ™‚é–“ |
| ... | ... | ... |
| 10 | 1 | 50 GPUæ™‚é–“ |

**åˆè¨ˆ**: 500 GPUæ™‚é–“ (ç´„3é€±é–“ 8xA100)

**å“è³ªåŠ£åŒ–**: FID 2.8 â†’ 3.4 (0.6åŠ£åŒ–)

</details>

<details><summary>Q13: Rectified Flowã®ã€Œç›´ç·šåŒ–ã€ã¯ç†è«–ä¿è¨¼ãŒã‚ã‚‹ï¼Ÿ</summary>

**A**: ã‚ã‚‹ï¼ˆOptimal Transportç†è«–ï¼‰

**å®šç† (Liu+ 2023)**: Reflowæ“ä½œã‚’ç¹°ã‚Šè¿”ã™ã¨ã€Flowè»Œé“ã¯**ç›´ç·š**ã«åæŸ

$$
\lim_{k \to \infty} \text{Reflow}^k(\mathbf{v}_\theta) = \nabla T^*
$$

$T^*$: Optimal Transport map

**å®Ÿæ¸¬**:
- Reflow 0å›: å¹³å‡æ›²ç‡ 0.32
- Reflow 1å›: å¹³å‡æ›²ç‡ 0.12
- Reflow 2å›: å¹³å‡æ›²ç‡ 0.04
- Reflow 3å›: å¹³å‡æ›²ç‡ 0.01

â†’ 3å›ã§**ã»ã¼ç›´ç·š**

</details>

<details><summary>Q14: UniPCã®Predictor-Correctorã¯ä½•ï¼Ÿ</summary>

**A**: æ•°å€¤è§£æã®å¤å…¸æ‰‹æ³•

**Predictor**: æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã‚’äºˆæ¸¬
$$
\tilde{\mathbf{x}}_{t-\Delta t} = \mathbf{x}_t - \Delta t \cdot \mathbf{v}_\theta(\mathbf{x}_t, t)
$$

**Corrector**: äºˆæ¸¬ã‚’ä¿®æ­£
$$
\mathbf{x}_{t-\Delta t} = \mathbf{x}_t - \Delta t \cdot \frac{\mathbf{v}_\theta(\mathbf{x}_t, t) + \mathbf{v}_\theta(\tilde{\mathbf{x}}_{t-\Delta t}, t-\Delta t)}{2}
$$

â†’ Heunæ³•ï¼ˆ2æ¬¡ç²¾åº¦ï¼‰ã®ä¸€ç¨®

**UniPCã®å·¥å¤«**: Multi-step Adams-Bashforthã§**3æ¬¡ç²¾åº¦**é”æˆ

</details>

<details><summary>Q15: Information-theoretic lower boundã¯å®Ÿç”¨çš„ï¼Ÿ</summary>

**A**: ç†è«–çš„èˆˆå‘³ãŒä¸»ã€å®Ÿç”¨ã¯é™å®šçš„

**ä¸‹ç•Œ**:
$$
N \geq \Omega\left( \frac{\log d}{\varepsilon} \right)
$$

**ImageNet 256x256 ($d = 196608$)**:
- $\varepsilon = 0.01$ â†’ $N \geq 1.1 \times 10^6$ ã‚¹ãƒ†ãƒƒãƒ—

**å®Ÿæ¸¬**: 50-step ã§ FID < 5 é”æˆ

**ã‚®ãƒ£ãƒƒãƒ—ã®ç†ç”±**:
1. ä¸‹ç•Œã¯**æœ€æ‚ªã‚±ãƒ¼ã‚¹**ï¼ˆæ•µå¯¾çš„åˆ†å¸ƒï¼‰
2. è‡ªç„¶ç”»åƒã¯ä½æ¬¡å…ƒå¤šæ§˜ä½“ â†’ å®ŸåŠ¹æ¬¡å…ƒ $\ll d$
3. Diffusionã¯æš—é»™ã«å¤šæ§˜ä½“ã‚’å­¦ç¿’

â†’ ä¸‹ç•Œã¯ã€Œç†è«–çš„é™ç•Œã€ã€å®Ÿç”¨ã¯ã€Œãƒ‡ãƒ¼ã‚¿æ§‹é€ ä¾å­˜ã€

</details>

<details><summary>Q16: CMã¯è¨“ç·´ã«ä½•GPUæ™‚é–“å¿…è¦ï¼Ÿ</summary>

**A**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹

**CIFAR-10 (32x32)**:
- CT: 4 A100 Ã— 24æ™‚é–“ = 96 GPUæ™‚é–“
- iCT: 8 A100 Ã— 12æ™‚é–“ = 96 GPUæ™‚é–“
- ECT: 1 A100 Ã— 0.6æ™‚é–“ = **0.6 GPUæ™‚é–“**

**ImageNet 64x64**:
- CT: 32 A100 Ã— 7æ—¥ = 5,376 GPUæ™‚é–“
- iCT: 512 A100 Ã— 1æ—¥ = 12,288 GPUæ™‚é–“
- ECT: 8 A100 Ã— 4æ™‚é–“ = **32 GPUæ™‚é–“**

**SDXLè’¸ç•™ (LCM)**:
- 8 A100 Ã— 12æ™‚é–“ = 96 GPUæ™‚é–“

â†’ ECTã¯**1/100ã€œ1/400ã®ã‚³ã‚¹ãƒˆ**

</details>

<details><summary>Q17: CMã¯æ¡ä»¶ä»˜ãç”Ÿæˆï¼ˆText-to-Imageï¼‰ã«ä½¿ãˆã‚‹ï¼Ÿ</summary>

**A**: ä½¿ãˆã‚‹ï¼ˆLCMã§å®Ÿè¨¼æ¸ˆã¿ï¼‰

**æ‰‹æ³•**:
1. äº‹å‰è¨“ç·´æ¸ˆã¿Latent Diffusion (SDXLç­‰) ã‚’è’¸ç•™
2. Text embeddingã‚’ $F_\theta(\mathbf{z}_t, t, \mathbf{c})$ ã«æ¡ä»¶ä»˜ã‘
3. **CFGè’¸ç•™**ã‚‚åŒæ™‚å®Ÿè¡Œ

**LCMå®Ÿè£…**:
```rust
// LCM conditional consistency function with CFG distillation
fn consistency_function_cond(
    model: &impl Fn(&Tensor, &Tensor, Option<&Tensor>) -> Result<Tensor>,
    z_t: &Tensor,
    t: &Tensor,
    text_embed: &Tensor,
    cfg_scale: f32,
) -> Result<Tensor> {
    // Conditional + Unconditional forward pass
    let eps_cond   = model(z_t, t, Some(text_embed))?;
    let zeros      = text_embed.zeros_like()?;
    let eps_uncond = model(z_t, t, Some(&zeros))?;

    // CFG-distilled prediction: Îµ_guided = Îµ_uncond + w*(Îµ_cond - Îµ_uncond)
    let eps_guided = eps_uncond.add(
        &eps_cond.sub(&eps_uncond)?.affine(cfg_scale as f64, 0.0)?
    )?;

    consistency_transform(z_t, t, &eps_guided)
}
```

**çµæœ (SDXL)**:
- 50-step: FID 23.4
- LCM 4-step: FID 25.1

â†’ å“è³ªåŠ£åŒ–ã‚ãšã‹ã€é€Ÿåº¦12.5x

</details>

<details><summary>Q18: DMD2ã¯ãƒ“ãƒ‡ã‚ªç”Ÿæˆã«ã‚‚ä½¿ãˆã‚‹ï¼Ÿ</summary>

**A**: ä½¿ãˆã‚‹ï¼ˆè«–æ–‡ã§å®Ÿè¨¼ï¼‰

**é©ç”¨å…ˆ**: AnimateDiff (Text-to-Video)
- äº‹å‰è¨“ç·´: 25-step Diffusion
- DMD2 post-training: 1-step Generator

**çµæœ**:
- FVD (FrÃ©chet Video Distance): 251 (25-step) â†’ 289 (1-step)
- æ¨è«–é€Ÿåº¦: 37s â†’ **1.6s** (A100, 16ãƒ•ãƒ¬ãƒ¼ãƒ )

**èª²é¡Œ**: æ™‚é–“çš„ä¸€è²«æ€§ã®åŠ£åŒ–
- Flickerå¢—åŠ 
- ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³æ»‘ã‚‰ã‹ã•ä½ä¸‹

**è§£æ±ºç­–**: Temporal Discriminatorã®å¼·åŒ–ï¼ˆä»Šå¾Œã®ç ”ç©¶ï¼‰

</details>

<details><summary>Q19: Self-consistencyã¯ä»–ã®ã‚¿ã‚¹ã‚¯ã«å¿œç”¨ã§ãã‚‹ï¼Ÿ</summary>

**A**: ã§ãã‚‹ï¼ˆç†è«–ã¯æ±ç”¨ï¼‰

**å¿œç”¨ä¾‹**:
1. **å¼·åŒ–å­¦ç¿’**: Value functionã®Bellmanä¸€è²«æ€§
2. **éŸ³å£°ç”Ÿæˆ**: Waveformæ™‚é–“æ–¹å‘ã®ä¸€è²«æ€§
3. **åˆ†å­ç”Ÿæˆ**: Energyä¸€è²«æ€§ï¼ˆç‰©ç†æ³•å‰‡ï¼‰
4. **3Dç”Ÿæˆ**: Multi-viewä¸€è²«æ€§

**ä¾‹ (3D Consistency)**:
$$
F_\theta(\text{view}_1) = F_\theta(\text{view}_2) = \text{3D object}
$$

â†’ ç•°ãªã‚‹è¦–ç‚¹ã‹ã‚‰è¦‹ãŸ2Dç”»åƒãŒã€åŒã˜3Dè¡¨ç¾ã«å†™åƒã•ã‚Œã‚‹ã¹ã

</details>

<details><summary>Q20: æœ€æ–°ã®Consistencyç ”ç©¶ï¼ˆ2025-2026ï¼‰ã¯ï¼Ÿ</summary>

**A**: 3ã¤ã®ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢

**1. Multi-modal Consistency**:
- Text + Image + Audio + Video ã®çµ±ä¸€ä¸€è²«æ€§
- Transfusion (Meta 2025): AR + Diffusionçµ±åˆ

**2. World Model Consistency**:
- ç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æ™‚ç©ºé–“ä¸€è²«æ€§
- V-JEPA (LeCun 2024): å‹•ç”»äºˆæ¸¬ã®ä¸€è²«æ€§å­¦ç¿’

**3. Consistency + Reinforcement**:
- Human feedbackã§Consistency fintuning
- DPO (Direct Preference Optimization) + CM

**2026äºˆæƒ³**: **Self-consistency = å…¨ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®çµ±ä¸€åŸç†**ã¸

</details>

### 7.3 å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆè©³ç´°ç‰ˆï¼‰

#### 7.3.1 åˆå­¦è€…å‘ã‘ï¼ˆ2é€±é–“ãƒ—ãƒ©ãƒ³ï¼‰

**Week 1: ç†è«–ã®åŸºç¤å›ºã‚**

| æ—¥ | Zone | å†…å®¹ | æ™‚é–“ | å…·ä½“çš„ã‚¿ã‚¹ã‚¯ | åˆ°é”ç›®æ¨™ |
|:---|:-----|:-----|:-----|:-------------|:---------|
| Day 1 | Z0-Z1 | QuickStart + ä½“é¨“ | 1.5h | Candle CMã§ç”»åƒç”Ÿæˆå®Ÿè¡Œ | ã€Œ1-stepã§ç”Ÿæˆã§ãã‚‹ã€ã‚’ä½“æ„Ÿ |
| Day 2 | Z2 | ç›´æ„Ÿç†è§£ | 2h | è»Œé“å›³ã‚’æ‰‹æ›¸ãã€Self-consistencyå¼ã‚’éŸ³èª­ | PF-ODEã¨Consistencyã®é–¢ä¿‚ç†è§£ |
| Day 3 | Z3.1-3.3 | CTåŸºç¤ | 3h | Consistencyæå¤±ã®å°å‡ºã‚’ç´™ã«æ›¸ã | $\mathcal{L}_{\text{CT}}$ ã‚’å®Œå…¨ç†è§£ |
| Day 4 | Z3.4-3.6 | CD/iCT | 3h | Pseudo-Huberæå¤±ã®ã‚°ãƒ©ãƒ•ã‚’ãƒ—ãƒ­ãƒƒãƒˆ | æ•™å¸«ã‚ã‚Š/ãªã—è’¸ç•™ã®é•ã„æ˜ç¢ºåŒ– |
| Day 5 | Z3.7-3.9 | ECT | 2h | Analytical ODEã®å°å‡ºè¿½è·¡ | 168xé«˜é€ŸåŒ–ã®åŸç†ç†è§£ |
| Day 6 | ä¼‘æ¯ | å¾©ç¿’ | 1h | Z3ã®æ•°å¼ã‚’ãƒãƒ¼ãƒˆã«æ•´ç† | - |
| Day 7 | Z3.10-3.14 | é«˜æ¬¡ã‚½ãƒ«ãƒãƒ¼ | 3h | DPM-Solver++ã®Runge-Kuttaè¡¨ | æ•°å€¤ODEã‚½ãƒ«ãƒãƒ¼åŸºç¤ç¿’å¾— |

**Week 2: å®Ÿè£…ã¨å¿œç”¨**

| æ—¥ | Zone | å†…å®¹ | æ™‚é–“ | å…·ä½“çš„ã‚¿ã‚¹ã‚¯ | åˆ°é”ç›®æ¨™ |
|:---|:-----|:-----|:-----|:-------------|:---------|
| Day 8 | Z4.1-4.2 | RuståŸºç¤å®Ÿè£… | 3h | MNIST CMã‚’è¨“ç·´ (CT) | è¨“ç·´ãƒ«ãƒ¼ãƒ—å®Œå…¨ç†è§£ |
| Day 9 | Z4.3 | Rustå®Ÿè£… | 2h | Candle CMã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é«˜é€ŸåŒ– | FFIå¢ƒç•Œç†è§£ |
| Day 10 | Z5 | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ | 2h | è‡ªå‰CMã¨DDPMã‚’æ¯”è¼ƒ | NFE vs FIDãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ä½“æ„Ÿ |
| Day 11 | Z6.1-6.3 | è’¸ç•™ç³»ç ”ç©¶ | 3h | LCM/InstaFlow/DMD2è«–æ–‡èª­è§£ | Progressiveç³»çµ±æ¨¹ç†è§£ |
| Day 12 | Z6.4-6.6 | ç†è«–çš„ç™ºå±• | 2h | CTMã¨Infoç†è«–ä¸‹ç•Œã®è¨¼æ˜ã‚¹ã‚±ãƒƒãƒ | ç†è«–é™ç•ŒæŠŠæ¡ |
| Day 13 | Z7 FAQ | ç·å¾©ç¿’ | 2h | FAQ 20å•ã™ã¹ã¦ã«è‡ªåŠ›å›ç­” | çŸ¥è­˜ã®ç©´ã‚’åŸ‹ã‚ã‚‹ |
| Day 14 | çµ±åˆ | Course IVæŒ¯ã‚Šè¿”ã‚Š | 2h | ç¬¬33-40å›ã®ã¤ãªãŒã‚Šå›³ä½œæˆ | ç”Ÿæˆãƒ¢ãƒ‡ãƒ«å…¨ä½“åƒæŠŠæ¡ |

**åˆè¨ˆ**: 33.5æ™‚é–“ï¼ˆ1æ—¥å¹³å‡2.4æ™‚é–“ï¼‰

#### 7.3.2 çµŒé¨“è€…å‘ã‘ï¼ˆ1é€±é–“é›†ä¸­ãƒ—ãƒ©ãƒ³ï¼‰

| æ—¥ | å†…å®¹ | æ™‚é–“ | ã‚¿ã‚¹ã‚¯ |
|:---|:-----|:-----|:-------|
| Day 1 | Z0-2 + Z3.1-3.6 | 4h | QuickStartâ†’CT/CD/iCTå®Œå…¨ç†è§£ |
| Day 2 | Z3.7-3.14 | 5h | ECT+DPM++/UniPC+Progressive |
| Day 3 | Z4 Rustå®Ÿè£… | 4h | CIFAR-10 CMãƒ•ãƒ«å®Ÿè£… |
| Day 4 | Z4 Rustå®Ÿè£… | 3h | Candleæœ€é©åŒ– + ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ |
| Day 5 | Z5 + Z6.1-6.3 | 4h | æ¯”è¼ƒå®Ÿé¨“ + LCM/InstaFlow/DMD2 |
| Day 6 | Z6.4-6.6 | 3h | CTMç†è«– + æƒ…å ±ç†è«–ä¸‹ç•Œ |
| Day 7 | Z7 + è«–æ–‡ç²¾èª­ | 3h | FAQå¾©ç¿’ + CMåŸè«–æ–‡å†èª­ |

**åˆè¨ˆ**: 26æ™‚é–“ï¼ˆ1æ—¥å¹³å‡3.7æ™‚é–“ï¼‰

#### 7.3.3 ç ”ç©¶è€…å‘ã‘ï¼ˆå®Ÿè£…å„ªå…ˆãƒ—ãƒ©ãƒ³ï¼‰

**Day 1-2**: ç†è«–é€Ÿç¿’ï¼ˆZ0-Z3å…¨èª­ã€6hï¼‰
**Day 3-5**: ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒå®Ÿè£…
  - Day 3: CTè¨“ç·´ãƒ«ãƒ¼ãƒ— (MNIST)
  - Day 4: iCT with Pseudo-Huber (CIFAR-10)
  - Day 5: ECT with Analytical ODE (ImageNet 64x64)

**Day 6-7**: å†ç¾å®Ÿé¨“
  - è«–æ–‡Table 1ã®FIDå†ç¾
  - DPM-Solver++/UniPCã¨ã®æ¯”è¼ƒ
  - Ablation study (EMA $\mu$, Huber $c$, $N$ ä¾å­˜æ€§)

**æˆæœç‰©**: arXivæŠ•ç¨¿ãƒ¬ãƒ™ãƒ«ã®å®Ÿé¨“ãƒãƒ¼ãƒˆ

### 7.4 Course IV å…¨ä½“ç·æ‹¬ï¼ˆç¬¬33-40å›ã®çµ±åˆï¼‰

#### 7.4.1 Course IV: æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«å®Œå…¨ç³»ã®çŸ¥è­˜ãƒãƒƒãƒ—

```mermaid
graph TB
    subgraph "Phase 1: åŸºç¤ç†è«–"
        L33[ç¬¬33å›: Normalizing Flows]
        L34[ç¬¬34å›: EBM & çµ±è¨ˆç‰©ç†]
        L35[ç¬¬35å›: Score Matching]
        L33 --> L34
        L34 --> L35
    end

    subgraph "Phase 2: æ‹¡æ•£ç†è«–"
        L36[ç¬¬36å›: DDPMåŸºç¤]
        L37[ç¬¬37å›: SDE/ODEç†è«–]
        L35 --> L36
        L36 --> L37
    end

    subgraph "Phase 3: çµ±ä¸€ç†è«–"
        L38[ç¬¬38å›: Flow Matchingçµ±ä¸€]
        L37 --> L38
    end

    subgraph "Phase 4: å¿œç”¨ãƒ»é«˜é€ŸåŒ–"
        L39[ç¬¬39å›: Latent Diffusion]
        L40[ç¬¬40å›: Consistency Models]
        L38 --> L39
        L39 --> L40
    end

    style L40 fill:#f96,stroke:#333,stroke-width:4px
```

#### 7.4.2 å„è¬›ç¾©ã®ä½ç½®ã¥ã‘

| è¬›ç¾© | æ ¸å¿ƒæ¦‚å¿µ | ã‚­ãƒ¼æ•°å¼ | å®Ÿè£…é›£æ˜“åº¦ | é‡è¦åº¦ |
|:-----|:---------|:---------|:-----------|:-------|
| 33 NF | å¯é€†å¤‰æ› | $p_X(x) = p_Z(z) \|\det J_f\|^{-1}$ | â˜…â˜…â˜… | â˜…â˜…â˜…â˜†â˜† |
| 34 EBM | ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ™ãƒ¼ã‚¹ | $p(x) = \frac{1}{Z}\exp(-E(x))$ | â˜…â˜…â˜…â˜† | â˜…â˜…â˜…â˜†â˜† |
| 35 Score | ã‚¹ã‚³ã‚¢é–¢æ•°å­¦ç¿’ | $\nabla_x \log p(x) = -\nabla_x E(x)$ | â˜…â˜…â˜… | â˜…â˜…â˜…â˜…â˜† |
| 36 DDPM | Markové€†æ‹¡æ•£ | $\mathbf{x}_{t-1} = \frac{1}{\sqrt{\alpha_t}}(\mathbf{x}_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\varepsilon}_\theta) + \sigma_t \mathbf{z}$ | â˜…â˜…â˜† | â˜…â˜…â˜…â˜…â˜… |
| 37 SDE/ODE | é€£ç¶šæ™‚é–“SDE | $d\mathbf{x} = \mathbf{f}(\mathbf{x},t)dt + g(t)\nabla_\mathbf{x}\log p_t(\mathbf{x})dt$ | â˜…â˜…â˜… | â˜…â˜…â˜…â˜…â˜† |
| 38 Flow Match | CFMçµ±ä¸€ç†è«– | $\mathcal{L}_{\text{CFM}} = \mathbb{E}_{t,p_t(\mathbf{x})}[\|\mathbf{u}_t(\mathbf{x}) - \mathbf{v}_\theta(\mathbf{x},t)\|^2]$ | â˜…â˜…â˜† | â˜…â˜…â˜…â˜…â˜† |
| 39 Latent | VAEåœ§ç¸®æ‹¡æ•£ | $\mathbf{z} = \mathcal{E}(\mathbf{x}), \mathbf{x} = \mathcal{D}(\mathbf{z})$ | â˜…â˜…â˜…â˜… | â˜…â˜…â˜…â˜…â˜… |
| 40 Consistency | Self-consistency | $F_\theta(\mathbf{x}_t, t) = F_\theta(\mathbf{x}_{t'}, t'), \forall t,t'$ | â˜…â˜…â˜…â˜† | â˜…â˜…â˜…â˜…â˜† |

#### 7.4.3 çŸ¥è­˜ã®ä¾å­˜é–¢ä¿‚

**å¿…é ˆå‰æçŸ¥è­˜**:
- ç¬¬33å› (Normalizing Flows) â†’ å¯é€†å¤‰æ›ã®åŸºç¤
- ç¬¬35å› (Score Matching) â†’ ç¬¬36-37å›ã®ç†è§£ã«å¿…é ˆ
- ç¬¬36å› (DDPM) ã¯**å…¨ã¦ã®åŸºç¤** â†’ æœ€å„ªå…ˆ

**æ¨å¥¨å­¦ç¿’é †**:
1. **36 DDPM** (åœŸå°ã€æœ€å„ªå…ˆ)
2. **37 SDE/ODE** (ç†è«–åŸºç›¤)
3. **38 Flow Matching** (çµ±ä¸€ç†è«–)
4. **39 Latent** (å®Ÿç”¨)
5. **40 Consistency** (1-stepç”Ÿæˆ)
6. **35 Score Matching** (ç†è«–æ·±æ˜ã‚Š)
7. **33 NF, 34 EBM** (è£œè¶³ç†è«–)

#### 7.4.4 å®Ÿè£…ã®ç´¯ç©ï¼ˆç©ã¿ä¸Šã’å¼ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰

**Stage 1: DDPMå®Ÿè£…** (ç¬¬36å›)
```rust
// åŸºæœ¬æ§‹é€ 
struct Ddpm {
    betas: Vec<f32>,
    model: DenoisingUNet,
}
```

**Stage 2: DDIMè¿½åŠ ** (ç¬¬36å›ã§å°å‡ºæ¸ˆã¿)
```rust
// DDPMã‚’æ‹¡å¼µ
fn ddim_sample(ddpm: &Ddpm, x_t: &Tensor, eta: f32) -> Result<Tensor> {
    // DDPMã®betasã‚’å†åˆ©ç”¨
    todo!()
}
```

**Stage 3: Score SDEçµ±åˆ** (ç¬¬37å›)
```rust
// SDEè¦–ç‚¹ã§ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
fn sde_sample(model: &impl candle_nn::Module, x_t: &Tensor, sde_type: &str) -> Result<Tensor> {
    // VP-SDE ã¾ãŸã¯ VE-SDE
    todo!()
}
```

**Stage 4: Latent Diffusion** (ç¬¬39å›)
```rust
// VAEè¿½åŠ 
struct LatentDiffusion {
    vae: Vae,
    diffusion: Ddpm, // Stage 1-3ã‚’å†åˆ©ç”¨
}
```

**Stage 5: Consistency Model** (ç¬¬40å›)
```rust
// æ–°è¦å®Ÿè£…ï¼ˆDDPMã‹ã‚‰è’¸ç•™å¯èƒ½ï¼‰
struct ConsistencyModel {
    f_theta: ConsistencyFunction,
    teacher: Option<Ddpm>, // CDæ™‚ã®ã¿
}
```

â†’ **å„è¬›ç¾©ã®å®Ÿè£…ãŒæ¬¡ã®è¬›ç¾©ã®åŸºç¤ã«ãªã‚‹è¨­è¨ˆ**

#### 7.4.5 Course IVä¿®äº†å¾Œã®ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ

**ç†è«–**:
- [ ] Diffusionã®3å½¢å¼ï¼ˆDDPM/Score SDE/ODEï¼‰ã‚’ç›¸äº’å¤‰æ›ã§ãã‚‹
- [ ] Flow Matchingã¨Diffusionã®ç­‰ä¾¡æ€§ã‚’è¨¼æ˜ã§ãã‚‹
- [ ] Self-consistencyæ¡ä»¶ã®ç†è«–çš„ä¿è¨¼ã‚’èª¬æ˜ã§ãã‚‹
- [ ] æƒ…å ±ç†è«–ä¸‹ç•Œ $N \geq \Omega(\log d/\varepsilon)$ ã®æ„å‘³ã‚’ç†è§£

**å®Ÿè£…**:
- [ ] DDPM/DDIM/DPMã‚’ã‚¼ãƒ­ã‹ã‚‰å®Ÿè£…ã§ãã‚‹
- [ ] EDM Preconditioningã§å“è³ªå‘ä¸Šã§ãã‚‹
- [ ] Latent Diffusionã§å¤§è¦æ¨¡ç”»åƒç”Ÿæˆã§ãã‚‹
- [ ] Consistency Modelã‚’CTã¾ãŸã¯CDã§è¨“ç·´ã§ãã‚‹
- [ ] Rustã§Candleæ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã§ãã‚‹

**å¿œç”¨**:
- [ ] Text-to-Image (Stable Diffusionç›¸å½“) ã‚’å†ç¾ã§ãã‚‹
- [ ] 1-stepç”Ÿæˆã§50xé«˜é€ŸåŒ–ã‚’å®Ÿç¾ã§ãã‚‹
- [ ] NFE-FIDãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å®šé‡è©•ä¾¡ã§ãã‚‹
- [ ] æ–°è¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«è’¸ç•™æ‰‹æ³•ã‚’é©ç”¨ã§ãã‚‹

#### 7.4.6 Course IV â†’ Course V ã¸ã®æ¥ç¶š

**Course IV ã®æˆæœ**: é™æ­¢ç”»ç”Ÿæˆã‚’å®Œå…¨åˆ¶è¦‡

**Course V (äºˆå®š)**: ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®æœ€çµ‚å½¢æ…‹

| è¬›ç¾© | ãƒ†ãƒ¼ãƒ | Course IVã¨ã®é–¢é€£ |
|:-----|:-------|:------------------|
| 41 | World Models | Diffusion â†’ ç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ |
| 42 | Video Diffusion | é™æ­¢ç”» â†’ æ™‚ç³»åˆ—ä¸€è²«æ€§ |
| 43 | 3D Generation | 2D â†’ 3D/Multi-viewä¸€è²«æ€§ |
| 44 | Embodied AI | ç”Ÿæˆ â†’ è¡Œå‹• (RLçµ±åˆ) |
| 45 | Multimodal | Text+Image+Audioçµ±åˆ |

**æ¬¡ã®æŒ‘æˆ¦**: ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®ç›®çš„ã¯ã€Œã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€ã‹ï¼Ÿã€Œä¸–ç•Œç†è§£ã€ã‹ï¼Ÿ

### 7.5 æ¨å¥¨ãƒªã‚½ãƒ¼ã‚¹ï¼ˆå³é¸10é¸ï¼‰

#### 7.5.1 è«–æ–‡ï¼ˆå¿…èª­ï¼‰

1. **Song+ (2023) "Consistency Models"** [arXiv:2303.01469](https://arxiv.org/abs/2303.01469)
   - ç†ç”±: CMåŸè«–æ–‡ã€Self-consistencyæ¡ä»¶ã®åˆå‡º
   - é›£æ˜“åº¦: â˜…â˜…â˜…â˜†â˜†
   - æ¨å¥¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°: æœ¬è¬›ç¾©å®Œäº†ç›´å¾Œ

2. **Geng+ (2025) "Consistency Models Made Easy"** [arXiv:2406.14548](https://arxiv.org/abs/2406.14548)
   - ç†ç”±: ECTã®Analytical ODEã€å®Ÿè£…ãŒåœ§å€’çš„ã«ã‚·ãƒ³ãƒ—ãƒ«
   - é›£æ˜“åº¦: â˜…â˜…â˜†â˜†â˜†
   - æ¨å¥¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°: Z3.7èª­äº†å¾Œ

3. **Kim+ (2023) "Consistency Trajectory Models"** [arXiv:2310.02279](https://arxiv.org/abs/2310.02279)
   - ç†ç”±: CMã®ä¸€èˆ¬åŒ–ã€Multi-stepæ¨è«–ã®ç†è«–
   - é›£æ˜“åº¦: â˜…â˜…â˜…â˜…â˜†
   - æ¨å¥¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°: CMå®Œå…¨ç†è§£å¾Œ

4. **Luo+ (2023) "Latent Consistency Models"** [arXiv:2310.04378](https://arxiv.org/abs/2310.04378)
   - ç†ç”±: Stable Diffusioné«˜é€ŸåŒ–ã®å®Ÿç”¨ä¾‹
   - é›£æ˜“åº¦: â˜…â˜…â˜…â˜†â˜†
   - æ¨å¥¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°: ç¬¬39å›å¾©ç¿’å¾Œ

5. **Lin+ (2025) "Diffusion Adversarial Post-Training"** [arXiv:2501.08316](https://arxiv.org/abs/2501.08316)
   - ç†ç”±: æœ€æ–°ã®1-stepè’¸ç•™ã€GANçµ±åˆ
   - é›£æ˜“åº¦: â˜…â˜…â˜…â˜†â˜†
   - æ¨å¥¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°: ç¬¬12å› (GAN) å¾©ç¿’å¾Œ

#### 7.5.2 å®Ÿè£…ãƒªãƒã‚¸ãƒˆãƒª

6. **openai/consistency_models** (å…¬å¼PyTorchå®Ÿè£…)
   - URL: [github.com/openai/consistency_models](https://github.com/openai/consistency_models)
   - è¨€èª: Python/PyTorch
   - æ¨å¥¨ç”¨é€”: CT/iCTå®Ÿè£…ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

7. **Stability-AI/generative-models** (LCMå…¬å¼å®Ÿè£…)
   - URL: [github.com/Stability-AI/generative-models](https://github.com/Stability-AI/generative-models)
   - è¨€èª: Python/PyTorch
   - æ¨å¥¨ç”¨é€”: LCM-LoRA fine-tuning

8. **huggingface/diffusers** (çµ±åˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª)
   - URL: [github.com/huggingface/diffusers](https://github.com/huggingface/diffusers)
   - è¨€èª: Python/PyTorch
   - æ¨å¥¨ç”¨é€”: LCMæ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

#### 7.5.3 æ•™æãƒ»è¬›ç¾©

9. **MIT 6.S184 (2026) "Diffusion Models"**
   - URL: [diffusion.csail.mit.edu](https://diffusion.csail.mit.edu/)
   - å½¢å¼: å‹•ç”»è¬›ç¾© + ã‚¹ãƒ©ã‚¤ãƒ‰
   - æ¨å¥¨Lecture: Lecture 8 "Fast Sampling" (DPM/DDIM/CMç¶²ç¾…)

10. **Hugging Face Diffusion Course**
    - URL: [huggingface.co/learn/diffusion-course](https://huggingface.co/learn/diffusion-course)
    - å½¢å¼: ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯
    - æ¨å¥¨Unit: Unit 4 "Fine-tuning and Guidance"

### 7.6 æ¬¡å›äºˆå‘Š: ç¬¬41å› World Models & ç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ç†è«–

**ãƒ†ãƒ¼ãƒ**: ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®æœ€çµ‚åˆ°é”ç‚¹ â€” ç’°å¢ƒã®ç†è§£ã¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

**å†…å®¹**:
- JEPA (LeCunäºˆæ¸¬ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£)
- V-JEPA (å‹•ç”»ã§ã®å®Ÿè£…)
- Transfusion (AR + Diffusionçµ±åˆ)
- ç‰©ç†æ³•å‰‡å­¦ç¿’ç†è«–
- Energy-based World Models
- ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æŒ‡æ¨™

**æ¥ç¶š**:
- ç¬¬40å›: 1-stepç”Ÿæˆã§é«˜é€ŸåŒ–ã‚’å®Ÿç¾
- **ç¬¬41å›**: ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®çœŸã®ç›®çš„ â€” ä¸–ç•Œã‚’ç†è§£ã—æœªæ¥ã‚’äºˆæ¸¬ã™ã‚‹

**ğŸ’€ å¸¸è­˜ç ´å£Šã®å•ã„**: ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®çµ‚ç€ç‚¹ã¯"ç†è§£"ã§ã¯ï¼Ÿ

> **Note:** **Course IV ç¬¬8å›ï¼ˆç¬¬40å›ï¼‰å®Œäº†ï¼**
>
> **é”æˆã—ãŸã“ã¨**:
> - Self-consistencyæ¡ä»¶ã®ç†è«–çš„ä¿è¨¼ã‚’å®Œå…¨ç†è§£
> - CT/CD/iCT/ECTã®è¨“ç·´æ‰‹æ³•ã‚’æ•°å¼ãƒ¬ãƒ™ãƒ«ã§æŠŠæ¡
> - DPM-Solver++/UniPCã¨ã®æ¯”è¼ƒã§é«˜æ¬¡ã‚½ãƒ«ãƒãƒ¼ã‚’ç†è§£
> - Progressive/LCM/InstaFlow/DMD2ã®è’¸ç•™ç³»è­œã‚’æ•´ç†
> - Rustã§CTå®Ÿè£…ã€Rustã§Candleæ¨è«–ã‚’å®Œæˆ
> - 1-stepç”Ÿæˆã®ç†è«–é™ç•Œã¨å®Ÿç”¨ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’ç¿’å¾—
>
> **æ¬¡ã®æŒ‘æˆ¦**:
> ç¬¬41å›ã§World Modelsã¸ã€‚Diffusionã¯ã€Œã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã€ã‹ã‚‰ã€Œä¸–ç•Œç†è§£ã‚¨ãƒ³ã‚¸ãƒ³ã€ã¸é€²åŒ–ã™ã‚‹ã€‚
>
> **Course IVå…¨ä½“ã®åˆ°é”ç‚¹**:
> é™æ­¢ç”»ç”Ÿæˆã®å…¨ç†è«–ï¼ˆDDPMâ†’Scoreâ†’Flowâ†’Latentâ†’Consistencyï¼‰ã‚’å®Œå…¨åˆ¶è¦‡ã€‚æ¬¡ã¯æ™‚ç©ºé–“ã¸ã€‚

---

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: Song, Y., Dhariwal, P., Chen, M., & Sutskever, I. (2023). Consistency Models. *ICML 2023*.
<https://arxiv.org/abs/2303.01469>

[^2]: Song, Y., & Dhariwal, P. (2023). Improved Techniques for Training Consistency Models. *arXiv:2310.14189*.
<https://arxiv.org/abs/2310.14189>

[^3]: Geng, Z., Pokle, A., Luo, W., Lin, J., & Kolter, J. Z. (2025). Consistency Models Made Easy. *ICLR 2025*.
<https://arxiv.org/abs/2406.14548>

[^4]: Lu, C., Zhou, Y., Bao, F., Chen, J., Li, C., & Zhu, J. (2022). DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models. *arXiv:2211.01095*.
<https://arxiv.org/abs/2211.01095>

[^5]: Zhao, W., Bai, L., Rao, Y., Zhou, J., & Lu, J. (2023). UniPC: A Unified Predictor-Corrector Framework for Fast Sampling of Diffusion Models. *NeurIPS 2023*.
<https://arxiv.org/abs/2302.04867>

[^6]: Salimans, T., & Ho, J. (2022). Progressive Distillation for Fast Sampling of Diffusion Models. *ICLR 2022*.
<https://arxiv.org/abs/2202.00512>

[^7]: Luo, S., Tan, Y., Huang, L., Li, J., & Zhao, H. (2023). Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference. *arXiv:2310.04378*.
<https://arxiv.org/abs/2310.04378>

[^8]: Liu, X., Gong, C., & Liu, Q. (2023). InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation. *arXiv:2309.06380*.
<https://arxiv.org/abs/2309.06380>

[^9]: Lin, S., Xia, X., Ren, Y., Yang, C., Xiao, X., & Jiang, L. (2025). Diffusion Adversarial Post-Training for One-Step Video Generation. *arXiv:2501.08316*.
<https://arxiv.org/abs/2501.08316>

[^10]: Karras, T., Aittala, M., Aila, T., & Laine, S. (2022). Elucidating the Design Space of Diffusion-Based Generative Models. *NeurIPS 2022*.
<https://arxiv.org/abs/2206.00364>

[^11]: Kim, D., Lai, C.-H., Liao, W.-H., Murata, N., Takida, Y., Uesaka, T., ... & Ermon, S. (2023). Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion. *arXiv:2310.02279*.
<https://arxiv.org/abs/2310.02279>

### æ•™ç§‘æ›¸ãƒ»ã‚µãƒ¼ãƒ™ã‚¤

- MIT 6.S184 (2026). *Diffusion Models*. [diffusion.csail.mit.edu](https://diffusion.csail.mit.edu/)
- Song, Y., & Ermon, S. (2020). "Score-Based Generative Modeling through Stochastic Differential Equations" (èƒŒæ™¯ç†è«–)
- Ho, J., Jain, A., & Abbeel, P. (2020). "Denoising Diffusion Probabilistic Models" (DDPMåŸè«–æ–‡)

---

> **Progress: 95%**
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. Consistency Trajectory Models (CTM) ãŒ Consistency Models ã®ä¸€èˆ¬åŒ–ã«ãªã£ã¦ã„ã‚‹ç†ç”±ã‚’ã€ä»»æ„ $(t,s)$ ãƒšã‚¢ã¸ã®ä¸€èˆ¬åŒ–ã®è¦³ç‚¹ã‹ã‚‰èª¬æ˜ã›ã‚ˆã€‚
> 2. 1-step ç”Ÿæˆã®ç†è«–çš„ä¸‹ç•Œï¼ˆFID ã®æƒ…å ±ç†è«–çš„é™ç•Œï¼‰ã¯å­˜åœ¨ã™ã‚‹ã‹ï¼Ÿ Rate-Distortion ç†è«–ã®è¦³ç‚¹ã‹ã‚‰è«–ã˜ã‚ˆã€‚

---

## è‘—è€…ãƒªãƒ³ã‚¯

- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
