---
title: "ç¬¬4å›: ç¢ºç‡è«–ãƒ»çµ±è¨ˆå­¦ã€å‰ç·¨ã€‘â€” Kolmogorovã®å…¬ç†ç³»ã‹ã‚‰ãƒ™ã‚¤ã‚ºæ¨è«–ã¾ã§"
emoji: "ğŸ²"
type: "tech"
topics: ["machinelearning", "probability", "statistics", "math", "python"]
published: false
slug: "ml-lecture-04-part1"
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Python"]
keywords: ["ç¢ºç‡è«–", "ãƒ™ã‚¤ã‚ºã®å®šç†", "MLE", "æŒ‡æ•°å‹åˆ†å¸ƒæ—", "å¤šå¤‰é‡æ­£è¦åˆ†å¸ƒ"]
---

# ç¬¬4å›: ç¢ºç‡è«–ãƒ»çµ±è¨ˆå­¦ã€å‰ç·¨ã€‘

## Learning Objectives

ã“ã®è¬›ç¾©ã‚’ä¿®äº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™:

- [ ] Kolmogorovã®å…¬ç†ç³»ã‹ã‚‰ç¢ºç‡ç©ºé–“ã‚’å®šç¾©ã§ãã‚‹
- [ ] ãƒ™ã‚¤ã‚ºã®å®šç†ã®é›¢æ•£ç‰ˆãƒ»é€£ç¶šç‰ˆã‚’å°å‡ºã§ãã‚‹
- [ ] æŒ‡æ•°å‹åˆ†å¸ƒæ—ã®çµ±ä¸€çš„æ§‹é€ ã‚’èª¬æ˜ã§ãã‚‹
- [ ] å¤šå¤‰é‡æ­£è¦åˆ†å¸ƒã®æ¡ä»¶ä»˜ãåˆ†å¸ƒã‚’è¨ˆç®—ã§ãã‚‹
- [ ] MLEã®ä¸€è‡´æ€§ãƒ»æ¼¸è¿‘æ­£è¦æ€§ã‚’è¨¼æ˜ã§ãã‚‹
- [ ] è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«ã®å°¤åº¦ã‚’é€£é–è¦å‰‡ã§åˆ†è§£ã§ãã‚‹

---

## ğŸš€ Z1. ãƒ—ãƒ­ãƒ­ãƒ¼ã‚°ï¼ˆ5åˆ†ï¼‰â€” æœ¬è¬›ç¾©ã®ä½ç½®ã¥ã‘

**ã‚´ãƒ¼ãƒ«**: ç¬¬4å›ãŒæ©Ÿæ¢°å­¦ç¿’ä½“ç³»ã®ä¸­ã§ã©ã“ã«ä½ç½®ã™ã‚‹ã‹ã‚’ç†è§£ã™ã‚‹ã€‚

> Progress: 3%

### ãªãœä»Šã€ç¢ºç‡è«–ãªã®ã‹ï¼Ÿ

ç¬¬1-3å›ã§æ‰±ã£ãŸç·šå½¢ä»£æ•°ãƒ»æœ€é©åŒ–ãƒ»å¾®åˆ†ã¯ã€æ©Ÿæ¢°å­¦ç¿’ã® **è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³** ã ã£ãŸã€‚ã—ã‹ã—ç¾ä»£ã®æ©Ÿæ¢°å­¦ç¿’ã¯ã€ã‚‚ã†ä¸€ã¤ã®æ•°å­¦çš„åŸºç›¤ã‚’æŒã¤:

**ç¢ºç‡è«– (Probability Theory)** â€” ä¸ç¢ºå®Ÿæ€§ã‚’æ‰±ã†æ•°å­¦ã€‚

| ç·šå½¢ä»£æ•° | ç¢ºç‡è«– |
|:---------|:-------|
| ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¾ (`$\mathbf{x} \in \mathbb{R}^d$`) | ãƒ‡ãƒ¼ã‚¿ã®ä¸ç¢ºå®Ÿæ€§ (`$p(\mathbf{x})$`) |
| å¤‰æ› (`$\mathbf{y} = W\mathbf{x}$`) | æ¡ä»¶ä»˜ãç¢ºç‡ (`$p(\mathbf{y} \mid \mathbf{x})$`) |
| æœ€é©åŒ– (`$\min L(W)$`) | æœ€å°¤æ¨å®š (`$\max p(\mathcal{D} \mid \theta)$`) |

**ç¬¬3å›ã¾ã§ã®ã€Œæ±ºå®šè«–çš„ã€ä¸–ç•Œ**:

```python
y = W @ x + b  # å…¥åŠ› x ãŒæ±ºã¾ã‚Œã°ã€å‡ºåŠ› y ã‚‚ä¸€æ„ã«æ±ºã¾ã‚‹
```

**ç¬¬4å›ä»¥é™ã®ã€Œç¢ºç‡è«–çš„ã€ä¸–ç•Œ**:


### ç¾ä»£æ©Ÿæ¢°å­¦ç¿’ã«ãŠã‘ã‚‹ç¢ºç‡è«–

| ãƒ¢ãƒ‡ãƒ« | ç¢ºç‡è«–çš„è¦ç´  |
|:-------|:-------------|
| **VAE** | æ½œåœ¨å¤‰æ•° `$\mathbf{z} \sim q_\phi(\mathbf{z} \mid \mathbf{x})$` |
| **Diffusion** | æ‹¡æ•£éç¨‹ `$q(\mathbf{x}_t \mid \mathbf{x}_{t-1})$` |
| **LLM** | ãƒˆãƒ¼ã‚¯ãƒ³åˆ†å¸ƒ `$p_\theta(x_t \mid x_{<t})$` |
| **GAN** | Generator `$G: \mathbf{z} \sim p_z(\mathbf{z}) \to \mathbf{x}$` |
| **Flow** | ç¢ºç‡å¯†åº¦å¤‰æ› `$p_X(\mathbf{x}) = p_Z(f^{-1}(\mathbf{x})) \left|\det \frac{\partial f^{-1}}{\partial \mathbf{x}}\right|$` |

**å…¨ã¦ç¢ºç‡åˆ†å¸ƒ `$p(\cdot)$` ã‚’æ‰±ã†ã€‚**

ç¢ºç‡è«–ãªãã—ã¦ã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯èªã‚Œãªã„ã€‚

### ç¬¬4å›ã§å­¦ã¶5ã¤ã®Topic

1. **ç¢ºç‡ç©ºé–“ã¨ç¢ºç‡å¤‰æ•°** (30åˆ†)
   - Kolmogorovã®å…¬ç†ç³»
   - ç¢ºç‡æ¸¬åº¦ã€å¯æ¸¬é–¢æ•°ã€ç¢ºç‡å¤‰æ•°ã®å³å¯†ãªå®šç¾©
   - é›¢æ•£ vs é€£ç¶šç¢ºç‡å¤‰æ•°

2. **ä¸»è¦ç¢ºç‡åˆ†å¸ƒ** (45åˆ†)
   - Gaussian (Normal) distribution
   - Bernoulli, Categorical, Multinomial
   - Dirichlet distribution (Bayesian priors)
   - Exponential Family ã®çµ±ä¸€çš„è¦–ç‚¹

3. **ãƒ™ã‚¤ã‚ºã®å®šç†ã¨MLE** (45åˆ†)
   - æœ€å°¤æ¨å®š (Maximum Likelihood Estimation, MLE)
   - æœ€å¤§äº‹å¾Œç¢ºç‡æ¨å®š (Maximum A Posteriori, MAP)
   - ãƒ™ã‚¤ã‚ºæ¨è«– (Bayesian Inference)
   - Conjugate priors (å…±å½¹äº‹å‰åˆ†å¸ƒ)

4. **ç¢ºç‡å¤‰æ•°ã®å¤‰æ›** (30åˆ†)
   - Change of Variables formula
   - Jacobian determinant
   - Normalizing Flows ã¸ã®ä¼ç·š

5. **Boss Battle: è‡ªå·±å›å¸°LLMã®å°¤åº¦** (30åˆ†)
   - `$\log p(\mathbf{x}) = \sum_{t=1}^T \log p(x_t \mid x_{<t})$`
   - Cross-entropy loss ã¨ã®ç­‰ä¾¡æ€§
   - Teacher forcing vs autoregressive sampling

### Learning Objectives

æœ¬è¬›ç¾©ã‚’ä¿®äº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚‹:

- [ ] Kolmogorovã®å…¬ç†ç³»ã‹ã‚‰ç¢ºç‡è«–ã‚’æ§‹ç¯‰ã§ãã‚‹
- [ ] ä¸»è¦ç¢ºç‡åˆ†å¸ƒã®æ€§è³ªã¨ç›¸äº’é–¢ä¿‚ã‚’èª¬æ˜ã§ãã‚‹
- [ ] MLE, MAP, Bayesianæ¨è«–ã®é•ã„ã¨ä½¿ã„åˆ†ã‘ã‚’ç†è§£ã™ã‚‹
- [ ] ç¢ºç‡å¤‰æ•°ã®å¤‰æ›å…¬å¼ã‚’å°å‡ºãƒ»é©ç”¨ã§ãã‚‹
- [ ] GPTã®å°¤åº¦æœ€å¤§åŒ–ãŒCross-entropyã¨ç­‰ä¾¡ã§ã‚ã‚‹ã“ã¨ã‚’è¨¼æ˜ã§ãã‚‹

---

## ğŸ“– Z2. ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ï¼ˆ15åˆ†ï¼‰â€” ç¢ºç‡è«–ã®åŸºç¤æ¦‚å¿µ

**ã‚´ãƒ¼ãƒ«**: ç¢ºç‡è«–ã®å³å¯†ãªæ•°å­¦çš„å®šç¾©ã‚’ç†è§£ã™ã‚‹ã€‚

> Progress: 10%

### 1.1 Kolmogorovã®å…¬ç†ç³»

ç¢ºç‡è«–ã¯ã€ãƒ­ã‚·ã‚¢ã®æ•°å­¦è€… **Andrey Kolmogorov** (1933) ãŒå…¬ç†åŒ–ã—ãŸã€‚

**Definition 1.1 (ç¢ºç‡ç©ºé–“)**

ç¢ºç‡ç©ºé–“ã¯3ã¤çµ„ `$(\Omega, \mathcal{F}, P)$` ã¨ã—ã¦å®šç¾©ã•ã‚Œã‚‹:

1. **æ¨™æœ¬ç©ºé–“** (Sample Space) `$\Omega$`: å…¨ã¦ã®å¯èƒ½ãªçµæœã®é›†åˆ
2. **Ïƒ-algebra** `$\mathcal{F}$`: `$\Omega$` ã®éƒ¨åˆ†é›†åˆæ—ï¼ˆäº‹è±¡ã®é›†åˆï¼‰
3. **ç¢ºç‡æ¸¬åº¦** (Probability Measure) `$P: \mathcal{F} \to [0, 1]$`

**Axiom 1.1 (Kolmogorovã®3å…¬ç†)**

ç¢ºç‡æ¸¬åº¦ `$P$` ã¯ä»¥ä¸‹ã‚’æº€ãŸã™:

1. **éè² æ€§**: `$\forall A \in \mathcal{F}, \; P(A) \geq 0$`
2. **æ­£è¦æ€§**: `$P(\Omega) = 1$`
3. **å¯ç®—åŠ æ³•æ€§**: äº’ã„ã«ç´ ãªäº‹è±¡ `$A_1, A_2, \ldots$` ã«å¯¾ã—ã¦ã€

```math
P\left(\bigcup_{i=1}^\infty A_i\right) = \sum_{i=1}^\infty P(A_i)
```

**ã“ã®3å…¬ç†ã‹ã‚‰ã€ç¢ºç‡è«–ã®å…¨ã¦ãŒå°å‡ºã•ã‚Œã‚‹ã€‚**

### 1.2 Ïƒ-algebra ã®å½¹å‰²

ãªãœ Ïƒ-algebra ãŒå¿…è¦ãªã®ã‹ï¼Ÿ

**ç›´æ„Ÿçš„èª¬æ˜**:

- ã‚µã‚¤ã‚³ãƒ­ã‚’æŒ¯ã‚‹: `$\Omega = \{1, 2, 3, 4, 5, 6\}$`
- ã€Œå¶æ•°ãŒå‡ºã‚‹ã€äº‹è±¡: `$A = \{2, 4, 6\}$`
- ã€Œå¶æ•°ãŒå‡ºãªã„ã€äº‹è±¡: `$A^c = \{1, 3, 5\}$`

**ç¢ºç‡ã‚’å‰²ã‚Šå½“ã¦ã‚‹ã«ã¯ã€äº‹è±¡ `$A$` ãŒã€Œæ¸¬å®šå¯èƒ½ã€ã§ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚**

**Definition 1.2 (Ïƒ-algebra)**

é›†åˆæ— `$\mathcal{F} \subseteq 2^\Omega$` ãŒ Ïƒ-algebra ã§ã‚ã‚‹ã¨ã¯:

1. `$\Omega \in \mathcal{F}$`
2. `$A \in \mathcal{F} \Rightarrow A^c \in \mathcal{F}$` (è£œé›†åˆ)
3. `$A_1, A_2, \ldots \in \mathcal{F} \Rightarrow \bigcup_{i=1}^\infty A_i \in \mathcal{F}$` (å¯ç®—å’Œ)

**Example 1.1 (é›¢æ•£ç¢ºç‡ç©ºé–“)**

ã‚µã‚¤ã‚³ãƒ­: `$\Omega = \{1, 2, 3, 4, 5, 6\}$`

- `$\mathcal{F} = 2^\Omega$` (å…¨ã¦ã®éƒ¨åˆ†é›†åˆ)
- `$P(\{k\}) = 1/6$` for `$k = 1, \ldots, 6$`
- `$P(\{2, 4, 6\}) = P(\{2\}) + P(\{4\}) + P(\{6\}) = 1/2$`

**Example 1.2 (é€£ç¶šç¢ºç‡ç©ºé–“)**

å®Ÿæ•°ä¸Šã®ç¢ºç‡: `$\Omega = \mathbb{R}$`

- `$\mathcal{F} = \mathcal{B}(\mathbb{R})$` (Borel Ïƒ-algebra)
- `$P([a, b]) = \int_a^b p(x) dx$`

â†’ é€£ç¶šç¢ºç‡ç©ºé–“ã§ã¯ã€Ïƒ-algebra ãŒæ¸¬åº¦è«–ã®æŠ€è¡“ã‚’å¿…è¦ã¨ã™ã‚‹ã€‚

### 1.3 ç¢ºç‡å¤‰æ•°

**Definition 1.3 (ç¢ºç‡å¤‰æ•°)**

ç¢ºç‡å¤‰æ•° `$X$` ã¯ã€å¯æ¸¬é–¢æ•° `$X: \Omega \to \mathbb{R}$` ã§ã‚ã‚‹:

```math
\forall B \in \mathcal{B}(\mathbb{R}), \; X^{-1}(B) := \{\omega \in \Omega : X(\omega) \in B\} \in \mathcal{F}
```

**ç›´æ„Ÿçš„æ„å‘³**:

- `$\Omega$`: ã€Œã‚µã‚¤ã‚³ãƒ­ã®ç›®ã€
- `$X(\omega)$`: ã€Œå‡ºãŸç›®ã®å€¤ã€

**Example 1.3 (ã‚µã‚¤ã‚³ãƒ­ã®å’Œ)**

2ã¤ã®ã‚µã‚¤ã‚³ãƒ­ `$X_1, X_2$` ã®å’Œ `$S = X_1 + X_2$`:

- `$\Omega = \{(i, j) : i, j \in \{1, \ldots, 6\}\}$`
- `$S(\omega) = i + j$`
- `$P(S = 7) = P(\{(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\}) = 6/36 = 1/6$`

### 1.4 ç¢ºç‡å¯†åº¦é–¢æ•° (PDF) ã¨ç¢ºç‡è³ªé‡é–¢æ•° (PMF)

**Definition 1.4 (ç¢ºç‡è³ªé‡é–¢æ•°, PMF)**

é›¢æ•£ç¢ºç‡å¤‰æ•° `$X$` ã«å¯¾ã—ã¦ã€

```math
p_X(x) := P(X = x), \quad \sum_{x \in \mathcal{X}} p_X(x) = 1
```

**Definition 1.5 (ç¢ºç‡å¯†åº¦é–¢æ•°, PDF)**

é€£ç¶šç¢ºç‡å¤‰æ•° `$X$` ã«å¯¾ã—ã¦ã€

```math
P(a \leq X \leq b) = \int_a^b p_X(x) dx, \quad \int_{-\infty}^\infty p_X(x) dx = 1
```

**é‡è¦**: PDF `$p_X(x)$` è‡ªä½“ã¯ç¢ºç‡ã§ã¯ãªã„ï¼ˆ`$p_X(x) > 1$` ã‚‚ã‚ã‚Šå¾—ã‚‹ï¼‰ã€‚

**Example 1.4 (Uniform distribution)**

```math
p_X(x) = \begin{cases} \frac{1}{b-a} & a \leq x \leq b \\ 0 & \text{otherwise} \end{cases}
```

- `$a = 0, b = 0.5$` ã®ã¨ãã€`$p_X(0.1) = 2 > 1$` ï¼ˆç¢ºç‡ã§ã¯ãªã„ï¼ï¼‰

### 1.5 ç´¯ç©åˆ†å¸ƒé–¢æ•° (CDF)

**Definition 1.6 (ç´¯ç©åˆ†å¸ƒé–¢æ•°, CDF)**

```math
F_X(x) := P(X \leq x) = \begin{cases}
\sum_{x_i \leq x} p_X(x_i) & \text{(discrete)} \\
\int_{-\infty}^x p_X(t) dt & \text{(continuous)}
\end{cases}
```

**Properties**:

1. `$F_X(-\infty) = 0, \; F_X(\infty) = 1$`
2. `$F_X$` ã¯å˜èª¿éæ¸›å°‘
3. å³é€£ç¶š: `$\lim_{h \to 0^+} F_X(x+h) = F_X(x)$`

**Theorem 1.1 (Fundamental Theorem of Calculus for Probability)**

é€£ç¶šç¢ºç‡å¤‰æ•° `$X$` ã«å¯¾ã—ã¦ã€

```math
p_X(x) = \frac{dF_X}{dx}(x)
```

### 1.6 æœŸå¾…å€¤ã¨åˆ†æ•£

**Definition 1.7 (æœŸå¾…å€¤, Expectation)**

```math
\mathbb{E}[X] := \begin{cases}
\sum_{x \in \mathcal{X}} x \, p_X(x) & \text{(discrete)} \\
\int_{-\infty}^\infty x \, p_X(x) dx & \text{(continuous)}
\end{cases}
```

**Definition 1.8 (åˆ†æ•£, Variance)**

```math
\text{Var}(X) := \mathbb{E}[(X - \mathbb{E}[X])^2] = \mathbb{E}[X^2] - (\mathbb{E}[X])^2
```

**Proof** (åˆ†æ•£ã®å…¬å¼):

```math
\text{Var}(X) = \mathbb{E}[(X - \mathbb{E}[X])^2] = \mathbb{E}[X^2 - 2X\mathbb{E}[X] + (\mathbb{E}[X])^2]
```

Linearity of expectation:

```math
= \mathbb{E}[X^2] - 2\mathbb{E}[X]\mathbb{E}[X] + (\mathbb{E}[X])^2 = \mathbb{E}[X^2] - (\mathbb{E}[X])^2
```

âˆ

**Theorem 1.2 (Linearity of Expectation)**

```math
\mathbb{E}[aX + bY] = a\mathbb{E}[X] + b\mathbb{E}[Y]
```

**é‡è¦**: `$X, Y$` ãŒç‹¬ç«‹ã§ãªãã¦ã‚‚æˆç«‹ã€‚

**Theorem 1.3 (Variance of Linear Transformation)**

```math
\text{Var}(aX + b) = a^2 \text{Var}(X)
```

**Proof**:

```math
\text{Var}(aX + b) = \mathbb{E}[(aX + b - \mathbb{E}[aX + b])^2]
```

```math
= \mathbb{E}[(aX + b - a\mathbb{E}[X] - b)^2] = \mathbb{E}[(aX - a\mathbb{E}[X])^2]
```

```math
= a^2 \mathbb{E}[(X - \mathbb{E}[X])^2] = a^2 \text{Var}(X)
```

âˆ

### 1.7 ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆç”Ÿæˆé–¢æ•° (MGF)

**Definition 1.9 (Moment Generating Function)**

```math
M_X(t) := \mathbb{E}[e^{tX}] = \begin{cases}
\sum_{x} e^{tx} p_X(x) & \text{(discrete)} \\
\int_{-\infty}^\infty e^{tx} p_X(x) dx & \text{(continuous)}
\end{cases}
```

**Why useful?**

MGF ã® Taylor å±•é–‹ã‹ã‚‰å…¨ã¦ã®ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆã‚’å–å¾—å¯èƒ½:

```math
M_X(t) = \sum_{n=0}^\infty \frac{\mathbb{E}[X^n]}{n!} t^n
```

**Theorem 1.4 (MGF â†’ Moments)**

```math
\frac{d^n M_X}{dt^n}\bigg|_{t=0} = \mathbb{E}[X^n]
```

**Example 1.5 (Gaussian MGF)**

`$X \sim \mathcal{N}(\mu, \sigma^2)$`:

```math
M_X(t) = \mathbb{E}[e^{tX}] = \int_{-\infty}^\infty e^{tx} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right) dx
```

Complete the square:

```math
= \exp\left(\mu t + \frac{\sigma^2 t^2}{2}\right)
```

**Verification**:

```math
\frac{dM_X}{dt}\bigg|_{t=0} = (\mu + \sigma^2 t) \exp\left(\mu t + \frac{\sigma^2 t^2}{2}\right)\bigg|_{t=0} = \mu = \mathbb{E}[X] \quad \checkmark
```

```math
\frac{d^2M_X}{dt^2}\bigg|_{t=0} = \mu^2 + \sigma^2 = \mathbb{E}[X^2] \quad \Rightarrow \quad \text{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}[X])^2 = \sigma^2 \quad \checkmark
```

### 1.8 å…±åˆ†æ•£ã¨ç›¸é–¢ä¿‚æ•°

**Definition 1.10 (Covariance)**

```math
\text{Cov}(X, Y) := \mathbb{E}[(X - \mathbb{E}[X])(Y - \mathbb{E}[Y])] = \mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y]
```

**Properties**:

1. `$\text{Cov}(X, X) = \text{Var}(X)$`
2. `$\text{Cov}(X, Y) = \text{Cov}(Y, X)$`
3. `$\text{Cov}(aX, bY) = ab \, \text{Cov}(X, Y)$`
4. Independent â†’ `$\text{Cov}(X, Y) = 0$` ï¼ˆé€†ã¯ä¸æˆç«‹ï¼‰

**Definition 1.11 (Correlation Coefficient)**

```math
\rho_{XY} := \frac{\text{Cov}(X, Y)}{\sqrt{\text{Var}(X) \text{Var}(Y)}} = \frac{\text{Cov}(X, Y)}{\sigma_X \sigma_Y}
```

**Range**: `$-1 \leq \rho_{XY} \leq 1$`

**Interpretation**:

- `$\rho = 1$`: Perfect positive correlation (`$Y = aX + b$`, `$a > 0$`)
- `$\rho = -1$`: Perfect negative correlation (`$Y = aX + b$`, `$a < 0$`)
- `$\rho = 0$`: Uncorrelatedï¼ˆç‹¬ç«‹ã¨ã¯é™ã‚‰ãªã„ï¼‰

**Example 1.6 (Uncorrelated but Dependent)**

`$X \sim \mathcal{N}(0, 1)$`, `$Y = X^2$`:

```math
\mathbb{E}[XY] = \mathbb{E}[X^3] = 0 \quad (\text{odd moment of Gaussian})
```

```math
\text{Cov}(X, Y) = \mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y] = 0 - 0 \cdot 1 = 0
```

ã—ã‹ã— `$Y$` ã¯ `$X$` ã«å®Œå…¨ã«ä¾å­˜ã—ã¦ã„ã‚‹ã€‚ â†’ **Uncorrelated â‰  Independent**

### 1.9 æ¡ä»¶ä»˜ãç¢ºç‡ã¨ç‹¬ç«‹æ€§

**Definition 1.12 (Conditional Probability)**

```math
P(A \mid B) := \frac{P(A \cap B)}{P(B)}, \quad P(B) > 0
```

**Theorem 1.5 (Law of Total Probability)**

`$\{B_1, B_2, \ldots\}$` ãŒ partition of `$\Omega$` ãªã‚‰:

```math
P(A) = \sum_{i} P(A \mid B_i) P(B_i)
```

**Definition 1.13 (Independence)**

Events `$A, B$` ãŒç‹¬ç«‹ã§ã‚ã‚‹ã¨ã¯:

```math
P(A \cap B) = P(A) P(B)
```

Random variables `$X, Y$` ãŒç‹¬ç«‹ã§ã‚ã‚‹ã¨ã¯:

```math
p_{X,Y}(x, y) = p_X(x) p_Y(y) \quad \forall x, y
```

**Theorem 1.6 (Independence â†’ Uncorrelated)**

`$X, Y$` independent â†’ `$\text{Cov}(X, Y) = 0$`

**Proof**:

```math
\mathbb{E}[XY] = \int \int xy \, p_{X,Y}(x, y) dx dy = \int \int xy \, p_X(x) p_Y(y) dx dy
```

```math
= \left(\int x p_X(x) dx\right) \left(\int y p_Y(y) dy\right) = \mathbb{E}[X] \mathbb{E}[Y]
```

```math
\text{Cov}(X, Y) = \mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y] = 0
```

âˆ

---

## ğŸ§­ Z3. ä¸–ç•Œè¦³ï¼ˆ20åˆ†ï¼‰â€” Topic 1 & 2: ä¸»è¦ç¢ºç‡åˆ†å¸ƒ

**ã‚´ãƒ¼ãƒ«**: ä¸»è¦ç¢ºç‡åˆ†å¸ƒã‚’å®Œå…¨ã«ç†è§£ã™ã‚‹ã€‚

> Progress: 20%

### Topic 1: ä¸»è¦é›¢æ•£ç¢ºç‡åˆ†å¸ƒ

#### 1.1 Bernoulli åˆ†å¸ƒ

**Definition 2.1 (Bernoulli Distribution)**

```math
X \sim \text{Bernoulli}(p), \quad p_X(x) = \begin{cases} p & x = 1 \\ 1-p & x = 0 \end{cases}
```

**Properties**:

- `$\mathbb{E}[X] = p$`
- `$\text{Var}(X) = p(1-p)$`

**Application**: Binary classification (label 0 or 1)

#### 1.2 Categorical åˆ†å¸ƒ

**Definition 2.2 (Categorical Distribution)**

```math
X \sim \text{Categorical}(\mathbf{p}), \quad p_X(k) = p_k, \quad \sum_{k=1}^K p_k = 1
```

**Example**: ã‚µã‚¤ã‚³ãƒ­ (`$K = 6$`)

**Notation**: One-hot encoding

```math
\mathbf{x} = [0, 0, 1, 0, 0, 0]^\top \quad (\text{outcome } k=3)
```

**Likelihood**:

```math
p(\mathbf{x} \mid \mathbf{p}) = \prod_{k=1}^K p_k^{x_k}
```

#### 1.3 Multinomial åˆ†å¸ƒ

**Definition 2.3 (Multinomial Distribution)**

`$n$` å›ã®è©¦è¡Œã§ã€å„ã‚«ãƒ†ã‚´ãƒª `$k$` ãŒ `$n_k$` å›å‡ºç¾ã™ã‚‹ç¢ºç‡:

```math
\mathbf{n} \sim \text{Multinomial}(n, \mathbf{p}), \quad p(\mathbf{n}) = \frac{n!}{n_1! \cdots n_K!} \prod_{k=1}^K p_k^{n_k}
```

**Properties**:

- `$\mathbb{E}[n_k] = n p_k$`
- `$\text{Var}(n_k) = n p_k (1 - p_k)$`
- `$\text{Cov}(n_i, n_j) = -n p_i p_j$` (`$i \neq j$`)

### Topic 2: ä¸»è¦é€£ç¶šç¢ºç‡åˆ†å¸ƒ

#### 2.1 Gaussian (Normal) åˆ†å¸ƒ

**Definition 2.4 (Gaussian Distribution)**

```math
X \sim \mathcal{N}(\mu, \sigma^2), \quad p_X(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)
```

**Properties**:

- `$\mathbb{E}[X] = \mu$`
- `$\text{Var}(X) = \sigma^2$`

**Multivariate Gaussian**:

```math
\mathbf{x} \sim \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\Sigma}), \quad p(\mathbf{x}) = \frac{1}{(2\pi)^{d/2} |\boldsymbol{\Sigma}|^{1/2}} \exp\left(-\frac{1}{2}(\mathbf{x} - \boldsymbol{\mu})^\top \boldsymbol{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu})\right)
```

**Why Gaussian?**

1. **Central Limit Theorem**: ç‹¬ç«‹ãªç¢ºç‡å¤‰æ•°ã®å’Œã¯ Gaussian ã«åæŸ
2. **Maximum Entropy**: ä¸ãˆã‚‰ã‚ŒãŸå¹³å‡ãƒ»åˆ†æ•£ã®ä¸‹ã§ã€ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒæœ€å¤§
3. **Conjugate Prior**: Likelihood ãŒ Gaussian ãªã‚‰ã€posterior ã‚‚ Gaussian

#### 2.2 Exponential Family

**Definition 2.5 (Exponential Family)**

ç¢ºç‡åˆ†å¸ƒ `$p(x \mid \boldsymbol{\theta})$` ãŒ exponential family ã«å±ã™ã‚‹ã¨ã¯:

```math
p(x \mid \boldsymbol{\theta}) = h(x) \exp\left(\boldsymbol{\eta}(\boldsymbol{\theta})^\top \mathbf{T}(x) - A(\boldsymbol{\theta})\right)
```

ã“ã“ã§:

- `$\boldsymbol{\eta}(\boldsymbol{\theta})$`: Natural parameter (è‡ªç„¶ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)
- `$\mathbf{T}(x)$`: Sufficient statistic (ååˆ†çµ±è¨ˆé‡)
- `$A(\boldsymbol{\theta})$`: Log-partition function

**Example 2.1 (Gaussian as Exponential Family)**

```math
\mathcal{N}(x \mid \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)
```

Natural parameters:

```math
\eta_1 = \frac{\mu}{\sigma^2}, \quad \eta_2 = -\frac{1}{2\sigma^2}
```

Sufficient statistics:

```math
T_1(x) = x, \quad T_2(x) = x^2
```

Log-partition function:

```math
A(\mu, \sigma^2) = \frac{\mu^2}{2\sigma^2} + \frac{1}{2}\log(2\pi\sigma^2)
```

**é‡è¦æ€§**:

1. **çµ±ä¸€çš„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**: Gaussian, Bernoulli, Poisson, Gamma, â€¦ å…¨ã¦ exponential family
2. **Sufficient Statistics**: ãƒ‡ãƒ¼ã‚¿ `$\{x_1, \ldots, x_n\}$` ã‚’ `$\mathbf{T}(\mathcal{D})$` ã«åœ§ç¸®å¯èƒ½
3. **Conjugate Priors**: Exponential family ã«ã¯å¸¸ã« conjugate prior ãŒå­˜åœ¨

#### 2.3 Dirichlet åˆ†å¸ƒ

**Definition 2.6 (Dirichlet Distribution)**

```math
\mathbf{p} \sim \text{Dir}(\boldsymbol{\alpha}), \quad p(\mathbf{p}) = \frac{1}{B(\boldsymbol{\alpha})} \prod_{k=1}^K p_k^{\alpha_k - 1}
```

ã“ã“ã§:

```math
B(\boldsymbol{\alpha}) = \frac{\prod_{k=1}^K \Gamma(\alpha_k)}{\Gamma\left(\sum_{k=1}^K \alpha_k\right)}
```

**Properties**:

- `$\mathbb{E}[p_k] = \frac{\alpha_k}{\sum_{j=1}^K \alpha_j}$`
- `$\mathbf{p}$` ã¯ simplex ä¸Šã®åˆ†å¸ƒ: `$\sum_{k=1}^K p_k = 1, \; p_k \geq 0$`

**Application**: Categorical åˆ†å¸ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ `$\mathbf{p}$` ã®äº‹å‰åˆ†å¸ƒ

**Example 2.2 (Beta Distribution)**

`$K = 2$` ã®ã¨ãã€Dirichlet = Beta:

```math
p(\theta \mid \alpha, \beta) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \theta^{\alpha-1} (1-\theta)^{\beta-1}
```

- `$\alpha = \beta = 1$`: Uniform
- `$\alpha = \beta = 0.5$`: Jeffreys prior
- `$\alpha, \beta > 1$`: Peaked around mean

#### 2.4 Poisson åˆ†å¸ƒ

**Definition 2.7 (Poisson Distribution)**

```math
X \sim \text{Poisson}(\lambda), \quad p_X(k) = \frac{\lambda^k e^{-\lambda}}{k!}, \quad k = 0, 1, 2, \ldots
```

**Properties**:

- `$\mathbb{E}[X] = \lambda$`
- `$\text{Var}(X) = \lambda$`

**Application**: Count dataï¼ˆäº‹è±¡ã®ç™ºç”Ÿå›æ•°ï¼‰

**Example 2.3 (Poisson as limit of Binomial)**

`$n \to \infty$`, `$p \to 0$`, `$np = \lambda$` (fixed) ã®ã¨ã:

```math
\text{Binomial}(n, p) \to \text{Poisson}(\lambda)
```

**Proof Sketch**:

```math
P(X = k) = \binom{n}{k} p^k (1-p)^{n-k} = \frac{n!}{k!(n-k)!} \left(\frac{\lambda}{n}\right)^k \left(1 - \frac{\lambda}{n}\right)^{n-k}
```

As `$n \to \infty$`:

```math
\frac{n!}{(n-k)! n^k} \to 1, \quad \left(1 - \frac{\lambda}{n}\right)^n \to e^{-\lambda}, \quad \left(1 - \frac{\lambda}{n}\right)^{-k} \to 1
```

```math
\Rightarrow \quad P(X = k) \to \frac{\lambda^k e^{-\lambda}}{k!}
```

âˆ

#### 2.5 Gamma åˆ†å¸ƒ

**Definition 2.8 (Gamma Distribution)**

```math
X \sim \text{Gamma}(\alpha, \beta), \quad p_X(x) = \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-1} e^{-\beta x}, \quad x > 0
```

ã“ã“ã§ `$\Gamma(\alpha) = \int_0^\infty t^{\alpha-1} e^{-t} dt$` (Gamma function)

**Properties**:

- `$\mathbb{E}[X] = \frac{\alpha}{\beta}$`
- `$\text{Var}(X) = \frac{\alpha}{\beta^2}$`

**Special Cases**:

1. `$\alpha = 1$`: Exponential distribution (`$p_X(x) = \beta e^{-\beta x}$`)
2. `$\alpha = \frac{d}{2}$`, `$\beta = \frac{1}{2}$`: Chi-squared distribution with `$d$` degrees of freedom

**Application**: Waiting times, Bayesian conjugate prior for Poisson rate

#### 2.6 Central Limit Theorem

**Theorem 2.1 (Central Limit Theorem)**

`$X_1, \ldots, X_n$` i.i.d., `$\mathbb{E}[X_i] = \mu$`, `$\text{Var}(X_i) = \sigma^2$` ã¨ã™ã‚‹ã€‚

```math
\bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i
```

ã®ã¨ãã€

```math
\sqrt{n}\left(\frac{\bar{X}_n - \mu}{\sigma}\right) \xrightarrow{d} \mathcal{N}(0, 1) \quad (n \to \infty)
```

**Implication**: **ã©ã‚“ãªåˆ†å¸ƒã§ã‚‚ã€ã‚µãƒ³ãƒ—ãƒ«å¹³å‡ã®åˆ†å¸ƒã¯ Gaussian ã«åæŸã™ã‚‹ã€‚**

**Example 2.4 (CLT for Uniform)**

`$X_i \sim \text{Uniform}(0, 1)$` (i.i.d.):

- `$\mathbb{E}[X_i] = 1/2$`
- `$\text{Var}(X_i) = 1/12$`

```math
\sqrt{n}\left(\bar{X}_n - \frac{1}{2}\right) \xrightarrow{d} \mathcal{N}\left(0, \frac{1}{12}\right)
```

**Practical Application**:

- `$n = 30$` ã§è¿‘ä¼¼ãŒè‰¯å¥½ï¼ˆrule of thumbï¼‰
- çµ±è¨ˆçš„ä»®èª¬æ¤œå®šã®ç†è«–çš„åŸºç›¤
- Bootstrap methods

#### 2.7 Multivariate Gaussian ã®æ€§è³ª

**Theorem 2.2 (Conditional Gaussian)**

`$\mathbf{x} \sim \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\Sigma})$`, partition:

```math
\mathbf{x} = \begin{bmatrix} \mathbf{x}_1 \\ \mathbf{x}_2 \end{bmatrix}, \quad
\boldsymbol{\mu} = \begin{bmatrix} \boldsymbol{\mu}_1 \\ \boldsymbol{\mu}_2 \end{bmatrix}, \quad
\boldsymbol{\Sigma} = \begin{bmatrix} \boldsymbol{\Sigma}_{11} & \boldsymbol{\Sigma}_{12} \\ \boldsymbol{\Sigma}_{21} & \boldsymbol{\Sigma}_{22} \end{bmatrix}
```

æ¡ä»¶ä»˜ãåˆ†å¸ƒ:

```math
\mathbf{x}_1 \mid \mathbf{x}_2 \sim \mathcal{N}(\boldsymbol{\mu}_{1|2}, \boldsymbol{\Sigma}_{1|2})
```

ã“ã“ã§:

```math
\boldsymbol{\mu}_{1|2} = \boldsymbol{\mu}_1 + \boldsymbol{\Sigma}_{12} \boldsymbol{\Sigma}_{22}^{-1} (\mathbf{x}_2 - \boldsymbol{\mu}_2)
```

```math
\boldsymbol{\Sigma}_{1|2} = \boldsymbol{\Sigma}_{11} - \boldsymbol{\Sigma}_{12} \boldsymbol{\Sigma}_{22}^{-1} \boldsymbol{\Sigma}_{21}
```

**Application**: Gaussian Process regression, Kalman Filter

**Example 2.5 (2D Gaussian)**

```math
\mathbf{x} = \begin{bmatrix} X \\ Y \end{bmatrix} \sim \mathcal{N}\left(\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 1 & \rho \\ \rho & 1 \end{bmatrix}\right)
```

Conditional distribution:

```math
X \mid Y = y \sim \mathcal{N}(\rho y, 1 - \rho^2)
```

**Interpretation**: `$Y$` ã®æƒ…å ±ãŒ `$X$` ã®ä¸ç¢ºå®Ÿæ€§ã‚’ `$1 - \rho^2$` ã«æ¸›å°‘ã•ã›ã‚‹ã€‚

---

## âš”ï¸ Z4. Boss Battleï¼ˆ90åˆ†ï¼‰â€” Topic 3 & 4: ãƒ™ã‚¤ã‚ºæ¨è«–ã¨ç¢ºç‡å¤‰æ•°å¤‰æ›

**ã‚´ãƒ¼ãƒ«**: ãƒ™ã‚¤ã‚ºæ¨è«–ã¨ç¢ºç‡å¤‰æ•°ã®å¤‰æ›ã‚’å®Œå…¨ã«ç†è§£ã™ã‚‹ã€‚

> Progress: 50%

### Topic 3: ãƒ™ã‚¤ã‚ºã®å®šç†ã¨MLE/MAP

#### 3.1 Bayes' Theorem

**Theorem 3.1 (Bayes' Theorem)**

```math
p(\theta \mid \mathcal{D}) = \frac{p(\mathcal{D} \mid \theta) p(\theta)}{p(\mathcal{D})}
```

ã“ã“ã§:

- `$p(\theta \mid \mathcal{D})$`: **Posterior** (äº‹å¾Œåˆ†å¸ƒ)
- `$p(\mathcal{D} \mid \theta)$`: **Likelihood** (å°¤åº¦)
- `$p(\theta)$`: **Prior** (äº‹å‰åˆ†å¸ƒ)
- `$p(\mathcal{D}) = \int p(\mathcal{D} \mid \theta) p(\theta) d\theta$`: **Evidence** (å‘¨è¾ºå°¤åº¦)

**Proof**:

```math
p(\theta, \mathcal{D}) = p(\mathcal{D} \mid \theta) p(\theta) = p(\theta \mid \mathcal{D}) p(\mathcal{D})
```

ä¸¡è¾ºã‚’ `$p(\mathcal{D})$` ã§å‰²ã‚‹ã€‚ âˆ

#### 3.2 Maximum Likelihood Estimation (MLE)

**Definition 3.1 (MLE)**

```math
\hat{\theta}_{\text{MLE}} := \arg\max_\theta p(\mathcal{D} \mid \theta) = \arg\max_\theta \log p(\mathcal{D} \mid \theta)
```

**Example 3.1 (MLE for Gaussian)**

ãƒ‡ãƒ¼ã‚¿ `$\mathcal{D} = \{x_1, \ldots, x_n\}$`, `$x_i \sim \mathcal{N}(\mu, \sigma^2)$` (i.i.d.):

```math
\log p(\mathcal{D} \mid \mu, \sigma^2) = \sum_{i=1}^n \log \mathcal{N}(x_i \mid \mu, \sigma^2) = -\frac{n}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n (x_i - \mu)^2
```

**Derivation**:

```math
\frac{\partial}{\partial \mu} \log p = \frac{1}{\sigma^2}\sum_{i=1}^n (x_i - \mu) = 0 \quad \Rightarrow \quad \hat{\mu}_{\text{MLE}} = \frac{1}{n}\sum_{i=1}^n x_i
```

```math
\frac{\partial}{\partial \sigma^2} \log p = -\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4}\sum_{i=1}^n (x_i - \mu)^2 = 0 \quad \Rightarrow \quad \hat{\sigma}^2_{\text{MLE}} = \frac{1}{n}\sum_{i=1}^n (x_i - \hat{\mu})^2
```

**Note**: MLE ã®åˆ†æ•£ã¯ä¸åæ¨å®šé‡ã§ã¯ãªã„ï¼ˆ`$\mathbb{E}[\hat{\sigma}^2] = \frac{n-1}{n}\sigma^2$`ï¼‰ã€‚

#### 3.3 Maximum A Posteriori (MAP)

**Definition 3.2 (MAP)**

```math
\hat{\theta}_{\text{MAP}} := \arg\max_\theta p(\theta \mid \mathcal{D}) = \arg\max_\theta \left[\log p(\mathcal{D} \mid \theta) + \log p(\theta)\right]
```

**MLE ã¨ã®é•ã„**:

- MLE: Prior `$p(\theta)$` ã‚’ç„¡è¦–ï¼ˆä¸€æ§˜åˆ†å¸ƒã¨ä»®å®šï¼‰
- MAP: Prior `$p(\theta)$` ã‚’è€ƒæ…®

**Example 3.2 (MAP with Gaussian Prior)**

Likelihood: `$\mathcal{D} \mid \theta \sim \mathcal{N}(\theta, \sigma^2)$`
Prior: `$\theta \sim \mathcal{N}(0, \tau^2)$`

```math
\log p(\theta \mid \mathcal{D}) \propto -\frac{1}{2\sigma^2}\sum_{i=1}^n (x_i - \theta)^2 - \frac{\theta^2}{2\tau^2}
```

```math
\frac{\partial}{\partial \theta} = \frac{1}{\sigma^2}\sum_{i=1}^n (x_i - \theta) - \frac{\theta}{\tau^2} = 0
```

```math
\hat{\theta}_{\text{MAP}} = \frac{\frac{n}{\sigma^2} \bar{x}}{\frac{n}{\sigma^2} + \frac{1}{\tau^2}} = \frac{n\tau^2}{n\tau^2 + \sigma^2} \bar{x}
```

**Interpretation**:

- `$\tau^2 \to \infty$` (weak prior): `$\hat{\theta}_{\text{MAP}} \to \bar{x}$` (MLE)
- `$n \to \infty$`: `$\hat{\theta}_{\text{MAP}} \to \bar{x}$` (data dominates prior)
- Small `$n$`, strong prior: `$\hat{\theta}_{\text{MAP}} \to 0$` (prior dominates)

#### 3.4 Bayesian Inference

MLE/MAP ã¯ç‚¹æ¨å®š (point estimate) ã ãŒã€**Bayesian Inference ã¯åˆ†å¸ƒæ¨å®š** ã ã€‚

**Definition 3.3 (Posterior Predictive Distribution)**

æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ `$x^*$` ã®äºˆæ¸¬åˆ†å¸ƒ:

```math
p(x^* \mid \mathcal{D}) = \int p(x^* \mid \theta) p(\theta \mid \mathcal{D}) d\theta
```

**Example 3.3 (Bayesian Inference for Bernoulli)**

Data: `$n_1$` heads, `$n_0$` tails
Likelihood: `$p(\mathcal{D} \mid \theta) = \theta^{n_1} (1-\theta)^{n_0}$`
Prior: `$\theta \sim \text{Beta}(\alpha, \beta)$`

**Posterior** (conjugate prior):

```math
p(\theta \mid \mathcal{D}) = \text{Beta}(\alpha + n_1, \beta + n_0)
```

**Posterior Predictive**:

```math
p(x^* = 1 \mid \mathcal{D}) = \mathbb{E}_{\theta \sim p(\theta \mid \mathcal{D})}[\theta] = \frac{\alpha + n_1}{\alpha + \beta + n_1 + n_0}
```

#### 3.5 Conjugate Priors

**Definition 3.4 (Conjugate Prior)**

Prior `$p(\theta)$` ãŒ likelihood `$p(\mathcal{D} \mid \theta)$` ã«å¯¾ã—ã¦ conjugate ã§ã‚ã‚‹ã¨ã¯ã€posterior `$p(\theta \mid \mathcal{D})$` ãŒ prior ã¨åŒã˜ family ã«å±ã™ã‚‹ã“ã¨ã€‚

**Table: Common Conjugate Pairs**

| Likelihood | Conjugate Prior | Posterior |
|:-----------|:----------------|:----------|
| Bernoulli(`$\theta$`) | Beta(`$\alpha, \beta$`) | Beta(`$\alpha + n_1, \beta + n_0$`) |
| Categorical(`$\mathbf{p}$`) | Dirichlet(`$\boldsymbol{\alpha}$`) | Dirichlet(`$\boldsymbol{\alpha} + \mathbf{n}$`) |
| Gaussian(`$\mu$`, known `$\sigma^2$`) | Gaussian(`$\mu_0, \tau^2$`) | Gaussian(`$\mu_n, \tau_n^2$`) |
| Gaussian(`$\sigma^2$`, known `$\mu$`) | Inverse-Gamma(`$\alpha, \beta$`) | Inverse-Gamma(`$\alpha_n, \beta_n$`) |

### Topic 4: ç¢ºç‡å¤‰æ•°ã®å¤‰æ›

#### 4.1 Change of Variables Formula

**Theorem 4.1 (Univariate Change of Variables)**

`$Y = g(X)$` ã¨ã™ã‚‹ã€‚`$g$` ãŒå˜èª¿å¢—åŠ ã‹ã¤å¾®åˆ†å¯èƒ½ãªã‚‰:

```math
p_Y(y) = p_X(g^{-1}(y)) \left|\frac{d g^{-1}}{dy}(y)\right|
```

**Proof**:

CDF approach:

```math
F_Y(y) = P(Y \leq y) = P(g(X) \leq y) = P(X \leq g^{-1}(y)) = F_X(g^{-1}(y))
```

Differentiate:

```math
p_Y(y) = \frac{dF_Y}{dy} = \frac{dF_X}{dx}\bigg|_{x=g^{-1}(y)} \cdot \frac{dg^{-1}}{dy} = p_X(g^{-1}(y)) \left|\frac{dg^{-1}}{dy}\right|
```

**Example 4.1 (Log-Normal Distribution)**

`$X \sim \mathcal{N}(\mu, \sigma^2)$`, `$Y = e^X$`:

```math
p_Y(y) = \frac{1}{y\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(\log y - \mu)^2}{2\sigma^2}\right), \quad y > 0
```

**Derivation**:

- `$g^{-1}(y) = \log y$`
- `$\frac{dg^{-1}}{dy} = \frac{1}{y}$`

```math
p_Y(y) = p_X(\log y) \cdot \frac{1}{y} = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(\log y - \mu)^2}{2\sigma^2}\right) \cdot \frac{1}{y}
```

#### 4.2 Multivariate Change of Variables

**Theorem 4.2 (Multivariate Change of Variables)**

`$\mathbf{y} = \mathbf{g}(\mathbf{x})$` ã¨ã™ã‚‹ã€‚`$\mathbf{g}$` ãŒå¯é€†ã‹ã¤å¾®åˆ†å¯èƒ½ãªã‚‰:

```math
p_{\mathbf{Y}}(\mathbf{y}) = p_{\mathbf{X}}(\mathbf{g}^{-1}(\mathbf{y})) \left|\det \frac{\partial \mathbf{g}^{-1}}{\partial \mathbf{y}}\right|
```

ã“ã“ã§ Jacobian è¡Œåˆ—:

```math
\mathbf{J} = \frac{\partial \mathbf{g}^{-1}}{\partial \mathbf{y}} = \begin{bmatrix}
\frac{\partial g_1^{-1}}{\partial y_1} & \cdots & \frac{\partial g_1^{-1}}{\partial y_d} \\
\vdots & \ddots & \vdots \\
\frac{\partial g_d^{-1}}{\partial y_1} & \cdots & \frac{\partial g_d^{-1}}{\partial y_d}
\end{bmatrix}
```

**Example 4.2 (Polar Coordinates)**

`$(X, Y) \sim \mathcal{N}(0, I_2)$` (2D standard Gaussian), `$R = \sqrt{X^2 + Y^2}$`, `$\Theta = \arctan(Y/X)$`:

**Jacobian**:

```math
\mathbf{g}^{-1}(r, \theta) = \begin{bmatrix} r\cos\theta \\ r\sin\theta \end{bmatrix}, \quad \mathbf{J} = \begin{bmatrix} \cos\theta & -r\sin\theta \\ \sin\theta & r\cos\theta \end{bmatrix}
```

```math
\det \mathbf{J} = r
```

**PDF**:

```math
p_{R,\Theta}(r, \theta) = p_{X,Y}(r\cos\theta, r\sin\theta) \cdot r = \frac{1}{2\pi} e^{-r^2/2} \cdot r
```

Marginalize:

```math
p_R(r) = \int_0^{2\pi} p_{R,\Theta}(r, \theta) d\theta = r e^{-r^2/2} \quad (\text{Rayleigh distribution})
```

#### 4.3 Normalizing Flows ã¸ã®ä¼ç·š

**Normalizing Flows** (Rezende & Mohamed, 2015; Kobyzev et al., 2020)[^NF1] ã¯ã€change of variables ã‚’åˆ©ç”¨ã—ãŸç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã ã€‚

**Idea**:

1. Simple distribution `$p_Z(\mathbf{z})$` (e.g., Gaussian) ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ« `$\mathbf{z} \sim p_Z$`
2. Invertible transformation `$\mathbf{x} = \mathbf{f}(\mathbf{z})$` ã‚’é©ç”¨
3. Change of variables:

```math
p_X(\mathbf{x}) = p_Z(\mathbf{f}^{-1}(\mathbf{x})) \left|\det \frac{\partial \mathbf{f}^{-1}}{\partial \mathbf{x}}\right|
```

**Challenge**:

- `$\mathbf{f}$` ã¯å¯é€†ã§ãªã‘ã‚Œã°ãªã‚‰ãªã„
- Jacobian determinant ã®è¨ˆç®—ãŒ `$O(d^3)$` ï¼ˆå¤§è¦æ¨¡ã§ã¯å›°é›£ï¼‰

**Solution**:

- **Coupling Layers**: Jacobian ãŒ triangularï¼ˆ`$O(d)$` è¨ˆç®—ï¼‰
- **Autoregressive Flows**: Sequential transformation

â†’ ç¬¬20å›ï¼ˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«ï¼‰ã§è©³ç´°ã‚’æ‰±ã†ã€‚

#### 4.4 Reparameterization Trick

**Problem**: VAE ã®å‹¾é…è¨ˆç®—

```math
\nabla_\phi \mathbb{E}_{q_\phi(\mathbf{z} \mid \mathbf{x})}[f(\mathbf{z})]
```

`$\mathbf{z} \sim q_\phi$` ã‹ã‚‰ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã« `$\phi$` ãŒå«ã¾ã‚Œã‚‹ â†’ å‹¾é…ãŒå–ã‚Œãªã„ã€‚

**Solution**: Reparameterization (Kingma & Welling, 2014)

**Idea**: `$\mathbf{z} = \boldsymbol{\mu}_\phi + \boldsymbol{\sigma}_\phi \odot \boldsymbol{\epsilon}$`, `$\boldsymbol{\epsilon} \sim \mathcal{N}(0, I)$`

```math
\nabla_\phi \mathbb{E}_{q_\phi(\mathbf{z} \mid \mathbf{x})}[f(\mathbf{z})] = \nabla_\phi \mathbb{E}_{\boldsymbol{\epsilon} \sim \mathcal{N}(0,I)}[f(\boldsymbol{\mu}_\phi + \boldsymbol{\sigma}_\phi \odot \boldsymbol{\epsilon})]
```

```math
= \mathbb{E}_{\boldsymbol{\epsilon}}[\nabla_\phi f(\boldsymbol{\mu}_\phi + \boldsymbol{\sigma}_\phi \odot \boldsymbol{\epsilon})]
```

**Key**: æœŸå¾…å€¤ã®å¤–ã« gradient ã‚’å‡ºã›ã‚‹ï¼ˆMonte Carlo estimator ãŒ unbiasedï¼‰ã€‚

**Generalization** (Rezende & Mohamed, 2015):

ä»»æ„ã®åˆ†å¸ƒ `$q_\phi(\mathbf{z})$` ã«å¯¾ã—ã¦ã€invertible transformation `$T_\phi$` ãŒå­˜åœ¨ã™ã‚Œã°:

```math
\mathbf{z} = T_\phi(\boldsymbol{\epsilon}), \quad \boldsymbol{\epsilon} \sim p(\boldsymbol{\epsilon})
```

**Application**: VAE, Normalizing Flows, Diffusion Models

---

## âš”ï¸ Z4. æœ€å¼·ã‚¿ã‚¹ã‚¯ï¼ˆ30åˆ†ï¼‰â€” Boss Battle: è‡ªå·±å›å¸°LLMå°¤åº¦åˆ†è§£

**ã‚´ãƒ¼ãƒ«**: è‡ªå·±å›å¸°LLMã®å°¤åº¦æœ€å¤§åŒ–ã‚’å®Œå…¨ã«ç†è§£ã™ã‚‹ã€‚

> Progress: 70%

### Boss Battle: è‡ªå·±å›å¸°LLMã®å°¤åº¦åˆ†è§£

GPT ã‚„ LLaMA ãªã©ã® **Autoregressive Language Model (ARM)** ã¯ã€æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã‚’ç¹°ã‚Šè¿”ã™:

```math
p_\theta(\mathbf{x}) = \prod_{t=1}^T p_\theta(x_t \mid x_{<t})
```

ã“ã“ã§:

- `$\mathbf{x} = (x_1, \ldots, x_T)$`: Sequence of tokens
- `$x_{<t} = (x_1, \ldots, x_{t-1})$`: Context
- `$p_\theta(x_t \mid x_{<t})$`: Categorical distribution (vocabulary size `$V$`)

### 4.1 Likelihood ã®å¯¾æ•°åŒ–

**Log-likelihood**:

```math
\log p_\theta(\mathbf{x}) = \sum_{t=1}^T \log p_\theta(x_t \mid x_{<t})
```

**Why log?**

1. **æ•°å€¤å®‰å®šæ€§**: `$p_\theta(\mathbf{x}) = 10^{-100}$` ã®ã‚ˆã†ãªå°ã•ã„ç¢ºç‡ã‚’æ‰±ãˆã‚‹
2. **è¨ˆç®—åŠ¹ç‡**: ç© â†’ å’Œ
3. **Gradient**: `$\nabla_\theta \log p = \frac{1}{p} \nabla_\theta p$`

### 4.2 Cross-Entropy Loss ã¨ã®ç­‰ä¾¡æ€§

**Definition** (Cross-Entropy Loss):

```math
\mathcal{L}_{\text{CE}} = -\frac{1}{T}\sum_{t=1}^T \log p_\theta(x_t \mid x_{<t})
```

**Theorem 4.3 (MLE = Minimize Cross-Entropy)**

```math
\arg\max_\theta \log p_\theta(\mathcal{D}) = \arg\min_\theta \mathcal{L}_{\text{CE}}(\theta, \mathcal{D})
```

**Proof**:

```math
\max_\theta \log p_\theta(\mathbf{x}) = \max_\theta \sum_{t=1}^T \log p_\theta(x_t \mid x_{<t}) = \min_\theta \left(-\sum_{t=1}^T \log p_\theta(x_t \mid x_{<t})\right)
```

âˆ

### 4.3 Teacher Forcing

**Training**: Ground truth `$x_t$` ã‚’ context ã«ä½¿ã†


**Inference**: Model è‡ªèº«ã® prediction ã‚’ context ã«ä½¿ã†


### 4.4 Exposure Bias

**Problem**: Training ã¨ Inference ã®ãƒŸã‚¹ãƒãƒƒãƒ

- Training: å¸¸ã«æ­£ã—ã„ context
- Inference: Model ãŒé–“é•ãˆãŸå ´åˆã€èª¤ã£ãŸ context ãŒç´¯ç©

**Solutions**:

1. **Scheduled Sampling**: Training ä¸­ã« model ã® prediction ã‚’ç¢ºç‡çš„ã«ä½¿ã†
2. **Reinforcement Learning**: Policy gradient ã§ inference ã‚’ç›´æ¥æœ€é©åŒ–
3. **Non-Autoregressive Models**: å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä¸¦åˆ—ç”Ÿæˆï¼ˆBERT, Diffusion LMsï¼‰

### 4.5 Perplexity

**Definition** (Perplexity):

```math
\text{PPL} = \exp\left(-\frac{1}{T}\sum_{t=1}^T \log p_\theta(x_t \mid x_{<t})\right) = \exp(\mathcal{L}_{\text{CE}})
```

**Interpretation**:

- å„ã‚¹ãƒ†ãƒƒãƒ—ã§å¹³å‡çš„ã« `$\text{PPL}$` å€‹ã®é¸æŠè‚¢ã‹ã‚‰é¸ã‚“ã§ã„ã‚‹
- Lower is better
- GPT-3: PPL â‰ˆ 20 on WebText

### 4.6 æ•°å­¦çš„è©³ç´°: Likelihood Decomposition

**Theorem 4.4 (Chain Rule of Probability)**

```math
p(\mathbf{x}) = p(x_1) p(x_2 \mid x_1) p(x_3 \mid x_1, x_2) \cdots p(x_T \mid x_1, \ldots, x_{T-1})
```

**Proof** (by induction):

Base case:

```math
p(x_1, x_2) = p(x_2 \mid x_1) p(x_1)
```

Inductive step: Assume true for `$T-1$`:

```math
p(x_1, \ldots, x_T) = p(x_T \mid x_1, \ldots, x_{T-1}) p(x_1, \ldots, x_{T-1})
```

Apply induction hypothesis to `$p(x_1, \ldots, x_{T-1})$`. âˆ

**Example 4.3** (GPT-2 on "Hello world"):

```
x = ["Hello", " world", "!"]
```

```math
\log p(\mathbf{x}) = \log p(\text{"Hello"}) + \log p(\text{" world"} \mid \text{"Hello"}) + \log p(\text{"!"} \mid \text{"Hello world"})
```

**Empirical values** (GPT-2):


---

## ğŸ”¬ Z4. æ·±åŒ–ï¼ˆ20åˆ†ï¼‰â€” ç ”ç©¶å‹•å‘ã¨ç™ºå±•

**ã‚´ãƒ¼ãƒ«**: ç¢ºç‡è«–ã®æœ€æ–°ç ”ç©¶å‹•å‘ã‚’çŸ¥ã‚‹ã€‚

> Progress: 90%

### 5.1 Bayesian Deep Learning ã®å¾©èˆˆ

**Problem**: Deep Learning ã¯ MLE ã§è¨“ç·´ã•ã‚Œã‚‹ãŒã€ä¸ç¢ºå®Ÿæ€§ã‚’å®šé‡åŒ–ã§ããªã„ã€‚

**Solution**: Bayesian Neural Networks (BNNs)[^2][^3]

**Idea**:

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ `$\theta$` ã‚’ç¢ºç‡åˆ†å¸ƒã¨ã—ã¦æ‰±ã†:

```math
p(\theta \mid \mathcal{D}) = \frac{p(\mathcal{D} \mid \theta) p(\theta)}{p(\mathcal{D})}
```

**Prediction**:

```math
p(y^* \mid \mathbf{x}^*, \mathcal{D}) = \int p(y^* \mid \mathbf{x}^*, \theta) p(\theta \mid \mathcal{D}) d\theta
```

**Challenge**: Posterior `$p(\theta \mid \mathcal{D})$` ã¯è¨ˆç®—ä¸å¯èƒ½ï¼ˆ`$10^6$` parameters â†’ `$10^6$` æ¬¡å…ƒç©åˆ†ï¼‰

**Approximation Methods**:

1. **Variational Inference** (VI)
   - Approximate posterior `$q_\phi(\theta)$` ã‚’æœ€é©åŒ–
   - Minimize KL divergence: `$\text{KL}(q_\phi \| p(\theta \mid \mathcal{D}))$`
   - ELBO (Evidence Lower Bound):

```math
\log p(\mathcal{D}) \geq \mathbb{E}_{q_\phi}[\log p(\mathcal{D} \mid \theta)] - \text{KL}(q_\phi(\theta) \| p(\theta))
```

2. **Monte Carlo Dropout** (Gal & Ghahramani, 2016)
   - Dropout at test time = Bayesian approximation
   - Fast but approximate

3. **Stochastic Gradient MCMC** (SG-MCMC)
   - Langevin dynamics with SGD
   - Theoretically grounded but slow

**Recent Advances** (2024-2025):

- **Laplace Approximation** (Daxberger et al., 2021): äº‹å¾Œåˆ†å¸ƒã‚’ Gaussian è¿‘ä¼¼ï¼ˆé«˜é€Ÿï¼‰
- **Deep Ensembles** (Lakshminarayanan et al., 2017): è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®å¹³å‡ = ç°¡æ˜“çš„ Bayesian
- **Normalizing Flows for Posteriors**: è¤‡é›‘ãªäº‹å¾Œåˆ†å¸ƒã‚’è¡¨ç¾

### 5.2 Epistemic Uncertainty ã¨ Maximum Mean Imprecision

Classical Kolmogorov å…¬ç†ã®é™ç•Œ[^6]:

**Problem**: `$P(A) + P(A^c) = 1$` (additivity) ã¯å³ã—ã™ãã‚‹

- ã€ŒAã«ã¤ã„ã¦é«˜ã„ä¸ç¢ºå®Ÿæ€§ã€ â†’ ã€ŒAã®è£œé›†åˆã«ã¤ã„ã¦é«˜ã„ç¢ºå®Ÿæ€§ã€ã‚’æš—ç¤º
- Partial ignorance ã‚’è¡¨ç¾ã§ããªã„

**Solution**: Maximum Mean Imprecision (MMI)[^6]

**Idea**: ç‚¹æ¨å®šç¢ºç‡ `$P(A)$` ã§ã¯ãªãã€åŒºé–“ `$[\underline{P}(A), \overline{P}(A)]$` ã§ä¸ç¢ºå®Ÿæ€§ã‚’è¡¨ç¾

**Application to ML**:

- Out-of-distribution detection
- Active learning (uncertainty sampling)
- Safety-critical systems (autonomous driving)

### 5.3 Continuous Autoregressive Models

å¾“æ¥ã® ARM ã¯ discrete tokens ã«é™å®šã•ã‚Œã¦ã„ãŸã€‚**Continuous ARM**[^5] ã¯é€£ç¶šç©ºé–“ã§å‹•ä½œ:

**Idea**:

1. Autoencoder ã§ token chunks ã‚’ continuous vectors ã«åœ§ç¸®
2. é€£ç¶šç©ºé–“ã§ autoregressive modeling
3. Decoder ã§å…ƒã® tokens ã«å¾©å…ƒ

**Problem**: Likelihood ãŒ intractableï¼ˆé€£ç¶šç©ºé–“ã§ã¯ç¢ºç‡å¯†åº¦ã®æ­£è¦åŒ–å®šæ•°ãŒè¨ˆç®—ä¸å¯èƒ½ï¼‰

**Solution**: **BrierLM** â€” Brier score ãƒ™ãƒ¼ã‚¹ã® likelihood-free è©•ä¾¡æŒ‡æ¨™

```math
\text{BrierScore} = \mathbb{E}_{\mathbf{y} \sim p(\mathbf{y} \mid \mathbf{x})}[\|\mathbf{y} - \mathbf{y}^*\|^2]
```

**Advantages**:

- Unbiased estimation via sampling
- Strictly proper scoring rule
- é€£ç¶šè¡¨ç¾ã®åˆ©ç‚¹ï¼ˆtoken-level errors ã‚’å›é¿ï¼‰

### 5.4 Energy-Based View of Autoregressive Models

Recent work[^7] establishes that ARMs are secretly Energy-Based Models (EBMs):

**ARM**:

```math
p_\theta(\mathbf{x}) = \prod_{t=1}^T p_\theta(x_t \mid x_{<t})
```

**EBM**:

```math
p_\theta(\mathbf{x}) = \frac{1}{Z(\theta)} \exp(-E_\theta(\mathbf{x}))
```

**Theorem** (Informal): There exists a bijection between ARMs and EBMs in function space.

**Implication**:

- ARM ã® energy function ã‚’ explicit ã«è¨ˆç®—å¯èƒ½
- Lookahead capabilities ã®ç†è«–çš„ç†è§£
- Hybrid models (ARM+EBM) ã®è¨­è¨ˆæŒ‡é‡

### 5.5 Normalizing Flows â€” ç¢ºç‡å¯†åº¦ã® explicit modeling

**Definition**[^1][^4]:

Normalizing Flow ã¯ã€simple distribution `$p_Z(\mathbf{z})$` ã‚’ complex distribution `$p_X(\mathbf{x})$` ã«å¤‰æ›ã™ã‚‹ invertible transformation `$\mathbf{f}$` ã :

```math
\mathbf{x} = \mathbf{f}(\mathbf{z}), \quad \mathbf{z} \sim p_Z(\mathbf{z})
```

Change of variables:

```math
\log p_X(\mathbf{x}) = \log p_Z(\mathbf{f}^{-1}(\mathbf{x})) + \log \left|\det \frac{\partial \mathbf{f}^{-1}}{\partial \mathbf{x}}\right|
```

**Advantages**:

- Exact likelihood computationï¼ˆVAE ã¯ intractableï¼‰
- Exact samplingï¼ˆGAN ã¯ mode collapseï¼‰
- Bidirectional mappingï¼ˆencoder & decoderï¼‰

**Architectures**:

1. **Coupling Layers** (RealNVP, Glow)
   - Split `$\mathbf{x} = (\mathbf{x}_1, \mathbf{x}_2)$`
   - `$\mathbf{x}_1$` unchanged, `$\mathbf{x}_2$` transformed by `$\mathbf{x}_1$`
   - Jacobian is triangular â†’ `$O(d)$` computation

2. **Autoregressive Flows** (MAF, IAF)
   - Sequential transformation
   - High expressiveness but slow sampling

3. **Continuous Normalizing Flows** (Neural ODEs)
   - Parameterize flow as ODE
   - Adjoint method for gradient computation

**Recent Advances** (2024-2025):

- **Hybrid Bernstein Flows**: Interpretable marginals
- **Flexible Tails**: Heavy-tailed distributions for robust modeling
- **Distillation**: Fast student networks from slow teacher flows

### ç ”ç©¶ç³»è­œå›³

```mermaid
graph TD
    A["Kolmogorov 1933<br/>Probability Axioms"] --> B["Jaynes 1957<br/>Maximum Entropy"]
    B --> C["Neal 1996<br/>Bayesian NN"]
    C --> D["Gal+ 2016<br/>MC Dropout"]
    D --> E["Wilson+ 2020<br/>Bayesian DL<br/>(arXiv:2001.10995)"]

    F["Rezende & Mohamed 2015<br/>Normalizing Flows"] --> G["Kingma+ 2018<br/>Glow"]
    G --> H["Chen+ 2018<br/>Neural ODE"]
    H --> I["Papamakarios+ 2021<br/>NF Review<br/>(arXiv:1912.02762)"]

    J["Kolmogorov 1933"] --> K["Imprecise Probability<br/>1990s"]
    K --> L["MMI 2025<br/>(arXiv:2505.16156)"]

    style E fill:#c8e6c9
    style I fill:#bbdefb
    style L fill:#fff9c4
```

---

## ğŸ“ Z4. ã¾ã¨ã‚ã¨æ¥ç¶šï¼ˆ20åˆ†ï¼‰â€” æŒ¯ã‚Šè¿”ã‚Šã¨æ¬¡å›äºˆå‘Š

**ã‚´ãƒ¼ãƒ«**: æœ¬è¬›ç¾©ã®å­¦ã³ã‚’æ•´ç†ã—ã€æ¬¡å›ã¸ã®æ¥ç¶šã‚’ç¢ºèªã™ã‚‹ã€‚

> Progress: 100%

### 6.1 æ•°å¼ã¨ã‚³ãƒ¼ãƒ‰å¯¾å¿œè¡¨

| æ•°å­¦çš„æ¦‚å¿µ | ç”¨é€” |
|:----------|:-----|
| `$P(\Omega) = 1$` | Kolmogorov å…¬ç†ï¼ˆæ­£è¦æ€§ï¼‰ |
| `$p_X(x) = P(X = x)$` | PMF (é›¢æ•£ç¢ºç‡å¤‰æ•°) |
| `$\int p_X(x) dx = 1$` | PDF (é€£ç¶šç¢ºç‡å¤‰æ•°) |
| `$p(\theta \mid \mathcal{D}) \propto p(\mathcal{D} \mid \theta) p(\theta)$` | Bayes' Theorem |
| `$\hat{\theta}_{\text{MLE}} = \arg\max_\theta \log p(\mathcal{D} \mid \theta)$` | Maximum Likelihood |
| `$\hat{\theta}_{\text{MAP}} = \arg\max_\theta [\log p(\mathcal{D} \mid \theta) + \log p(\theta)]$` | Maximum A Posteriori |
| `$p_Y(y) = p_X(g^{-1}(y)) \left|\frac{dg^{-1}}{dy}\right|$` | Change of Variables |
| `$\log p_\theta(\mathbf{x}) = \sum_{t=1}^T \log p_\theta(x_t \mid x_{<t})$` | Autoregressive Likelihood |

### 6.2 Quick Check â€” ç†è§£åº¦ç¢ºèª

<details>
<summary>Q1: Kolmogorovã®3å…¬ç†ã‚’è¿°ã¹ã‚ˆ</summary>

**A**:

1. éè² æ€§: `$P(A) \geq 0$`
2. æ­£è¦æ€§: `$P(\Omega) = 1$`
3. å¯ç®—åŠ æ³•æ€§: `$P(\bigcup_{i=1}^\infty A_i) = \sum_{i=1}^\infty P(A_i)$` (disjoint events)

</details>

<details>
<summary>Q2: PDF `$p_X(x)$` ã¨ç¢ºç‡ `$P(a \leq X \leq b)$` ã®é–¢ä¿‚ã¯ï¼Ÿ</summary>

**A**:

```math
P(a \leq X \leq b) = \int_a^b p_X(x) dx
```

PDF è‡ªä½“ã¯ç¢ºç‡ã§ã¯ãªã„ï¼ˆ`$p_X(x) > 1$` ã‚‚ã‚ã‚Šå¾—ã‚‹ï¼‰ã€‚

</details>

<details>
<summary>Q3: MLE ã¨ MAP ã®é•ã„ã¯ï¼Ÿ</summary>

**A**:

- **MLE**: Prior ã‚’ç„¡è¦–ï¼ˆä¸€æ§˜åˆ†å¸ƒã¨ä»®å®šï¼‰
- **MAP**: Prior `$p(\theta)$` ã‚’è€ƒæ…®

```math
\hat{\theta}_{\text{MLE}} = \arg\max_\theta p(\mathcal{D} \mid \theta)
```

```math
\hat{\theta}_{\text{MAP}} = \arg\max_\theta [p(\mathcal{D} \mid \theta) p(\theta)]
```

</details>

<details>
<summary>Q4: Conjugate prior ã¨ã¯ï¼Ÿ</summary>

**A**:

Likelihood ã¨ prior ãŒåŒã˜ family ãªã‚‰ã€posterior ã‚‚åŒã˜ family ã«å±ã™ã‚‹ã€‚

**Example**: Bernoulli likelihood + Beta prior = Beta posterior

</details>

<details>
<summary>Q5: ãªãœ GPT ã®è¨“ç·´ã¯ MLE ãªã®ã‹ï¼Ÿ</summary>

**A**:

Cross-entropy loss ã‚’æœ€å°åŒ–ã™ã‚‹ã“ã¨ã¯ã€log-likelihood ã‚’æœ€å¤§åŒ–ã™ã‚‹ã“ã¨ã¨ç­‰ä¾¡:

```math
\arg\min_\theta \mathcal{L}_{\text{CE}} = \arg\max_\theta \log p_\theta(\mathcal{D})
```

</details>

### 6.3 FAQ

<details>
<summary>Q1: Ïƒ-algebra ã¯ãªãœå¿…è¦ãªã®ã‹ï¼Ÿ</summary>

**A**: é€£ç¶šç¢ºç‡ç©ºé–“ã§ã¯ã€ã€Œå…¨ã¦ã®éƒ¨åˆ†é›†åˆã«ç¢ºç‡ã‚’å‰²ã‚Šå½“ã¦ã‚‹ã€ã“ã¨ã¯æ•°å­¦çš„ã«ä¸å¯èƒ½ï¼ˆBanach-Tarski paradoxï¼‰ã€‚Ïƒ-algebra ã¯ã€Œæ¸¬å®šå¯èƒ½ãªã€äº‹è±¡ã®é›†åˆã‚’å®šç¾©ã™ã‚‹ã€‚

</details>

<details>
<summary>Q2: Exponential Family ã«å±ã™ã‚‹åˆ†å¸ƒã¯ï¼Ÿ</summary>

**A**: Gaussian, Bernoulli, Categorical, Poisson, Gamma, Beta, Dirichlet, â€¦ ã»ã¨ã‚“ã©ã®ä¸»è¦åˆ†å¸ƒã€‚

**åˆ©ç‚¹**: Sufficient statistics ãŒå­˜åœ¨ â†’ ãƒ‡ãƒ¼ã‚¿åœ§ç¸®å¯èƒ½ & Conjugate priors ä¿è¨¼

</details>

<details>
<summary>Q3: Normalizing Flow ã¨ VAE ã®é•ã„ã¯ï¼Ÿ</summary>

**A**:

| | Normalizing Flow | VAE |
|:---|:----------------|:----|
| Likelihood | Exact | Intractable (ELBO) |
| Sampling | Exact | Approximate (reparameterization) |
| Training | MLE | ELBO maximization |
| Expressiveness | High (deep flows) | High (deep encoder/decoder) |

</details>

<details>
<summary>Q4: Bayesian NN ã¯å®Ÿç”¨çš„ã‹ï¼Ÿ</summary>

**A**: Tradeoff ã‚ã‚Š:

- âœ… Uncertainty quantificationï¼ˆåŒ»ç™‚ãƒ»è‡ªå‹•é‹è»¢ã§é‡è¦ï¼‰
- âŒ è¨ˆç®—ã‚³ã‚¹ãƒˆå¤§ï¼ˆposterior approximationï¼‰
- âš–ï¸ å®Ÿç”¨åŒ–: Laplace approximation, Deep Ensembles, MC Dropout

</details>

### 6.4 æ¬¡å›äºˆå‘Š â€” ç¬¬5å›: æƒ…å ±ç†è«–

ç¬¬4å›ã§ç¢ºç‡åˆ†å¸ƒã‚’å®Œå…¨æ­¦è£…ã—ãŸã€‚æ¬¡ã¯**æƒ…å ±ç†è«–** â€” ã€Œæƒ…å ±ã¨ã¯ä½•ã‹ï¼Ÿã€ã‚’æ•°å­¦ã§å®šç¾©ã™ã‚‹ã€‚

**ç¬¬5å›ã§å­¦ã¶ã“ã¨**:

1. **ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼**: ä¸ç¢ºå®Ÿæ€§ã®å®šé‡åŒ–
2. **KL divergence**: åˆ†å¸ƒé–“ã®ã€Œè·é›¢ã€
3. **Mutual Information**: å¤‰æ•°é–“ã®ä¾å­˜é–¢ä¿‚
4. **Cross-Entropy Loss**: ãªãœã“ã‚ŒãŒ loss function ãªã®ã‹ï¼Ÿ
5. **Boss Battle**: VAE ã® ELBO å°å‡º

**ãªãœä»Šã€æƒ…å ±ç†è«–ãªã®ã‹ï¼Ÿ**

VAE ã®æå¤±é–¢æ•°:

```math
\mathcal{L} = -\mathbb{E}_{q_\phi(\mathbf{z} \mid \mathbf{x})}[\log p_\theta(\mathbf{x} \mid \mathbf{z})] + \text{KL}(q_\phi(\mathbf{z} \mid \mathbf{x}) \| p(\mathbf{z}))
```

Diffusion ã® denoising objective:

```math
\mathcal{L}_t = \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon}}[\|\boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\|^2]
```

LLM ã® perplexity:

```math
\text{PPL} = \exp(H(p_{\text{data}}))
```

**å…¨ã¦æƒ…å ±ç†è«–ã®è¨€è‘‰ã§è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚**

æƒ…å ±ç†è«–ãªãã—ã¦ã€æå¤±é–¢æ•°ã®è¨­è¨ˆã¯èªã‚Œãªã„ã€‚

---

**å¾Œç·¨ã«ç¶šã**: [ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨](/articles/ml-lecture-04-part2)

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

[^1]: Papamakarios, G., Nalisnick, E., Rezende, D. J., Mohamed, S., & Lakshminarayanan, B. (2021). Normalizing flows for probabilistic modeling and inference. *Journal of Machine Learning Research*, 22(57), 1-64. [arXiv:1912.02762](https://arxiv.org/abs/1912.02762)

[^2]: Wilson, A. G., & Izmailov, P. (2020). Bayesian Deep Learning and a Probabilistic Perspective of Generalization. *NeurIPS 2020*. [arXiv:2001.10995](https://arxiv.org/abs/2001.10995)

[^3]: Krause, A., & HÃ¼botter, J. (2025). Probabilistic Artificial Intelligence. ETH ZÃ¼rich. [arXiv:2502.05244](https://arxiv.org/abs/2502.05244)

[^4]: Kobyzev, I., Prince, S., & Brubaker, M. (2020). Normalizing flows: An introduction and review of current methods. *IEEE TPAMI*. [arXiv:1908.09257](https://arxiv.org/abs/1908.09257)

[^5]: (2024). Continuous Autoregressive Language Models. [arXiv:2510.27688](https://arxiv.org/abs/2510.27688)

---

## è‘—è€…ãƒªãƒ³ã‚¯

- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

---

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**

- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:

- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
