---
title: "ç¬¬27å›: è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
slug: "ml-lecture-27-part2"
emoji: "ğŸ“Š"
type: "tech"
topics: ["machinelearning", "evaluation", "julia", "rust", "statistics"]
published: true
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Julia", "Rust", "Elixir"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---

> **ç¬¬27å›ã€å‰ç·¨ã€‘**: [ç¬¬27å›ã€å‰ç·¨ã€‘](https://zenn.dev/fumishiki/ml-lecture-27-part1)


## ğŸ’» 4. å®Ÿè£…ã‚¾ãƒ¼ãƒ³ï¼ˆ45åˆ†ï¼‰â€” Juliaçµ±è¨ˆåˆ†æ + Rust Criterion

### 4.1 Juliaçµ±è¨ˆåˆ†æçµ±åˆ

ç¬¬24å›ã§å­¦ã‚“ã çµ±è¨ˆæ¤œå®šã‚’è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«çµ±åˆã™ã‚‹ã€‚

#### 4.1.1 FIDã®ä¿¡é ¼åŒºé–“

FIDæ¨å®šé‡ $\widehat{\text{FID}}$ ã¯æœ‰é™ã‚µãƒ³ãƒ—ãƒ«ã§ã®æ¨å®š â†’ ä¸ç¢ºå®Ÿæ€§ãŒã‚ã‚‹ã€‚

çœŸã® FID ã‚’ $\text{FID}^*$ ã¨ã™ã‚‹ã¨ã€$n$ ã‚µãƒ³ãƒ—ãƒ«ã§ã®æ¨å®šèª¤å·®ã¯ $|\widehat{\text{FID}} - \text{FID}^*| = O(1/\sqrt{n})$ ã®ã‚ªãƒ¼ãƒ€ãƒ¼ã§æ¸›å°‘ã™ã‚‹ã€‚$n=50$ ã¨ $n=5000$ ã§ã¯æ¨å®šç²¾åº¦ãŒ $\sqrt{100} = 10$ å€ç•°ãªã‚‹ã€‚

> **âš ï¸ Warning:** è«–æ–‡ã§ã€ŒFID=3.12ã€ã¨å ±å‘Šã™ã‚‹å ´åˆã€ä¿¡é ¼åŒºé–“ã‚’ç¤ºã•ãªã„ã¨ç„¡æ„å‘³ã€‚ç‰¹ã« FID å·®ãŒå°ã•ã„å ´åˆï¼ˆä¾‹: 3.12 vs 3.08ï¼‰ã¯çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’å¿…ãšç¢ºèªã™ã‚‹ã“ã¨ã€‚

**Bootstrapæ³•ã§ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—**:

```julia
# FID confidence interval via bootstrap
using Bootstrap

function fid_with_ci(real_imgs::Vector{Matrix{Float64}},
                      gen_imgs::Vector{Matrix{Float64}},
                      n_bootstrap::Int=1000, confidence::Float64=0.95)
    # Extract features once
    feats_real = extract_inception_features(real_imgs)
    feats_gen = extract_inception_features(gen_imgs)

    # Compute point estimate
    Î¼_r, Î£_r = compute_statistics(feats_real)
    Î¼_g, Î£_g = compute_statistics(feats_gen)
    fid_point = frechet_distance(Î¼_r, Î£_r, Î¼_g, Î£_g)

    # Bootstrap resampling
    n_real = size(feats_real, 1)
    n_gen = size(feats_gen, 1)

    fid_samples = map(1:n_bootstrap) do _
        idx_r, idx_g = rand(1:n_real, n_real), rand(1:n_gen, n_gen)
        Î¼_r_b, Î£_r_b = compute_statistics(@views feats_real[idx_r, :])
        Î¼_g_b, Î£_g_b = compute_statistics(@views feats_gen[idx_g, :])
        frechet_distance(Î¼_r_b, Î£_r_b, Î¼_g_b, Î£_g_b)
    end

    # Confidence interval
    Î± = 1 - confidence
    ci_lower = quantile(fid_samples, Î±/2)
    ci_upper = quantile(fid_samples, 1 - Î±/2)

    return fid_point, ci_lower, ci_upper, fid_samples
end

# Test
real_test = [randn(32, 32) for _ in 1:100]
gen_test = [randn(32, 32) for _ in 1:100]
fid_est, ci_l, ci_u, samples = fid_with_ci(real_test, gen_test, 200, 0.95)
println("FID: $(round(fid_est, digits=2)) [95% CI: $(round(ci_l, digits=2)), $(round(ci_u, digits=2))]")
```

#### 4.1.2 ãƒ¢ãƒ‡ãƒ«é–“æ¯”è¼ƒ â€” æœ‰æ„å·®æ¤œå®š

2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®FIDã‚’æ¯”è¼ƒ â†’ çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ãŒã‚ã‚‹ã‹ï¼Ÿ

**Welch's t-test** (ç¬¬24å›):

$$
t = \frac{\bar{x}_A - \bar{x}_B}{\sqrt{\frac{s_A^2}{n_A} + \frac{s_B^2}{n_B}}}
$$

è‡ªç”±åº¦ã¯ Welch-Satterthwaite è¿‘ä¼¼ $\nu \approx \frac{(s_A^2/n_A + s_B^2/n_B)^2}{(s_A^2/n_A)^2/(n_A-1) + (s_B^2/n_B)^2/(n_B-1)}$ ã§è¨ˆç®—ã™ã‚‹ã€‚Student's t-testï¼ˆç­‰åˆ†æ•£ä»®å®šï¼‰ã¨ã®é•ã„ã¯åˆ†æ¯ã®åˆ†æ•£æ¨å®šé‡ã§ã‚ã‚Šã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«é–“ã® FID æ¯”è¼ƒã§ã¯åˆ†æ•£ãŒç•°ãªã‚‹ã“ã¨ãŒå¤šã„ãŸã‚ Welch ãŒé©åˆ‡ã€‚

**Cohen's d (åŠ¹æœé‡)**: på€¤ã ã‘ã§ã¯ã€Œæ”¹å–„ã®å¤§ãã•ã€ãŒã‚ã‹ã‚‰ãªã„ã€‚Cohen's d ã¯æ¨™æº–åŒ–ã—ãŸå·®ã§ã‚ã‚Šã€|d| < 0.2 = å°ã€0.2-0.5 = ä¸­ã€> 0.8 = å¤§ã¨è§£é‡ˆã™ã‚‹ã€‚FID ã§ d=0.3 ã¯ã€Œä¸­ç¨‹åº¦ã®æ”¹å–„ã€â†’ è«–æ–‡å ±å‘Šã«ã¯ på€¤ã¨ä½µè¨˜ãŒæœ›ã¾ã—ã„ã€‚

```julia

function compare_models_fid(model_a_fid_samples::Vector{Float64},
                             model_b_fid_samples::Vector{Float64}, Î±::Float64=0.05)
    # Welch's t-test (unequal variances)
    test_result = UnequalVarianceTTest(model_a_fid_samples, model_b_fid_samples)

    p_value = pvalue(test_result)
    is_significant = p_value < Î±

    # Effect size (Cohen's d)
    Î¼_a, Î¼_b = mean(model_a_fid_samples), mean(model_b_fid_samples)
    s_a, s_b = std(model_a_fid_samples), std(model_b_fid_samples)
    pooled_std = sqrt((s_a^2 + s_b^2) / 2)
    cohens_d = (Î¼_a - Î¼_b) / pooled_std

    println("Model A FID: $(round(Î¼_a, digits=2)) Â± $(round(s_a, digits=2))")
    println("Model B FID: $(round(Î¼_b, digits=2)) Â± $(round(s_b, digits=2))")
    println("p-value: $(round(p_value, digits=4))")
    println("Significant? $(is_significant) (Î±=$(Î±))")
    println("Effect size (Cohen's d): $(round(cohens_d, digits=3))")

    return test_result, p_value, cohens_d
end

# Test: simulate FID samples for 2 models
# Model A: FID ~ N(15, 2)
# Model B: FID ~ N(13, 1.5) (better model)
fid_a = 15 .+ 2 .* randn(100)
fid_b = 13 .+ 1.5 .* randn(100)

compare_models_fid(fid_a, fid_b)
```

#### 4.1.3 å¤šé‡æ¯”è¼ƒè£œæ­£ â€” Bonferroni/FDR

è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ï¼ˆNå€‹ï¼‰ã‚’æ¯”è¼ƒ â†’ å¤šé‡æ¤œå®šå•é¡Œï¼ˆç¬¬24å›ï¼‰ã€‚

**Bonferroniè£œæ­£**: $\alpha' = \alpha / N$

**ãªãœå¿…è¦ã‹**: $N=6$ ãƒšã‚¢æ¯”è¼ƒã‚’ $\alpha=0.05$ ã§è¡Œã†ã¨ã€å¸°ç„¡ä»®èª¬ãŒå…¨ã¦çœŸã§ã‚‚å°‘ãªãã¨ã‚‚1ã¤ã®å½é™½æ€§ãŒå‡ºã‚‹ç¢ºç‡ã¯ $1 - (1-0.05)^6 \approx 0.26$ã€‚è£œæ­£å¾Œã¯ $1 - (1-\alpha')^6 = 1 - (1-0.0083)^6 \approx 0.049 < 0.05$ ã«æŠ‘ãˆã‚‰ã‚Œã‚‹ã€‚

> **âš ï¸ Warning:** Bonferroni ã¯ä¿å®ˆçš„ã™ãã‚‹å ´åˆãŒã‚ã‚‹ï¼ˆæ¤œå‡ºåŠ›ãŒä¸‹ãŒã‚‹ï¼‰ã€‚ã‚ˆã‚Šç·©ã‚„ã‹ãª Holm-Bonferroni ã‚„ Benjamini-Hochberg (FDR) è£œæ­£ã‚‚æ¤œè¨ã™ã‚‹ã“ã¨ã€‚

```julia
# Multiple model comparison with Bonferroni correction
function compare_multiple_models(fid_samples_list::Vector{Vector{Float64}}, Î±::Float64=0.05)
    n_models = length(fid_samples_list)
    n_comparisons = n_models * (n_models - 1) Ã· 2
    Î±_bonf = Î± / n_comparisons

    println("Comparing $(n_models) models ($(n_comparisons) pairwise tests)")
    println("Bonferroni-corrected Î±: $(round(Î±_bonf, digits=5))")

    pairs = [(i, j) for i in 1:n_models for j in (i+1):n_models]
    results = map(pairs) do (i, j)
        p_val = pvalue(UnequalVarianceTTest(fid_samples_list[i], fid_samples_list[j]))
        is_sig = p_val < Î±_bonf
        println("Model $i vs $j: p=$(round(p_val, digits=4)), significant=$is_sig")
        (i, j, p_val, is_sig)
    end

    return results
end

# Test: 4 models
fid_model1 = 20 .+ 3 .* randn(50)
fid_model2 = 15 .+ 2 .* randn(50)
fid_model3 = 14 .+ 2.5 .* randn(50)
fid_model4 = 13 .+ 1.5 .* randn(50)
fid_list = [fid_model1, fid_model2, fid_model3, fid_model4]

compare_multiple_models(fid_list)
```

### 4.2 Rust Criterion ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

**Criterion.rs** [^criterion] ã¯Rustã®çµ±è¨ˆçš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚

å†…éƒ¨ã§ã¯å„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–¢æ•°ã‚’ç¹°ã‚Šè¿”ã—å®Ÿè¡Œã—ã€å®Ÿè¡Œæ™‚é–“ã®åˆ†å¸ƒã‚’æ¨å®šã™ã‚‹ã€‚ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¾Œã«æ¸¬å®šã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’è¨­ã‘ã€å¹³å‡ãƒ»æ¨™æº–åå·®ãƒ»[ä¸‹é™, æ¨å®šå€¤, ä¸Šé™] ã®3ç‚¹ä¿¡é ¼åŒºé–“ï¼ˆBootstrapãƒ™ãƒ¼ã‚¹ï¼‰ã‚’å‡ºåŠ›ã™ã‚‹ã€‚ã€Œperformance regression detected (p=0.03)ã€ã¯å‰å›ã¨ã®å·®ãŒWelch tæ¤œå®šã§ $p < 0.05$ ã«ãªã£ãŸã“ã¨ã‚’æ„å‘³ã™ã‚‹ã€‚

**ç‰¹å¾´**:
- çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå‡ºï¼ˆå›å¸°æ¤œå‡ºï¼‰
- è‡ªå‹• outlier é™¤å»
- CIçµ±åˆå¯èƒ½

#### 4.2.1 Rust FIDå®Ÿè£…ã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

```rust
// Cargo.toml
// [dependencies]
// ndarray = "0.16"
// ndarray-linalg = "0.19"
// [dev-dependencies]
// criterion = "0.5"

use ndarray::{Array1, Array2};
use ndarray_linalg::*;

/// Compute FrÃ©chet distance between two Gaussians
pub fn frechet_distance(
    mu1: &Array1<f64>,
    sigma1: &Array2<f64>,
    mu2: &Array1<f64>,
    sigma2: &Array2<f64>,
) -> Result<f64, Box<dyn std::error::Error>> {
    // Mean difference term
    let diff = mu1 - mu2;
    let mean_term = diff.dot(&diff);

    // Covariance term: Tr(Î£1 + Î£2 - 2(Î£1 Î£2)^{1/2})
    let product = sigma1.dot(sigma2);

    // shape: sigma1, sigma2 âˆˆ â„^{dÃ—d}, product âˆˆ â„^{dÃ—d}  (d=2048 å…¸å‹)
    // è¡Œåˆ—å¹³æ–¹æ ¹ã®è¨ˆç®—ãŒæ”¯é…çš„ã‚³ã‚¹ãƒˆ: å›ºæœ‰å€¤åˆ†è§£ O(dÂ³) â‰ˆ 8.6Ã—10â¹ flops (d=2048)

    // Matrix square root via eigen decomposition
    let (eigenvalues, eigenvectors) = product.eigh(UPLO::Lower)?;
    let sqrt_eig = eigenvalues.mapv(|x| x.abs().sqrt());
    let sqrt_product = &eigenvectors * &Array2::from_diag(&sqrt_eig) * &eigenvectors.t();

    let trace_term = sigma1.diag().sum() + sigma2.diag().sum() - 2.0 * sqrt_product.diag().sum();

    Ok(mean_term + trace_term)
}

#[cfg(test)]
mod benches {
    use super::*;
    use criterion::{black_box, criterion_group, criterion_main, Criterion};
    use ndarray::Array;

    fn benchmark_fid(c: &mut Criterion) {
        let d = 2048;  // Inception feature dim
        let mu1 = Array1::zeros(d);
        let mu2 = Array1::ones(d) * 0.1;
        let sigma1 = Array2::eye(d);
        let sigma2 = Array2::eye(d) * 1.1;

        c.bench_function("fid_2048d", |b| {
            b.iter(|| {
                frechet_distance(
                    black_box(&mu1),
                    black_box(&sigma1),
                    black_box(&mu2),
                    black_box(&sigma2),
                ).unwrap()
            })
        });
    }

    criterion_group!(benches, benchmark_fid);
    criterion_main!(benches);
}
```

**å®Ÿè¡Œ**:

```bash
cargo bench
```

**å‡ºåŠ›ä¾‹**:

```
fid_2048d               time:   [12.234 ms 12.456 ms 12.701 ms]
                        change: [-2.3% +0.5% +3.1%] (p = 0.67 > 0.05)
                        No change in performance detected.
```

Criterionã¯è‡ªå‹•ã§:
- è¤‡æ•°å›å®Ÿè¡Œï¼ˆwarmup + measurementï¼‰
- çµ±è¨ˆé‡è¨ˆç®—ï¼ˆå¹³å‡ã€æ¨™æº–åå·®ã€ä¿¡é ¼åŒºé–“ï¼‰
- å‰å›ã¨ã®æ¯”è¼ƒï¼ˆå›å¸°æ¤œå‡ºï¼‰

**å‡ºåŠ›ã®èª­ã¿æ–¹**: `[12.234 ms 12.456 ms 12.701 ms]` ã¯ [ä¸‹é™, æ¨å®šå€¤, ä¸Šé™] ã®95%ä¿¡é ¼åŒºé–“ã€‚`change: [-2.3% +0.5% +3.1%] (p = 0.67 > 0.05)` ã¯å›å¸°ãªã—ï¼ˆp > 0.05ï¼‰ã€‚`p < 0.05` ãŒå‡ºãŸã‚‰æ€§èƒ½åŠ£åŒ–ç¢ºå®šã¨åˆ¤æ–­ã™ã‚‹ã€‚

#### 4.2.2 è‡ªå‹•ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

**CIçµ±åˆ**: GitHub Actions ã§è‡ªå‹•ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ + å›å¸°ã‚¢ãƒ©ãƒ¼ãƒˆã€‚

```yaml
# .github/workflows/bench.yml
name: Benchmark

on: [push, pull_request]

jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
      - name: Run benchmarks
        run: cargo bench --bench fid_bench
      - name: Upload results
        uses: actions/upload-artifact@v2
        with:
          name: criterion-results
          path: target/criterion/
```

### 4.3 è‡ªå‹•è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­è¨ˆ

**ãƒ•ãƒ­ãƒ¼**:

```mermaid
graph LR
    A[ãƒ¢ãƒ‡ãƒ«è¨“ç·´] --> B[ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜]
    B --> C[ç”»åƒç”Ÿæˆ<br/>n=5000]
    C --> D[ç‰¹å¾´æŠ½å‡º<br/>Inception/CLIP]
    D --> E1[FIDè¨ˆç®—]
    D --> E2[ISè¨ˆç®—]
    D --> E3[LPIPSè¨ˆç®—]
    D --> E4[P&Rè¨ˆç®—]
    D --> E5[CMMDè¨ˆç®—]
    E1 & E2 & E3 & E4 & E5 --> F[çµ±è¨ˆæ¤œå®š<br/>CI+t-test]
    F --> G[ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ<br/>JSON/HTML]
    G --> H[CI Artifact]
    style F fill:#fff3e0
    style G fill:#c8e6c9
```

**å®Ÿè£…** (Julia):

```julia
# Automatic evaluation pipeline
using JSON

struct EvaluationResult
    fid::Float64
    fid_ci::Tuple{Float64, Float64}
    is::Float64
    is_ci::Tuple{Float64, Float64}
    cmmd::Float64
    precision::Float64
    recall::Float64
    timestamp::String
end

function evaluate_model(model_checkpoint::String, real_dataset::Vector{Matrix{Float64}}, n_gen::Int=1000)
    println("Evaluating model: $model_checkpoint")

    # Step 1: Generate images
    println("Generating $(n_gen) images...")
    gen_images = generate_images(model_checkpoint, n_gen)  # placeholder

    # Step 2: Extract features
    println("Extracting features...")
    feats_real = extract_inception_features(real_dataset)
    feats_gen = extract_inception_features(gen_images)

    # Step 3: Compute metrics
    println("Computing FID...")
    fid_val, fid_l, fid_u, _ = fid_with_ci(real_dataset, gen_images, 200, 0.95)

    println("Computing IS...")
    is_val, _ = inception_score(gen_images)
    # Simplified: no bootstrap for IS here

    println("Computing CMMD...")
    cmmd_val, _ = cmmd_paper(real_dataset, gen_images)

    println("Computing Precision-Recall...")
    prec, rec = precision_recall(feats_real, feats_gen, 5)

    # Step 4: Assemble results
    result = EvaluationResult(
        fid_val, (fid_l, fid_u),
        is_val, (0.0, 0.0),  # placeholder CI
        cmmd_val,
        prec, rec,
        string(now())
    )

    # Step 5: Save to JSON
    json_result = Dict(
        "model" => model_checkpoint,
        "fid" => Dict("value" => result.fid, "ci" => result.fid_ci),
        "is" => result.is,
        "cmmd" => result.cmmd,
        "precision" => result.precision,
        "recall" => result.recall,
        "timestamp" => result.timestamp
    )

    output_path = "eval_results_$(split(model_checkpoint, '/')[end]).json"
    open(output_path, "w") do f
        JSON.print(f, json_result, 2)
    end

    println("âœ… Evaluation complete. Results saved to $output_path")
    return result
end

# Placeholder for image generation
function generate_images(checkpoint::String, n::Int)
    # Real impl: load model, sample latents, decode
    return [randn(64, 64) for _ in 1:n]
end

# Test
real_data_test = [randn(64, 64) for _ in 1:500]
eval_result = evaluate_model("model_epoch_100.ckpt", real_data_test, 500)
```

> **Note:** **é€²æ—: 70% å®Œäº†** å®Ÿè£…ã‚¾ãƒ¼ãƒ³å®Œäº† â€” Juliaçµ±è¨ˆåˆ†æ + Rust Criterion + è‡ªå‹•è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚ã“ã“ã‹ã‚‰å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ã¸ â€” VAE/GAN/GPTçµ±åˆè©•ä¾¡ã€‚

---


> Progress: [85%]
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. Criterion.rsãŒã€Œçµ±è¨ˆçš„æœ‰æ„ãªå›å¸°ã€ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã«Welch tæ¤œå®šã‚’ç”¨ã„ã‚‹ç†ç”±ã¯ï¼Ÿ
>    - *ãƒ’ãƒ³ãƒˆ*: ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å‰å¾Œã®å®Ÿè¡Œæ™‚é–“åˆ†å¸ƒãŒç­‰åˆ†æ•£ã ã¨ä»®å®šã§ãã‚‹ã‹è€ƒãˆã‚ˆã€‚
> 2. FIDè¨ˆç®—ã§Inceptionç‰¹å¾´é‡ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ãªã„ã¨è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒé‡ããªã‚‹è¨ˆç®—é‡çš„ç†ç”±ã¯ï¼Ÿ
>    - *ãƒ’ãƒ³ãƒˆ*: Inception-v3ã® forward pass ãŒ1ç”»åƒã‚ãŸã‚Šä½• FLOP ã‹ã€5000ã‚µãƒ³ãƒ—ãƒ«ã§ä½•å›èµ°ã‚‹ã‹è¨ˆç®—ã›ã‚ˆã€‚

## ğŸ”¬ 5. å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” VAE/GAN/GPTçµ±åˆè©•ä¾¡

### 5.1 æ¼”ç¿’: 3ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æ¯”è¼ƒ

**èª²é¡Œ**: VAE, GAN, GPT (autoregressive) ã®3ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ã€æ¯”è¼ƒã›ã‚ˆã€‚

**æœŸå¾…ã•ã‚Œã‚‹çµæœã®äº‹å‰ãƒã‚§ãƒƒã‚¯**: FID(VAE) > FID(GAN) â‰ˆ FID(AR) ãŒå…¸å‹ã€‚VAE ã¯ã¼ã‚„ã‘ãŸç”»åƒã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ FID ãŒæ‚ªããªã‚‹ã€‚ãŸã ã— Recall(VAE) > Recall(GAN) ã¨ãªã‚‹ã“ã¨ãŒå¤šã„ï¼ˆVAE ã¯å¤šæ§˜æ€§é«˜ã„ãŒã¼ã‚„ã‘ã€GAN ã¯é®®æ˜ã ãŒ mode collapseï¼‰ã€‚å®Ÿé¨“å‰ã«ã€Œã©ã®æŒ‡æ¨™ãŒå¤§ãããªã‚‹/å°ã•ããªã‚‹ã€ã‚’ä»®èª¬ã¨ã—ã¦æ›¸ã„ã¦ã‹ã‚‰å®Ÿé¨“ã™ã‚‹ã“ã¨ã€‚

**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: MNIST (ç°¡æ˜“ç‰ˆ)

#### 5.1.1 ãƒ¢ãƒ‡ãƒ«å®Ÿè£…ï¼ˆç°¡ç•¥ç‰ˆï¼‰

```julia
# Simplified VAE/GAN/GPT for evaluation demo
using Flux

# VAE (from ç¬¬10å›)
struct TinyVAE
    encoder::Chain
    decoder::Chain
end

function (vae::TinyVAE)(x::Matrix{Float64})
    # Encode
    z_params = vae.encoder(x)  # (2*latent_dim, batch)
    d = size(z_params, 1) Ã· 2
    @views Î¼, logÏƒ = z_params[1:d,:], z_params[d+1:end,:]
    z = Î¼ .+ exp.(logÏƒ) .* randn(size(Î¼))

    # Decode
    x_recon = z |> vae.decoder
    return x_recon, Î¼, logÏƒ
end

# GAN (from ç¬¬12å›)
struct TinyGAN
    generator::Chain
    discriminator::Chain
end

generate_gan(gan::TinyGAN, n::Int, latent_dim::Int=32) = randn(latent_dim, n) |> gan.generator

# Autoregressive (from ç¬¬15å›)
struct TinyAR
    model::Chain
end

generate_ar(ar::TinyAR, n::Int, seq_len::Int=784) = map(1:n) do _
    x = zeros(seq_len)
    @inbounds for t in 1:seq_len
        x[t] = @views ar.model(x[1:t]) |> softmax |> sample_categorical
    end
    reshape(x, 28, 28)
end

# Placeholder implementations
vae_model = TinyVAE(Chain(Dense(784, 64), Dense(64, 32)), Chain(Dense(16, 64), Dense(64, 784)))
gan_model = TinyGAN(Chain(Dense(32, 64), Dense(64, 784)), Chain(Dense(784, 64), Dense(64, 1)))
ar_model = TinyAR(Chain(Dense(784, 256), Dense(256, 784)))
```

#### 5.1.2 çµ±åˆè©•ä¾¡

```julia
# Unified evaluation for 3 models
function evaluate_all_models(real_data::Vector{Matrix{Float64}}, n_gen::Int=1000)
    println("ğŸ”¬ Evaluating 3 models: VAE, GAN, AR")

    # Generate samples from each model
    println("Generating VAE samples...")
    vae_samples = [generate_vae(vae_model) for _ in 1:n_gen]  # placeholder

    println("Generating GAN samples...")
    gan_samples = [generate_gan(gan_model, 1, 32)[:,1] |> x -> reshape(x, 28, 28) for _ in 1:n_gen]

    println("Generating AR samples...")
    ar_samples = generate_ar(ar_model, n_gen, 784)

    # Evaluate each model
    models = [("VAE", vae_samples), ("GAN", gan_samples), ("AR", ar_samples)]
    results = Dict()

    for (name, samples) in models
        println("\nğŸ“Š Evaluating $name...")
        fid_val, _, _, _ = fid_with_ci(real_data, samples, 100, 0.95)
        is_val, _  = inception_score(samples)
        cmmd_val, _ = cmmd_paper(real_data, samples)
        prec, rec  = precision_recall(extract_inception_features(real_data),
                                      extract_inception_features(samples), 5)
        results[name] = Dict("FID" => fid_val, "IS" => is_val,
                             "CMMD" => cmmd_val, "Precision" => prec, "Recall" => rec)
    end

    # Display comparison table
    println("\nğŸ“‹ Comparison Table:")
    println("| Model | FID â†“ | IS â†‘ | CMMD â†“ | Precision â†‘ | Recall â†‘ |")
    println("|:------|:------|:-----|:-------|:------------|:---------|")
    for (name, metrics) in results
        println("| $name | $(round(metrics["FID"], digits=2)) | $(round(metrics["IS"], digits=2)) | " *
                "$(round(metrics["CMMD"], digits=4)) | $(round(metrics["Precision"], digits=3)) | $(round(metrics["Recall"], digits=3)) |")
    end

    return results
end

# Placeholder
function generate_vae(vae::TinyVAE, latent_dim::Int=16)
    randn(latent_dim) |> vae.decoder |> x -> reshape(x, 28, 28)
end

# Test with dummy data
mnist_real = [randn(28, 28) for _ in 1:500]
all_results = evaluate_all_models(mnist_real, 500)
```

**æœŸå¾…ã•ã‚Œã‚‹çµæœãƒ‘ã‚¿ãƒ¼ãƒ³**:

| Model | FID â†“ | IS â†‘ | CMMD â†“ | Precision â†‘ | Recall â†‘ | ç‰¹å¾´ |
|:------|:------|:-----|:-------|:------------|:---------|:-----|
| VAE | ä¸­ | ä¸­ | ä¸­ | ä¸­ | **é«˜** | å¤šæ§˜æ€§é«˜ã„ãŒã¼ã‚„ã‘ã‚‹ |
| GAN | **ä½** | **é«˜** | **ä½** | **é«˜** | ä½ | é«˜å“è³ªã ãŒmode collapse |
| AR | ä½-ä¸­ | é«˜ | ä½ | é«˜ | é«˜ | å“è³ªã‚‚å¤šæ§˜æ€§ã‚‚è‰¯ã„ãŒé…ã„ |

> **âš ï¸ Warning:** ã“ã®çµæœãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ç†æƒ³åŒ–ã•ã‚ŒãŸã‚‚ã®ã€‚å®Ÿéš›ã® MNIST ã§ã¯å…¨ãƒ¢ãƒ‡ãƒ«ãŒé¡ä¼¼ã® FID ã‚’ç¤ºã™ã“ã¨ã‚‚å¤šã„ã€‚å·®ãŒå‡ºã‚‹ã®ã¯ CIFAR-10 ã‚„ CelebA ãªã©ã®è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§é¡•è‘—ã«ãªã‚‹ã€‚å°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡ã™ã‚‹éš›ã¯ Bootstrap ã§ä¿¡é ¼åŒºé–“ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã€‚

### 5.2 äººé–“è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«è¨­è¨ˆ

**å®šé‡è©•ä¾¡ã®é™ç•Œ** â†’ äººé–“è©•ä¾¡ãŒå¿…è¦ã€‚

#### 5.2.1 A/Bãƒ†ã‚¹ãƒˆè¨­è¨ˆ

**è³ªå•**: ã€Œã©ã¡ã‚‰ã®ç”»åƒãŒã‚ˆã‚Šè‡ªç„¶ã§ã™ã‹ï¼Ÿã€

**è¨­è¨ˆ**:
1. ãƒšã‚¢wiseæ¯”è¼ƒï¼ˆ2ç”»åƒã‚’æç¤ºï¼‰
2. ç„¡ä½œç‚ºåŒ–ï¼ˆé †åºã€ãƒšã‚¢é¸æŠï¼‰
3. è©•ä¾¡è€…é–“ä¸€è‡´åº¦ï¼ˆInter-rater reliabilityï¼‰

**ã‚µãƒ³ãƒ—ãƒ«æ•°ã®è¦‹ç©ã‚‚ã‚Š**: å·®ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã«å¿…è¦ãªãƒšã‚¢æ•° $n$ ã¯ã€åŠ¹æœé‡ $d$ ã¨æœ‰æ„æ°´æº– $\alpha=0.05$ã€æ¤œå‡ºåŠ› $1-\beta=0.80$ ã‹ã‚‰ $n \approx 16 / d^2$ï¼ˆCohen ã®å…¬å¼ï¼‰ã€‚GAN vs VAE ã®å·®ãŒä¸­ç¨‹åº¦ï¼ˆ$d=0.5$ï¼‰ãªã‚‰ $n \approx 64$ ãƒšã‚¢ãŒå¿…è¦ã€‚

```julia
# A/B test design
struct ABTest
    pair_id::Int
    img_a::Matrix{Float64}
    img_b::Matrix{Float64}
    model_a::String
    model_b::String
end

function design_ab_test(models::Dict{String, Vector{Matrix{Float64}}}, n_pairs::Int=100)
    # Generate random pairs
    model_names = collect(keys(models))

    tests = map(1:n_pairs) do i
        m1, m2 = rand(model_names, 2)
        while m1 == m2; m2 = rand(model_names) end
        img1, img2 = rand(models[m1]), rand(models[m2])
        rand() < 0.5 ? ABTest(i, img1, img2, m1, m2) : ABTest(i, img2, img1, m2, m1)
    end

    return tests
end

# Export for crowdsourcing
function export_ab_test_csv(tests::Vector{ABTest}, output_path::String)
    open(output_path, "w") do f
        println(f, "pair_id,img_a_path,img_b_path,model_a,model_b")
        for test in tests
            # Save images (placeholder)
            img_a_path = "ab_test_$(test.pair_id)_a.png"
            img_b_path = "ab_test_$(test.pair_id)_b.png"
            println(f, "$(test.pair_id),$img_a_path,$img_b_path,$(test.model_a),$(test.model_b)")
        end
    end
    println("âœ… A/B test CSV exported to $output_path")
end

# Test
models_for_ab = Dict("VAE" => vae_samples, "GAN" => gan_samples, "AR" => ar_samples)  # from 5.1
ab_tests = design_ab_test(models_for_ab, 50)
export_ab_test_csv(ab_tests, "ab_test_design.csv")
```

#### 5.2.2 Mean Opinion Score (MOS)

**è³ªå•**: ã€Œã“ã®ç”»åƒã®å“è³ªã‚’1-5ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€

**è¨­è¨ˆ**:
1. Likert scale (1=æœ€æ‚ª, 5=æœ€é«˜)
2. è¤‡æ•°è©•ä¾¡è€…ï¼ˆâ‰¥3äººï¼‰ã§å¹³å‡
3. ä¿¡é ¼åŒºé–“è¨ˆç®—

**MOS ã®çµ±è¨ˆçš„è§£é‡ˆ**: æ¨™æº–èª¤å·® $\text{SE} = \sigma / \sqrt{n_\text{raters} \times n_\text{items}}$ã€‚95% CI $= \mu \pm 1.96 \cdot \text{SE}$ã€‚MOS 3.5 Â± 0.1 ã¯ã€ŒMOS 4.0 ã¨ã®å·®ãŒæœ‰æ„ã€ã‚’ç¤ºã™ï¼ˆCI ãŒé‡ãªã‚‰ãªã„ï¼‰ã€‚GTã¨ã®å·®ãŒ 0.2 ä»¥ä¸‹ãªã‚‰ã€Œå®Ÿç”¨çš„ã«åŒç­‰å“è³ªã€ã¨ã¿ãªã™ã“ã¨ãŒå¤šã„ã€‚

```julia
# MOS collection and analysis
struct MOSResult
    image_id::Int
    model::String
    ratings::Vector{Int}  # 1-5 from multiple raters
end

function analyze_mos(results::Vector{MOSResult})
    println("ğŸ“Š MOS Analysis:")
    println("| Model | Mean MOS | Std | 95% CI |")
    println("|:------|:---------|:----|:-------|")

    for model in unique(r.model for r in results)
        model_ratings = reduce(vcat, r.ratings for r in results if r.model == model)
        Î¼, Ïƒ = mean(model_ratings), std(model_ratings)
        se = Ïƒ / sqrt(length(model_ratings))
        ci_margin = 1.96 * se
        println("| $model | $(round(Î¼, digits=2)) | $(round(Ïƒ, digits=2)) | " *
                "[$(round(Î¼ - ci_margin, digits=2)), $(round(Î¼ + ci_margin, digits=2))] |")
    end
end

# Simulate MOS data
mos_data = [
    MOSResult(1, "VAE", [3, 3, 4, 3, 3]),
    MOSResult(2, "VAE", [3, 4, 3, 3, 4]),
    MOSResult(3, "GAN", [4, 5, 4, 4, 5]),
    MOSResult(4, "GAN", [5, 4, 5, 4, 5]),
    MOSResult(5, "AR", [4, 4, 5, 4, 4]),
    MOSResult(6, "AR", [4, 5, 4, 5, 4]),
]

analyze_mos(mos_data)
```

#### 5.2.3 è©•ä¾¡è€…é–“ä¸€è‡´åº¦ (Inter-rater Reliability)

**Fleiss' Kappa** (ç¬¬24å›) â€” è¤‡æ•°è©•ä¾¡è€…ã®ä¸€è‡´åº¦ã€‚

$$
\kappa = \frac{\bar{P} - P_e}{1 - P_e}
$$

- $\bar{P}$: å®Ÿéš›ã®è©•ä¾¡è€…é–“ä¸€è‡´ç‡ï¼ˆè¦³æ¸¬å€¤ï¼‰
- $P_e$: å¶ç„¶ã«æœŸå¾…ã•ã‚Œã‚‹ä¸€è‡´ç‡ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰
- $\kappa = 1$: å®Œå…¨ä¸€è‡´ã€$\kappa = 0$: å¶ç„¶ã¨åŒã˜ã€$\kappa < 0$: å¶ç„¶ã‚ˆã‚Šæ‚ªã„

**æ•°å€¤ä¾‹**: $\kappa = 0.65$ ãªã‚‰ã€Œå¶ç„¶ã®ä¸€è‡´ã‚’è¶…ãˆãŸä¸€è‡´ç‡ãŒ 65%ã€â†’ Substantialã€‚ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®äººé–“è©•ä¾¡ã§ã¯ $\kappa \geq 0.4$ ã‚’æœ€ä½åŸºæº–ã¨ã™ã‚‹ã“ã¨ã€‚

```julia
# Fleiss' Kappa for inter-rater reliability
using Statistics

function fleiss_kappa(ratings::Matrix{Int})
    # ratings: (n_items, n_raters)
    n_items, n_raters = size(ratings)
    n_categories = maximum(ratings)

    # Proportion of agreement per item
    P_i = map(1:n_items) do i
        counts = [sum(@views(ratings[i,:]) .== k) for k in 1:n_categories]
        (sum(counts.^2) - n_raters) / (n_raters * (n_raters - 1))
    end
    P_bar = mean(P_i)

    # Expected agreement by chance
    p_j = [sum(ratings .== j) / (n_items * n_raters) for j in 1:n_categories]
    P_e = sum(p_j.^2)

    # Kappa
    Îº = (P_bar - P_e) / (1 - P_e)
end

# Test
ratings_test = [
    1 2 1 1;  # item 1: raters gave 1,2,1,1
    2 2 2 2;  # item 2: all agree on 2
    3 3 4 3;  # item 3: mostly 3
]
Îº = fleiss_kappa(ratings_test)
println("Fleiss' Kappa: $(round(Îº, digits=3))")
println("Interpretation: Îº < 0.2 = poor, 0.2-0.4 = fair, 0.4-0.6 = moderate, 0.6-0.8 = substantial, > 0.8 = almost perfect")
```

> **Note:** **é€²æ—: 85% å®Œäº†** å®Ÿé¨“ã‚¾ãƒ¼ãƒ³å®Œäº† â€” VAE/GAN/ARçµ±åˆè©•ä¾¡ + äººé–“è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã€‚ã“ã“ã‹ã‚‰ç™ºå±•ã‚¾ãƒ¼ãƒ³ã¸ â€” æœ€æ–°ç ”ç©¶å‹•å‘ã€‚

---

## ğŸ“ 6. æŒ¯ã‚Šè¿”ã‚Šã¨ç™ºå±•ã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” ã¾ã¨ã‚ã¨æœ€æ–°ç ”ç©¶å‹•å‘

### 6.1 FLD+ (Flow-based Likelihood Distance)

**è«–æ–‡** [^7]: FLD+: Data-efficient Evaluation Metric for Generative Models (2024)

**å‹•æ©Ÿ**: FIDã¯2000+ã‚µãƒ³ãƒ—ãƒ«å¿…è¦ â†’ å°‘ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®šã™ã‚‹æŒ‡æ¨™ãŒæ¬²ã—ã„ã€‚

**ã‚¢ã‚¤ãƒ‡ã‚¢**: Normalizing Flowã§å¯†åº¦æ¨å®š â†’ å°¤åº¦ãƒ™ãƒ¼ã‚¹ã®è·é›¢ã€‚

**å®šç¾©**:

$$
\text{FLD}(P_r, P_g) = \mathbb{E}_{x \sim P_r}[-\log q_\theta(x)] - \mathbb{E}_{x \sim P_g}[-\log q_\theta(x)]
$$

ã“ã“ã§ $q_\theta$ ã¯Normalizing Flowã§è¨“ç·´ã•ã‚ŒãŸå¯†åº¦ãƒ¢ãƒ‡ãƒ«ï¼ˆçœŸç”»åƒã§è¨“ç·´ï¼‰ã€‚

**æ•°å€¤ä¾‹**: $q_\theta$ ãŒå®Œç’§ã« $P_r$ ã‚’å­¦ç¿’ã—ãŸå ´åˆï¼ˆ$q_\theta = P_r$ï¼‰ã€ç¬¬1é …ã¯ $\mathcal{H}(P_r)$ï¼ˆãƒ‡ãƒ¼ã‚¿ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼‰ã€ç¬¬2é …ã¯ç”Ÿæˆåˆ†å¸ƒã® $P_r$ ä¸‹ã§ã® cross-entropyã€‚ä¸¡è€…ãŒç­‰ã—ã‘ã‚Œã° FLD=0 â†’ $P_g = P_r$ã€‚FLD $> 0$ ã¯ç”Ÿæˆåˆ†å¸ƒãŒçœŸåˆ†å¸ƒã‹ã‚‰å¤–ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚

**åˆ©ç‚¹**:
- 200-500ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®šï¼ˆFIDã¯2000+å¿…è¦ï¼‰
- ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œå¯èƒ½ï¼ˆåŒ»ç™‚ç”»åƒãªã©ã§å†è¨“ç·´ï¼‰
- å˜èª¿æ€§ãŒå¼·ã„ï¼ˆç”»åƒåŠ£åŒ–ã«å¯¾ã—ã¦ï¼‰

**ãªãœå°‘ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®šã™ã‚‹ã‹**: FID ã¯ $d \times d$ å…±åˆ†æ•£è¡Œåˆ—ï¼ˆ$d=2048$ï¼‰ã®æ¨å®šãŒå¿…è¦ã§ã€ã“ã‚Œã«ã¯ $O(d^2) \approx 4 \times 10^6$ è‡ªç”±ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚‹ã€‚FLD+ ã¯ Normalizing Flow ã®å¯¾æ•°å°¤åº¦ã‚¹ã‚«ãƒ©ãƒ¼1ã¤ã‚’æ¯”è¼ƒã™ã‚‹ã ã‘ â†’ æ¨å®šå¯¾è±¡ã®æ¬¡å…ƒãŒåœ§å€’çš„ã«å°‘ãªã„ã€‚

### 6.2 è©•ä¾¡æŒ‡æ¨™ã®ç ”ç©¶ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢

**2024-2026ã®ãƒˆãƒ¬ãƒ³ãƒ‰**:

| ç ”ç©¶æ–¹å‘ | ä»£è¡¨è«–æ–‡ | æ¦‚è¦ |
|:---------|:---------|:-----|
| **ä»®å®šãªã—æŒ‡æ¨™** | CMMD [^5], NFM [^8] | MMD/Flowãƒ™ãƒ¼ã‚¹ã€æ­£è¦æ€§ä¸è¦ |
| **å°‘ã‚µãƒ³ãƒ—ãƒ«æŒ‡æ¨™** | FLD+ [^7] | 200ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®š |
| **ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œ** | CMMD-CLIP [^5] | Text-to-Imageç”Ÿæˆå¯¾å¿œ |
| **åˆ†é›¢è©•ä¾¡** | Precision-Recall Cover [^9] | å“è³ªãƒ»å¤šæ§˜æ€§ãƒ»è¢«è¦†ç‡ã‚’åˆ†é›¢ |
| **äººé–“è©•ä¾¡äºˆæ¸¬** | ImageReward, PickScore | äººé–“è©•ä¾¡ã‚’ãƒ¢ãƒ‡ãƒ«åŒ– |

**ãƒˆãƒ¬ãƒ³ãƒ‰ã®æ–¹å‘æ€§**: è©•ä¾¡æŒ‡æ¨™ã®é€²åŒ–ã¯ã€Œä»®å®šã®å‰Šæ¸›ã€ã¨ã€Œäººé–“æ•´åˆæ€§ã®å‘ä¸Šã€ã®2æ–¹å‘ã«å‘ã‹ã£ã¦ã„ã‚‹ã€‚FID â†’ CMMD â†’ FLD+ ã¨ã„ã†æµã‚Œã¯å‰è€…ã€ImageReward â†’ PickScore ã¯å¾Œè€…ã€‚ç©¶æ¥µã¯ã€Œäººé–“ã®ä¸»è¦³ã‚’ã‚¼ãƒ­ã‚³ã‚¹ãƒˆã§å†ç¾ã™ã‚‹æŒ‡æ¨™ã€ã ãŒã€äººé–“è©•ä¾¡è‡ªä½“ãŒä¸»è¦³çš„ã§å¤‰å‹•ã™ã‚‹ãŸã‚ã€çµ±è¨ˆçš„ã«ä¿¡é ¼ã§ãã‚‹è‡ªå‹•æŒ‡æ¨™ã®ç ”ç©¶ã¯ä»Šå¾Œã‚‚ç¶šãã€‚

### 6.3 ç”Ÿæˆãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã®ç³»è­œ

```mermaid
graph TD
    A[2014: Inception Score] --> B[2017: FID]
    B --> C[2019: Precision-Recall]
    C --> D[2024: CMMD]
    D --> E[2024: FLD+]

    A2[ä»®å®š: ImageNetåˆ†é¡] -.->|é™ç•Œ| B2[ä»®å®š: ã‚¬ã‚¦ã‚¹æ€§]
    B2 -.->|é™ç•Œ| C2[è¨ˆç®—ã‚³ã‚¹ãƒˆé«˜]
    C2 -.->|é™ç•Œ| D2[ä»®å®šãªã—<br/>CLIPåŸ‹ã‚è¾¼ã¿]
    D2 --> E2[å°‘ã‚µãƒ³ãƒ—ãƒ«<br/>Flowå¯†åº¦]

    style D fill:#c8e6c9
    style E fill:#b3e5fc
```

### 6.4 è©•ä¾¡æŒ‡æ¨™ã®é¸æŠã‚¬ã‚¤ãƒ‰ï¼ˆ2026å¹´ç‰ˆï¼‰

| çŠ¶æ³ | æ¨å¥¨æŒ‡æ¨™ | ç†ç”± |
|:-----|:---------|:-----|
| **æ¨™æº–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆImageNetç­‰ï¼‰** | FID + IS | æ¯”è¼ƒå¯èƒ½æ€§é‡è¦– |
| **æ–°è¦ç ”ç©¶ï¼ˆ2024ä»¥é™ï¼‰** | **CMMD** + FID | FIDã®é™ç•Œã‚’è£œå®Œ [^5] |
| **å°‘ã‚µãƒ³ãƒ—ãƒ«ï¼ˆ<1000ï¼‰** | **FLD+** | 200ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®š [^7] |
| **Text-to-Image** | **CMMD-CLIP** | ãƒ†ã‚­ã‚¹ãƒˆ-ç”»åƒå¯¾å¿œ [^5] |
| **å“è³ªvså¤šæ§˜æ€§åˆ†æ** | **Precision-Recall** | ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å¯è¦–åŒ– [^4] |
| **ãƒšã‚¢wiseæ¯”è¼ƒ** | **LPIPS** | äººé–“çŸ¥è¦šã¨ç›¸é–¢ [^3] |
| **ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ï¼ˆåŒ»ç™‚ç­‰ï¼‰** | FLD+ (å†è¨“ç·´) | ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œ [^7] |
| **äººé–“è©•ä¾¡ä»£æ›¿** | ImageReward / PickScore | äººé–“è©•ä¾¡äºˆæ¸¬ãƒ¢ãƒ‡ãƒ« |

**æŒ‡æ¨™é¸æŠã®åŸå‰‡**: (1) éå»ã®è«–æ–‡ã¨ã®æ¯”è¼ƒãŒå¿…è¦ â†’ FID å¿…é ˆã€(2) æ–°ã—ã„è©•ä¾¡ã®ä¸»å¼µ â†’ CMMD + FID ã®ä¸¡æ–¹å ±å‘Šã€(3) ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„ â†’ FLD+ ã§æ—©æœŸè©•ä¾¡ã—ã¦ã‹ã‚‰ FID è¿½åŠ ã€‚å˜ä¸€æŒ‡æ¨™ã§ãƒ¢ãƒ‡ãƒ«ã‚’åˆ¤æ–­ã™ã‚‹ã®ã¯é¿ã‘ã‚‹ã“ã¨ã€‚

> **Note:** **é€²æ—: 95% å®Œäº†** ç™ºå±•ã‚¾ãƒ¼ãƒ³å®Œäº† â€” æœ€æ–°ç ”ç©¶å‹•å‘ã€‚ã“ã“ã‹ã‚‰æŒ¯ã‚Šè¿”ã‚Šã‚¾ãƒ¼ãƒ³ã¸ã€‚

---

### 6.6 ã¾ã¨ã‚ â€” 5ã¤ã®è¦ç‚¹

1. **è©•ä¾¡ã¯å¤šé¢çš„**: FID/IS/LPIPS/P&R/CMMD â€” å„æŒ‡æ¨™ã¯ç•°ãªã‚‹å´é¢ã‚’æ¸¬å®šã€‚è¤‡æ•°æŒ‡æ¨™ã‚’çµ„ã¿åˆã‚ã›ã¦ç·åˆåˆ¤æ–­ã€‚

2. **æ•°å¼ã®ç†è§£ãŒæœ¬è³ª**: FID = Wassersteinè·é›¢ã®ã‚¬ã‚¦ã‚¹é–‰å½¢å¼ã€‚IS = KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã®æœŸå¾…å€¤ã€‚CMMD = MMD + CLIPã€‚æ•°å¼ã‚’å°å‡ºã™ã‚Œã°ã€æŒ‡æ¨™ã®ä»®å®šã¨é™ç•ŒãŒè¦‹ãˆã‚‹ã€‚

   **å„æŒ‡æ¨™ã®ä»®å®šã¾ã¨ã‚**:
   - FID: $P_r, P_g$ ãŒå¤šå¤‰é‡ã‚¬ã‚¦ã‚¹åˆ†å¸ƒ + Inceptionç‰¹å¾´ãŒ meaningful
   - IS: Inceptionåˆ†é¡å™¨ãŒæ„å‘³ã®ã‚ã‚‹ã‚¯ãƒ©ã‚¹ç¢ºç‡ã‚’å‡ºåŠ› + $p_g(y)$ ãŒä¸€æ§˜
   - LPIPS: VGG/AlexNet ã®ä¸­é–“ç‰¹å¾´ãŒäººé–“çŸ¥è¦šã‚’åæ˜ 
   - P&R: å¤šæ§˜ä½“ä»®å®šï¼ˆé«˜å¯†åº¦é ˜åŸŸãŒé€£çµï¼‰+ k-NN ãŒå¤šæ§˜ä½“ã‚’è¿‘ä¼¼
   - CMMD: CLIP åŸ‹ã‚è¾¼ã¿ãŒæ„å‘³ç©ºé–“ã‚’åæ˜  + RBF ã‚«ãƒ¼ãƒãƒ«ãŒé©åˆ‡

3. **çµ±è¨ˆæ¤œå®šãŒä¸å¯æ¬ **: FIDã®ç‚¹æ¨å®šã ã‘ã§ã¯ä¸ååˆ†ã€‚ä¿¡é ¼åŒºé–“ãƒ»ä»®èª¬æ¤œå®šãƒ»åŠ¹æœé‡ã§å®Ÿè³ªçš„ãªæ”¹å–„ã‚’åˆ¤æ–­ã€‚

4. **2024å¹´ã®è»¢æ›ç‚¹**: FIDã®é™ç•Œ â†’ CMMD/FLD+ç™»å ´ã€‚æ­£è¦æ€§ä»®å®šã®æ’é™¤ãƒ»å°‘ã‚µãƒ³ãƒ—ãƒ«å¯¾å¿œãƒ»ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œã€‚

5. **è‡ªå‹•åŒ–ãŒéµ**: è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆJuliaçµ±è¨ˆ + Rust Criterionï¼‰ã‚’CIçµ±åˆ â†’ ç¶™ç¶šçš„ãªå“è³ªç›£è¦–ã€‚

> **âš ï¸ Warning:** è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§æœ€ã‚‚ã‚ˆãã‚ã‚‹å¤±æ•—ã¯ã€Œå®Ÿãƒ‡ãƒ¼ã‚¿ã¨ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã§å‰å‡¦ç†ãŒé•ã†ã€ã“ã¨ã€‚Inceptionç‰¹å¾´æŠ½å‡ºå‰ã«åŒã˜ãƒªã‚µã‚¤ã‚ºãƒ»æ­£è¦åŒ–ã‚’é©ç”¨ã—ã¦ã„ã‚‹ã‹å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨ã€‚å‰å‡¦ç†ã®å·®ç•°ã§ FID ãŒæ•°åå˜ä½ãšã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚

<details><summary>Q1: FIDãŒä½ã„ã®ã«ISãŒé«˜ã„ â€” ã©ã¡ã‚‰ã‚’ä¿¡ã˜ã‚‹ã¹ãï¼Ÿ</summary>

**A**: ä¸¡æ–¹ã¨ã‚‚æ­£ã—ã„å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚FIDã¯åˆ†å¸ƒå…¨ä½“ã®è·é›¢ã€ISã¯å“è³ª+å¤šæ§˜æ€§ã®å˜ä¸€ã‚¹ã‚³ã‚¢ã€‚

**ä¾‹**:
- FIDä½ + ISé«˜ â†’ ç†æƒ³çš„ï¼ˆåˆ†å¸ƒä¸€è‡´ + é«˜å“è³ªãƒ»å¤šæ§˜ï¼‰
- FIDä½ + ISä½ â†’ åˆ†å¸ƒã¯è¿‘ã„ãŒã€å“è³ªorå¤šæ§˜æ€§ãŒä½ã„
- FIDé«˜ + ISé«˜ â†’ mode collapseã®å¯èƒ½æ€§ï¼ˆå°‘æ•°ã®é«˜å“è³ªç”»åƒã®ã¿ç”Ÿæˆï¼‰

**å¯¾ç­–**: Precision-Recallã§å“è³ªã¨å¤šæ§˜æ€§ã‚’åˆ†é›¢æ¸¬å®šã€‚

**è¿½åŠ è§£èª¬**: IS ãŒé«˜ã FID ã‚‚ä½ã„ç†æƒ³ã‚±ãƒ¼ã‚¹ã§ã‚‚ã€å®Ÿã¯ mode collapse ãŒèµ·ãã¦ã„ã‚‹å ´åˆãŒã‚ã‚‹ã€‚IS ã¯ç”Ÿæˆåˆ†å¸ƒ $p_g(y|x)$ ã®é®®æ˜ã•ã¨ $p_g(y)$ ã®å¤šæ§˜æ€§ã‚’æ¸¬ã‚‹ãŒã€$x$ ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒåã£ã¦ã„ã¦ã‚‚é«˜ã„ IS ã‚’ç¤ºã—ã†ã‚‹ã€‚FID ã¨ã®çŸ›ç›¾ãŒã‚ã‚Œã° Precision-Recall ã§è©³ç´°ç¢ºèªã™ã‚‹ã“ã¨ã€‚

</details>

<details><summary>Q2: CMMDã¯FIDã‚’å®Œå…¨ã«ç½®ãæ›ãˆã‚‰ã‚Œã‚‹ã‹ï¼Ÿ</summary>

**A**: å ´åˆã«ã‚ˆã‚‹ã€‚

**CMMDã®åˆ©ç‚¹** [^5]:
- æ­£è¦æ€§ä»®å®šãªã—
- äººé–“è©•ä¾¡ã¨ã®ç›¸é–¢ãŒé«˜ã„ï¼ˆ0.72 vs FID 0.56ï¼‰
- ãƒ†ã‚­ã‚¹ãƒˆæ¡ä»¶ä»˜ãç”Ÿæˆã«å¯¾å¿œ

**FIDã®åˆ©ç‚¹**:
- æ¨™æº–åŒ–ã•ã‚Œã¦ã„ã‚‹ï¼ˆéå»ã®ç ”ç©¶ã¨æ¯”è¼ƒå¯èƒ½ï¼‰
- è¨ˆç®—ã‚³ã‚¹ãƒˆä½ï¼ˆè¡Œåˆ—æ¼”ç®—ã®ã¿ï¼‰
- ãƒ„ãƒ¼ãƒ«ãŒè±Šå¯Œï¼ˆtorch-fidelityç­‰ï¼‰

**æ¨å¥¨**: æ–°è¦ç ”ç©¶ã§ã¯**CMMD + FIDä½µè¨˜**ã€‚FIDã¯æ¯”è¼ƒå¯èƒ½æ€§ã®ãŸã‚ã€CMMDã¯å®Ÿè³ªçš„ãªè©•ä¾¡ã®ãŸã‚ã€‚

**ãªãœäººé–“è©•ä¾¡ã¨ã®ç›¸é–¢ãŒ CMMD > FID ã‹**: FID ã®ã‚¬ã‚¦ã‚¹ä»®å®šãŒå´©ã‚Œã‚‹å¤šæ§˜ãªç”Ÿæˆç‰©ï¼ˆStyle GAN ã®å¤šå³°åˆ†å¸ƒï¼‰ã§ã¯ãƒ•ãƒ¬ã‚·ã‚§è·é›¢ãŒéå¤§è©•ä¾¡ã•ã‚Œã‚‹ã€‚CLAP/CLIP ãƒ™ãƒ¼ã‚¹ã® MMD ã¯éç·šå½¢ã‚«ãƒ¼ãƒãƒ«ã§åˆ†å¸ƒå½¢çŠ¶ã«ä¾å­˜ã—ãªã„ãŸã‚ã€äººé–“ã®ã€Œè‡ªç„¶ã•ã€çŸ¥è¦šã«è¿‘ã„è·é›¢ã‚’è¨ˆç®—ã§ãã‚‹ã€‚

</details>

<details><summary>Q3: ã‚µãƒ³ãƒ—ãƒ«æ•°ã¯ã©ã‚Œãã‚‰ã„å¿…è¦ï¼Ÿ</summary>

**A**: æŒ‡æ¨™ã«ã‚ˆã£ã¦ç•°ãªã‚‹ã€‚

| æŒ‡æ¨™ | æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•° | æ¨å¥¨ã‚µãƒ³ãƒ—ãƒ«æ•° | ç†ç”± |
|:-----|:--------------|:--------------|:-----|
| FID | 2000 | 5000+ | å…±åˆ†æ•£è¡Œåˆ—ã®å®‰å®šæ¨å®šã«å¿…è¦ |
| IS | 1000 | 5000+ | å‘¨è¾ºåˆ†å¸ƒ $p(y)$ ã®æ¨å®š |
| LPIPS | 1ãƒšã‚¢ | N/A | ãƒšã‚¢wiseæ¯”è¼ƒ |
| P&R | 1000 | 5000+ | k-NNå¤šæ§˜ä½“ã®å®‰å®šæ¨å®š |
| CMMD | 500 | 2000+ | MMDã¯FIDã‚ˆã‚Šå°‘ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®š |
| FLD+ | **200** | 1000 | Normalizing Flowã§åŠ¹ç‡çš„ [^7] |

**å°‘ã‚µãƒ³ãƒ—ãƒ«ã®å ´åˆ**: FLD+ [^7] ã‚’ä½¿ç”¨ã€‚

> **âš ï¸ Warning:** FID ã®ã€Œæœ€å°2000ã‚µãƒ³ãƒ—ãƒ«ã€ã¯éå…¬å¼ãªçµŒé¨“å‰‡ã€‚å®Ÿéš›ã«ã¯ç”Ÿæˆåˆ†å¸ƒãŒè¤‡é›‘ï¼ˆå¤šå³°ãƒ»é«˜æ¬¡å…ƒï¼‰ãªã»ã©å¿…è¦ã‚µãƒ³ãƒ—ãƒ«æ•°ã¯å¢—ãˆã‚‹ã€‚StyleGAN2 ã® FFHQï¼ˆé«˜è§£åƒåº¦é¡”ï¼‰ã§ã¯ 5000ã€œ10000 ã‚µãƒ³ãƒ—ãƒ«ã§ã‚‚ä¿¡é ¼åŒºé–“ãŒåºƒã„ã“ã¨ãŒã‚ã‚‹ã€‚å°‘ã‚µãƒ³ãƒ—ãƒ«ã—ã‹ç”Ÿæˆã§ããªã„å ´åˆï¼ˆè¨ˆç®—ã‚³ã‚¹ãƒˆåˆ¶ç´„ï¼‰ã¯å¿…ãš Bootstrap CI ã‚’å ±å‘Šã™ã‚‹ã“ã¨ã€‚

</details>

<details><summary>Q4: åŒ»ç™‚ç”»åƒã‚„ã‚¢ãƒ¼ãƒˆç”»åƒã§FIDã‚’ä½¿ã£ã¦ã„ã„ã‹ï¼Ÿ</summary>

**A**: æ³¨æ„ãŒå¿…è¦ã€‚

**å•é¡Œ**: Inception-v3ã¯ImageNetã§è¨“ç·´ â†’ è‡ªç„¶ç”»åƒãƒã‚¤ã‚¢ã‚¹ã€‚åŒ»ç™‚ç”»åƒï¼ˆXç·šã€MRIï¼‰ã‚„ã‚¢ãƒ¼ãƒˆç”»åƒã§ã¯ä¸é©åˆ‡ã€‚

**è§£æ±ºç­–**:
1. **ãƒ‰ãƒ¡ã‚¤ãƒ³å°‚ç”¨ã®ç‰¹å¾´æŠ½å‡ºå™¨ã‚’ä½¿ã†**: åŒ»ç™‚ãªã‚‰ RadImageNet è¨“ç·´ãƒ¢ãƒ‡ãƒ«ã€ã‚¢ãƒ¼ãƒˆç”»åƒãªã‚‰ CLIP ViT-L/14
2. **FLD+ ã§ãƒ‰ãƒ¡ã‚¤ãƒ³å†è¨“ç·´**: $q_\theta$ ã‚’å¯¾è±¡ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã§å†è¨“ç·´ â†’ ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œã—ãŸå¯†åº¦ãƒ¢ãƒ‡ãƒ«
3. **ã‚«ãƒ¼ãƒãƒ«æŒ‡æ¨™ï¼ˆKID/CMMDï¼‰**: ç‰¹å¾´æŠ½å‡ºå™¨ã‚’å·®ã—æ›¿ãˆã‚‹ã ã‘ã§æµç”¨å¯èƒ½

**æ•°å€¤ä¾‹**: èƒ¸éƒ¨ X ç·šãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ Inception FID = 120ï¼ˆImageNet ãƒã‚¤ã‚¢ã‚¹ã§ highï¼‰ã€RadImageNet FID = 15ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³é©åˆ‡ãªè©•ä¾¡ï¼‰â†’ 8å€ã®å·®ã€‚å ±å‘Šã™ã‚‹éš›ã¯å¿…ãšä½¿ç”¨ç‰¹å¾´æŠ½å‡ºå™¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨ã€‚

</details>

| æ—¥ | å†…å®¹ | æ™‚é–“ | æˆæœç‰© |
|:---|:-----|:-----|:-------|
| 1æ—¥ç›® | Zone 0-2: æŒ‡æ¨™ã‚’è§¦ã‚‹ | 2h | 5æŒ‡æ¨™ã®è¨ˆç®—ã‚³ãƒ¼ãƒ‰ |
| 2-3æ—¥ç›® | Zone 3: æ•°å¼ä¿®è¡Œ | 4h | FID/IS/LPIPS/MMDå®Œå…¨å°å‡º |
| 4æ—¥ç›® | Zone 4: Juliaçµ±è¨ˆåˆ†æ | 3h | ä¿¡é ¼åŒºé–“ãƒ»t-testå®Ÿè£… |
| 5æ—¥ç›® | Zone 4: Rust Criterion | 2h | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ |
| 6æ—¥ç›® | Zone 5: çµ±åˆè©•ä¾¡ | 3h | VAE/GAN/ARæ¯”è¼ƒ |
| 7æ—¥ç›® | Zone 6-7: æœ€æ–°ç ”ç©¶+å¾©ç¿’ | 2h | ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ |

**å­¦ç¿’ã®å„ªå…ˆé †ä½**: 7æ—¥é–“ã¯ç†æƒ³ã€‚æœ€å°é™ã§ 3æ—¥ã§ã‚‚ Zone 3ï¼ˆFID/CMMD æ•°å¼ï¼‰+ Zone 4ï¼ˆBootstrap CI + t-testï¼‰+ å•5 ã® Welch t-test å®Ÿè£…ã¾ã§å®Œèµ°ã™ã‚Œã°ã€è«–æ–‡èª­è§£ã¨è©•ä¾¡è¨­è¨ˆã«ååˆ†ãªåŸºç¤ãŒã§ãã‚‹ã€‚ã€ŒæŒ‡æ¨™ã‚’è¨ˆç®—ã§ãã‚‹ã€ã‹ã‚‰ã€ŒæŒ‡æ¨™ã‚’è¨­è¨ˆã§ãã‚‹ã€ã¸ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚¢ãƒƒãƒ—ãŒæœ¬è¬›ç¾©ã®æ ¸å¿ƒã€‚

### 6.9 æ¬¡å›äºˆå‘Š â€” ç¬¬28å›: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

**ç¬¬27å›ã§è©•ä¾¡åŸºç›¤ã‚’æ§‹ç¯‰ã—ãŸã€‚æ¬¡ã¯ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®åˆ¶å¾¡ â€” ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã§LLMã‚’è‡ªåœ¨ã«æ“ã‚‹ã€‚**

**ç¬¬28å›ã®å†…å®¹**:
- XML + Markdownä½µç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ
- Chain-of-Thought (CoT) ã¨Tree-of-Thought (ToT)
- System Promptè¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³
- Few-shotå­¦ç¿’ã¨In-context Learning
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–
- ğŸ¦€ Rustå®Ÿè£…: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¨ãƒ³ã‚¸ãƒ³

**ç¬¬27å›ã‹ã‚‰ç¬¬28å›ã¸ã®æ¶ã‘æ©‹**: è©•ä¾¡åŸºç›¤ã‚’æŒã¤ã“ã¨ã§ã€Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ”¹å–„ãŒç”Ÿæˆå“è³ªã«ã©ã†å½±éŸ¿ã™ã‚‹ã‹ã€ã‚’å®šé‡è©•ä¾¡ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚ç¬¬28å›ã§ã¯ã€Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆA vs ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆBã€ã®æ¯”è¼ƒã‚’ç¬¬27å›ã§å­¦ã‚“ã  Bootstrap tæ¤œå®šã¨ FID/CMMD ã§è¡Œã†å®Ÿé¨“ãŒç™»å ´ã™ã‚‹ã€‚è©•ä¾¡ãªã—ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ã¯æ„Ÿè¦šè«–ã§ã—ã‹ãªã„ãŒã€è©•ä¾¡ã‚ã‚Šãªã‚‰ç§‘å­¦ã ã€‚

```mermaid
graph LR
    A["ç¬¬27å›<br/>è©•ä¾¡åŸºç›¤"] --> B["ç¬¬28å›<br/>ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"]
    B --> C["ç¬¬29å›<br/>RAG"]
    C --> D["ç¬¬30å›<br/>ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"]
    D --> E["ç¬¬32å›<br/>çµ±åˆPJ"]
    style B fill:#fff3e0
    style E fill:#c8e6c9
```

> **Note:** **é€²æ—: 100% å®Œäº†ï¼ğŸ‰** ç¬¬27å›å®Œäº†ã€‚è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ â€” FID/IS/LPIPS/P&R/CMMD/MMDã®ç†è«–ã¨å®Ÿè£…ã‚’ãƒã‚¹ã‚¿ãƒ¼ã—ãŸã€‚
>
> </details>
>
> ---
>
> ### 6.11 ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„
>
> > **æ•°å€¤ãŒæ”¹å–„ã™ã‚Œã°"è‰¯ã„"ãƒ¢ãƒ‡ãƒ«ã‹ï¼Ÿ**
>
> **å¾“æ¥**: FIDâ†“ + ISâ†‘ = è‰¯ã„ãƒ¢ãƒ‡ãƒ«
>
> **è»¢æ›**:
>
> 1. **å®šé‡æŒ‡æ¨™ã¯å¿…è¦æ¡ä»¶ã€ååˆ†æ¡ä»¶ã§ã¯ãªã„**
>    - FID=5ã§ã‚‚äººé–“ãŒè¦‹ã¦ä¸è‡ªç„¶ãªç”»åƒã¯"æ‚ªã„"ãƒ¢ãƒ‡ãƒ«
>    - äººé–“è©•ä¾¡ã¨å®šé‡æŒ‡æ¨™ã®ä¹–é›¢ã‚’å¸¸ã«æ„è­˜
>
> 2. **æŒ‡æ¨™ã¯ä»®å®šã‚’æŒã¤ â€” ä»®å®šãŒå´©ã‚Œã‚Œã°æŒ‡æ¨™ã‚‚å´©ã‚Œã‚‹**
>    - FIDã®ã‚¬ã‚¦ã‚¹æ€§ä»®å®š â†’ å¤šå³°åˆ†å¸ƒã§å¤±æ•—
>    - ISã®ImageNetåˆ†é¡ä¾å­˜ â†’ ãƒ‰ãƒ¡ã‚¤ãƒ³å¤–ã§ç„¡æ„å‘³
>    - **æŒ‡æ¨™ã®æ•°å¼ã‚’ç†è§£ = ä»®å®šã‚’ç†è§£ = é™ç•Œã‚’çŸ¥ã‚‹**
>
> 3. **è©•ä¾¡ã¯å¤šé¢çš„ â€” ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å¯è¦–åŒ–ã›ã‚ˆ**
>    - Precision-Recallã§å“è³ªvså¤šæ§˜æ€§ã‚’åˆ†é›¢
>    - å˜ä¸€ã‚¹ã‚³ã‚¢ã«é›†ç´„ã™ã‚‹ãªï¼ˆISã®ç½ ï¼‰
>
> **ã‚ãªãŸã¸ã®å•ã„**:
>
> - è«–æ–‡ã®FIDæ”¹å–„ã‚’è¦‹ãŸã¨ãã€ã€Œã‚µãƒ³ãƒ—ãƒ«æ•°ã¯ï¼Ÿã€ã€Œä¿¡é ¼åŒºé–“ã¯ï¼Ÿã€ã€Œäººé–“è©•ä¾¡ã¨ã®ç›¸é–¢ã¯ï¼Ÿã€ã¨å•ãˆã‚‹ã‹ï¼Ÿ
> - è‡ªåˆ†ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹ã¨ãã€è¤‡æ•°æŒ‡æ¨™ã‚’è¦‹ã¦ç·åˆåˆ¤æ–­ã§ãã‚‹ã‹ï¼Ÿ
> - æ–°ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆåŒ»ç™‚ç”»åƒã€éŸ³å£°ï¼‰ã§ã€é©åˆ‡ãªè©•ä¾¡æŒ‡æ¨™ã‚’é¸æŠãƒ»è¨­è¨ˆã§ãã‚‹ã‹ï¼Ÿ
>
> **æ¬¡ã®ä¸€æ­©**: è©•ä¾¡ã¯æ‰‹æ®µã§ã‚ã£ã¦ç›®çš„ã§ã¯ãªã„ã€‚è©•ä¾¡åŸºç›¤ã‚’æ•´ãˆãŸä»Šã€**ä½•ã‚’ä½œã‚‹ã‹**ã«é›†ä¸­ã›ã‚ˆã€‚ç¬¬32å›ã®çµ±åˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã€è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿæˆ¦æŠ•å…¥ã™ã‚‹ã€‚
>
> **æœ¬è³ªçš„ãªå§¿å‹¢**: FID æ”¹å–„ã¯çµæœã§ã‚ã£ã¦ç›®æ¨™ã§ã¯ãªã„ã€‚ã€Œã©ã†ã„ã†éŸ³å£°/ç”»åƒã‚’ç”Ÿæˆã—ãŸã„ã‹ã€ã¨ã„ã†ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹å®šç¾©ãŒå…ˆã«ã‚ã‚Šã€ãã‚Œã«åˆã£ãŸæŒ‡æ¨™ã‚’é¸ã¶ã¹ãã ã€‚FID ã‚’ä¸‹ã’ã‚‹ãŸã‚ã«è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’æ°´å¢—ã—ã™ã‚‹ã€ŒæŒ‡æ¨™ãƒãƒƒã‚­ãƒ³ã‚°ã€ã¯ã€ç¾å®Ÿã®å“è³ªæ”¹å–„ã¨ã¯å…¨ãåˆ¥ç‰©ã€‚è©•ä¾¡æŒ‡æ¨™ã®æ•°å¼ã‚’ç†è§£ã™ã‚‹ã“ã¨ã¯ã€ã“ã†ã—ãŸè½ã¨ã—ç©´ã‚’é¿ã‘ã‚‹ãŸã‚ã®æœ€ä½é™ã®ç´ é¤Šã ã€‚
>
> ### 6.6 è‡ªå‹•è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰
>
> Productionç’°å¢ƒã§ã¯ã€è©•ä¾¡ã‚’**è‡ªå‹•åŒ–ãƒ»ç¶™ç¶šçš„å®Ÿè¡Œ**ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
>
> #### 6.6.1 CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¸ã®çµ±åˆ
>
> **GitHub Actionsä¾‹** (ç–‘ä¼¼YAML):
>
> ```yaml
> name: Model Evaluation Pipeline
>
> on:
>   push:
>     branches: [main]
>     paths: ['models/**', 'data/**']
>
> jobs:
>   evaluate:
>     runs-on: ubuntu-latest
>     steps:
>       - uses: actions/checkout@v3
>
>       - name: Setup Julia
>         uses: julia-actions/setup-julia@v1
>         with:
>           version: '1.10'
>
>       - name: Install dependencies
>         run: |
>           julia --project=. -e 'using Pkg; Pkg.instantiate()'
>
>       - name: Download test dataset
>         run: |
>           wget https://example.com/test_images.tar.gz
>           tar -xzf test_images.tar.gz
>
>       - name: Run evaluation
>         run: |
>           julia --project=. scripts/evaluate.jl \
>             --model models/generator.jld2 \
>             --real-data data/test_real/ \
>             --output results/metrics.json
>
>       - name: Upload results
>         uses: actions/upload-artifact@v3
>         with:
>           name: evaluation-results
>           path: results/
>
>       - name: Quality gate check
>         run: |
>           julia --project=. scripts/check_quality.jl \
>             --metrics results/metrics.json \
>             --fid-threshold 15.0 \
>             --is-threshold 8.0
> ```
>
> **å“è³ªã‚²ãƒ¼ãƒˆ (Quality Gate)**:
>
> ```julia
> # scripts/check_quality.jl
> using JSON
>
> function check_quality_gate(metrics_file::String; fid_threshold=15.0, is_threshold=8.0)
>     metrics = JSON.parsefile(metrics_file)
>
>     checks = Dict(
>         "FID" => metrics["FID"] < fid_threshold,
>         "IS" => metrics["IS"]["mean"] > is_threshold,
>         "Precision" => metrics["Precision"] > 0.65,
>         "Recall" => metrics["Recall"] > 0.55
>     )
>
>     all_pass = all(values(checks))
>
>     for (name, pass) in checks
>         println("$name: $(pass ? "âœ… PASS" : "âŒ FAIL")")
>     end
>
>     if !all_pass
>         println("\nâŒ Quality gate FAILED. Model does not meet minimum criteria.")
>         exit(1)
>     else
>         println("\nâœ… Quality gate PASSED. Model approved for deployment.")
>     end
> end
>
> # Parse command line args
> using ArgParse
> s = ArgParseSettings()
> @add_arg_table! s begin
>     "--metrics"
>         required = true
>     "--fid-threshold"
>         arg_type = Float64
>         default = 15.0
>     "--is-threshold"
>         arg_type = Float64
>         default = 8.0
> end
> args = parse_args(s)
>
> check_quality_gate(args["metrics"];
>     fid_threshold=args["fid-threshold"],
>     is_threshold=args["is-threshold"])
> ```
>
> #### 6.6.2 è©•ä¾¡çµæœã®å¯è¦–åŒ–ã¨ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
>
> **Weights & Biasesçµ±åˆ**:
>
> ```julia
> using WandB
>
> # Initialize W&B run
> wandb = WandB.init(
>     project="gan-evaluation",
>     name="experiment-$(Dates.now())",
>     config=Dict(
>         "model" => "StyleGAN3",
>         "dataset" => "FFHQ",
>         "batch_size" => 64
>     )
> )
>
> # Log metrics
> WandB.log(wandb, Dict(
>     "FID" => fid_score,
>     "IS_mean" => is_mean,
>     "IS_std" => is_std,
>     "Precision" => precision,
>     "Recall" => recall,
>     "LPIPS" => lpips_mean
> ))
>
> # Log images
> real_imgs_grid = @views(real_imgs[1:25]) |> make_grid
> gen_imgs_grid  = @views(gen_imgs[1:25])  |> make_grid
> WandB.log_image(wandb, "real_images", real_imgs_grid)
> WandB.log_image(wandb, "generated_images", gen_imgs_grid)
>
> # Log distribution plots
> hist_real = histogram(extract_features(real_imgs))
> hist_gen = histogram(extract_features(gen_imgs))
> WandB.log_plot(wandb, "feature_distribution", [hist_real, hist_gen])
>
> WandB.finish(wandb)
> ```
>
> **å¯è¦–åŒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ§‹æˆ**:
>
> 1. **æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰**: FID/IS/LPIPS ã®è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®å¤‰åŒ–
> 2. **Precision-Recallæ›²ç·š**: å“è³ªvså¤šæ§˜æ€§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•
> 3. **ã‚µãƒ³ãƒ—ãƒ«ç”»åƒ**: Real vs Generated ã®æ¯”è¼ƒã‚°ãƒªãƒƒãƒ‰
> 4. **ç‰¹å¾´é‡åˆ†å¸ƒ**: Inceptionç‰¹å¾´é‡ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
> 5. **ã‚¢ãƒ©ãƒ¼ãƒˆ**: å“è³ªã‚²ãƒ¼ãƒˆé•åæ™‚ã®é€šçŸ¥
>
> #### 6.6.3 A/Bãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
>
> è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒè©•ä¾¡ã™ã‚‹ä»•çµ„ã¿:
>
> ```julia
> struct ModelVariant
>     name::String
>     generator::Any
>     metrics::Dict{String, Float64}
> end
>
> function ab_test_models(
>     variants::Vector{ModelVariant},
>     real_data::Vector,
>     n_samples::Int=1000,
>     significance_level::Float64=0.05
> )
>     results = Dict(variant.name => begin
>         gen_samples = [variant.generator(randn(100)) for _ in 1:n_samples]
>         fid      = compute_fid(real_data, gen_samples)
>         is_score = compute_is(gen_samples)
>         prec, rec = compute_precision_recall(real_data, gen_samples)
>         Dict("FID" => fid, "IS" => is_score, "Precision" => prec, "Recall" => rec)
>     end for variant in variants)
>
>     # Statistical significance testing
>     # Pairwise comparison using bootstrap
>     comparisons = Dict()
>     for (name1, metrics1) in results
>         for (name2, metrics2) in results
>             if name1 < name2  # avoid duplicate pairs
>                 # Bootstrap test for FID difference
>                 diff = metrics1["FID"] - metrics2["FID"]
>                 ci = bootstrap_ci_difference(
>                     real_data, variants_by_name[name1], variants_by_name[name2],
>                     metric="FID", n_bootstrap=1000, confidence=1-significance_level
>                 )
>
>                 significant = !in_interval(0, ci)  # 0 not in CI => significant
>                 comparisons["$(name1)_vs_$(name2)"] = Dict(
>                     "diff" => diff,
>                     "ci" => ci,
>                     "significant" => significant,
>                     "winner" => diff < 0 ? name1 : name2
>                 )
>             end
>         end
>     end
>
>     return results, comparisons
> end
>
> # Usage
> variants = [
>     ModelVariant("Baseline", generator_v1, Dict()),
>     ModelVariant("StyleGAN2", generator_v2, Dict()),
>     ModelVariant("StyleGAN3", generator_v3, Dict())
> ]
>
> results, comparisons = ab_test_models(variants, real_test_data, 5000)
>
> # Print report
> println("=== A/B Test Results ===")
> for (name, metrics) in results
>     println("\n$name:")
>     for (metric, value) in metrics
>         println("  $metric: $(round(value, digits=3))")
>     end
> end
>
> println("\n=== Statistical Comparisons ===")
> for (pair, comp) in comparisons
>     if comp["significant"]
>         println("âœ… $pair: $(comp["winner"]) wins (p < 0.05)")
>         println("   Difference: $(round(comp["diff"], digits=2)) [$(round.(comp["ci"], digits=2))]")
>     else
>         println("â– $pair: No significant difference")
>     end
> end
> ```
>
> #### 6.6.4 è©•ä¾¡ã‚³ã‚¹ãƒˆã®æœ€é©åŒ–
>
> **èª²é¡Œ**: FIDè¨ˆç®—ã¯é‡ã„ï¼ˆInception forward pass Ã— å…¨ã‚µãƒ³ãƒ—ãƒ«ï¼‰
>
> **å®šé‡åŒ–**: Inception-v3 ã¯ 1æšã® 299Ã—299 ç”»åƒã§ç´„ 5.7 GFLOPsã€‚10,000 ã‚µãƒ³ãƒ—ãƒ«ã§ 57 TFLOPs â†’ A100 (312 TFLOPS) ã§ç´„ 0.2 ç§’ã€‚ãŸã ã— CPU ã§ã¯ 10 GFLOPS â†’ ç´„ 5700 ç§’ï¼ˆ1.5æ™‚é–“ï¼‰ã€‚è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§æœ€ã‚‚æ™‚é–“ãŒã‹ã‹ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ã®ãŸã‚ã€ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã¨æ—©æœŸçµ‚äº†ãŒé‡è¦ã€‚
>
> **è§£æ±ºç­–1: æ—©æœŸçµ‚äº† (Early Stopping)**
>
> ```julia
> function adaptive_fid_estimation(real_features, gen_features;
>                                   initial_samples=500,
>                                   max_samples=10000,
>                                   tolerance=0.5)
>     n_real = size(real_features, 1)
>     n_gen = size(gen_features, 1)
>
>     fid_history = Float64[]
>     n_samples = initial_samples
>
>     while n_samples <= max_samples
>         # Subsample
>         idx_r = randperm(n_real)[1:min(n_samples, n_real)]
>         idx_g = randperm(n_gen)[1:min(n_samples, n_gen)]
>
>         fid = @views compute_fid(real_features[idx_r, :], gen_features[idx_g, :])
>         push!(fid_history, fid)
>
>         # Check convergence
>         if length(fid_history) >= 3
>             recent_std = @views std(fid_history[end-2:end])
>             if recent_std < tolerance
>                 println("Converged at $n_samples samples (std=$recent_std)")
>                 return fid, n_samples
>             end
>         end
>
>         n_samples = min(n_samples * 2, max_samples)
>     end
>
>     return fid_history[end], n_samples
> end
> ```
>
> **è§£æ±ºç­–2: ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°**
>
> ```julia
> # Cache Inception features to avoid recomputation
> struct FeatureCache
>     cache_dir::String
> end
>
> function get_or_compute_features(cache::FeatureCache, images::Vector, key::String)
>     cache_file = joinpath(cache.cache_dir, "$key.jld2")
>     if isfile(cache_file)
>         @info "Loading cached features from $cache_file"
>         load(cache_file, "features")
>     else
>         @info "Computing features for $key"
>         features = extract_inception_features(images)
>         save(cache_file, "features", features)
>         features
>     end
> end
>
> # Usage
> cache = FeatureCache("./feature_cache")
> real_feats = get_or_compute_features(cache, real_images, "real_ffhq_10k")
> gen_feats = extract_inception_features(generated_images)  # Only compute for generated
> fid = compute_fid_from_features(real_feats, gen_feats)
> ```
>
> #### 6.6.5 ãƒãƒ«ãƒGPUä¸¦åˆ—è©•ä¾¡
>
> ```julia
> using Distributed
>
> # Add worker processes
> addprocs(4)  # 4 GPUs
>
> @everywhere using CUDA, Flux
>
> @everywhere function evaluate_batch(model, real_batch, gen_batch, gpu_id)
>     # Assign to specific GPU
>     device = gpu(gpu_id)
>     model_gpu = model |> device
>
>     # Compute metrics on this GPU
>     fid = compute_fid(real_batch, gen_batch)
>     is_score = compute_is(gen_batch)
>
>     return Dict("FID" => fid, "IS" => is_score)
> end
>
> function parallel_evaluation(model, real_data, gen_data, n_gpus=4)
>     # Split data into chunks
>     chunk_size = div(length(real_data), n_gpus)
>     chunks = [(real_data[(i-1)*chunk_size+1:i*chunk_size],
>                gen_data[(i-1)*chunk_size+1:i*chunk_size],
>                i-1)  # GPU ID
>               for i in 1:n_gpus]
>
>     # Parallel computation
>     results = pmap(chunk -> evaluate_batch(model, chunk...), chunks)
>
>     # Aggregate results
>     fid_mean = mean(r["FID"] for r in results)
>     is_mean  = mean(r["IS"]  for r in results)
>
>     return Dict("FID" => fid_mean, "IS" => is_mean)
> end
> ```
>
> **é«˜é€ŸåŒ–çµæœ**:
>
> | æ‰‹æ³• | ã‚µãƒ³ãƒ—ãƒ«æ•° | GPUs | æ™‚é–“ | é«˜é€ŸåŒ– |
> |:-----|:----------|:-----|:-----|:-------|
> | Baseline | 10,000 | 1 | 45åˆ† | 1x |
> | ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚° | 10,000 | 1 | 12åˆ† | 3.75x |
> | æ—©æœŸçµ‚äº† | ~2,000 | 1 | 5åˆ† | 9x |
> | ãƒãƒ«ãƒGPU | 10,000 | 4 | 3åˆ† | 15x |
>
> #### 6.6.6 è©•ä¾¡ã®å†ç¾æ€§ç¢ºä¿
>
> **æ±ºå®šè«–çš„å®Ÿè¡Œ**:
>
> ```julia
> using Random, CUDA
>
> function set_seed_all(seed::Int)
>     Random.seed!(seed)              # Julia RNG
>     CUDA.seed!(seed)                # CUDA RNG
>     ENV["PYTHONHASHSEED"] = string(seed)  # Python (if used via PyCall)
> end
>
> function deterministic_evaluation(generator, real_data; seed=42)
>     set_seed_all(seed)
>
>     # Generate with fixed seed
>     gen_data = [generator(randn(100)) for _ in 1:1000]
>
>     # Compute metrics
>     results = compute_all_metrics(real_data, gen_data)
>
>     # Log seed for reproducibility
>     merge!(results, Dict("seed" => seed, "timestamp" => Dates.now(),
>                          "julia_version" => VERSION, "cuda_version" => CUDA.versioninfo()))
>
>     results
> end
> ```
>
> **ãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼**:
>
> ```julia
> using SHA
>
> function verify_data_integrity(data_path::String, expected_sha256::String)
>     actual_sha256 = open(read, data_path) |> sha256 |> bytes2hex
>     actual_sha256 == expected_sha256 ||
>         error("Data integrity check failed!\nExpected: $expected_sha256\nActual: $actual_sha256")
>     @info "âœ… Data integrity verified"
> end
>
> # Before evaluation
> verify_data_integrity("test_data.jld2", "a1b2c3d4...")
> ```
>
> > **Note:** **é€²æ—: 100% å®Œäº†** ğŸ‰ è¬›ç¾©å®Œèµ°ï¼è‡ªå‹•è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ã€CI/CDçµ±åˆã€A/Bãƒ†ã‚¹ãƒˆã€æœ€é©åŒ–æ‰‹æ³•ã¾ã§å®Œå…¨å®Ÿè£…ã—ãŸã€‚
>
> **Progress: [95%]**
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. FLD+ï¼ˆãƒ•ãƒ­ãƒ¼ãƒ™ãƒ¼ã‚¹å°¤åº¦è·é›¢ï¼‰ãŒFIDã‚ˆã‚Šå°‘ãªã„ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®šã™ã‚‹æ•°å­¦çš„ç†ç”±ã¯ï¼Ÿ
>    - *ãƒ’ãƒ³ãƒˆ*: FIDã¯ $d \times d$ å…±åˆ†æ•£è¡Œåˆ—ï¼ˆ$d=2048$ï¼‰ã‚’æ¨å®šã™ã‚‹ãŒã€FLD+ã¯ä½•æ¬¡å…ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¨å®šã™ã‚‹ã‹ï¼Ÿ
> 2. ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã§FID/IS/LPIPS/CMMDã®4æŒ‡æ¨™ã‚’çµ„ã¿åˆã‚ã›ã‚‹å¿…è¦æ€§ã‚’å„æŒ‡æ¨™ã®é™ç•Œã‹ã‚‰è¿°ã¹ã‚ˆã€‚

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., & Hochreiter, S. (2017). GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium. *NeurIPS 2017*.
<https://arxiv.org/abs/1706.08500>

[^2]: Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., & Chen, X. (2016). Improved Techniques for Training GANs. *NeurIPS 2016*.
<https://arxiv.org/abs/1609.03126>

[^3]: Zhang, R., Isola, P., Efros, A. A., Shechtman, E., & Wang, O. (2018). The Unreasonable Effectiveness of Deep Features as a Perceptual Metric. *CVPR 2018*.
<https://arxiv.org/abs/1801.03924>

[^4]: KynkÃ¤Ã¤nniemi, T., Karras, T., Laine, S., Lehtinen, J., & Aila, T. (2019). Improved Precision and Recall Metric for Assessing Generative Models. *NeurIPS 2019*.
<https://arxiv.org/abs/1904.06991>

[^5]: Jayasumana, S., Ramalingam, S., Veit, A., Glasner, D., Chakrabarti, A., & Kumar, S. (2024). Rethinking FID: Towards a Better Evaluation Metric for Image Generation. *CVPR 2024*.
<https://arxiv.org/abs/2401.09603>

[^6]: Gretton, A., Borgwardt, K. M., Rasch, M. J., SchÃ¶lkopf, B., & Smola, A. (2012). A Kernel Two-Sample Test. *Journal of Machine Learning Research*.
<https://www.jmlr.org/papers/v13/gretton12a.html>

[^7]: Jeevan, P., Nixon, N., & Sethi, A. (2024). FLD+: Data-efficient Evaluation Metric for Generative Models. *arXiv:2411.15584*.
<https://arxiv.org/abs/2411.15584>

[^8]: Pranav, P., et al. (2024). Normalizing Flow-Based Metric for Image Generation. *arXiv:2410.02004*.
<https://arxiv.org/abs/2410.02004>

[^9]: Cheema, G. S., et al. (2023). Unifying and Extending Precision Recall Metrics for Assessing Generative Models. *AISTATS 2023*.
<https://proceedings.mlr.press/v206/cheema23a.html>

### å®Ÿè£…ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

- [torch-fidelity](https://github.com/toshas/torch-fidelity) â€” PyTorch FID/ISå®Ÿè£…
- [lpips](https://github.com/richzhang/PerceptualSimilarity) â€” LPIPSå…¬å¼å®Ÿè£…
- [Criterion.rs](https://github.com/bheisler/criterion.rs) â€” Rustçµ±è¨ˆçš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
- [HypothesisTests.jl](https://github.com/JuliaStats/HypothesisTests.jl) â€” Juliaçµ±è¨ˆæ¤œå®š

**å•5**: Welch's t-testã§2ã¤ã®FIDã‚µãƒ³ãƒ—ãƒ«ã‚’æ¯”è¼ƒã›ã‚ˆã€‚

**å‰æã®ç¢ºèª**: FID sample A = [12.3, 11.8, 12.7, 13.1, 11.5]ï¼ˆn=5ï¼‰ã€FID sample B = [15.2, 14.8, 15.6, 16.0, 14.5]ï¼ˆn=5ï¼‰ã€‚æœŸå¾…ã•ã‚Œã‚‹çµæœ: p < 0.01ï¼ˆæ˜ç¢ºãªå·®ï¼‰, Cohen's d â‰ˆ 3ï¼ˆlarge effectï¼‰ã€‚

<details><summary>è§£ç­”</summary>

```julia
using HypothesisTests

function compare_fid(fid_a::Vector{Float64}, fid_b::Vector{Float64}, Î±::Float64=0.05)
    # Welch's t-test (unequal variances)
    test = UnequalVarianceTTest(fid_a, fid_b)
    p_val = pvalue(test)
    is_sig = p_val < Î±

    # Effect size (Cohen's d)
    Î¼_a, Î¼_b = mean(fid_a), mean(fid_b)
    s_a, s_b = std(fid_a), std(fid_b)
    pooled_std = sqrt((s_a^2 + s_b^2) / 2)
    cohens_d = (Î¼_a - Î¼_b) / pooled_std

    return Dict(
        "p_value" => p_val,
        "significant" => is_sig,
        "cohens_d" => cohens_d
    )
end
```

</details>

#### 7.5.3 å®Ÿè£…ãƒãƒ£ãƒ¬ãƒ³ã‚¸ï¼ˆ2å•ï¼‰

**ãƒãƒ£ãƒ¬ãƒ³ã‚¸1**: è‡ªå‹•è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè£…ã—ã€VAE/GAN/ARã®3ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒã›ã‚ˆã€‚å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: JSONï¼ˆFID/IS/CMMD/Precision/Recallï¼‰

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ä¾‹**:
```json
{
  "VAE": {"FID": 45.2, "IS": 4.1, "CMMD": 0.023, "Precision": 0.71, "Recall": 0.82},
  "GAN": {"FID": 18.7, "IS": 7.3, "CMMD": 0.008, "Precision": 0.88, "Recall": 0.54},
  "AR":  {"FID": 22.1, "IS": 6.9, "CMMD": 0.012, "Precision": 0.85, "Recall": 0.76}
}
```

ã“ã‚Œã‚’è¦‹ã‚Œã°ã€ŒGAN ãŒ FID/CMMD ã§æœ€è‰¯ã ãŒ Recall ã§æœ€æ‚ª â†’ mode collapse ã®å…†å€™ã€ãŒä¸€ç›®ã§ã‚ã‹ã‚‹ã€‚

<details><summary>ãƒ’ãƒ³ãƒˆ</summary>

**æ‰‹é †**:
1. å„ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰1000ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆ
2. Inceptionç‰¹å¾´æŠ½å‡º
3. å„æŒ‡æ¨™ã‚’è¨ˆç®—ï¼ˆFID, IS, CMMD, P&Rï¼‰
4. çµ±è¨ˆæ¤œå®šï¼ˆä¿¡é ¼åŒºé–“ã€t-testï¼‰
5. JSONå‡ºåŠ›

**ã‚³ãƒ¼ãƒ‰éª¨æ ¼**:

```julia
function auto_eval_pipeline(models::Dict{String, Function}, real_data::Vector, n_gen::Int=1000)
    Dict(name => begin
        samples = [gen_fn() for _ in 1:n_gen]
        fid, ci_l, ci_u, _ = fid_with_ci(real_data, samples)
        is_val, _ = inception_score(samples)
        # ... compute other metrics
        Dict("fid" => fid, "fid_ci" => [ci_l, ci_u], ...)
    end for (name, gen_fn) in models)
end
```

</details>

**ãƒãƒ£ãƒ¬ãƒ³ã‚¸2**: Rust Criterionã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè£…ã—ã€FIDè¨ˆç®—ã®æ€§èƒ½å›å¸°ã‚’æ¤œå‡ºã›ã‚ˆã€‚

<details><summary>ãƒ’ãƒ³ãƒˆ</summary>

**Cargo.toml**:

```toml
[dev-dependencies]
criterion = "0.5"
ndarray = "0.16"
ndarray-linalg = "0.19"

[[bench]]
name = "fid_bench"
harness = false
```

**benches/fid_bench.rs**:

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};
use ndarray::{Array1, Array2};

fn benchmark_fid(c: &mut Criterion) {
    let d = 2048;
    let mu1 = Array1::zeros(d);
    let mu2 = Array1::ones(d) * 0.1;
    let sigma1 = Array2::eye(d);
    let sigma2 = Array2::eye(d) * 1.1;

    c.bench_function("fid_2048d", |b| {
        b.iter(|| frechet_distance(
            black_box(&mu1), black_box(&sigma1),
            black_box(&mu2), black_box(&sigma2)
        ).unwrap())
    });
}

criterion_group!(benches, benchmark_fid);
criterion_main!(benches);
```

**å®Ÿè¡Œ**: `cargo bench` â†’ CIçµ±åˆã§è‡ªå‹•å›å¸°æ¤œå‡º

</details>

### 6.6 é€²æ—ãƒˆãƒ©ãƒƒã‚«ãƒ¼ï¼ˆè‡ªå·±è©•ä¾¡ï¼‰

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ** â€” å„é …ç›®ã‚’é”æˆã—ãŸã‚‰ãƒã‚§ãƒƒã‚¯:

```julia
# Progress tracker
checklist = [
    "âœ… Zone 0: FIDã‚’3è¡Œã§è¨ˆç®—ã§ãã‚‹",
    "âœ… Zone 1: 5ã¤ã®æŒ‡æ¨™ï¼ˆFID/IS/LPIPS/P&R/CMMDï¼‰ã‚’è§¦ã£ãŸ",
    "âœ… Zone 2: è©•ä¾¡ã®3ã¤ã®å›°é›£ã‚’ç†è§£ã—ãŸ",
    "âœ… Zone 3: FIDã®æ•°å¼ã‚’å®Œå…¨å°å‡ºã§ãã‚‹",
    "âœ… Zone 3: ISã®KLç™ºæ•£ã‚’å°å‡ºã§ãã‚‹",
    "âœ… Zone 3: LPIPSã®channel-wise normalizationã‚’ç†è§£ã—ãŸ",
    "âœ… Zone 3: Precision-Recallã®å¤šæ§˜ä½“ãƒ™ãƒ¼ã‚¹å®šç¾©ã‚’ç†è§£ã—ãŸ",
    "âœ… Zone 3: MMDã®ã‚«ãƒ¼ãƒãƒ«å±•é–‹ã‚’å°å‡ºã§ãã‚‹",
    "âœ… Zone 3: âš”ï¸ Boss Battle: CMMDè«–æ–‡ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰ã‚’å†å®Ÿè£…ã—ãŸ",
    "âœ… Zone 4: Juliaã§ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—ã§ãã‚‹",
    "âœ… Zone 4: Juliaã§t-testã‚’å®Ÿè¡Œã§ãã‚‹",
    "âœ… Zone 4: Rust Criterionã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè£…ã§ãã‚‹",
    "âœ… Zone 5: VAE/GAN/ARã®çµ±åˆè©•ä¾¡ã‚’å®Ÿè£…ã—ãŸ",
    "âœ… Zone 5: A/Bãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’è¨­è¨ˆã—ãŸ",
    "âœ… Zone 5: MOSã‚’é›†è¨ˆãƒ»åˆ†æã—ãŸ",
    "âœ… Zone 6: CMMD/FLD+ã®æœ€æ–°ç ”ç©¶ã‚’ç†è§£ã—ãŸ",
    "âœ… Zone 7: è‡ªå·±è¨ºæ–­ãƒ†ã‚¹ãƒˆã‚’å…¨å•è§£ã„ãŸ",
    "âœ… Zone 7: å®Ÿè£…ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã‚’å®Œäº†ã—ãŸ",
]

completed = count(x -> startswith(x, "âœ…"), checklist)
total = length(checklist)
progress = round(100 * completed / total, digits=1)

println("Progress: $(completed)/$(total) ($(progress)%)")
if progress == 100.0
    println("ğŸ‰ ç¬¬27å›å®Œå…¨åˆ¶è¦‡ï¼")
end
```

**ç›®æ¨™é”æˆåŸºæº–**:

| ãƒ¬ãƒ™ãƒ« | é”æˆç‡ | åˆ°é”ç‚¹ |
|:-------|:------|:-------|
| **Level 1: ä½¿ãˆã‚‹** | 40% | FID/IS/LPIPSã‚’è¨ˆç®—ã§ãã‚‹ |
| **Level 2: ç†è§£ã—ã¦ã„ã‚‹** | 70% | æ•°å¼ã‚’å®Œå…¨å°å‡ºã§ãã‚‹ |
| **Level 3: è¨­è¨ˆã§ãã‚‹** | 100% | è‡ªå‹•è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã§ãã‚‹ |

**Level 3 ã®æ„ç¾©**: ã€ŒæŒ‡æ¨™ã‚’è¨­è¨ˆã§ãã‚‹ã€ã¨ã¯ã€æ–°ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆåŒ»ç™‚ç”»åƒã€éŸ³å£°ç”Ÿæˆã€ã‚¿ãƒ³ãƒ‘ã‚¯è³ªè¨­è¨ˆï¼‰ã«å¯¾ã—ã¦ã€Œã©ã®ä»®å®šãŒæˆç«‹ã™ã‚‹ã‹ã€ã‚’åˆ¤æ–­ã—ã€ãã‚Œã«é©ã—ãŸè©•ä¾¡æŒ‡æ¨™ã‚’é¸æŠãƒ»ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã‚‹ã“ã¨ã‚’æ„å‘³ã™ã‚‹ã€‚FID ã‚’ä½¿ã† â†’ CMMD ã‚’æ¤œè¨ â†’ FLD+ ã§å°‘ã‚µãƒ³ãƒ—ãƒ«å¯¾å¿œ â†’ å¿…è¦ãªã‚‰ç‹¬è‡ªã‚«ãƒ¼ãƒãƒ«ã‚’è¨­è¨ˆã€ã¨ã„ã†æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ãŒ Level 3 ã®ã‚³ã‚¢ã‚¹ã‚­ãƒ«ã€‚

---

## è‘—è€…ãƒªãƒ³ã‚¯
- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

**ğŸ“ ç¬¬27å›å®Œäº†ï¼æ¬¡å›: ç¬¬28å› ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° â€” LLMåˆ¶å¾¡ã®æŠ€è¡“**