---
title: "ç¬¬27å›: è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨""
slug: "ml-lecture-27-part2"
emoji: "ğŸ“Š"
type: "tech"
topics: ["machinelearning", "evaluation", "julia", "rust", "statistics"]
published: true
---

## ğŸ’» 4. å®Ÿè£…ã‚¾ãƒ¼ãƒ³ï¼ˆ45åˆ†ï¼‰â€” Juliaçµ±è¨ˆåˆ†æ + Rust Criterion

### 4.1 Juliaçµ±è¨ˆåˆ†æçµ±åˆ

ç¬¬24å›ã§å­¦ã‚“ã çµ±è¨ˆæ¤œå®šã‚’è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«çµ±åˆã™ã‚‹ã€‚

#### 4.1.1 FIDã®ä¿¡é ¼åŒºé–“

FIDæ¨å®šé‡ $\widehat{\text{FID}}$ ã¯æœ‰é™ã‚µãƒ³ãƒ—ãƒ«ã§ã®æ¨å®š â†’ ä¸ç¢ºå®Ÿæ€§ãŒã‚ã‚‹ã€‚

**Bootstrapæ³•ã§ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—**:

```julia
# FID confidence interval via bootstrap
using Bootstrap

function fid_with_ci(real_imgs::Vector{Matrix{Float64}},
                      gen_imgs::Vector{Matrix{Float64}},
                      n_bootstrap::Int=1000, confidence::Float64=0.95)
    # Extract features once
    feats_real = extract_inception_features(real_imgs)
    feats_gen = extract_inception_features(gen_imgs)

    # Compute point estimate
    Î¼_r, Î£_r = compute_statistics(feats_real)
    Î¼_g, Î£_g = compute_statistics(feats_gen)
    fid_point = frechet_distance(Î¼_r, Î£_r, Î¼_g, Î£_g)

    # Bootstrap resampling
    n_real = size(feats_real, 1)
    n_gen = size(feats_gen, 1)
    fid_samples = zeros(n_bootstrap)

    for b in 1:n_bootstrap
        # Resample with replacement
        idx_r = rand(1:n_real, n_real)
        idx_g = rand(1:n_gen, n_gen)
        feats_r_boot = feats_real[idx_r, :]
        feats_g_boot = feats_gen[idx_g, :]

        Î¼_r_b, Î£_r_b = compute_statistics(feats_r_boot)
        Î¼_g_b, Î£_g_b = compute_statistics(feats_g_boot)
        fid_samples[b] = frechet_distance(Î¼_r_b, Î£_r_b, Î¼_g_b, Î£_g_b)
    end

    # Confidence interval
    Î± = 1 - confidence
    ci_lower = quantile(fid_samples, Î±/2)
    ci_upper = quantile(fid_samples, 1 - Î±/2)

    return fid_point, ci_lower, ci_upper, fid_samples
end

# Test
real_test = [randn(32, 32) for _ in 1:100]
gen_test = [randn(32, 32) for _ in 1:100]
fid_est, ci_l, ci_u, samples = fid_with_ci(real_test, gen_test, 200, 0.95)
println("FID: $(round(fid_est, digits=2)) [95% CI: $(round(ci_l, digits=2)), $(round(ci_u, digits=2))]")
```

#### 4.1.2 ãƒ¢ãƒ‡ãƒ«é–“æ¯”è¼ƒ â€” æœ‰æ„å·®æ¤œå®š

2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®FIDã‚’æ¯”è¼ƒ â†’ çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ãŒã‚ã‚‹ã‹ï¼Ÿ

**Welch's t-test** (ç¬¬24å›):

```julia
# Welch's t-test for FID comparison
using HypothesisTests

function compare_models_fid(model_a_fid_samples::Vector{Float64},
                             model_b_fid_samples::Vector{Float64}, Î±::Float64=0.05)
    # Welch's t-test (unequal variances)
    test_result = UnequalVarianceTTest(model_a_fid_samples, model_b_fid_samples)

    p_value = pvalue(test_result)
    is_significant = p_value < Î±

    # Effect size (Cohen's d)
    Î¼_a = mean(model_a_fid_samples)
    Î¼_b = mean(model_b_fid_samples)
    s_a = std(model_a_fid_samples)
    s_b = std(model_b_fid_samples)
    pooled_std = sqrt((s_a^2 + s_b^2) / 2)
    cohens_d = (Î¼_a - Î¼_b) / pooled_std

    println("Model A FID: $(round(Î¼_a, digits=2)) Â± $(round(s_a, digits=2))")
    println("Model B FID: $(round(Î¼_b, digits=2)) Â± $(round(s_b, digits=2))")
    println("p-value: $(round(p_value, digits=4))")
    println("Significant? $(is_significant) (Î±=$(Î±))")
    println("Effect size (Cohen's d): $(round(cohens_d, digits=3))")

    return test_result, p_value, cohens_d
end

# Test: simulate FID samples for 2 models
# Model A: FID ~ N(15, 2)
# Model B: FID ~ N(13, 1.5) (better model)
fid_a = 15 .+ 2 .* randn(100)
fid_b = 13 .+ 1.5 .* randn(100)

compare_models_fid(fid_a, fid_b)
```

#### 4.1.3 å¤šé‡æ¯”è¼ƒè£œæ­£ â€” Bonferroni/FDR

è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ï¼ˆNå€‹ï¼‰ã‚’æ¯”è¼ƒ â†’ å¤šé‡æ¤œå®šå•é¡Œï¼ˆç¬¬24å›ï¼‰ã€‚

**Bonferroniè£œæ­£**: $\alpha' = \alpha / N$

```julia
# Multiple model comparison with Bonferroni correction
function compare_multiple_models(fid_samples_list::Vector{Vector{Float64}}, Î±::Float64=0.05)
    n_models = length(fid_samples_list)
    n_comparisons = n_models * (n_models - 1) Ã· 2
    Î±_bonf = Î± / n_comparisons

    println("Comparing $(n_models) models ($(n_comparisons) pairwise tests)")
    println("Bonferroni-corrected Î±: $(round(Î±_bonf, digits=5))")

    results = []
    for i in 1:n_models, j in (i+1):n_models
        test = UnequalVarianceTTest(fid_samples_list[i], fid_samples_list[j])
        p_val = pvalue(test)
        is_sig = p_val < Î±_bonf
        push!(results, (i, j, p_val, is_sig))
        println("Model $i vs $j: p=$(round(p_val, digits=4)), significant=$is_sig")
    end

    return results
end

# Test: 4 models
fid_model1 = 20 .+ 3 .* randn(50)
fid_model2 = 15 .+ 2 .* randn(50)
fid_model3 = 14 .+ 2.5 .* randn(50)
fid_model4 = 13 .+ 1.5 .* randn(50)
fid_list = [fid_model1, fid_model2, fid_model3, fid_model4]

compare_multiple_models(fid_list)
```

### 4.2 Rust Criterion ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

**Criterion.rs** [^criterion] ã¯Rustã®çµ±è¨ˆçš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚

**ç‰¹å¾´**:
- çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå‡ºï¼ˆå›å¸°æ¤œå‡ºï¼‰
- è‡ªå‹• outlier é™¤å»
- CIçµ±åˆå¯èƒ½

#### 4.2.1 Rust FIDå®Ÿè£…ã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

```rust
// Cargo.toml
// [dependencies]
// ndarray = "0.16"
// ndarray-linalg = "0.19"
// [dev-dependencies]
// criterion = "0.5"

use ndarray::{Array1, Array2};
use ndarray_linalg::*;

/// Compute FrÃ©chet distance between two Gaussians
pub fn frechet_distance(
    mu1: &Array1<f64>,
    sigma1: &Array2<f64>,
    mu2: &Array1<f64>,
    sigma2: &Array2<f64>,
) -> f64 {
    // Mean difference term
    let diff = mu1 - mu2;
    let mean_term = diff.dot(&diff);

    // Covariance term: Tr(Î£1 + Î£2 - 2(Î£1 Î£2)^{1/2})
    let product = sigma1.dot(sigma2);

    // Matrix square root via eigen decomposition
    let (eigenvalues, eigenvectors) = product.eigh(UPLO::Lower).unwrap();
    let sqrt_eig = eigenvalues.mapv(|x| x.abs().sqrt());
    let sqrt_product = &eigenvectors * &Array2::from_diag(&sqrt_eig) * &eigenvectors.t();

    let trace_term = sigma1.diag().sum() + sigma2.diag().sum() - 2.0 * sqrt_product.diag().sum();

    mean_term + trace_term
}

#[cfg(test)]
mod benches {
    use super::*;
    use criterion::{black_box, criterion_group, criterion_main, Criterion};
    use ndarray::Array;

    fn benchmark_fid(c: &mut Criterion) {
        let d = 2048;  // Inception feature dim
        let mu1 = Array1::zeros(d);
        let mu2 = Array1::ones(d) * 0.1;
        let sigma1 = Array2::eye(d);
        let sigma2 = Array2::eye(d) * 1.1;

        c.bench_function("fid_2048d", |b| {
            b.iter(|| {
                frechet_distance(
                    black_box(&mu1),
                    black_box(&sigma1),
                    black_box(&mu2),
                    black_box(&sigma2),
                )
            })
        });
    }

    criterion_group!(benches, benchmark_fid);
    criterion_main!(benches);
}
```

**å®Ÿè¡Œ**:

```bash
cargo bench
```

**å‡ºåŠ›ä¾‹**:

```
fid_2048d               time:   [12.234 ms 12.456 ms 12.701 ms]
                        change: [-2.3% +0.5% +3.1%] (p = 0.67 > 0.05)
                        No change in performance detected.
```

Criterionã¯è‡ªå‹•ã§:
- è¤‡æ•°å›å®Ÿè¡Œï¼ˆwarmup + measurementï¼‰
- çµ±è¨ˆé‡è¨ˆç®—ï¼ˆå¹³å‡ã€æ¨™æº–åå·®ã€ä¿¡é ¼åŒºé–“ï¼‰
- å‰å›ã¨ã®æ¯”è¼ƒï¼ˆå›å¸°æ¤œå‡ºï¼‰

#### 4.2.2 è‡ªå‹•ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

**CIçµ±åˆ**: GitHub Actions ã§è‡ªå‹•ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ + å›å¸°ã‚¢ãƒ©ãƒ¼ãƒˆã€‚

```yaml
# .github/workflows/bench.yml
name: Benchmark

on: [push, pull_request]

jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
      - name: Run benchmarks
        run: cargo bench --bench fid_bench
      - name: Upload results
        uses: actions/upload-artifact@v2
        with:
          name: criterion-results
          path: target/criterion/
```

### 4.3 è‡ªå‹•è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­è¨ˆ

**ãƒ•ãƒ­ãƒ¼**:

```mermaid
graph LR
    A[ãƒ¢ãƒ‡ãƒ«è¨“ç·´] --> B[ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜]
    B --> C[ç”»åƒç”Ÿæˆ<br/>n=5000]
    C --> D[ç‰¹å¾´æŠ½å‡º<br/>Inception/CLIP]
    D --> E1[FIDè¨ˆç®—]
    D --> E2[ISè¨ˆç®—]
    D --> E3[LPIPSè¨ˆç®—]
    D --> E4[P&Rè¨ˆç®—]
    D --> E5[CMMDè¨ˆç®—]
    E1 & E2 & E3 & E4 & E5 --> F[çµ±è¨ˆæ¤œå®š<br/>CI+t-test]
    F --> G[ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ<br/>JSON/HTML]
    G --> H[CI Artifact]
    style F fill:#fff3e0
    style G fill:#c8e6c9
```

**å®Ÿè£…** (Julia):

```julia
# Automatic evaluation pipeline
using JSON

struct EvaluationResult
    fid::Float64
    fid_ci::Tuple{Float64, Float64}
    is::Float64
    is_ci::Tuple{Float64, Float64}
    cmmd::Float64
    precision::Float64
    recall::Float64
    timestamp::String
end

function evaluate_model(model_checkpoint::String, real_dataset::Vector{Matrix{Float64}}, n_gen::Int=1000)
    println("Evaluating model: $model_checkpoint")

    # Step 1: Generate images
    println("Generating $(n_gen) images...")
    gen_images = generate_images(model_checkpoint, n_gen)  # placeholder

    # Step 2: Extract features
    println("Extracting features...")
    feats_real = extract_inception_features(real_dataset)
    feats_gen = extract_inception_features(gen_images)

    # Step 3: Compute metrics
    println("Computing FID...")
    fid_val, fid_l, fid_u, _ = fid_with_ci(real_dataset, gen_images, 200, 0.95)

    println("Computing IS...")
    is_val, _ = inception_score(gen_images)
    # Simplified: no bootstrap for IS here

    println("Computing CMMD...")
    cmmd_val, _ = cmmd_paper(real_dataset, gen_images)

    println("Computing Precision-Recall...")
    prec, rec = precision_recall(feats_real, feats_gen, 5)

    # Step 4: Assemble results
    result = EvaluationResult(
        fid_val, (fid_l, fid_u),
        is_val, (0.0, 0.0),  # placeholder CI
        cmmd_val,
        prec, rec,
        string(now())
    )

    # Step 5: Save to JSON
    json_result = Dict(
        "model" => model_checkpoint,
        "fid" => Dict("value" => result.fid, "ci" => result.fid_ci),
        "is" => result.is,
        "cmmd" => result.cmmd,
        "precision" => result.precision,
        "recall" => result.recall,
        "timestamp" => result.timestamp
    )

    output_path = "eval_results_$(split(model_checkpoint, '/')[end]).json"
    open(output_path, "w") do f
        JSON.print(f, json_result, 2)
    end

    println("âœ… Evaluation complete. Results saved to $output_path")
    return result
end

# Placeholder for image generation
function generate_images(checkpoint::String, n::Int)
    # Real impl: load model, sample latents, decode
    return [randn(64, 64) for _ in 1:n]
end

# Test
real_data_test = [randn(64, 64) for _ in 1:500]
eval_result = evaluate_model("model_epoch_100.ckpt", real_data_test, 500)
```

:::message
**é€²æ—: 70% å®Œäº†** å®Ÿè£…ã‚¾ãƒ¼ãƒ³å®Œäº† â€” Juliaçµ±è¨ˆåˆ†æ + Rust Criterion + è‡ªå‹•è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚ã“ã“ã‹ã‚‰å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ã¸ â€” VAE/GAN/GPTçµ±åˆè©•ä¾¡ã€‚
:::

---

## ğŸ”¬ 5. å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” VAE/GAN/GPTçµ±åˆè©•ä¾¡

### 5.1 æ¼”ç¿’: 3ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æ¯”è¼ƒ

**èª²é¡Œ**: VAE, GAN, GPT (autoregressive) ã®3ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ã€æ¯”è¼ƒã›ã‚ˆã€‚

**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: MNIST (ç°¡æ˜“ç‰ˆ)

#### 5.1.1 ãƒ¢ãƒ‡ãƒ«å®Ÿè£…ï¼ˆç°¡ç•¥ç‰ˆï¼‰

```julia
# Simplified VAE/GAN/GPT for evaluation demo
using Flux

# VAE (from ç¬¬10å›)
struct TinyVAE
    encoder::Chain
    decoder::Chain
end

function (vae::TinyVAE)(x::Matrix{Float64})
    # Encode
    z_params = vae.encoder(x)  # (2*latent_dim, batch)
    d = size(z_params, 1) Ã· 2
    Î¼, logÏƒ = z_params[1:d,:], z_params[d+1:end,:]
    z = Î¼ .+ exp.(logÏƒ) .* randn(size(Î¼))

    # Decode
    x_recon = vae.decoder(z)
    return x_recon, Î¼, logÏƒ
end

# GAN (from ç¬¬12å›)
struct TinyGAN
    generator::Chain
    discriminator::Chain
end

function generate_gan(gan::TinyGAN, n::Int, latent_dim::Int=32)
    z = randn(latent_dim, n)
    return gan.generator(z)
end

# Autoregressive (from ç¬¬15å›)
struct TinyAR
    model::Chain
end

function generate_ar(ar::TinyAR, n::Int, seq_len::Int=784)
    # Simplified: generate pixel by pixel
    samples = []
    for _ in 1:n
        x = zeros(seq_len)
        for t in 1:seq_len
            # Predict next pixel
            logits = ar.model(x[1:t])
            x[t] = sample_categorical(softmax(logits))
        end
        push!(samples, reshape(x, 28, 28))
    end
    return samples
end

# Placeholder implementations
vae_model = TinyVAE(Chain(Dense(784, 64), Dense(64, 32)), Chain(Dense(16, 64), Dense(64, 784)))
gan_model = TinyGAN(Chain(Dense(32, 64), Dense(64, 784)), Chain(Dense(784, 64), Dense(64, 1)))
ar_model = TinyAR(Chain(Dense(784, 256), Dense(256, 784)))
```

#### 5.1.2 çµ±åˆè©•ä¾¡

```julia
# Unified evaluation for 3 models
function evaluate_all_models(real_data::Vector{Matrix{Float64}}, n_gen::Int=1000)
    println("ğŸ”¬ Evaluating 3 models: VAE, GAN, AR")

    # Generate samples from each model
    println("Generating VAE samples...")
    vae_samples = [generate_vae(vae_model) for _ in 1:n_gen]  # placeholder

    println("Generating GAN samples...")
    gan_samples = [generate_gan(gan_model, 1, 32)[:,1] |> x -> reshape(x, 28, 28) for _ in 1:n_gen]

    println("Generating AR samples...")
    ar_samples = generate_ar(ar_model, n_gen, 784)

    # Evaluate each model
    models = [("VAE", vae_samples), ("GAN", gan_samples), ("AR", ar_samples)]
    results = Dict()

    for (name, samples) in models
        println("\nğŸ“Š Evaluating $name...")
        fid_val, _, _, _ = fid_with_ci(real_data, samples, 100, 0.95)
        is_val, _ = inception_score(samples)
        cmmd_val, _ = cmmd_paper(real_data, samples)

        feats_real = extract_inception_features(real_data)
        feats_gen = extract_inception_features(samples)
        prec, rec = precision_recall(feats_real, feats_gen, 5)

        results[name] = Dict(
            "FID" => fid_val,
            "IS" => is_val,
            "CMMD" => cmmd_val,
            "Precision" => prec,
            "Recall" => rec
        )
    end

    # Display comparison table
    println("\nğŸ“‹ Comparison Table:")
    println("| Model | FID â†“ | IS â†‘ | CMMD â†“ | Precision â†‘ | Recall â†‘ |")
    println("|:------|:------|:-----|:-------|:------------|:---------|")
    for (name, metrics) in results
        println("| $name | $(round(metrics["FID"], digits=2)) | $(round(metrics["IS"], digits=2)) | " *
                "$(round(metrics["CMMD"], digits=4)) | $(round(metrics["Precision"], digits=3)) | $(round(metrics["Recall"], digits=3)) |")
    end

    return results
end

# Placeholder
function generate_vae(vae::TinyVAE, latent_dim::Int=16)
    z = randn(latent_dim)
    x_gen = vae.decoder(z)
    return reshape(x_gen, 28, 28)
end

# Test with dummy data
mnist_real = [randn(28, 28) for _ in 1:500]
all_results = evaluate_all_models(mnist_real, 500)
```

**æœŸå¾…ã•ã‚Œã‚‹çµæœãƒ‘ã‚¿ãƒ¼ãƒ³**:

| Model | FID â†“ | IS â†‘ | CMMD â†“ | Precision â†‘ | Recall â†‘ | ç‰¹å¾´ |
|:------|:------|:-----|:-------|:------------|:---------|:-----|
| VAE | ä¸­ | ä¸­ | ä¸­ | ä¸­ | **é«˜** | å¤šæ§˜æ€§é«˜ã„ãŒã¼ã‚„ã‘ã‚‹ |
| GAN | **ä½** | **é«˜** | **ä½** | **é«˜** | ä½ | é«˜å“è³ªã ãŒmode collapse |
| AR | ä½-ä¸­ | é«˜ | ä½ | é«˜ | é«˜ | å“è³ªã‚‚å¤šæ§˜æ€§ã‚‚è‰¯ã„ãŒé…ã„ |

### 5.2 äººé–“è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«è¨­è¨ˆ

**å®šé‡è©•ä¾¡ã®é™ç•Œ** â†’ äººé–“è©•ä¾¡ãŒå¿…è¦ã€‚

#### 5.2.1 A/Bãƒ†ã‚¹ãƒˆè¨­è¨ˆ

**è³ªå•**: ã€Œã©ã¡ã‚‰ã®ç”»åƒãŒã‚ˆã‚Šè‡ªç„¶ã§ã™ã‹ï¼Ÿã€

**è¨­è¨ˆ**:
1. ãƒšã‚¢wiseæ¯”è¼ƒï¼ˆ2ç”»åƒã‚’æç¤ºï¼‰
2. ç„¡ä½œç‚ºåŒ–ï¼ˆé †åºã€ãƒšã‚¢é¸æŠï¼‰
3. è©•ä¾¡è€…é–“ä¸€è‡´åº¦ï¼ˆInter-rater reliabilityï¼‰

```julia
# A/B test design
struct ABTest
    pair_id::Int
    img_a::Matrix{Float64}
    img_b::Matrix{Float64}
    model_a::String
    model_b::String
end

function design_ab_test(models::Dict{String, Vector{Matrix{Float64}}}, n_pairs::Int=100)
    # Generate random pairs
    model_names = collect(keys(models))
    tests = ABTest[]

    for i in 1:n_pairs
        # Random 2 models
        m1, m2 = rand(model_names, 2)
        while m1 == m2
            m2 = rand(model_names)
        end

        # Random sample from each
        img1 = rand(models[m1])
        img2 = rand(models[m2])

        # Randomize order
        if rand() < 0.5
            push!(tests, ABTest(i, img1, img2, m1, m2))
        else
            push!(tests, ABTest(i, img2, img1, m2, m1))
        end
    end

    return tests
end

# Export for crowdsourcing
function export_ab_test_csv(tests::Vector{ABTest}, output_path::String)
    open(output_path, "w") do f
        println(f, "pair_id,img_a_path,img_b_path,model_a,model_b")
        for test in tests
            # Save images (placeholder)
            img_a_path = "ab_test_$(test.pair_id)_a.png"
            img_b_path = "ab_test_$(test.pair_id)_b.png"
            println(f, "$(test.pair_id),$img_a_path,$img_b_path,$(test.model_a),$(test.model_b)")
        end
    end
    println("âœ… A/B test CSV exported to $output_path")
end

# Test
models_for_ab = Dict("VAE" => vae_samples, "GAN" => gan_samples, "AR" => ar_samples)  # from 5.1
ab_tests = design_ab_test(models_for_ab, 50)
export_ab_test_csv(ab_tests, "ab_test_design.csv")
```

#### 5.2.2 Mean Opinion Score (MOS)

**è³ªå•**: ã€Œã“ã®ç”»åƒã®å“è³ªã‚’1-5ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€

**è¨­è¨ˆ**:
1. Likert scale (1=æœ€æ‚ª, 5=æœ€é«˜)
2. è¤‡æ•°è©•ä¾¡è€…ï¼ˆâ‰¥3äººï¼‰ã§å¹³å‡
3. ä¿¡é ¼åŒºé–“è¨ˆç®—

```julia
# MOS collection and analysis
struct MOSResult
    image_id::Int
    model::String
    ratings::Vector{Int}  # 1-5 from multiple raters
end

function analyze_mos(results::Vector{MOSResult})
    println("ğŸ“Š MOS Analysis:")
    println("| Model | Mean MOS | Std | 95% CI |")
    println("|:------|:---------|:----|:-------|")

    for model in unique([r.model for r in results])
        model_ratings = vcat([r.ratings for r in results if r.model == model]...)
        Î¼ = mean(model_ratings)
        Ïƒ = std(model_ratings)
        n = length(model_ratings)
        se = Ïƒ / sqrt(n)
        ci_margin = 1.96 * se
        println("| $model | $(round(Î¼, digits=2)) | $(round(Ïƒ, digits=2)) | " *
                "[$(round(Î¼ - ci_margin, digits=2)), $(round(Î¼ + ci_margin, digits=2))] |")
    end
end

# Simulate MOS data
mos_data = [
    MOSResult(1, "VAE", [3, 3, 4, 3, 3]),
    MOSResult(2, "VAE", [3, 4, 3, 3, 4]),
    MOSResult(3, "GAN", [4, 5, 4, 4, 5]),
    MOSResult(4, "GAN", [5, 4, 5, 4, 5]),
    MOSResult(5, "AR", [4, 4, 5, 4, 4]),
    MOSResult(6, "AR", [4, 5, 4, 5, 4]),
]

analyze_mos(mos_data)
```

#### 5.2.3 è©•ä¾¡è€…é–“ä¸€è‡´åº¦ (Inter-rater Reliability)

**Fleiss' Kappa** (ç¬¬24å›) â€” è¤‡æ•°è©•ä¾¡è€…ã®ä¸€è‡´åº¦ã€‚

```julia
# Fleiss' Kappa for inter-rater reliability
using Statistics

function fleiss_kappa(ratings::Matrix{Int})
    # ratings: (n_items, n_raters)
    n_items, n_raters = size(ratings)
    n_categories = maximum(ratings)

    # Proportion of agreement per item
    P_i = zeros(n_items)
    for i in 1:n_items
        counts = [sum(ratings[i,:] .== k) for k in 1:n_categories]
        P_i[i] = (sum(counts.^2) - n_raters) / (n_raters * (n_raters - 1))
    end
    P_bar = mean(P_i)

    # Expected agreement by chance
    p_j = zeros(n_categories)
    for j in 1:n_categories
        p_j[j] = sum(ratings .== j) / (n_items * n_raters)
    end
    P_e = sum(p_j.^2)

    # Kappa
    Îº = (P_bar - P_e) / (1 - P_e)
    return Îº
end

# Test
ratings_test = [
    1 2 1 1;  # item 1: raters gave 1,2,1,1
    2 2 2 2;  # item 2: all agree on 2
    3 3 4 3;  # item 3: mostly 3
]
Îº = fleiss_kappa(ratings_test)
println("Fleiss' Kappa: $(round(Îº, digits=3))")
println("Interpretation: Îº < 0.2 = poor, 0.2-0.4 = fair, 0.4-0.6 = moderate, 0.6-0.8 = substantial, > 0.8 = almost perfect")
```

:::message
**é€²æ—: 85% å®Œäº†** å®Ÿé¨“ã‚¾ãƒ¼ãƒ³å®Œäº† â€” VAE/GAN/ARçµ±åˆè©•ä¾¡ + äººé–“è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã€‚ã“ã“ã‹ã‚‰ç™ºå±•ã‚¾ãƒ¼ãƒ³ã¸ â€” æœ€æ–°ç ”ç©¶å‹•å‘ã€‚
:::

---

## ğŸ“ 6. æŒ¯ã‚Šè¿”ã‚Šã¨ç™ºå±•ã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” ã¾ã¨ã‚ã¨æœ€æ–°ç ”ç©¶å‹•å‘

### 6.1 FLD+ (Flow-based Likelihood Distance)

**è«–æ–‡** [^7]: FLD+: Data-efficient Evaluation Metric for Generative Models (2024)

**å‹•æ©Ÿ**: FIDã¯2000+ã‚µãƒ³ãƒ—ãƒ«å¿…è¦ â†’ å°‘ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®šã™ã‚‹æŒ‡æ¨™ãŒæ¬²ã—ã„ã€‚

**ã‚¢ã‚¤ãƒ‡ã‚¢**: Normalizing Flowã§å¯†åº¦æ¨å®š â†’ å°¤åº¦ãƒ™ãƒ¼ã‚¹ã®è·é›¢ã€‚

**å®šç¾©**:

$$
\text{FLD}(P_r, P_g) = \mathbb{E}_{x \sim P_r}[-\log q_\theta(x)] - \mathbb{E}_{x \sim P_g}[-\log q_\theta(x)]
$$

ã“ã“ã§ $q_\theta$ ã¯Normalizing Flowã§è¨“ç·´ã•ã‚ŒãŸå¯†åº¦ãƒ¢ãƒ‡ãƒ«ï¼ˆçœŸç”»åƒã§è¨“ç·´ï¼‰ã€‚

**åˆ©ç‚¹**:
- 200-500ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®šï¼ˆFIDã¯2000+å¿…è¦ï¼‰
- ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œå¯èƒ½ï¼ˆåŒ»ç™‚ç”»åƒãªã©ã§å†è¨“ç·´ï¼‰
- å˜èª¿æ€§ãŒå¼·ã„ï¼ˆç”»åƒåŠ£åŒ–ã«å¯¾ã—ã¦ï¼‰

### 6.2 è©•ä¾¡æŒ‡æ¨™ã®ç ”ç©¶ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢

**2024-2026ã®ãƒˆãƒ¬ãƒ³ãƒ‰**:

| ç ”ç©¶æ–¹å‘ | ä»£è¡¨è«–æ–‡ | æ¦‚è¦ |
|:---------|:---------|:-----|
| **ä»®å®šãªã—æŒ‡æ¨™** | CMMD [^5], NFM [^8] | MMD/Flowãƒ™ãƒ¼ã‚¹ã€æ­£è¦æ€§ä¸è¦ |
| **å°‘ã‚µãƒ³ãƒ—ãƒ«æŒ‡æ¨™** | FLD+ [^7] | 200ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®š |
| **ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œ** | CMMD-CLIP [^5] | Text-to-Imageç”Ÿæˆå¯¾å¿œ |
| **åˆ†é›¢è©•ä¾¡** | Precision-Recall Cover [^9] | å“è³ªãƒ»å¤šæ§˜æ€§ãƒ»è¢«è¦†ç‡ã‚’åˆ†é›¢ |
| **äººé–“è©•ä¾¡äºˆæ¸¬** | ImageReward, PickScore | äººé–“è©•ä¾¡ã‚’ãƒ¢ãƒ‡ãƒ«åŒ– |

### 6.3 ç”Ÿæˆãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã®ç³»è­œ

```mermaid
graph TD
    A[2014: Inception Score] --> B[2017: FID]
    B --> C[2019: Precision-Recall]
    C --> D[2024: CMMD]
    D --> E[2024: FLD+]

    A2[ä»®å®š: ImageNetåˆ†é¡] -.->|é™ç•Œ| B2[ä»®å®š: ã‚¬ã‚¦ã‚¹æ€§]
    B2 -.->|é™ç•Œ| C2[è¨ˆç®—ã‚³ã‚¹ãƒˆé«˜]
    C2 -.->|é™ç•Œ| D2[ä»®å®šãªã—<br/>CLIPåŸ‹ã‚è¾¼ã¿]
    D2 --> E2[å°‘ã‚µãƒ³ãƒ—ãƒ«<br/>Flowå¯†åº¦]

    style D fill:#c8e6c9
    style E fill:#b3e5fc
```

### 6.4 è©•ä¾¡æŒ‡æ¨™ã®é¸æŠã‚¬ã‚¤ãƒ‰ï¼ˆ2026å¹´ç‰ˆï¼‰

| çŠ¶æ³ | æ¨å¥¨æŒ‡æ¨™ | ç†ç”± |
|:-----|:---------|:-----|
| **æ¨™æº–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆImageNetç­‰ï¼‰** | FID + IS | æ¯”è¼ƒå¯èƒ½æ€§é‡è¦– |
| **æ–°è¦ç ”ç©¶ï¼ˆ2024ä»¥é™ï¼‰** | **CMMD** + FID | FIDã®é™ç•Œã‚’è£œå®Œ [^5] |
| **å°‘ã‚µãƒ³ãƒ—ãƒ«ï¼ˆ<1000ï¼‰** | **FLD+** | 200ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®š [^7] |
| **Text-to-Image** | **CMMD-CLIP** | ãƒ†ã‚­ã‚¹ãƒˆ-ç”»åƒå¯¾å¿œ [^5] |
| **å“è³ªvså¤šæ§˜æ€§åˆ†æ** | **Precision-Recall** | ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å¯è¦–åŒ– [^4] |
| **ãƒšã‚¢wiseæ¯”è¼ƒ** | **LPIPS** | äººé–“çŸ¥è¦šã¨ç›¸é–¢ [^3] |
| **ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ï¼ˆåŒ»ç™‚ç­‰ï¼‰** | FLD+ (å†è¨“ç·´) | ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œ [^7] |
| **äººé–“è©•ä¾¡ä»£æ›¿** | ImageReward / PickScore | äººé–“è©•ä¾¡äºˆæ¸¬ãƒ¢ãƒ‡ãƒ« |

:::message
**é€²æ—: 95% å®Œäº†** ç™ºå±•ã‚¾ãƒ¼ãƒ³å®Œäº† â€” æœ€æ–°ç ”ç©¶å‹•å‘ã€‚ã“ã“ã‹ã‚‰æŒ¯ã‚Šè¿”ã‚Šã‚¾ãƒ¼ãƒ³ã¸ã€‚
:::

---

### 6.6 ã¾ã¨ã‚ â€” 5ã¤ã®è¦ç‚¹

1. **è©•ä¾¡ã¯å¤šé¢çš„**: FID/IS/LPIPS/P&R/CMMD â€” å„æŒ‡æ¨™ã¯ç•°ãªã‚‹å´é¢ã‚’æ¸¬å®šã€‚è¤‡æ•°æŒ‡æ¨™ã‚’çµ„ã¿åˆã‚ã›ã¦ç·åˆåˆ¤æ–­ã€‚

2. **æ•°å¼ã®ç†è§£ãŒæœ¬è³ª**: FID = Wassersteinè·é›¢ã®ã‚¬ã‚¦ã‚¹é–‰å½¢å¼ã€‚IS = KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã®æœŸå¾…å€¤ã€‚CMMD = MMD + CLIPã€‚æ•°å¼ã‚’å°å‡ºã™ã‚Œã°ã€æŒ‡æ¨™ã®ä»®å®šã¨é™ç•ŒãŒè¦‹ãˆã‚‹ã€‚

3. **çµ±è¨ˆæ¤œå®šãŒä¸å¯æ¬ **: FIDã®ç‚¹æ¨å®šã ã‘ã§ã¯ä¸ååˆ†ã€‚ä¿¡é ¼åŒºé–“ãƒ»ä»®èª¬æ¤œå®šãƒ»åŠ¹æœé‡ã§å®Ÿè³ªçš„ãªæ”¹å–„ã‚’åˆ¤æ–­ã€‚

4. **2024å¹´ã®è»¢æ›ç‚¹**: FIDã®é™ç•Œ â†’ CMMD/FLD+ç™»å ´ã€‚æ­£è¦æ€§ä»®å®šã®æ’é™¤ãƒ»å°‘ã‚µãƒ³ãƒ—ãƒ«å¯¾å¿œãƒ»ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œã€‚

5. **è‡ªå‹•åŒ–ãŒéµ**: è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆJuliaçµ±è¨ˆ + Rust Criterionï¼‰ã‚’CIçµ±åˆ â†’ ç¶™ç¶šçš„ãªå“è³ªç›£è¦–ã€‚

### 6.7 FAQ â€” ã‚ˆãã‚ã‚‹è³ªå•

:::details Q1: FIDãŒä½ã„ã®ã«ISãŒé«˜ã„ â€” ã©ã¡ã‚‰ã‚’ä¿¡ã˜ã‚‹ã¹ãï¼Ÿ

**A**: ä¸¡æ–¹ã¨ã‚‚æ­£ã—ã„å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚FIDã¯åˆ†å¸ƒå…¨ä½“ã®è·é›¢ã€ISã¯å“è³ª+å¤šæ§˜æ€§ã®å˜ä¸€ã‚¹ã‚³ã‚¢ã€‚

**ä¾‹**:
- FIDä½ + ISé«˜ â†’ ç†æƒ³çš„ï¼ˆåˆ†å¸ƒä¸€è‡´ + é«˜å“è³ªãƒ»å¤šæ§˜ï¼‰
- FIDä½ + ISä½ â†’ åˆ†å¸ƒã¯è¿‘ã„ãŒã€å“è³ªorå¤šæ§˜æ€§ãŒä½ã„
- FIDé«˜ + ISé«˜ â†’ mode collapseã®å¯èƒ½æ€§ï¼ˆå°‘æ•°ã®é«˜å“è³ªç”»åƒã®ã¿ç”Ÿæˆï¼‰

**å¯¾ç­–**: Precision-Recallã§å“è³ªã¨å¤šæ§˜æ€§ã‚’åˆ†é›¢æ¸¬å®šã€‚

:::

:::details Q2: CMMDã¯FIDã‚’å®Œå…¨ã«ç½®ãæ›ãˆã‚‰ã‚Œã‚‹ã‹ï¼Ÿ

**A**: å ´åˆã«ã‚ˆã‚‹ã€‚

**CMMDã®åˆ©ç‚¹** [^5]:
- æ­£è¦æ€§ä»®å®šãªã—
- äººé–“è©•ä¾¡ã¨ã®ç›¸é–¢ãŒé«˜ã„ï¼ˆ0.72 vs FID 0.56ï¼‰
- ãƒ†ã‚­ã‚¹ãƒˆæ¡ä»¶ä»˜ãç”Ÿæˆã«å¯¾å¿œ

**FIDã®åˆ©ç‚¹**:
- æ¨™æº–åŒ–ã•ã‚Œã¦ã„ã‚‹ï¼ˆéå»ã®ç ”ç©¶ã¨æ¯”è¼ƒå¯èƒ½ï¼‰
- è¨ˆç®—ã‚³ã‚¹ãƒˆä½ï¼ˆè¡Œåˆ—æ¼”ç®—ã®ã¿ï¼‰
- ãƒ„ãƒ¼ãƒ«ãŒè±Šå¯Œï¼ˆtorch-fidelityç­‰ï¼‰

**æ¨å¥¨**: æ–°è¦ç ”ç©¶ã§ã¯**CMMD + FIDä½µè¨˜**ã€‚FIDã¯æ¯”è¼ƒå¯èƒ½æ€§ã®ãŸã‚ã€CMMDã¯å®Ÿè³ªçš„ãªè©•ä¾¡ã®ãŸã‚ã€‚

:::

:::details Q3: ã‚µãƒ³ãƒ—ãƒ«æ•°ã¯ã©ã‚Œãã‚‰ã„å¿…è¦ï¼Ÿ

**A**: æŒ‡æ¨™ã«ã‚ˆã£ã¦ç•°ãªã‚‹ã€‚

| æŒ‡æ¨™ | æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•° | æ¨å¥¨ã‚µãƒ³ãƒ—ãƒ«æ•° | ç†ç”± |
|:-----|:--------------|:--------------|:-----|
| FID | 2000 | 5000+ | å…±åˆ†æ•£è¡Œåˆ—ã®å®‰å®šæ¨å®šã«å¿…è¦ |
| IS | 1000 | 5000+ | å‘¨è¾ºåˆ†å¸ƒ $p(y)$ ã®æ¨å®š |
| LPIPS | 1ãƒšã‚¢ | N/A | ãƒšã‚¢wiseæ¯”è¼ƒ |
| P&R | 1000 | 5000+ | k-NNå¤šæ§˜ä½“ã®å®‰å®šæ¨å®š |
| CMMD | 500 | 2000+ | MMDã¯FIDã‚ˆã‚Šå°‘ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®š |
| FLD+ | **200** | 1000 | Normalizing Flowã§åŠ¹ç‡çš„ [^7] |

**å°‘ã‚µãƒ³ãƒ—ãƒ«ã®å ´åˆ**: FLD+ [^7] ã‚’ä½¿ç”¨ã€‚

:::

:::details Q4: åŒ»ç™‚ç”»åƒã‚„ã‚¢ãƒ¼ãƒˆç”»åƒã§FIDã‚’ä½¿ã£ã¦ã„ã„ã‹ï¼Ÿ

**A**: æ³¨æ„ãŒå¿…è¦ã€‚

**å•é¡Œ**: Inception-v3ã¯ImageNetã§è¨“ç·´ â†’ è‡ªç„¶ç”»åƒãƒã‚¤ã‚¢ã‚¹ã€‚åŒ»ç™‚ç”»åƒï¼ˆXç·šã€MRIï¼‰ã‚„ã‚¢ãƒ¼ãƒˆç”»åƒã§ã¯ä¸é©åˆ‡ã€‚

**å¯¾ç­–**:
1. **ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ã®ç‰¹å¾´æŠ½å‡ºå™¨**: åŒ»ç™‚ç”»åƒã§è¨“ç·´ã—ãŸResNetãªã©
2. **CLIPåŸ‹ã‚è¾¼ã¿ï¼ˆCMMDï¼‰**: ã‚ˆã‚Šæ±ç”¨çš„
3. **FLD+ã§å†è¨“ç·´** [^7]: ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ã®Normalizing Flowã‚’è¨“ç·´

**ç ”ç©¶ä¾‹**: åŒ»ç™‚ç”»åƒGANã®è©•ä¾¡ã§ã¯ã€Inception-v3ã§ã¯ãªãRadImageNetï¼ˆXç·šã§è¨“ç·´ï¼‰ã‚’ä½¿ç”¨ã€‚

:::

:::details Q5: äººé–“è©•ä¾¡ã¨å®šé‡æŒ‡æ¨™ãŒçŸ›ç›¾ã—ãŸã‚‰ã©ã†ã™ã‚‹ï¼Ÿ

**A**: äººé–“è©•ä¾¡ã‚’å„ªå…ˆã€‚

**å®šé‡æŒ‡æ¨™ã®å½¹å‰²**:
- ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆå¤§é‡ã®ãƒ¢ãƒ‡ãƒ«ã‚’çµã‚Šè¾¼ã‚€ï¼‰
- ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºï¼ˆè¨“ç·´ä¸­ã®æ”¹å–„ã‚’ç›£è¦–ï¼‰
- å†ç¾æ€§ï¼ˆäººé–“è©•ä¾¡ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ï¼‰

**æœ€çµ‚åˆ¤æ–­**: äººé–“è©•ä¾¡ï¼ˆA/Bãƒ†ã‚¹ãƒˆã€MOSï¼‰ã€‚

**ãƒãƒ©ãƒ³ã‚¹**: é–‹ç™ºä¸­ã¯å®šé‡æŒ‡æ¨™ã§é«˜é€Ÿã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ â†’ æœ€çµ‚è©•ä¾¡ã§äººé–“è©•ä¾¡ã€‚

:::

### 6.8 å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆ1é€±é–“ï¼‰

| æ—¥ | å†…å®¹ | æ™‚é–“ | æˆæœç‰© |
|:---|:-----|:-----|:-------|
| 1æ—¥ç›® | Zone 0-2: æŒ‡æ¨™ã‚’è§¦ã‚‹ | 2h | 5æŒ‡æ¨™ã®è¨ˆç®—ã‚³ãƒ¼ãƒ‰ |
| 2-3æ—¥ç›® | Zone 3: æ•°å¼ä¿®è¡Œ | 4h | FID/IS/LPIPS/MMDå®Œå…¨å°å‡º |
| 4æ—¥ç›® | Zone 4: Juliaçµ±è¨ˆåˆ†æ | 3h | ä¿¡é ¼åŒºé–“ãƒ»t-testå®Ÿè£… |
| 5æ—¥ç›® | Zone 4: Rust Criterion | 2h | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ |
| 6æ—¥ç›® | Zone 5: çµ±åˆè©•ä¾¡ | 3h | VAE/GAN/ARæ¯”è¼ƒ |
| 7æ—¥ç›® | Zone 6-7: æœ€æ–°ç ”ç©¶+å¾©ç¿’ | 2h | ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ |

### 6.9 æ¬¡å›äºˆå‘Š â€” ç¬¬28å›: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

**ç¬¬27å›ã§è©•ä¾¡åŸºç›¤ã‚’æ§‹ç¯‰ã—ãŸã€‚æ¬¡ã¯ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®åˆ¶å¾¡ â€” ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã§LLMã‚’è‡ªåœ¨ã«æ“ã‚‹ã€‚**

**ç¬¬28å›ã®å†…å®¹**:
- XML + Markdownä½µç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ
- Chain-of-Thought (CoT) ã¨Tree-of-Thought (ToT)
- System Promptè¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³
- Few-shotå­¦ç¿’ã¨In-context Learning
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–
- ğŸ¦€ Rustå®Ÿè£…: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¨ãƒ³ã‚¸ãƒ³

```mermaid
graph LR
    A["ç¬¬27å›<br/>è©•ä¾¡åŸºç›¤"] --> B["ç¬¬28å›<br/>ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"]
    B --> C["ç¬¬29å›<br/>RAG"]
    C --> D["ç¬¬30å›<br/>ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"]
    D --> E["ç¬¬32å›<br/>çµ±åˆPJ"]
    style B fill:#fff3e0
    style E fill:#c8e6c9
```

:::message
**é€²æ—: 100% å®Œäº†ï¼ğŸ‰** ç¬¬27å›å®Œäº†ã€‚è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ â€” FID/IS/LPIPS/P&R/CMMD/MMDã®ç†è«–ã¨å®Ÿè£…ã‚’ãƒã‚¹ã‚¿ãƒ¼ã—ãŸã€‚
:::

---

### 6.11 ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„

> **æ•°å€¤ãŒæ”¹å–„ã™ã‚Œã°"è‰¯ã„"ãƒ¢ãƒ‡ãƒ«ã‹ï¼Ÿ**

**å¾“æ¥**: FIDâ†“ + ISâ†‘ = è‰¯ã„ãƒ¢ãƒ‡ãƒ«

**è»¢æ›**:

1. **å®šé‡æŒ‡æ¨™ã¯å¿…è¦æ¡ä»¶ã€ååˆ†æ¡ä»¶ã§ã¯ãªã„**
   - FID=5ã§ã‚‚äººé–“ãŒè¦‹ã¦ä¸è‡ªç„¶ãªç”»åƒã¯"æ‚ªã„"ãƒ¢ãƒ‡ãƒ«
   - äººé–“è©•ä¾¡ã¨å®šé‡æŒ‡æ¨™ã®ä¹–é›¢ã‚’å¸¸ã«æ„è­˜

2. **æŒ‡æ¨™ã¯ä»®å®šã‚’æŒã¤ â€” ä»®å®šãŒå´©ã‚Œã‚Œã°æŒ‡æ¨™ã‚‚å´©ã‚Œã‚‹**
   - FIDã®ã‚¬ã‚¦ã‚¹æ€§ä»®å®š â†’ å¤šå³°åˆ†å¸ƒã§å¤±æ•—
   - ISã®ImageNetåˆ†é¡ä¾å­˜ â†’ ãƒ‰ãƒ¡ã‚¤ãƒ³å¤–ã§ç„¡æ„å‘³
   - **æŒ‡æ¨™ã®æ•°å¼ã‚’ç†è§£ = ä»®å®šã‚’ç†è§£ = é™ç•Œã‚’çŸ¥ã‚‹**

3. **è©•ä¾¡ã¯å¤šé¢çš„ â€” ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å¯è¦–åŒ–ã›ã‚ˆ**
   - Precision-Recallã§å“è³ªvså¤šæ§˜æ€§ã‚’åˆ†é›¢
   - å˜ä¸€ã‚¹ã‚³ã‚¢ã«é›†ç´„ã™ã‚‹ãªï¼ˆISã®ç½ ï¼‰

**ã‚ãªãŸã¸ã®å•ã„**:

- è«–æ–‡ã®FIDæ”¹å–„ã‚’è¦‹ãŸã¨ãã€ã€Œã‚µãƒ³ãƒ—ãƒ«æ•°ã¯ï¼Ÿã€ã€Œä¿¡é ¼åŒºé–“ã¯ï¼Ÿã€ã€Œäººé–“è©•ä¾¡ã¨ã®ç›¸é–¢ã¯ï¼Ÿã€ã¨å•ãˆã‚‹ã‹ï¼Ÿ
- è‡ªåˆ†ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹ã¨ãã€è¤‡æ•°æŒ‡æ¨™ã‚’è¦‹ã¦ç·åˆåˆ¤æ–­ã§ãã‚‹ã‹ï¼Ÿ
- æ–°ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆåŒ»ç™‚ç”»åƒã€éŸ³å£°ï¼‰ã§ã€é©åˆ‡ãªè©•ä¾¡æŒ‡æ¨™ã‚’é¸æŠãƒ»è¨­è¨ˆã§ãã‚‹ã‹ï¼Ÿ

**æ¬¡ã®ä¸€æ­©**: è©•ä¾¡ã¯æ‰‹æ®µã§ã‚ã£ã¦ç›®çš„ã§ã¯ãªã„ã€‚è©•ä¾¡åŸºç›¤ã‚’æ•´ãˆãŸä»Šã€**ä½•ã‚’ä½œã‚‹ã‹**ã«é›†ä¸­ã›ã‚ˆã€‚ç¬¬32å›ã®çµ±åˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã€è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿæˆ¦æŠ•å…¥ã™ã‚‹ã€‚

:::message
**é€²æ—: 100% å®Œäº†** ğŸ‰ è¬›ç¾©å®Œèµ°ï¼
:::

---

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., & Hochreiter, S. (2017). GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium. *NeurIPS 2017*.
@[card](https://arxiv.org/abs/1706.08500)

[^2]: Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., & Chen, X. (2016). Improved Techniques for Training GANs. *NeurIPS 2016*.
@[card](https://arxiv.org/abs/1609.03126)

[^3]: Zhang, R., Isola, P., Efros, A. A., Shechtman, E., & Wang, O. (2018). The Unreasonable Effectiveness of Deep Features as a Perceptual Metric. *CVPR 2018*.
@[card](https://arxiv.org/abs/1801.03924)

[^4]: KynkÃ¤Ã¤nniemi, T., Karras, T., Laine, S., Lehtinen, J., & Aila, T. (2019). Improved Precision and Recall Metric for Assessing Generative Models. *NeurIPS 2019*.
@[card](https://arxiv.org/abs/1904.06991)

[^5]: Jayasumana, S., Ramalingam, S., Veit, A., Glasner, D., Chakrabarti, A., & Kumar, S. (2024). Rethinking FID: Towards a Better Evaluation Metric for Image Generation. *CVPR 2024*.
@[card](https://arxiv.org/abs/2401.09603)

[^6]: Gretton, A., Borgwardt, K. M., Rasch, M. J., SchÃ¶lkopf, B., & Smola, A. (2012). A Kernel Two-Sample Test. *Journal of Machine Learning Research*.
@[card](https://www.jmlr.org/papers/v13/gretton12a.html)

[^7]: Pranav, P., et al. (2024). FLD+: Data-efficient Evaluation Metric for Generative Models. *arXiv:2411.15584*.
@[card](https://arxiv.org/abs/2411.15584)

[^8]: Pranav, P., et al. (2024). Normalizing Flow-Based Metric for Image Generation. *arXiv:2410.02004*.
@[card](https://arxiv.org/abs/2410.02004)

[^9]: Cheema, G. S., et al. (2023). Unifying and Extending Precision Recall Metrics for Assessing Generative Models. *AISTATS 2023*.
@[card](https://proceedings.mlr.press/v206/cheema23a.html)

### å®Ÿè£…ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

- [torch-fidelity](https://github.com/toshas/torch-fidelity) â€” PyTorch FID/ISå®Ÿè£…
- [lpips](https://github.com/richzhang/PerceptualSimilarity) â€” LPIPSå…¬å¼å®Ÿè£…
- [Criterion.rs](https://github.com/bheisler/criterion.rs) â€” Rustçµ±è¨ˆçš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
- [HypothesisTests.jl](https://github.com/JuliaStats/HypothesisTests.jl) â€” Juliaçµ±è¨ˆæ¤œå®š

### æ•™ç§‘æ›¸

- Murphy, K. P. (2022). *Probabilistic Machine Learning: Advanced Topics*. MIT Press. [Chapter 20: Evaluation of Generative Models]
- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press. [Chapter 20: Deep Generative Models]

---

## è¨˜æ³•è¦ç´„

| è¨˜æ³• | æ„å‘³ | ä½¿ç”¨ä¾‹ |
|:-----|:-----|:-------|
| $P_r, P_g$ | çœŸç”»åƒã®åˆ†å¸ƒã€ç”Ÿæˆç”»åƒã®åˆ†å¸ƒ | $\text{FID}(P_r, P_g)$ |
| $\mu, \Sigma$ | å¹³å‡ãƒ™ã‚¯ãƒˆãƒ«ã€å…±åˆ†æ•£è¡Œåˆ— | $\mathcal{N}(\mu, \Sigma)$ |
| $\text{Tr}(A)$ | è¡Œåˆ— $A$ ã®ãƒˆãƒ¬ãƒ¼ã‚¹ | $\text{Tr}(\Sigma)$ |
| $\|\cdot\|_2$ | L2ãƒãƒ«ãƒ  | $\|\mu_r - \mu_g\|_2^2$ |
| $\text{KL}(P \| Q)$ | KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ | $\text{KL}(p(y|x) \| p(y))$ |
| $\mathbb{E}_{x \sim P}[\cdot]$ | åˆ†å¸ƒ $P$ ã«é–¢ã™ã‚‹æœŸå¾…å€¤ | $\mathbb{E}_{x \sim p_g}[f(x)]$ |
| $k(x, y)$ | ã‚«ãƒ¼ãƒãƒ«é–¢æ•° | $k(x, y) = \exp(-\|x - y\|^2 / 2\sigma^2)$ |
| $\mathcal{H}$ | å†ç”Ÿæ ¸ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆç©ºé–“ (RKHS) | $\mu_P \in \mathcal{H}$ |
| $\text{MMD}(P, Q)$ | Maximum Mean Discrepancy | $\text{MMD}^2(P, Q) = \|\mu_P - \mu_Q\|_{\mathcal{H}}^2$ |
| $p(y|x)$ | æ¡ä»¶ä»˜ãåˆ†å¸ƒï¼ˆInceptionåˆ†é¡ï¼‰ | Inception Scoreå®šç¾© |
| $W_2(P, Q)$ | 2-Wassersteinè·é›¢ | FIDã®ç†è«–çš„åŸºç›¤ |
| $\sigma$ | ã‚«ãƒ¼ãƒãƒ«å¸¯åŸŸå¹…ï¼ˆRBFï¼‰ | Median heuristic |
| $\alpha$ | æœ‰æ„æ°´æº– | Bonferroniè£œæ­£ $\alpha' = \alpha / N$ |

---

### 6.10 è‡ªå·±è¨ºæ–­ãƒ†ã‚¹ãƒˆ

#### 7.5.1 æ•°å¼èª­è§£ãƒ†ã‚¹ãƒˆï¼ˆ10å•ï¼‰

**å•1**: FIDã®å¼ $\text{FID} = \|\mu_r - \mu_g\|^2 + \text{Tr}(\Sigma_r + \Sigma_g - 2(\Sigma_r\Sigma_g)^{1/2})$ ã§ã€ç¬¬1é … $\|\mu_r - \mu_g\|^2$ ã¯ä½•ã‚’æ¸¬å®šã—ã¦ã„ã‚‹ã‹ï¼Ÿ

:::details è§£ç­”
**ç­”ãˆ**: 2ã¤ã®åˆ†å¸ƒã®å¹³å‡ãƒ™ã‚¯ãƒˆãƒ«é–“ã®ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã®äºŒä¹—ã€‚åˆ†å¸ƒã®ä¸­å¿ƒãŒã©ã‚Œã ã‘ãšã‚Œã¦ã„ã‚‹ã‹ã‚’æ¸¬å®šã€‚

**è©³ç´°**: ã‚¬ã‚¦ã‚¹åˆ†å¸ƒ $\mathcal{N}(\mu_r, \Sigma_r)$ ã¨ $\mathcal{N}(\mu_g, \Sigma_g)$ ã®å¹³å‡ãƒ™ã‚¯ãƒˆãƒ« $\mu_r, \mu_g \in \mathbb{R}^d$ ã®è·é›¢ã€‚$\mu_r = \mu_g$ ãªã‚‰ç¬¬1é … = 0ã€‚
:::

**å•2**: ISã®å¼ $\text{IS} = \exp(\mathbb{E}_{x}[\text{KL}(p(y|x) \| p(y))])$ ã§ã€$p(y|x)$ ã¨ $p(y)$ ã®é•ã„ã¯ï¼Ÿ

:::details è§£ç­”
**ç­”ãˆ**:
- $p(y|x)$: ç”»åƒ $x$ ã«å¯¾ã™ã‚‹Inception-v3ã®æ¡ä»¶ä»˜ãäºˆæ¸¬åˆ†å¸ƒï¼ˆsoftmax outputï¼‰
- $p(y) = \mathbb{E}_x[p(y|x)]$: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã§ã®äºˆæ¸¬åˆ†å¸ƒã®å¹³å‡ï¼ˆå‘¨è¾ºåˆ†å¸ƒï¼‰

**ç›´æ„Ÿ**: $p(y|x)$ ãŒã‚·ãƒ£ãƒ¼ãƒ—ï¼ˆé«˜confidenceï¼‰ã‹ã¤ $p(y)$ ãŒå‡ä¸€ï¼ˆå¤šæ§˜ãªã‚¯ãƒ©ã‚¹ï¼‰ãªã‚‰ IS ãŒé«˜ã„ã€‚
:::

**å•3**: MMDã®å±•é–‹å¼ $\text{MMD}^2 = \mathbb{E}_{x,x'}[k(x,x')] + \mathbb{E}_{y,y'}[k(y,y')] - 2\mathbb{E}_{x,y}[k(x,y)]$ ã§ã€å„é …ã®æ„å‘³ã¯ï¼Ÿ

:::details è§£ç­”
**ç­”ãˆ**:
- ç¬¬1é … $\mathbb{E}_{x,x' \sim P}[k(x,x')]$: çœŸç”»åƒåˆ†å¸ƒå†…ã®ã‚«ãƒ¼ãƒãƒ«é¡ä¼¼åº¦ã®æœŸå¾…å€¤
- ç¬¬2é … $\mathbb{E}_{y,y' \sim Q}[k(y,y')]$: ç”Ÿæˆç”»åƒåˆ†å¸ƒå†…ã®ã‚«ãƒ¼ãƒãƒ«é¡ä¼¼åº¦ã®æœŸå¾…å€¤
- ç¬¬3é … $-2\mathbb{E}_{x \sim P, y \sim Q}[k(x,y)]$: 2ã¤ã®åˆ†å¸ƒé–“ã®ã‚«ãƒ¼ãƒãƒ«é¡ä¼¼åº¦ã®æœŸå¾…å€¤ï¼ˆè² ï¼‰

**ç›´æ„Ÿ**: åˆ†å¸ƒå†…é¡ä¼¼åº¦ã®å’Œ - åˆ†å¸ƒé–“é¡ä¼¼åº¦ Ã— 2 = åˆ†å¸ƒé–“è·é›¢ã€‚
:::

**å•4**: LPIPSã®å¼ $d = \sum_\ell w_\ell \frac{1}{H_\ell W_\ell}\sum_{h,w}\|f_\ell(x) - f_\ell(x_0)\|^2$ ã§ã€$\ell$ ã¯ä½•ã‚’è¡¨ã™ã‹ï¼Ÿ

:::details è§£ç­”
**ç­”ãˆ**: VGG/AlexNetã®å±¤ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€‚è¤‡æ•°ã®å±¤ï¼ˆæµ…ã„å±¤ + æ·±ã„å±¤ï¼‰ã®ç‰¹å¾´ã‚’ä½¿ã†ã€‚

**ç†ç”±**: æµ…ã„å±¤ = edge, texture / æ·±ã„å±¤ = semantic contentã€‚ä¸¡æ–¹ã®æƒ…å ±ã‚’çµ±åˆã™ã‚‹ã“ã¨ã§äººé–“ã®çŸ¥è¦šã«è¿‘ã„è·é›¢ã‚’æ¸¬å®šã€‚
:::

**å•5**: Precision-Recallã§ã€Precision = 1.0, Recall = 0.3 ã®æ„å‘³ã¯ï¼Ÿ

:::details è§£ç­”
**ç­”ãˆ**:
- Precision = 1.0: ç”Ÿæˆç”»åƒã¯å…¨ã¦çœŸç”»åƒã®å¤šæ§˜ä½“ã«å«ã¾ã‚Œã‚‹ â†’ **é«˜å“è³ª**
- Recall = 0.3: çœŸç”»åƒã®30%ã—ã‹ç”Ÿæˆç”»åƒã®å¤šæ§˜ä½“ã«ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ãªã„ â†’ **ä½å¤šæ§˜æ€§ï¼ˆmode collapseï¼‰**

**å…¸å‹ä¾‹**: GANãŒå°‘æ•°ã®ãƒ¢ãƒ¼ãƒ‰ã«é›†ä¸­ã—ã¦é«˜å“è³ªç”»åƒã‚’ç”Ÿæˆã™ã‚‹ãŒã€å…¨ä½“ã®åˆ†å¸ƒã‚’ã‚«ãƒãƒ¼ã—ã¦ã„ãªã„ã€‚
:::

**å•6**: FIDã§ã‚¬ã‚¦ã‚¹æ€§ã®ä»®å®šãŒå´©ã‚Œã‚‹ã¨ã©ã†ãªã‚‹ã‹ï¼Ÿ

:::details è§£ç­”
**ç­”ãˆ**: å¤šå³°åˆ†å¸ƒã‚’å˜ä¸€ã‚¬ã‚¦ã‚¹ã§è¿‘ä¼¼ â†’ æƒ…å ±æå¤± â†’ FIDãŒå®Ÿéš›ã®åˆ†å¸ƒè·é›¢ã‚’æ­£ã—ãåæ˜ ã—ãªã„ã€‚

**ä¾‹**: 2ã¤ã®ãƒ¢ãƒ¼ãƒ‰ã‚’æŒã¤åˆ†å¸ƒï¼ˆçŒ«ã¨çŠ¬ã®2ã‚¯ãƒ©ã‚¹ï¼‰ã‚’å˜ä¸€ã‚¬ã‚¦ã‚¹ã§è¿‘ä¼¼ã™ã‚‹ã¨ã€ãƒ¢ãƒ¼ãƒ‰é–“ã®è·é›¢æƒ…å ±ãŒå¤±ã‚ã‚Œã‚‹ã€‚

**å¯¾ç­–**: CMMDï¼ˆMMDãƒ™ãƒ¼ã‚¹ã€ä»®å®šãªã—ï¼‰ã‚’ä½¿ç”¨ [^5]ã€‚
:::

**å•7**: CMMDãŒFIDã‚ˆã‚Šäººé–“è©•ä¾¡ã¨ç›¸é–¢ãŒé«˜ã„ç†ç”±ã¯ï¼Ÿ

:::details è§£ç­”
**ç­”ãˆ** [^5]:
1. **æ­£è¦æ€§ä»®å®šãªã—**: MMDã¯åˆ†å¸ƒã®å½¢çŠ¶ã«åˆ¶ç´„ãŒãªã„
2. **CLIPåŸ‹ã‚è¾¼ã¿**: Vision-Languageäº‹å‰è¨“ç·´ â†’ ã‚ˆã‚Šæ±ç”¨çš„ãªç‰¹å¾´ç©ºé–“
3. **ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œ**: Text-to-Imageç”Ÿæˆã§ã€ãƒ†ã‚­ã‚¹ãƒˆã¨ã®æ•´åˆæ€§ã‚‚è©•ä¾¡å¯èƒ½

**å®Ÿé¨“çµæœ**: Pearsonç›¸é–¢ â€” CMMD: 0.72 vs FID: 0.56 [^5]
:::

**å•8**: Bootstrapã§ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—ã™ã‚‹æ‰‹é †ã¯ï¼Ÿ

:::details è§£ç­”
**æ‰‹é †**:
1. å…ƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰**å¾©å…ƒæŠ½å‡º**ã§ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã¯å…ƒã¨åŒã˜ï¼‰
2. ãƒªã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§çµ±è¨ˆé‡ï¼ˆFIDãªã©ï¼‰ã‚’è¨ˆç®—
3. æ‰‹é †1-2ã‚’Bå›ç¹°ã‚Šè¿”ã—ï¼ˆä¾‹: B=1000ï¼‰
4. Bå€‹ã®çµ±è¨ˆé‡ã®åˆ†å¸ƒã‹ã‚‰ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—ï¼ˆä¾‹: 95%CI = 2.5percentile, 97.5percentileï¼‰

**æ•°å¼**: $\text{CI}_{95\%} = [\text{quantile}_{0.025}(\hat{\theta}^*), \text{quantile}_{0.975}(\hat{\theta}^*)]$
:::

**å•9**: Bonferroniè£œæ­£ã§ã€4ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒã™ã‚‹å ´åˆã®è£œæ­£å¾Œã®æœ‰æ„æ°´æº–ã¯ï¼Ÿï¼ˆå…ƒã® $\alpha = 0.05$ï¼‰

:::details è§£ç­”
**ç­”ãˆ**: $\alpha' = \alpha / N_{\text{comp}}$ where $N_{\text{comp}} = \binom{4}{2} = 6$ (ãƒšã‚¢wiseæ¯”è¼ƒæ•°)

$$
\alpha' = 0.05 / 6 \approx 0.0083
$$

**ç†ç”±**: å¤šé‡æ¤œå®šã§ç¬¬1ç¨®éèª¤ï¼ˆå½é™½æ€§ï¼‰ã‚’åˆ¶å¾¡ã™ã‚‹ãŸã‚ã€å„æ¤œå®šã®æœ‰æ„æ°´æº–ã‚’å³ã—ãã™ã‚‹ã€‚
:::

**å•10**: FLD+ãŒFIDã‚ˆã‚Šå°‘ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®šã™ã‚‹ç†ç”±ã¯ï¼Ÿ

:::details è§£ç­”
**ç­”ãˆ** [^7]:
- **FID**: å…±åˆ†æ•£è¡Œåˆ— $\Sigma \in \mathbb{R}^{d \times d}$ ã®æ¨å®šã« $O(d^2)$ ã‚µãƒ³ãƒ—ãƒ«å¿…è¦ï¼ˆd=2048 â†’ ç†è«–ä¸Š4Mï¼‰
- **FLD+**: Normalizing Flowã§å¯†åº¦ $q_\theta(x)$ ã‚’æ¨å®š â†’ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’åœ§ç¸® â†’ 200-500ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®š

**ä»•çµ„ã¿**: Flowã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§å¯†åº¦ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ â†’ å°‘ã‚µãƒ³ãƒ—ãƒ«ã§ã‚‚å°¤åº¦ãƒ™ãƒ¼ã‚¹ã®è·é›¢ãŒå®‰å®šã€‚
:::

#### 7.5.2 ã‚³ãƒ¼ãƒ‰ç¿»è¨³ãƒ†ã‚¹ãƒˆï¼ˆ5å•ï¼‰

**å•1**: ä»¥ä¸‹ã®æ•°å¼ã‚’Juliaã‚³ãƒ¼ãƒ‰ã«ç¿»è¨³ã›ã‚ˆã€‚

$$
\text{FID} = \|\mu_r - \mu_g\|_2^2 + \text{Tr}(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1/2})
$$

:::details è§£ç­”

```julia
using LinearAlgebra

function fid(Î¼_r::Vector{Float64}, Î£_r::Matrix{Float64},
             Î¼_g::Vector{Float64}, Î£_g::Matrix{Float64})
    # Mean difference term
    diff = Î¼_r .- Î¼_g
    mean_term = sum(diff.^2)  # ||Î¼_r - Î¼_g||Â²

    # Covariance term: Tr(Î£_r + Î£_g - 2(Î£_r Î£_g)^{1/2})
    prod = Î£_r * Î£_g
    eig = eigen(prod)
    sqrt_eig = sqrt.(abs.(eig.values))
    sqrt_prod = eig.vectors * Diagonal(sqrt_eig) * eig.vectors'

    trace_term = tr(Î£_r) + tr(Î£_g) - 2*tr(sqrt_prod)

    return mean_term + trace_term
end
```
:::

**å•2**: ä»¥ä¸‹ã®Inception Scoreè¨ˆç®—ã‚’ã‚³ãƒ¼ãƒ‰ã§å®Ÿè£…ã›ã‚ˆã€‚

$$
\text{IS} = \exp\left(\mathbb{E}_{x}[\text{KL}(p(y|x) \| p(y))]\right)
$$

:::details è§£ç­”

```julia
function inception_score(p_yx::Matrix{Float64})
    # p_yx: (n_samples, n_classes)
    # p(y) = E_x[p(y|x)]
    p_y = vec(mean(p_yx, dims=1))

    # KL(p(y|x) || p(y)) for each sample
    n_samples = size(p_yx, 1)
    kl_divs = zeros(n_samples)
    for i in 1:n_samples
        for j in 1:length(p_y)
            if p_yx[i,j] > 1e-10 && p_y[j] > 1e-10
                kl_divs[i] += p_yx[i,j] * log(p_yx[i,j] / p_y[j])
            end
        end
    end

    # IS = exp(E[KL])
    return exp(mean(kl_divs))
end
```
:::

**å•3**: RBFã‚«ãƒ¼ãƒãƒ« $k(x,y) = \exp(-\|x-y\|^2/(2\sigma^2))$ ã‚’å®Ÿè£…ã›ã‚ˆã€‚

:::details è§£ç­”

```julia
function rbf_kernel(x::Vector{Float64}, y::Vector{Float64}, Ïƒ::Float64=1.0)
    # k(x, y) = exp(-||x - y||Â² / (2ÏƒÂ²))
    dist_sq = sum((x .- y).^2)
    return exp(-dist_sq / (2 * Ïƒ^2))
end
```
:::

**å•4**: Bootstrapã§95%ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ã‚’å®Ÿè£…ã›ã‚ˆã€‚

:::details è§£ç­”

```julia
using Statistics

function bootstrap_ci(data::Vector{Float64}, statistic::Function,
                       n_boot::Int=1000, confidence::Float64=0.95)
    n = length(data)
    boot_stats = zeros(n_boot)

    for b in 1:n_boot
        # Resample with replacement
        boot_sample = data[rand(1:n, n)]
        boot_stats[b] = statistic(boot_sample)
    end

    # Confidence interval
    Î± = 1 - confidence
    ci_lower = quantile(boot_stats, Î±/2)
    ci_upper = quantile(boot_stats, 1 - Î±/2)

    return ci_lower, ci_upper
end

# Example usage
# data = randn(100)
# ci_l, ci_u = bootstrap_ci(data, mean, 1000, 0.95)
```
:::

**å•5**: Welch's t-testã§2ã¤ã®FIDã‚µãƒ³ãƒ—ãƒ«ã‚’æ¯”è¼ƒã›ã‚ˆã€‚

:::details è§£ç­”

```julia
using HypothesisTests

function compare_fid(fid_a::Vector{Float64}, fid_b::Vector{Float64}, Î±::Float64=0.05)
    # Welch's t-test (unequal variances)
    test = UnequalVarianceTTest(fid_a, fid_b)
    p_val = pvalue(test)
    is_sig = p_val < Î±

    # Effect size (Cohen's d)
    Î¼_a, Î¼_b = mean(fid_a), mean(fid_b)
    s_a, s_b = std(fid_a), std(fid_b)
    pooled_std = sqrt((s_a^2 + s_b^2) / 2)
    cohens_d = (Î¼_a - Î¼_b) / pooled_std

    return Dict(
        "p_value" => p_val,
        "significant" => is_sig,
        "cohens_d" => cohens_d
    )
end
```
:::

#### 7.5.3 å®Ÿè£…ãƒãƒ£ãƒ¬ãƒ³ã‚¸ï¼ˆ2å•ï¼‰

**ãƒãƒ£ãƒ¬ãƒ³ã‚¸1**: è‡ªå‹•è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè£…ã—ã€VAE/GAN/ARã®3ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒã›ã‚ˆã€‚å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: JSONï¼ˆFID/IS/CMMD/Precision/Recallï¼‰

:::details ãƒ’ãƒ³ãƒˆ

**æ‰‹é †**:
1. å„ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰1000ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆ
2. Inceptionç‰¹å¾´æŠ½å‡º
3. å„æŒ‡æ¨™ã‚’è¨ˆç®—ï¼ˆFID, IS, CMMD, P&Rï¼‰
4. çµ±è¨ˆæ¤œå®šï¼ˆä¿¡é ¼åŒºé–“ã€t-testï¼‰
5. JSONå‡ºåŠ›

**ã‚³ãƒ¼ãƒ‰éª¨æ ¼**:

```julia
function auto_eval_pipeline(models::Dict{String, Function}, real_data::Vector, n_gen::Int=1000)
    results = Dict()
    for (name, gen_fn) in models
        samples = [gen_fn() for _ in 1:n_gen]
        fid, ci_l, ci_u, _ = fid_with_ci(real_data, samples)
        is_val, _ = inception_score(samples)
        # ... compute other metrics
        results[name] = Dict("fid" => fid, "fid_ci" => [ci_l, ci_u], ...)
    end
    return results
end
```
:::

**ãƒãƒ£ãƒ¬ãƒ³ã‚¸2**: Rust Criterionã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè£…ã—ã€FIDè¨ˆç®—ã®æ€§èƒ½å›å¸°ã‚’æ¤œå‡ºã›ã‚ˆã€‚

:::details ãƒ’ãƒ³ãƒˆ

**Cargo.toml**:

```toml
[dev-dependencies]
criterion = "0.5"
ndarray = "0.16"
ndarray-linalg = "0.19"

[[bench]]
name = "fid_bench"
harness = false
```

**benches/fid_bench.rs**:

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};
use ndarray::{Array1, Array2};

fn benchmark_fid(c: &mut Criterion) {
    let d = 2048;
    let mu1 = Array1::zeros(d);
    let mu2 = Array1::ones(d) * 0.1;
    let sigma1 = Array2::eye(d);
    let sigma2 = Array2::eye(d) * 1.1;

    c.bench_function("fid_2048d", |b| {
        b.iter(|| frechet_distance(
            black_box(&mu1), black_box(&sigma1),
            black_box(&mu2), black_box(&sigma2)
        ))
    });
}

criterion_group!(benches, benchmark_fid);
criterion_main!(benches);
```

**å®Ÿè¡Œ**: `cargo bench` â†’ CIçµ±åˆã§è‡ªå‹•å›å¸°æ¤œå‡º
:::

### 6.6 é€²æ—ãƒˆãƒ©ãƒƒã‚«ãƒ¼ï¼ˆè‡ªå·±è©•ä¾¡ï¼‰

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ** â€” å„é …ç›®ã‚’é”æˆã—ãŸã‚‰ãƒã‚§ãƒƒã‚¯:

```julia
# Progress tracker
checklist = [
    "âœ… Zone 0: FIDã‚’3è¡Œã§è¨ˆç®—ã§ãã‚‹",
    "âœ… Zone 1: 5ã¤ã®æŒ‡æ¨™ï¼ˆFID/IS/LPIPS/P&R/CMMDï¼‰ã‚’è§¦ã£ãŸ",
    "âœ… Zone 2: è©•ä¾¡ã®3ã¤ã®å›°é›£ã‚’ç†è§£ã—ãŸ",
    "âœ… Zone 3: FIDã®æ•°å¼ã‚’å®Œå…¨å°å‡ºã§ãã‚‹",
    "âœ… Zone 3: ISã®KLç™ºæ•£ã‚’å°å‡ºã§ãã‚‹",
    "âœ… Zone 3: LPIPSã®channel-wise normalizationã‚’ç†è§£ã—ãŸ",
    "âœ… Zone 3: Precision-Recallã®å¤šæ§˜ä½“ãƒ™ãƒ¼ã‚¹å®šç¾©ã‚’ç†è§£ã—ãŸ",
    "âœ… Zone 3: MMDã®ã‚«ãƒ¼ãƒãƒ«å±•é–‹ã‚’å°å‡ºã§ãã‚‹",
    "âœ… Zone 3: âš”ï¸ Boss Battle: CMMDè«–æ–‡ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰ã‚’å†å®Ÿè£…ã—ãŸ",
    "âœ… Zone 4: Juliaã§ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—ã§ãã‚‹",
    "âœ… Zone 4: Juliaã§t-testã‚’å®Ÿè¡Œã§ãã‚‹",
    "âœ… Zone 4: Rust Criterionã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè£…ã§ãã‚‹",
    "âœ… Zone 5: VAE/GAN/ARã®çµ±åˆè©•ä¾¡ã‚’å®Ÿè£…ã—ãŸ",
    "âœ… Zone 5: A/Bãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’è¨­è¨ˆã—ãŸ",
    "âœ… Zone 5: MOSã‚’é›†è¨ˆãƒ»åˆ†æã—ãŸ",
    "âœ… Zone 6: CMMD/FLD+ã®æœ€æ–°ç ”ç©¶ã‚’ç†è§£ã—ãŸ",
    "âœ… Zone 7: è‡ªå·±è¨ºæ–­ãƒ†ã‚¹ãƒˆã‚’å…¨å•è§£ã„ãŸ",
    "âœ… Zone 7: å®Ÿè£…ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã‚’å®Œäº†ã—ãŸ",
]

completed = count(x -> startswith(x, "âœ…"), checklist)
total = length(checklist)
progress = round(100 * completed / total, digits=1)

println("Progress: $(completed)/$(total) ($(progress)%)")
if progress == 100.0
    println("ğŸ‰ ç¬¬27å›å®Œå…¨åˆ¶è¦‡ï¼")
end
```

**ç›®æ¨™é”æˆåŸºæº–**:

| ãƒ¬ãƒ™ãƒ« | é”æˆç‡ | åˆ°é”ç‚¹ |
|:-------|:------|:-------|
| **Level 1: ä½¿ãˆã‚‹** | 40% | FID/IS/LPIPSã‚’è¨ˆç®—ã§ãã‚‹ |
| **Level 2: ç†è§£ã—ã¦ã„ã‚‹** | 70% | æ•°å¼ã‚’å®Œå…¨å°å‡ºã§ãã‚‹ |
| **Level 3: è¨­è¨ˆã§ãã‚‹** | 100% | è‡ªå‹•è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã§ãã‚‹ |

---

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

**ğŸ“ ç¬¬27å›å®Œäº†ï¼æ¬¡å›: ç¬¬28å› ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° â€” LLMåˆ¶å¾¡ã®æŠ€è¡“**