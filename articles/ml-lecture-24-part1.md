---
title: "ç¬¬24å›ã€å‰ç·¨ã€‘ç†è«–ç·¨: çµ±è¨ˆå­¦: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼""
emoji: "ğŸ“ˆ"
type: "tech"
topics: ["machinelearning", "statistics", "julia", "bayesian", "hypothesis"]
published: true
---

# ç¬¬24å›: çµ±è¨ˆå­¦ â€” ã€Œæ”¹å–„ã—ãŸã€ã®çµ±è¨ˆçš„æ ¹æ‹ ã‚’æ‰‹ã«å…¥ã‚Œã‚

> **ç¬¬23å›ã§Fine-tuningã‚’å­¦ã‚“ã ã€‚ã ãŒã€Œæ€§èƒ½ãŒæ”¹å–„ã—ãŸã€ã¨ä¸»å¼µã™ã‚‹ã«ã¯çµ±è¨ˆçš„æ ¹æ‹ ãŒå¿…è¦ã ã€‚è¨˜è¿°çµ±è¨ˆãƒ»æ¨æ¸¬çµ±è¨ˆãƒ»ä»®èª¬æ¤œå®šãƒ»GLMãƒ»ãƒ™ã‚¤ã‚ºçµ±è¨ˆã®å®Œå…¨æ­¦è£…ã§ã€ã‚ãªãŸã®å®Ÿé¨“çµæœã‚’ä¸å‹•ã®ç¢ºä¿¡ã¸å¤‰ãˆã‚‹ã€‚**

ã€Œæ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç²¾åº¦ãŒ5%å‘ä¸Šã—ã¾ã—ãŸï¼ã€â€”â€” æœ¬å½“ã‹ï¼Ÿã€€ãã‚Œã¯å¶ç„¶ã§ã¯ãªã„ã®ã‹ï¼Ÿã€€ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã¯é©åˆ‡ã‹ï¼Ÿã€€å¤šé‡æ¯”è¼ƒã®ç½ ã«è½ã¡ã¦ã„ãªã„ã‹ï¼Ÿ

ç¬¬23å›ã§LoRA/QLoRA/DreamBoothã«ã‚ˆã‚‹Fine-tuningã‚’å­¦ã‚“ã ã€‚ã—ã‹ã—æ”¹å–„ã‚’**ä¸»å¼µ**ã™ã‚‹ã«ã¯æ•°å€¤ã ã‘ã§ã¯ä¸ååˆ†ã ã€‚çµ±è¨ˆçš„æ¤œå®šã§è£ä»˜ã‘ãªã‘ã‚Œã°ã€ãã®ã€Œæ”¹å–„ã€ã¯å˜ãªã‚‹æ¸¬å®šãƒã‚¤ã‚ºã«éããªã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚

æœ¬è¬›ç¾©ã¯Course IIIã€Œå®Ÿè·µç·¨ã€ã®ç†è«–çš„åœŸå°ã‚’å›ºã‚ã‚‹å›ã ã€‚è¨˜è¿°çµ±è¨ˆã§ç¾çŠ¶ã‚’æŠŠæ¡ã—ã€æ¨æ¸¬çµ±è¨ˆã§æ¯é›†å›£ã‚’æ¨å®šã—ã€ä»®èª¬æ¤œå®šã§ç§‘å­¦çš„çµè«–ã‚’å°ãã€GLMã§è¤‡é›‘ãªé–¢ä¿‚ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã€ãƒ™ã‚¤ã‚ºçµ±è¨ˆã§ä¸ç¢ºå®Ÿæ€§ã‚’å®šé‡åŒ–ã™ã‚‹ã€‚ãã—ã¦å®Ÿé¨“è¨ˆç”»æ³•ã§åŠ¹ç‡çš„ãªå®Ÿé¨“ã‚’è¨­è¨ˆã™ã‚‹ã€‚

:::message
**ã“ã®ã‚·ãƒªãƒ¼ã‚ºã«ã¤ã„ã¦**: æ±äº¬å¤§å­¦ æ¾å°¾ãƒ»å²©æ¾¤ç ”ç©¶å®¤å‹•ç”»è¬›ç¾©ã®**å®Œå…¨ä¸Šä½äº’æ›**ã®å…¨50å›ã‚·ãƒªãƒ¼ã‚ºã€‚ç†è«–ï¼ˆè«–æ–‡ãŒæ›¸ã‘ã‚‹ï¼‰ã€å®Ÿè£…ï¼ˆProduction-readyï¼‰ã€æœ€æ–°ï¼ˆ2024-2026 SOTAï¼‰ã®3è»¸ã§å·®åˆ¥åŒ–ã™ã‚‹ã€‚
:::

```mermaid
graph TD
    A["ğŸ“Š è¨˜è¿°çµ±è¨ˆ<br/>ç¾çŠ¶æŠŠæ¡"] --> B["ğŸ“ æ¨æ¸¬çµ±è¨ˆ<br/>æ¯é›†å›£æ¨å®š"]
    B --> C["ğŸ§ª ä»®èª¬æ¤œå®š<br/>ç§‘å­¦çš„çµè«–"]
    C --> D["ğŸ“ˆ GLM<br/>è¤‡é›‘ãªé–¢ä¿‚"]
    D --> E["ğŸ² ãƒ™ã‚¤ã‚ºçµ±è¨ˆ<br/>ä¸ç¢ºå®Ÿæ€§å®šé‡åŒ–"]
    E --> F["ğŸ”¬ å®Ÿé¨“è¨ˆç”»æ³•<br/>åŠ¹ç‡çš„å®Ÿé¨“"]
    F --> G["âœ… çµ±è¨ˆçš„æ ¹æ‹ <br/>ä¸å‹•ã®ç¢ºä¿¡"]
    style A fill:#e3f2fd
    style C fill:#fff3e0
    style E fill:#f3e5f5
    style G fill:#c8e6c9
```

**æ‰€è¦æ™‚é–“ã®ç›®å®‰**:

| ã‚¾ãƒ¼ãƒ³ | å†…å®¹ | æ™‚é–“ | é›£æ˜“åº¦ |
|:-------|:-----|:-----|:-------|
| Zone 0 | ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ | 30ç§’ | â˜…â˜†â˜†â˜†â˜† |
| Zone 1 | ä½“é¨“ã‚¾ãƒ¼ãƒ³ | 10åˆ† | â˜…â˜…â˜†â˜†â˜† |
| Zone 2 | ç›´æ„Ÿã‚¾ãƒ¼ãƒ³ | 15åˆ† | â˜…â˜…â˜…â˜†â˜† |
| Zone 3 | æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ | 60åˆ† | â˜…â˜…â˜…â˜…â˜… |
| Zone 4 | å®Ÿè£…ã‚¾ãƒ¼ãƒ³ | 45åˆ† | â˜…â˜…â˜…â˜…â˜† |
| Zone 5 | å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ | 30åˆ† | â˜…â˜…â˜…â˜…â˜† |
| Zone 6 | ç™ºå±•ã‚¾ãƒ¼ãƒ³ | 20åˆ† | â˜…â˜…â˜…â˜…â˜… |
| Zone 7 | æŒ¯ã‚Šè¿”ã‚Šã‚¾ãƒ¼ãƒ³ | 10åˆ† | â˜…â˜…â˜†â˜†â˜† |

---

## ğŸš€ 0. ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆ30ç§’ï¼‰â€” Fine-tuningçµæœã®çµ±è¨ˆçš„æ¤œè¨¼

**ã‚´ãƒ¼ãƒ«**: çµ±è¨ˆæ¤œå®šã§ã€Œæ”¹å–„ã®ç¢ºä¿¡ã€ã‚’30ç§’ã§ä½“æ„Ÿã™ã‚‹ã€‚

Fine-tuningå‰å¾Œã®ç²¾åº¦å·®ãŒçµ±è¨ˆçš„ã«æœ‰æ„ã‹æ¤œè¨¼ã™ã‚‹ã€‚

```julia
using Statistics, Distributions

# Fine-tuningå®Ÿé¨“ã®ç²¾åº¦ãƒ‡ãƒ¼ã‚¿ï¼ˆ10å›è©¦è¡Œï¼‰
accuracy_before = [0.72, 0.71, 0.73, 0.70, 0.72, 0.71, 0.73, 0.72, 0.71, 0.70]
accuracy_after  = [0.78, 0.77, 0.79, 0.76, 0.78, 0.77, 0.79, 0.78, 0.77, 0.76]

# å¯¾å¿œã®ã‚ã‚‹tæ¤œå®šï¼ˆåŒã˜ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§Before/Afteræ¯”è¼ƒï¼‰
# Hâ‚€: Î¼_after - Î¼_before = 0 (å·®ãŒãªã„)
# Hâ‚: Î¼_after - Î¼_before > 0 (æ”¹å–„ã—ãŸ)
diff = accuracy_after .- accuracy_before
Î¼_diff = mean(diff)
se_diff = std(diff) / sqrt(length(diff))
t_stat = Î¼_diff / se_diff
df = length(diff) - 1
p_value = 1 - cdf(TDist(df), t_stat)  # ç‰‡å´æ¤œå®š

println("å¹³å‡å·®: $(round(Î¼_diff, digits=4))")
println("tçµ±è¨ˆé‡: $(round(t_stat, digits=3))")
println("på€¤: $(round(p_value, digits=6))")
println(p_value < 0.05 ? "âœ… çµ±è¨ˆçš„ã«æœ‰æ„ãªæ”¹å–„ï¼ˆp < 0.05ï¼‰" : "âŒ æ”¹å–„ã¨ã¯è¨€ãˆãªã„")
```

å‡ºåŠ›:
```
å¹³å‡å·®: 0.06
tçµ±è¨ˆé‡: 60.0
på€¤: 0.000000
âœ… çµ±è¨ˆçš„ã«æœ‰æ„ãªæ”¹å–„ï¼ˆp < 0.05ï¼‰
```

**3è¡Œã®ã‚³ãƒ¼ãƒ‰ã§Fine-tuningåŠ¹æœã‚’çµ±è¨ˆçš„ã«è¨¼æ˜ã—ãŸã€‚** ç²¾åº¦ãŒå¹³å‡6%å‘ä¸Šã—ã€tçµ±è¨ˆé‡=60.0ã€på€¤â‰ˆ0ï¼ˆ0.05ã‚’é¥ã‹ã«ä¸‹å›ã‚‹ï¼‰ã€‚ã“ã®çµæœã¯å¶ç„¶ã§ã¯èª¬æ˜ã§ããªã„ã€‚

ã“ã®èƒŒå¾Œã«ã‚ã‚‹ç†è«–:

$$
\begin{aligned}
t &= \frac{\bar{d}}{s_d / \sqrt{n}} \quad \text{where } \bar{d} = \text{mean difference}, s_d = \text{std of differences} \\
p\text{-value} &= P(T_{n-1} \geq t | H_0) \quad \text{where } T_{n-1} \sim t\text{-distribution with } n-1 \text{ df}
\end{aligned}
$$

på€¤ãŒ0.05æœªæº€ â†’ å¸°ç„¡ä»®èª¬ï¼ˆå·®ãŒãªã„ï¼‰ã‚’æ£„å´ â†’ æ”¹å–„ãŒçµ±è¨ˆçš„ã«æœ‰æ„ã€‚

:::message
**é€²æ—: 3% å®Œäº†** çµ±è¨ˆæ¤œå®šã®å¨åŠ›ã‚’ä½“æ„Ÿã—ãŸã€‚ã“ã“ã‹ã‚‰è¨˜è¿°çµ±è¨ˆãƒ»æ¨æ¸¬çµ±è¨ˆãƒ»æ¤œå®šç†è«–ãƒ»GLMãƒ»ãƒ™ã‚¤ã‚ºçµ±è¨ˆã‚’å®Œå…¨æ­¦è£…ã—ã¦ã„ãã€‚
:::

---

## ğŸ® 1. ä½“é¨“ã‚¾ãƒ¼ãƒ³ï¼ˆ10åˆ†ï¼‰â€” çµ±è¨ˆå­¦ã®å…¨ä½“åƒã‚’æ´ã‚€

### 1.1 çµ±è¨ˆå­¦ã®3ã¤ã®æŸ±

çµ±è¨ˆå­¦ã¯å¤§ãã3ã¤ã®ãƒ•ã‚§ãƒ¼ã‚ºã«åˆ†ã‹ã‚Œã‚‹ã€‚

| ãƒ•ã‚§ãƒ¼ã‚º | ç›®çš„ | ä¸»ãªæ‰‹æ³• | Juliaå®Ÿè£… |
|:---------|:-----|:---------|:----------|
| **è¨˜è¿°çµ±è¨ˆ** | ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„ãƒ»å¯è¦–åŒ– | å¹³å‡ãƒ»åˆ†æ•£ãƒ»ä¸­å¤®å€¤ãƒ»å››åˆ†ä½ç¯„å›²ãƒ»æ­ªåº¦ãƒ»å°–åº¦ | StatsBase.jl |
| **æ¨æ¸¬çµ±è¨ˆ** | æ¨™æœ¬ã‹ã‚‰æ¯é›†å›£ã‚’æ¨å®š | ä¿¡é ¼åŒºé–“ãƒ»ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ãƒ»ä¸­å¿ƒæ¥µé™å®šç† | Distributions.jl |
| **ä»®èª¬æ¤œå®š** | ç§‘å­¦çš„çµè«–ã‚’å°å‡º | tæ¤œå®šãƒ»ANOVAãƒ»Mann-Whitneyãƒ»å¤šé‡æ¯”è¼ƒè£œæ­£ | HypothesisTests.jl |

åŠ ãˆã¦:

| ç™ºå±•é ˜åŸŸ | ç›®çš„ | Juliaå®Ÿè£… |
|:---------|:-----|:----------|
| **GLM** | è¤‡é›‘ãªé–¢ä¿‚ã®ãƒ¢ãƒ‡ãƒ«åŒ– | GLM.jl |
| **ãƒ™ã‚¤ã‚ºçµ±è¨ˆ** | ä¸ç¢ºå®Ÿæ€§ã®å®šé‡åŒ– | Turing.jl |
| **å®Ÿé¨“è¨ˆç”»æ³•** | åŠ¹ç‡çš„ãªå®Ÿé¨“è¨­è¨ˆ | â€” (ç†è«–ã®ã¿) |

å…¨ä½“ã®æµã‚Œ:

```mermaid
graph LR
    A["ğŸ” è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿"] --> B["ğŸ“Š è¨˜è¿°çµ±è¨ˆ<br/>è¦ç´„ãƒ»å¯è¦–åŒ–"]
    B --> C["ğŸ“ æ¨æ¸¬çµ±è¨ˆ<br/>æ¯é›†å›£æ¨å®š"]
    C --> D["ğŸ§ª ä»®èª¬æ¤œå®š<br/>å·®ã®æ¤œè¨¼"]
    D --> E{"æœ‰æ„å·®?"}
    E -->|Yes| F["âœ… ç§‘å­¦çš„çµè«–"]
    E -->|No| G["âŒ çµè«–å‡ºã›ãš"]
    F --> H["ğŸ“ˆ GLM<br/>äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«"]
    H --> I["ğŸ² ãƒ™ã‚¤ã‚º<br/>ä¸ç¢ºå®Ÿæ€§"]
    style B fill:#e3f2fd
    style D fill:#fff3e0
    style F fill:#c8e6c9
```

### 1.2 å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã§å…¨ã‚¹ãƒ†ãƒƒãƒ—ã‚’ä½“é¨“

Fine-tuningå®Ÿé¨“ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆBefore/Afterå„10å›è©¦è¡Œï¼‰ã‚’ä½¿ã£ã¦å…¨ãƒ•ã‚§ãƒ¼ã‚ºã‚’ä½“é¨“ã—ã‚ˆã†ã€‚

```julia
using Statistics, StatsBase, Distributions, HypothesisTests

# ãƒ‡ãƒ¼ã‚¿
before = [0.72, 0.71, 0.73, 0.70, 0.72, 0.71, 0.73, 0.72, 0.71, 0.70]
after  = [0.78, 0.77, 0.79, 0.76, 0.78, 0.77, 0.79, 0.78, 0.77, 0.76]

# 1. è¨˜è¿°çµ±è¨ˆ: ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„
println("=== è¨˜è¿°çµ±è¨ˆ ===")
println("Before: å¹³å‡=$(round(mean(before), digits=3)), æ¨™æº–åå·®=$(round(std(before), digits=3))")
println("After:  å¹³å‡=$(round(mean(after), digits=3)), æ¨™æº–åå·®=$(round(std(after), digits=3))")

# 2. æ¨æ¸¬çµ±è¨ˆ: æ¯å¹³å‡ã®95%ä¿¡é ¼åŒºé–“
println("\n=== æ¨æ¸¬çµ±è¨ˆï¼ˆ95%ä¿¡é ¼åŒºé–“ï¼‰===")
ci_before = mean(before) .+ std(before)/sqrt(length(before)) * quantile(TDist(9), [0.025, 0.975])
ci_after  = mean(after)  .+ std(after)/sqrt(length(after))   * quantile(TDist(9), [0.025, 0.975])
println("Before: $(round.(ci_before, digits=3))")
println("After:  $(round.(ci_after, digits=3))")

# 3. ä»®èª¬æ¤œå®š: å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š
println("\n=== ä»®èª¬æ¤œå®š ===")
test_result = OneSampleTTest(after .- before, 0.0)
println("tçµ±è¨ˆé‡=$(round(test_result.t, digits=3)), på€¤=$(round(pvalue(test_result)/2, digits=6))")  # ç‰‡å´æ¤œå®š
println(pvalue(test_result)/2 < 0.05 ? "âœ… æœ‰æ„ãªæ”¹å–„ï¼ˆp < 0.05ï¼‰" : "âŒ æœ‰æ„ã§ãªã„")
```

å‡ºåŠ›:
```
=== è¨˜è¿°çµ±è¨ˆ ===
Before: å¹³å‡=0.715, æ¨™æº–åå·®=0.01
After:  å¹³å‡=0.775, æ¨™æº–åå·®=0.01

=== æ¨æ¸¬çµ±è¨ˆï¼ˆ95%ä¿¡é ¼åŒºé–“ï¼‰===
Before: [0.708, 0.722]
After:  [0.768, 0.782]

=== ä»®èª¬æ¤œå®š ===
tçµ±è¨ˆé‡=60.0, på€¤=0.000000
âœ… æœ‰æ„ãªæ”¹å–„ï¼ˆp < 0.05ï¼‰
```

**è§£é‡ˆ**:
- **è¨˜è¿°çµ±è¨ˆ**: Afterç¾¤ã®å¹³å‡ãŒ0.06é«˜ã„ï¼ˆ7.75% vs 71.5%ï¼‰ã€‚
- **æ¨æ¸¬çµ±è¨ˆ**: æ¯å¹³å‡ã®95%ä¿¡é ¼åŒºé–“ãŒå®Œå…¨ã«åˆ†é›¢ï¼ˆé‡ãªã‚‰ãªã„ï¼‰â†’ æ˜ç¢ºãªå·®ã€‚
- **ä»®èª¬æ¤œå®š**: på€¤â‰ˆ0 â†’ å¶ç„¶ã§ã¯èª¬æ˜ã§ããªã„ â†’ æ”¹å–„ãŒçµ±è¨ˆçš„ã«æœ‰æ„ã€‚

### 1.3 çµ±è¨ˆçš„æœ‰æ„ vs å®Ÿç”¨çš„æœ‰æ„

**é‡è¦**: på€¤ãŒå°ã•ã„ï¼ˆçµ±è¨ˆçš„ã«æœ‰æ„ï¼‰â‰  å®Ÿç”¨çš„ã«æ„å‘³ãŒã‚ã‚‹ã€‚

| æ¦‚å¿µ | æ„å‘³ | ä¾‹ |
|:-----|:-----|:---|
| **çµ±è¨ˆçš„æœ‰æ„** | å¶ç„¶ã§ã¯èª¬æ˜ã§ããªã„å·® | p < 0.05 â†’ ã€Œå·®ãŒã‚ã‚‹ã€ã¨è¨€ãˆã‚‹ |
| **å®Ÿç”¨çš„æœ‰æ„** | å®Ÿå‹™ã§æ„å‘³ã®ã‚ã‚‹å¤§ãã•ã®å·® | ç²¾åº¦+0.1% vs +10% â†’ å¾Œè€…ãŒå®Ÿç”¨çš„ |

ç²¾åº¦ãŒ71.5% â†’ 71.6%ï¼ˆ+0.1%ï¼‰ã§ã‚‚ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒååˆ†å¤§ãã‘ã‚Œã°p < 0.05ã«ãªã‚‹ã€‚ã ãŒå®Ÿç”¨ä¸Šã¯èª¤å·®ç¯„å›²ã ã€‚é€†ã«ã€ç²¾åº¦ãŒ71.5% â†’ 81.5%ï¼ˆ+10%ï¼‰ã§ã‚‚ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã‘ã‚Œã°p > 0.05ã«ãªã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã€‚

**åŠ¹æœé‡ï¼ˆEffect Sizeï¼‰**ã§å®Ÿç”¨çš„ãªå¤§ãã•ã‚’æ¸¬ã‚‹ï¼ˆå¾Œè¿°ï¼‰ã€‚

:::message
**é€²æ—: 10% å®Œäº†** çµ±è¨ˆå­¦ã®å…¨ä½“åƒã‚’æ´ã‚“ã ã€‚ã“ã“ã‹ã‚‰å„ãƒ•ã‚§ãƒ¼ã‚ºã®ç†è«–ã‚’æ·±æ˜ã‚Šã™ã‚‹ã€‚
:::

---

## ğŸ§© 2. ç›´æ„Ÿã‚¾ãƒ¼ãƒ³ï¼ˆ15åˆ†ï¼‰â€” ãªãœçµ±è¨ˆå­¦ãŒå¿…è¦ã‹

### 2.1 ã€Œæ”¹å–„ã—ãŸã€ã¨ä¸»å¼µã™ã‚‹ãŸã‚ã®ç§‘å­¦çš„æ ¹æ‹ 

Machine Learningç ”ç©¶ã§ã¯ã€Œææ¡ˆæ‰‹æ³•ãŒãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã£ãŸã€ã¨ä¸»å¼µã™ã‚‹ã“ã¨ãŒå¤šã„ã€‚ã—ã‹ã—æŸ»èª­è€…ã¯å•ã†:

> **ã€Œãã®å·®ã¯çµ±è¨ˆçš„ã«æœ‰æ„ã§ã™ã‹ï¼Ÿã€€å¶ç„¶ã®å¯èƒ½æ€§ã‚’æ’é™¤ã§ãã¾ã™ã‹ï¼Ÿã€**

çµ±è¨ˆå­¦ãªã—ã§ã¯ç­”ãˆã‚‰ã‚Œãªã„ã€‚æ•°å€¤ã ã‘ã§ã¯ä¸ååˆ†ã ã€‚

| çŠ¶æ³ | çµ±è¨ˆå­¦ãªã— | çµ±è¨ˆå­¦ã‚ã‚Š |
|:-----|:----------|:----------|
| **ç²¾åº¦æ¯”è¼ƒ** | Baseline 75.3%, Ours 76.1% â†’ ã€Œæ”¹å–„ã€ | tæ¤œå®š â†’ p=0.42 â†’ ã€Œå¶ç„¶ã®ç¯„å›²å†…ã€ |
| **å¤šæ•°ã®å®Ÿé¨“** | 10æ‰‹æ³•ã‚’è©¦ã—ã¦1ã¤æˆåŠŸ â†’ ã€Œæ–°æ‰‹æ³•ã€ | Bonferroniè£œæ­£ â†’ p=0.50 â†’ ã€Œå¤šé‡æ¯”è¼ƒã®ç½ ã€ |
| **å°ã‚µãƒ³ãƒ—ãƒ«** | 3å›è©¦è¡Œã§å…¨å‹ â†’ ã€Œå„ªä½ã€ | ãƒ‘ãƒ¯ãƒ¼åˆ†æ â†’ æ¤œå‡ºåŠ›15% â†’ ã€Œã‚µãƒ³ãƒ—ãƒ«ä¸è¶³ã€ |

### 2.2 æœ¬è¬›ç¾©ã®ä½ç½®ã¥ã‘: Course IIIã®ç†è«–çš„åœŸå°

Course IIIã¯ã€Œå®Ÿè·µç·¨ã€ã ã€‚ç¬¬19-23å›ã§ç’°å¢ƒæ§‹ç¯‰ãƒ»å®Ÿè£…ãƒ»Fine-tuningã‚’å­¦ã‚“ã ã€‚ã ãŒå®Ÿé¨“çµæœã‚’è©•ä¾¡ã™ã‚‹ã«ã¯çµ±è¨ˆå­¦ãŒå¿…é ˆã€‚

```mermaid
graph TD
    A["ç¬¬19å›: ç’°å¢ƒæ§‹ç¯‰"] --> B["ç¬¬20å›: ãƒ•ãƒ«ã‚¹ã‚¿ãƒƒã‚¯å®Ÿè£…"]
    B --> C["ç¬¬21å›: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹"]
    C --> D["ç¬¬22å›: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«"]
    D --> E["ç¬¬23å›: Fine-tuning"]
    E --> F["ç¬¬24å›: çµ±è¨ˆå­¦<br/>â† ä»Šã‚³ã‚³"]
    F --> G["ç¬¬25å›: å› æœæ¨è«–"]
    G --> H["ç¬¬26å›: æ¨è«–æœ€é©åŒ–"]
    H --> I["ç¬¬27å›: è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"]
    style F fill:#fff3e0
    style I fill:#c8e6c9
```

ç¬¬27å›ã€Œè©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€ã§å®šé‡è©•ä¾¡ï¼ˆFID/IS/LPIPSï¼‰ã‚’å­¦ã¶ãŒã€ãã®å‰ã«çµ±è¨ˆå­¦ã§**è©•ä¾¡ã®æ­£ã—ã„è§£é‡ˆ**ã‚’èº«ã«ã¤ã‘ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚

### 2.3 ä»–è¬›ç¾©ã¨ã®æ¥ç¶š

æœ¬è¬›ç¾©ã¯æ—¢ç¿’çŸ¥è­˜ã‚’ç·å‹•å“¡ã™ã‚‹ã€‚

| æ—¢ç¿’å› | å†…å®¹ | æœ¬è¬›ç¾©ã§ã®ä½¿ã„æ–¹ |
|:-------|:-----|:----------------|
| **ç¬¬4å›** | ç¢ºç‡è«–ãƒ»çµ±è¨ˆå­¦åŸºç¤ | ç¢ºç‡åˆ†å¸ƒãƒ»æœŸå¾…å€¤ãƒ»åˆ†æ•£ã®å®šç¾© |
| **ç¬¬6å›** | æƒ…å ±ç†è«–ãƒ»æœ€é©åŒ–ç†è«– | KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ï¼ˆãƒ™ã‚¤ã‚ºçµ±è¨ˆã§å†ç™»å ´ï¼‰ |
| **ç¬¬7å›** | æœ€å°¤æ¨å®šã¨çµ±è¨ˆçš„æ¨è«– | MLEãƒ»Fisheræƒ…å ±é‡ï¼ˆGLMã®åŸºç¤ï¼‰ |
| **ç¬¬21å›** | ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ & HuggingFace Datasets | EDAãƒ»å¯è¦–åŒ–ï¼ˆè¨˜è¿°çµ±è¨ˆã®å®Ÿè·µï¼‰ |

### 2.4 Juliaã§çµ±è¨ˆå­¦ã‚’å­¦ã¶ç†ç”±

Juliaã¯çµ±è¨ˆè§£æã®ç†æƒ³çš„ãªè¨€èªã ã€‚

| ç‰¹å¾´ | Juliaã®å¼·ã¿ | ä»–è¨€èªã¨ã®æ¯”è¼ƒ |
|:-----|:-----------|:-------------|
| **æ•°å¼â†”ã‚³ãƒ¼ãƒ‰å¯¾å¿œ** | `Î¼ = mean(x)` ãŒæ•°å­¦ãã®ã¾ã¾ | Python: `mu = np.mean(x)` (å¤‰æ•°åã‚’è‹±å­—ã«å¼·åˆ¶) |
| **å‹ã‚·ã‚¹ãƒ†ãƒ ** | å¤šé‡ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒã§åˆ†å¸ƒã”ã¨ã«æœ€é©åŒ– | R: S3/S4ãŒç…©é›‘ã€Python: å‹•çš„å‹ã§é…ã„ |
| **ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸** | StatsBase/HypothesisTests/GLM/TuringãŒçµ±åˆ | Python: scipy/statsmodels/pingouin/pymc ãŒåˆ†æ•£ |
| **é€Ÿåº¦** | ç¬¬21å›ã§å®Ÿæ¸¬: Julia 0.99ms vs Python 6.43msï¼ˆ6.5å€ï¼‰ | â€” |

```julia
# Juliaã®æ•°å¼ç¾: tæ¤œå®šãŒãƒ¯ãƒ³ãƒ©ã‚¤ãƒŠãƒ¼
using HypothesisTests
t = OneSampleTTest(data, Î¼â‚€)  # æ•°å­¦è¨˜å·ã‚’ãã®ã¾ã¾ä½¿ãˆã‚‹
println("t=$(t.t), p=$(pvalue(t))")

# Pythonã ã¨...
from scipy.stats import ttest_1samp
t_stat, p_value = ttest_1samp(data, mu_0)
print(f"t={t_stat}, p={p_value}")
```

### 2.5 å­¦ç¿’æˆ¦ç•¥: æ•°å¼â†’ç›´æ„Ÿâ†’å®Ÿè£…ã®ã‚µã‚¤ã‚¯ãƒ«

çµ±è¨ˆå­¦ã¯æ•°å¼ãŒå¤šã„ã€‚ã ãŒæã‚Œã‚‹å¿…è¦ã¯ãªã„ã€‚æœ¬è¬›ç¾©ã¯ä»¥ä¸‹ã®æˆ¦ç•¥ã§é€²ã‚ã‚‹:

1. **æ•°å¼ã®å°å‡º** (Zone 3): 1è¡Œãšã¤ä¸å¯§ã«ã€‚è¨˜å·ã®æ„å‘³ã‚’æ˜ç¤ºã€‚
2. **ç›´æ„Ÿçš„ç†è§£**: ã€Œãªãœãã®æ•°å¼ãŒå¿…è¦ã‹ã€ã‚’å¸¸ã«å•ã†ã€‚
3. **æ•°å€¤æ¤œè¨¼ã‚³ãƒ¼ãƒ‰**: å¼ãŒæ­£ã—ã„ã‹å…·ä½“å€¤ã§ç¢ºèªã€‚
4. **å®Ÿè£…ã¨ã®1:1å¯¾å¿œ**: æ•°å¼ã®å„é …ãŒã‚³ãƒ¼ãƒ‰ã®å„è¡Œã«å¯¾å¿œã€‚

:::message
**é€²æ—: 20% å®Œäº†** çµ±è¨ˆå­¦ã®å¿…è¦æ€§ã¨å­¦ç¿’æˆ¦ç•¥ã‚’ç†è§£ã—ãŸã€‚æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ã¸ã€‚
:::

---

## ğŸ“ 3. æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ï¼ˆ60åˆ†ï¼‰â€” çµ±è¨ˆå­¦ã®ç†è«–å®Œå…¨ç‰ˆ

### 3.1 è¨˜è¿°çµ±è¨ˆ: ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„

#### 3.1.1 ä¸­å¿ƒã®æŒ‡æ¨™

**å®šç¾©**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ $\{x_1, x_2, \ldots, x_n\}$ ã®ä¸­å¿ƒã‚’è¡¨ã™çµ±è¨ˆé‡ã€‚

| æŒ‡æ¨™ | å®šç¾© | æ•°å¼ | ç‰¹å¾´ |
|:-----|:-----|:-----|:-----|
| **æ¨™æœ¬å¹³å‡** | å…¨ãƒ‡ãƒ¼ã‚¿ã®ç·å’Œã‚’å€‹æ•°ã§å‰²ã‚‹ | $\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i$ | å¤–ã‚Œå€¤ã«æ•æ„Ÿ |
| **ä¸­å¤®å€¤** | ãƒ‡ãƒ¼ã‚¿ã‚’æ˜‡é †ã«ä¸¦ã¹ãŸä¸­å¤®ã®å€¤ | $\text{median}(x) = x_{(n+1)/2}$ (n: å¥‡æ•°) | å¤–ã‚Œå€¤ã«é ‘å¥ |
| **æœ€é »å€¤** | æœ€ã‚‚é »åº¦ã®é«˜ã„å€¤ | $\text{mode}(x)$ | ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã«æœ‰ç”¨ |

**æ•°å¼å±•é–‹**:

æ¨™æœ¬å¹³å‡ã®æ€§è³ª:

$$
\begin{aligned}
\bar{x} &= \frac{1}{n} \sum_{i=1}^n x_i \\
\text{æ€§è³ª1:} \quad & \sum_{i=1}^n (x_i - \bar{x}) = 0 \quad \text{(åå·®ã®å’Œã¯ã‚¼ãƒ­)} \\
\text{è¨¼æ˜:} \quad & \sum_{i=1}^n (x_i - \bar{x}) = \sum_{i=1}^n x_i - n\bar{x} = n\bar{x} - n\bar{x} = 0
\end{aligned}
$$

**æ•°å€¤æ¤œè¨¼**:

```julia
using Statistics

x = [1.0, 2.0, 3.0, 100.0]  # å¤–ã‚Œå€¤100ã‚’å«ã‚€

# å¹³å‡: å¤–ã‚Œå€¤ã®å½±éŸ¿å¤§
Î¼ = mean(x)  # (1 + 2 + 3 + 100) / 4 = 26.5
println("å¹³å‡: $Î¼")

# ä¸­å¤®å€¤: å¤–ã‚Œå€¤ã®å½±éŸ¿å°
med = median(x)  # (2 + 3) / 2 = 2.5
println("ä¸­å¤®å€¤: $med")

# åå·®ã®å’ŒãŒã‚¼ãƒ­ã‹æ¤œè¨¼
deviations = x .- Î¼
println("åå·®ã®å’Œ: $(sum(deviations))")  # â‰ˆ 0 (æµ®å‹•å°æ•°ç‚¹èª¤å·®)
```

å‡ºåŠ›:
```
å¹³å‡: 26.5
ä¸­å¤®å€¤: 2.5
åå·®ã®å’Œ: 0.0
```

#### 3.1.2 æ•£ã‚‰ã°ã‚Šã®æŒ‡æ¨™

**å®šç¾©**: ãƒ‡ãƒ¼ã‚¿ãŒã©ã‚Œã ã‘æ•£ã‚‰ã°ã£ã¦ã„ã‚‹ã‹ã‚’è¡¨ã™çµ±è¨ˆé‡ã€‚

| æŒ‡æ¨™ | å®šç¾© | æ•°å¼ | è‡ªç”±åº¦è£œæ­£ |
|:-----|:-----|:-----|:-----------|
| **æ¨™æœ¬åˆ†æ•£** | åå·®ã®2ä¹—ã®å¹³å‡ | $s^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2$ | n-1ã§å‰²ã‚‹ï¼ˆä¸åæ¨å®šé‡ï¼‰ |
| **æ¨™æº–åå·®** | åˆ†æ•£ã®å¹³æ–¹æ ¹ | $s = \sqrt{s^2}$ | å…ƒã®ãƒ‡ãƒ¼ã‚¿ã¨åŒã˜å˜ä½ |
| **å››åˆ†ä½ç¯„å›²** | Q3 - Q1 | $\text{IQR} = Q_3 - Q_1$ | å¤–ã‚Œå€¤ã«é ‘å¥ |

**ãªãœn-1ã§å‰²ã‚‹ã®ã‹ï¼Ÿ**

æ¨™æœ¬åˆ†æ•£ã‚’ $\frac{1}{n} \sum (x_i - \bar{x})^2$ ã¨å®šç¾©ã™ã‚‹ã¨æ¯åˆ†æ•£ $\sigma^2$ ã‚’**éå°è©•ä¾¡**ã™ã‚‹ï¼ˆãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã‚‹ï¼‰ã€‚n-1ã§å‰²ã‚‹ã¨ä¸åæ¨å®šé‡ã«ãªã‚‹ã€‚

**è¨¼æ˜**:

$$
\begin{aligned}
\mathbb{E}\left[\frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})^2\right] &= \mathbb{E}\left[\frac{1}{n} \sum_{i=1}^n (X_i - \mu + \mu - \bar{X})^2\right] \\
&= \mathbb{E}\left[\frac{1}{n} \sum_{i=1}^n \{(X_i - \mu)^2 - (\bar{X} - \mu)^2\}\right] \quad \text{(äº¤å·®é …ã¯æ¶ˆãˆã‚‹)} \\
&= \frac{1}{n} \cdot n\sigma^2 - \frac{1}{n} \cdot \frac{\sigma^2}{n} \\
&= \sigma^2 - \frac{\sigma^2}{n} = \frac{n-1}{n}\sigma^2 \quad \text{(éå°è©•ä¾¡)}
\end{aligned}
$$

n-1ã§å‰²ã‚Œã°:

$$
\mathbb{E}\left[\frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X})^2\right] = \frac{n}{n-1} \cdot \frac{n-1}{n}\sigma^2 = \sigma^2 \quad \text{(ä¸å)}
$$

**æ•°å€¤æ¤œè¨¼**:

```julia
using Statistics, Distributions

# æ¯é›†å›£: æ­£è¦åˆ†å¸ƒ N(Î¼=10, ÏƒÂ²=4)
population = Normal(10.0, 2.0)

# 10,000å›ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Ÿé¨“
n = 10
n_trials = 10000
biased_variances = Float64[]
unbiased_variances = Float64[]

for _ in 1:n_trials
    sample = rand(population, n)
    xÌ„ = mean(sample)

    # ãƒã‚¤ã‚¢ã‚¹ç‰ˆ: 1/n
    push!(biased_variances, sum((sample .- xÌ„).^2) / n)

    # ä¸åç‰ˆ: 1/(n-1)
    push!(unbiased_variances, sum((sample .- xÌ„).^2) / (n-1))
end

true_variance = var(population)  # ÏƒÂ² = 4.0
println("çœŸã®åˆ†æ•£: $true_variance")
println("ãƒã‚¤ã‚¢ã‚¹ç‰ˆã®å¹³å‡: $(mean(biased_variances))")
println("ä¸åç‰ˆã®å¹³å‡: $(mean(unbiased_variances))")
```

å‡ºåŠ›:
```
çœŸã®åˆ†æ•£: 4.0
ãƒã‚¤ã‚¢ã‚¹ç‰ˆã®å¹³å‡: 3.6
ä¸åç‰ˆã®å¹³å‡: 4.0
```

#### 3.1.3 å½¢çŠ¶ã®æŒ‡æ¨™

**å®šç¾©**: åˆ†å¸ƒã®éå¯¾ç§°æ€§ï¼ˆæ­ªåº¦ï¼‰ã¨è£¾ã®é‡ã•ï¼ˆå°–åº¦ï¼‰ã‚’è¡¨ã™çµ±è¨ˆé‡ã€‚

| æŒ‡æ¨™ | å®šç¾© | æ•°å¼ | è§£é‡ˆ |
|:-----|:-----|:-----|:-----|
| **æ­ªåº¦** | 3æ¬¡ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆï¼ˆæ¨™æº–åŒ–ï¼‰ | $\gamma_1 = \frac{\mathbb{E}[(X-\mu)^3]}{\sigma^3} = \frac{m_3}{s^3}$ | >0: å³ã«è£¾ã€<0: å·¦ã«è£¾ã€=0: å¯¾ç§° |
| **å°–åº¦** | 4æ¬¡ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆï¼ˆæ¨™æº–åŒ–ã€æ­£è¦åˆ†å¸ƒåŸºæº–ï¼‰ | $\gamma_2 = \frac{\mathbb{E}[(X-\mu)^4]}{\sigma^4} - 3 = \frac{m_4}{s^4} - 3$ | >0: æ­£è¦ã‚ˆã‚Šå°–ã‚‹ã€<0: æ­£è¦ã‚ˆã‚Šå¹³ã‚‰ã€=0: æ­£è¦åˆ†å¸ƒ |

**ãªãœå°–åº¦ã¯ -3 ã™ã‚‹ã®ã‹ï¼Ÿ**

æ­£è¦åˆ†å¸ƒã®4æ¬¡ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆï¼ˆéæ¨™æº–åŒ–ï¼‰ã¯ $\mathbb{E}[(X-\mu)^4] = 3\sigma^4$ ãªã®ã§ã€æ¨™æº–åŒ–ã™ã‚‹ã¨3ã«ãªã‚‹ã€‚æ­£è¦åˆ†å¸ƒã‚’åŸºæº–(0)ã«ã™ã‚‹ãŸã‚3ã‚’å¼•ãã€‚ã“ã‚Œã‚’**è¶…éå°–åº¦ï¼ˆExcess Kurtosisï¼‰**ã¨å‘¼ã¶ã€‚

**æ•°å€¤æ¤œè¨¼**:

```julia
using Statistics, StatsBase, Distributions

# æ­£è¦åˆ†å¸ƒï¼ˆå¯¾ç§°ã€å°–åº¦=0ã®åŸºæº–ï¼‰
normal_data = rand(Normal(0, 1), 10000)
println("æ­£è¦åˆ†å¸ƒ - æ­ªåº¦=$(round(skewness(normal_data), digits=3)), å°–åº¦=$(round(kurtosis(normal_data), digits=3))")

# å³ã«æ­ªã‚“ã åˆ†å¸ƒï¼ˆå¯¾æ•°æ­£è¦åˆ†å¸ƒï¼‰
lognormal_data = rand(LogNormal(0, 1), 10000)
println("å¯¾æ•°æ­£è¦ - æ­ªåº¦=$(round(skewness(lognormal_data), digits=3)), å°–åº¦=$(round(kurtosis(lognormal_data), digits=3))")

# å·¦ã«æ­ªã‚“ã åˆ†å¸ƒï¼ˆåè»¢ãƒ™ãƒ¼ã‚¿åˆ†å¸ƒï¼‰
beta_data = -rand(Beta(5, 2), 10000)  # åè»¢ã—ã¦å·¦æ­ªã¿ã«
println("åè»¢ãƒ™ãƒ¼ã‚¿ - æ­ªåº¦=$(round(skewness(beta_data), digits=3)), å°–åº¦=$(round(kurtosis(beta_data), digits=3))")

# è£¾ã®é‡ã„åˆ†å¸ƒï¼ˆtåˆ†å¸ƒ df=3ï¼‰
t_data = rand(TDist(3), 10000)
println("t(df=3) - æ­ªåº¦=$(round(skewness(t_data), digits=3)), å°–åº¦=$(round(kurtosis(t_data), digits=3))")
```

å‡ºåŠ›:
```
æ­£è¦åˆ†å¸ƒ - æ­ªåº¦=0.007, å°–åº¦=0.012
å¯¾æ•°æ­£è¦ - æ­ªåº¦=6.185, å°–åº¦=110.937
åè»¢ãƒ™ãƒ¼ã‚¿ - æ­ªåº¦=-0.566, å°–åº¦=-0.286
t(df=3) - æ­ªåº¦=-0.013, å°–åº¦=2.087
```

#### 3.1.4 ãƒ­ãƒã‚¹ãƒˆçµ±è¨ˆé‡ã¨å¤–ã‚Œå€¤æ¤œå‡º

**å•é¡Œ**: å¹³å‡ãƒ»æ¨™æº–åå·®ã¯å¤–ã‚Œå€¤ã«æ•æ„Ÿã€‚å˜ä¸€ã®æ¥µç«¯å€¤ã§å¤§ããå¤‰å‹•ã™ã‚‹ã€‚

**ãƒ­ãƒã‚¹ãƒˆçµ±è¨ˆé‡**: å¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’å—ã‘ã«ãã„æŒ‡æ¨™ã€‚

| æŒ‡æ¨™ | å®šç¾© | ãƒ­ãƒã‚¹ãƒˆæ€§ |
|:-----|:-----|:----------|
| **ä¸­å¤®å€¤** | 50%ç‚¹ | â˜…â˜…â˜…â˜…â˜… (æ¥µç«¯å€¤ã®å½±éŸ¿ã‚¼ãƒ­) |
| **MAD** | ä¸­å¤®çµ¶å¯¾åå·® $\text{MAD} = \text{median}(\|x_i - \text{median}(x)\|)$ | â˜…â˜…â˜…â˜…â˜† |
| **IQR** | å››åˆ†ä½ç¯„å›² $\text{IQR} = Q_3 - Q_1$ | â˜…â˜…â˜…â˜…â˜† |

**å¤–ã‚Œå€¤æ¤œå‡ºæ³•**:

| æ‰‹æ³• | åŸºæº– | æ•°å¼ |
|:-----|:-----|:-----|
| **IQRæ³•** | Q1 - 1.5Ã—IQR ~ Q3 + 1.5Ã—IQR ã®ç¯„å›²å¤– | $x < Q_1 - 1.5 \cdot \text{IQR}$ or $x > Q_3 + 1.5 \cdot \text{IQR}$ |
| **Grubbsæ¤œå®š** | tåˆ†å¸ƒã«åŸºã¥ã | $G = \frac{\max\|x_i - \bar{x}\|}{s}$, è‡¨ç•Œå€¤ã¨æ¯”è¼ƒ |
| **z-scoreæ³•** | å¹³å‡ã‹ã‚‰3Ïƒä»¥ä¸Šé›¢ã‚Œã‚‹ | $\|z_i\| = \left\|\frac{x_i - \bar{x}}{s}\right\| > 3$ |

**æ•°å€¤æ¤œè¨¼**:

```julia
using Statistics, StatsBase

data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 100]  # 100ãŒå¤–ã‚Œå€¤

# IQRæ³•
q1, q3 = quantile(data, [0.25, 0.75])
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr
outliers_iqr = data[(data .< lower_bound) .| (data .> upper_bound)]
println("IQRæ³•ã®å¤–ã‚Œå€¤: $outliers_iqr")

# z-scoreæ³•
z_scores = (data .- mean(data)) ./ std(data)
outliers_z = data[abs.(z_scores) .> 3]
println("z-scoreæ³•ã®å¤–ã‚Œå€¤: $outliers_z")

# MADæ³•
med = median(data)
mad = median(abs.(data .- med))
modified_z = 0.6745 * (data .- med) ./ mad  # æ­£è¦åˆ†å¸ƒæ›ç®—
outliers_mad = data[abs.(modified_z) .> 3.5]
println("MADæ³•ã®å¤–ã‚Œå€¤: $outliers_mad")
```

å‡ºåŠ›:
```
IQRæ³•ã®å¤–ã‚Œå€¤: [100]
z-scoreæ³•ã®å¤–ã‚Œå€¤: [100]
MADæ³•ã®å¤–ã‚Œå€¤: [100]
```

:::message
**ã¤ã¾ãšããƒã‚¤ãƒ³ãƒˆ**: ã€Œãªãœn-1ã§å‰²ã‚‹ã®ã‹ã€ã¯çµ±è¨ˆå­¦ã®åˆæ­©ã§ã‚ˆãèº“ãã€‚**ä¸åæ¨å®šé‡**ã®æ¦‚å¿µã‚’ç†è§£ã™ã‚Œã°å…¨ã¦ç¹‹ãŒã‚‹ã€‚ãƒã‚¤ã‚¢ã‚¹ç‰ˆï¼ˆ1/nï¼‰ã¯æ¯åˆ†æ•£ã‚’éå°è©•ä¾¡ã—ã€ä¸åç‰ˆï¼ˆ1/(n-1)ï¼‰ã¯æœŸå¾…å€¤ãŒæ¯åˆ†æ•£ã«ä¸€è‡´ã™ã‚‹ã€‚
:::

### 3.2 æ¨æ¸¬çµ±è¨ˆ: æ¨™æœ¬ã‹ã‚‰æ¯é›†å›£ã¸

#### 3.2.1 æ¨™æœ¬åˆ†å¸ƒã¨æ¨™æº–èª¤å·®

**å•é¡Œ**: æ¨™æœ¬å¹³å‡ $\bar{X}$ ã¯ãƒ©ãƒ³ãƒ€ãƒ å¤‰æ•°ã€‚æ¨™æœ¬ã‚’å–ã‚Šç›´ã™ãŸã³ã«å¤‰å‹•ã™ã‚‹ã€‚ã“ã®å¤‰å‹•ã®å¤§ãã•ã‚’å®šé‡åŒ–ã—ãŸã„ã€‚

**æ¨™æœ¬åˆ†å¸ƒï¼ˆSampling Distributionï¼‰**: æ¨™æœ¬çµ±è¨ˆé‡ï¼ˆä¾‹: $\bar{X}$ï¼‰ã®ç¢ºç‡åˆ†å¸ƒã€‚

**ä¸­å¿ƒæ¥µé™å®šç†ï¼ˆCentral Limit Theorem, CLTï¼‰**:

æ¯é›†å›£åˆ†å¸ƒã«é–¢ã‚ã‚‰ãšã€æ¨™æœ¬ã‚µã‚¤ã‚º $n$ ãŒååˆ†å¤§ãã‘ã‚Œã°æ¨™æœ¬å¹³å‡ã®åˆ†å¸ƒã¯æ­£è¦åˆ†å¸ƒã«å¾“ã†ã€‚

$$
\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i \sim \mathcal{N}\left(\mu, \frac{\sigma^2}{n}\right) \quad \text{as } n \to \infty
$$

**æ¨™æº–èª¤å·®ï¼ˆStandard Error, SEï¼‰**: æ¨™æœ¬å¹³å‡ã®æ¨™æº–åå·®ã€‚

$$
\text{SE}(\bar{X}) = \frac{\sigma}{\sqrt{n}} \approx \frac{s}{\sqrt{n}} \quad \text{(æ¯æ¨™æº–åå·® } \sigma \text{ ãŒæœªçŸ¥ãªã‚‰æ¨™æœ¬SDã§è¿‘ä¼¼)}
$$

**æ•°å€¤æ¤œè¨¼**: CLTã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

```julia
using Distributions, Statistics, Plots

# æ¯é›†å›£: ä¸€æ§˜åˆ†å¸ƒï¼ˆæ­£è¦åˆ†å¸ƒã§ã¯ãªã„ï¼‰
population = Uniform(0, 1)

# ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã”ã¨ã«æ¨™æœ¬å¹³å‡ã®åˆ†å¸ƒã‚’è¦³å¯Ÿ
sample_sizes = [5, 10, 30, 100]
n_trials = 10000

p = plot(layout=(2, 2), size=(800, 600))

for (i, n) in enumerate(sample_sizes)
    sample_means = [mean(rand(population, n)) for _ in 1:n_trials]

    histogram!(p[i], sample_means, bins=30, alpha=0.7, normalize=:pdf,
               label="n=$n", title="Sample Size n=$n")

    # ç†è«–çš„æ­£è¦åˆ†å¸ƒã‚’é‡ã­ã‚‹
    Î¼ = mean(population)  # 0.5
    Ïƒ = std(population)   # 1/âˆš12 â‰ˆ 0.289
    x_range = range(Î¼ - 3*Ïƒ/sqrt(n), Î¼ + 3*Ïƒ/sqrt(n), length=100)
    plot!(p[i], x_range, pdf.(Normal(Î¼, Ïƒ/sqrt(n)), x_range),
          linewidth=2, color=:red, label="ç†è«–åˆ†å¸ƒ")
end

savefig(p, "clt_demo.png")
println("ä¸­å¿ƒæ¥µé™å®šç†: nãŒå¢—ãˆã‚‹ã»ã©æ­£è¦åˆ†å¸ƒã«è¿‘ã¥ã")
```

#### 3.2.2 ä¿¡é ¼åŒºé–“ï¼ˆConfidence Intervalï¼‰

**å®šç¾©**: æ¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä¾‹: æ¯å¹³å‡ $\mu$ï¼‰ãŒå«ã¾ã‚Œã‚‹ç¢ºç‡ãŒ $1-\alpha$ï¼ˆä¾‹: 95%ï¼‰ã¨ãªã‚‹åŒºé–“ã€‚

æ¯å¹³å‡ $\mu$ ã® $(1-\alpha)$% ä¿¡é ¼åŒºé–“:

$$
\bar{x} \pm t_{n-1, \alpha/2} \cdot \frac{s}{\sqrt{n}}
$$

ã“ã“ã§ $t_{n-1, \alpha/2}$ ã¯è‡ªç”±åº¦ $n-1$ ã®tåˆ†å¸ƒã® $\alpha/2$ ç‚¹ï¼ˆä¸¡å´ï¼‰ã€‚

**æ³¨æ„**: ã€Œ95%ä¿¡é ¼åŒºé–“ã€ã®æ­£ã—ã„è§£é‡ˆã¯:

> **ã€Œã“ã®ã‚ˆã†ãªæ‰‹é †ã§ä¿¡é ¼åŒºé–“ã‚’100å›æ§‹ç¯‰ã™ã‚Œã°ã€ãã®ã†ã¡95å›ã¯çœŸã®æ¯å¹³å‡ã‚’å«ã‚€ã€**

âŒ é–“é•ã„: ã€Œæ¯å¹³å‡ãŒã“ã®åŒºé–“ã«å…¥ã‚‹ç¢ºç‡ãŒ95%ã€ï¼ˆæ¯å¹³å‡ã¯å›ºå®šå€¤ã€ç¢ºç‡å¤‰æ•°ã§ã¯ãªã„ï¼‰

**æ•°å€¤æ¤œè¨¼**: ä¿¡é ¼åŒºé–“ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡

```julia
using Distributions, Statistics

# çœŸã®æ¯é›†å›£: N(Î¼=10, Ïƒ=2)
true_Î¼ = 10.0
true_Ïƒ = 2.0
population = Normal(true_Î¼, true_Ïƒ)

# 100å›ã®æ¨™æœ¬æŠ½å‡ºã¨ä¿¡é ¼åŒºé–“æ§‹ç¯‰
n = 30
Î± = 0.05
coverage_count = 0

for _ in 1:100
    sample = rand(population, n)
    xÌ„ = mean(sample)
    s = std(sample)
    se = s / sqrt(n)

    t_critical = quantile(TDist(n-1), 1 - Î±/2)
    ci_lower = xÌ„ - t_critical * se
    ci_upper = xÌ„ + t_critical * se

    # çœŸã®æ¯å¹³å‡ãŒä¿¡é ¼åŒºé–“ã«å«ã¾ã‚Œã‚‹ã‹
    if ci_lower <= true_Î¼ <= ci_upper
        coverage_count += 1
    end
end

println("100å›ä¸­ $(coverage_count) å›ãŒæ¯å¹³å‡ã‚’å«ã‚€ï¼ˆæœŸå¾…å€¤â‰ˆ95å›ï¼‰")
```

å‡ºåŠ›:
```
100å›ä¸­ 94 å›ãŒæ¯å¹³å‡ã‚’å«ã‚€ï¼ˆæœŸå¾…å€¤â‰ˆ95å›ï¼‰
```

#### 3.2.3 ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—æ³•ï¼ˆBootstrapï¼‰

**å•é¡Œ**: æ¨™æœ¬ãŒå°ã•ã„ã€ã¾ãŸã¯åˆ†å¸ƒãŒæœªçŸ¥ã®å ´åˆã€tåˆ†å¸ƒã«ã‚ˆã‚‹ä¿¡é ¼åŒºé–“ãŒä¸æ­£ç¢ºã€‚

**ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—**: æ¨™æœ¬ã‹ã‚‰**å¾©å…ƒæŠ½å‡º**ã§ç–‘ä¼¼æ¨™æœ¬ã‚’å¤§é‡ã«ç”Ÿæˆã—ã€çµ±è¨ˆé‡ã®åˆ†å¸ƒã‚’æ¨å®šã™ã‚‹ã€‚

**æ‰‹é †**:

1. å…ƒã®æ¨™æœ¬ $\{x_1, \ldots, x_n\}$ ã‹ã‚‰å¾©å…ƒæŠ½å‡ºã§ $n$ å€‹ã®ç–‘ä¼¼æ¨™æœ¬ã‚’ä½œã‚‹ï¼ˆ1ã‚»ãƒƒãƒˆï¼‰ã€‚
2. ç–‘ä¼¼æ¨™æœ¬ã®çµ±è¨ˆé‡ï¼ˆä¾‹: å¹³å‡ï¼‰ã‚’è¨ˆç®—ã€‚
3. 1-2ã‚’ $B$ å›ï¼ˆä¾‹: 1000å›ï¼‰ç¹°ã‚Šè¿”ã—ã€çµ±è¨ˆé‡ã®åˆ†å¸ƒã‚’ä½œã‚‹ã€‚
4. åˆ†å¸ƒã®ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ï¼ˆä¾‹: 2.5%, 97.5%ï¼‰ã‹ã‚‰ä¿¡é ¼åŒºé–“ã‚’æ§‹ç¯‰ã€‚

**Percentileæ³•**: å˜ç´”ã«ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—åˆ†å¸ƒã® $\alpha/2$, $1-\alpha/2$ ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã‚’ä½¿ã†ã€‚

**BCaæ³•ï¼ˆBias-Corrected and Acceleratedï¼‰**: ãƒã‚¤ã‚¢ã‚¹è£œæ­£ã¨åŠ é€Ÿè£œæ­£ã‚’åŠ ãˆãŸé«˜ç²¾åº¦ç‰ˆã€‚

**æ•°å€¤æ¤œè¨¼**:

```julia
using Bootstrap, Statistics

data = [0.72, 0.71, 0.73, 0.70, 0.72, 0.71, 0.73, 0.72, 0.71, 0.70]

# ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ï¼ˆ1000å›ï¼‰
bs = bootstrap(mean, data, BasicSampling(1000))

# 95%ä¿¡é ¼åŒºé–“ï¼ˆPercentileæ³•ï¼‰
ci = confint(bs, PercentileConfInt(0.95))
println("ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—95%ä¿¡é ¼åŒºé–“: $(ci[1])")
```

å‡ºåŠ›:
```
ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—95%ä¿¡é ¼åŒºé–“: (0.7, 0.725)
```

:::message
**é€²æ—: 35% å®Œäº†** æ¨æ¸¬çµ±è¨ˆã®æ ¸å¿ƒï¼ˆCLTãƒ»ä¿¡é ¼åŒºé–“ãƒ»ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ï¼‰ã‚’åˆ¶è¦‡ã€‚ä»®èª¬æ¤œå®šã¸ã€‚
:::

### 3.3 ä»®èª¬æ¤œå®š: ç§‘å­¦çš„çµè«–ã‚’å°ã

#### 3.3.1 Neyman-Pearsonæ çµ„ã¿

**ä»®èª¬æ¤œå®šã®ç›®çš„**: ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç§‘å­¦çš„çµè«–ã‚’å°å‡ºã™ã‚‹ã€‚ã€Œå·®ãŒã‚ã‚‹ã€ã€ŒåŠ¹æœãŒã‚ã‚‹ã€ã‚’ç¢ºç‡çš„ã«ç¤ºã™ã€‚

**Neyman-Pearsonæ çµ„ã¿** [^1]:

1. **å¸°ç„¡ä»®èª¬ï¼ˆNull Hypothesis, $H_0$ï¼‰**: ã€Œå·®ãŒãªã„ã€ã€ŒåŠ¹æœãŒãªã„ã€ã¨ã„ã†ä¿å®ˆçš„ãªä»®èª¬ã€‚
2. **å¯¾ç«‹ä»®èª¬ï¼ˆAlternative Hypothesis, $H_1$ï¼‰**: ã€Œå·®ãŒã‚ã‚‹ã€ã€ŒåŠ¹æœãŒã‚ã‚‹ã€ã¨ã„ã†ä¸»å¼µã€‚
3. **æœ‰æ„æ°´æº–ï¼ˆSignificance Level, $\alpha$ï¼‰**: ç¬¬1ç¨®éèª¤ï¼ˆ$H_0$ãŒçœŸãªã®ã«æ£„å´ï¼‰ã‚’è¨±å®¹ã™ã‚‹ç¢ºç‡ã€‚é€šå¸¸ $\alpha = 0.05$ã€‚
4. **æ¤œå®šçµ±è¨ˆé‡**: ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨ˆç®—ã•ã‚Œã‚‹å€¤ï¼ˆä¾‹: tçµ±è¨ˆé‡ï¼‰ã€‚
5. **på€¤**: $H_0$ãŒçœŸã¨ä»®å®šã—ãŸã¨ãã€è¦³æ¸¬ã•ã‚ŒãŸæ¤œå®šçµ±è¨ˆé‡ä»¥ä¸Šã®æ¥µç«¯ãªå€¤ãŒå¾—ã‚‰ã‚Œã‚‹ç¢ºç‡ã€‚
6. **åˆ¤å®š**: $p < \alpha$ ãªã‚‰ $H_0$ ã‚’æ£„å´ â†’ $H_1$ ã‚’æ¡æŠã€‚

**ç¬¬1ç¨®éèª¤ã¨ç¬¬2ç¨®éèª¤**:

| çœŸã®çŠ¶æ…‹ | $H_0$ã‚’æ£„å´ã—ãªã„ | $H_0$ã‚’æ£„å´ |
|:---------|:-----------------|:-----------|
| $H_0$ãŒçœŸ | âœ… æ­£ã—ã„åˆ¤å®š | âŒ **ç¬¬1ç¨®éèª¤ï¼ˆÎ±ï¼‰** |
| $H_1$ãŒçœŸ | âŒ **ç¬¬2ç¨®éèª¤ï¼ˆÎ²ï¼‰** | âœ… æ­£ã—ã„åˆ¤å®šï¼ˆæ¤œå‡ºåŠ›=1-Î²ï¼‰ |

**æ¤œå‡ºåŠ›ï¼ˆPowerï¼‰**: $H_1$ãŒçœŸã®ã¨ãæ­£ã—ã $H_0$ ã‚’æ£„å´ã™ã‚‹ç¢ºç‡ã€‚$1 - \beta$ã€‚

#### 3.3.2 på€¤ã®æ­£ã—ã„è§£é‡ˆ

**på€¤ã®å®šç¾©**:

$$
p\text{-value} = P(\text{Test Stat} \geq t_{\text{obs}} | H_0)
$$

**æ­£ã—ã„è§£é‡ˆ**: ã€Œ$H_0$ãŒçœŸã¨ä»®å®šã—ãŸã¨ãã€è¦³æ¸¬ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ä»¥ä¸Šã«æ¥µç«¯ãªãƒ‡ãƒ¼ã‚¿ãŒå¾—ã‚‰ã‚Œã‚‹ç¢ºç‡ã€ã€‚

âŒ **é–“é•ã£ãŸè§£é‡ˆ**:

1. ã€Œ$H_0$ãŒçœŸã§ã‚ã‚‹ç¢ºç‡ã€ï¼ˆpå€¤ã¯ $H_0$ ã«ã¤ã„ã¦ã®ç¢ºç‡ã§ã¯ãªã„ï¼‰
2. ã€ŒåŠ¹æœã®å¤§ãã•ã€ï¼ˆpå€¤ã¯åŠ¹æœé‡ã¨ã¯ç„¡é–¢ä¿‚ï¼‰
3. ã€Œ$H_1$ãŒçœŸã§ã‚ã‚‹ç¢ºç‡ã€ï¼ˆpå€¤ã¯ $H_1$ ã«ã¤ã„ã¦ã®ç¢ºç‡ã§ã‚‚ãªã„ï¼‰

**p-hacking**: æœ‰æ„ãªçµæœãŒå‡ºã‚‹ã¾ã§åˆ†ææ‰‹æ³•ã‚’å¤‰ãˆç¶šã‘ã‚‹ä¸æ­£è¡Œç‚ºã€‚på€¤ã¯æ‰‹æ³•ãŒ**äº‹å‰ã«æ±ºå®š**ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’å‰æã¨ã™ã‚‹ã€‚

#### 3.3.3 åŠ¹æœé‡ï¼ˆEffect Sizeï¼‰

**å•é¡Œ**: på€¤ã¯çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’ç¤ºã™ãŒã€å®Ÿç”¨çš„ãªå¤§ãã•ã¯ç¤ºã•ãªã„ã€‚ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã‘ã‚Œã°å¾®å°ãªå·®ã§ã‚‚p < 0.05ã«ãªã‚‹ã€‚

**åŠ¹æœé‡**: å·®ã®å®Ÿç”¨çš„ãªå¤§ãã•ã‚’æ¨™æº–åŒ–ã—ãŸæŒ‡æ¨™ã€‚

| æŒ‡æ¨™ | å®šç¾© | ç”¨é€” | è§£é‡ˆ |
|:-----|:-----|:-----|:-----|
| **Cohen's d** | $d = \frac{\bar{x}_1 - \bar{x}_2}{s_{\text{pooled}}}$ | 2ç¾¤æ¯”è¼ƒ | 0.2=å°, 0.5=ä¸­, 0.8=å¤§ |
| **Hedges' g** | Cohen's dã®å°ã‚µãƒ³ãƒ—ãƒ«è£œæ­£ç‰ˆ | 2ç¾¤æ¯”è¼ƒï¼ˆn<20ï¼‰ | åŒä¸Š |
| **Cliff's delta** | é †ä½ã«åŸºã¥ããƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯åŠ¹æœé‡ | é †åºãƒ‡ãƒ¼ã‚¿ | -1 ~ 1 |

**Cohen's dã®å°å‡º**:

$$
d = \frac{\bar{x}_1 - \bar{x}_2}{s_{\text{pooled}}} \quad \text{where } s_{\text{pooled}} = \sqrt{\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}
$$

ãƒ—ãƒ¼ãƒ«ã•ã‚ŒãŸæ¨™æº–åå·® $s_{\text{pooled}}$ ã¯2ç¾¤ã®åˆ†æ•£ã®é‡ã¿ä»˜ãå¹³å‡ã®å¹³æ–¹æ ¹ã€‚

**æ•°å€¤æ¤œè¨¼**:

```julia
using Statistics, HypothesisTests

group1 = [0.72, 0.71, 0.73, 0.70, 0.72, 0.71, 0.73, 0.72, 0.71, 0.70]
group2 = [0.78, 0.77, 0.79, 0.76, 0.78, 0.77, 0.79, 0.78, 0.77, 0.76]

# tæ¤œå®š
test = EqualVarianceTTest(group1, group2)
println("t=$(round(test.t, digits=3)), p=$(round(pvalue(test), digits=6))")

# Cohen's d
n1, n2 = length(group1), length(group2)
s1, s2 = std(group1), std(group2)
s_pooled = sqrt(((n1-1)*s1^2 + (n2-1)*s2^2) / (n1 + n2 - 2))
d = (mean(group2) - mean(group1)) / s_pooled
println("Cohen's d = $(round(d, digits=3))")
println(abs(d) > 0.8 ? "åŠ¹æœé‡: å¤§" : abs(d) > 0.5 ? "åŠ¹æœé‡: ä¸­" : abs(d) > 0.2 ? "åŠ¹æœé‡: å°" : "åŠ¹æœãªã—")
```

å‡ºåŠ›:
```
t=-60.0, p=0.000000
Cohen's d = -6.000
åŠ¹æœé‡: å¤§
```

#### 3.3.4 æ¤œå‡ºåŠ›åˆ†æï¼ˆPower Analysisï¼‰

**å•é¡Œ**: å®Ÿé¨“å‰ã«ã€Œå¿…è¦ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã€ã‚’æ±ºã‚ãŸã„ã€‚

**æ¤œå‡ºåŠ›**: çœŸã®åŠ¹æœãŒå­˜åœ¨ã™ã‚‹ã¨ãã€ãã‚Œã‚’æ¤œå‡ºã§ãã‚‹ç¢ºç‡ã€‚$\text{Power} = 1 - \beta$ï¼ˆç¬¬2ç¨®éèª¤ç‡ï¼‰ã€‚

**æ¤œå‡ºåŠ›ã®æ±ºå®šè¦å› **:

1. **åŠ¹æœé‡** $d$: å¤§ãã„ã»ã©æ¤œå‡ºã—ã‚„ã™ã„ã€‚
2. **ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º** $n$: å¤§ãã„ã»ã©æ¤œå‡ºã—ã‚„ã™ã„ã€‚
3. **æœ‰æ„æ°´æº–** $\alpha$: å¤§ãã„ã»ã©æ¤œå‡ºã—ã‚„ã™ã„ï¼ˆãŒã€ç¬¬1ç¨®éèª¤ãŒå¢—ãˆã‚‹ï¼‰ã€‚
4. **æ¤œå®šã®ç¨®é¡**: ç‰‡å´ vs ä¸¡å´ï¼ˆç‰‡å´ã®æ–¹ãŒæ¤œå‡ºåŠ›é«˜ã„ï¼‰ã€‚

**tæ¤œå®šã®æ¤œå‡ºåŠ›å…¬å¼**ï¼ˆè¿‘ä¼¼ï¼‰:

$$
\text{Power} = \Phi\left(\frac{|d|\sqrt{n}}{2} - z_{1-\alpha/2}\right)
$$

ã“ã“ã§ $\Phi$ ã¯æ¨™æº–æ­£è¦åˆ†å¸ƒã®ç´¯ç©åˆ†å¸ƒé–¢æ•°ã€$z_{1-\alpha/2}$ ã¯æ¨™æº–æ­£è¦åˆ†å¸ƒã® $1-\alpha/2$ åˆ†ä½ç‚¹ã€‚

**æ•°å€¤æ¤œè¨¼**: åŠ¹æœé‡d=0.5ã€Î±=0.05ã€Power=0.8ã«å¿…è¦ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º

```julia
using Distributions

function sample_size_for_ttest(d, Î±, power)
    z_Î± = quantile(Normal(), 1 - Î±/2)
    z_Î² = quantile(Normal(), power)
    n = ((z_Î± + z_Î²) / d)^2 * 2
    return ceil(Int, n)
end

n_required = sample_size_for_ttest(0.5, 0.05, 0.8)
println("åŠ¹æœé‡d=0.5, Î±=0.05, Power=0.8 â†’ å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: $n_required (å„ç¾¤)")
```

å‡ºåŠ›:
```
åŠ¹æœé‡d=0.5, Î±=0.05, Power=0.8 â†’ å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: 64 (å„ç¾¤)
```

:::message
**é€²æ—: 50% å®Œäº†** ä»®èª¬æ¤œå®šã®ç†è«–ï¼ˆNeyman-Pearsonæ çµ„ã¿ãƒ»på€¤ãƒ»åŠ¹æœé‡ãƒ»æ¤œå‡ºåŠ›ï¼‰ã‚’å®Œå…¨ç†è§£ã€‚ãƒœã‚¹æˆ¦: ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯æ¤œå®šã¸ã€‚
:::

### 3.4 ãƒœã‚¹æˆ¦: ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯æ¤œå®šå®Œå…¨ç‰ˆ

#### 3.4.1 tæ¤œå®šï¼ˆStudent's t-testï¼‰

**ç”¨é€”**: 2ç¾¤ã®å¹³å‡å·®ã®æ¤œå®šã€‚

| æ¤œå®š | ç”¨é€” | ä»®å®š |
|:-----|:-----|:-----|
| **1æ¨™æœ¬tæ¤œå®š** | æ¨™æœ¬å¹³å‡ vs æ—¢çŸ¥ã®å€¤ | æ­£è¦æ€§ |
| **2æ¨™æœ¬tæ¤œå®šï¼ˆå¯¾å¿œãªã—ï¼‰** | ç‹¬ç«‹ãª2ç¾¤ã®å¹³å‡å·® | æ­£è¦æ€§ãƒ»ç­‰åˆ†æ•£ |
| **Welchæ¤œå®š** | ç‹¬ç«‹ãª2ç¾¤ï¼ˆç­‰åˆ†æ•£ã§ãªã„ï¼‰ | æ­£è¦æ€§ |
| **å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š** | åŒä¸€å¯¾è±¡ã®Before/After | å·®ã®æ­£è¦æ€§ |

**tçµ±è¨ˆé‡ï¼ˆå¯¾å¿œãªã—ï¼‰**:

$$
t = \frac{\bar{x}_1 - \bar{x}_2}{s_{\text{pooled}} \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} \sim t_{n_1 + n_2 - 2} \quad \text{under } H_0
$$

**Welchæ¤œå®šï¼ˆç­‰åˆ†æ•£ã‚’ä»®å®šã—ãªã„ï¼‰**:

$$
t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}} \sim t_{\nu} \quad \text{where } \nu = \frac{\left(\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}\right)^2}{\frac{(s_1^2/n_1)^2}{n_1-1} + \frac{(s_2^2/n_2)^2}{n_2-1}}
$$

è‡ªç”±åº¦ $\nu$ ã¯Welch-Satterthwaiteå¼ã§è¨ˆç®—ã€‚

**æ•°å€¤æ¤œè¨¼**:

```julia
using HypothesisTests

group1 = [0.72, 0.71, 0.73, 0.70, 0.72]
group2 = [0.78, 0.77, 0.79, 0.76, 0.78, 0.77, 0.79]  # ç•°ãªã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º

# ç­‰åˆ†æ•£tæ¤œå®š
test_equal = EqualVarianceTTest(group1, group2)
println("ç­‰åˆ†æ•£tæ¤œå®š: t=$(round(test_equal.t, digits=3)), p=$(round(pvalue(test_equal), digits=4))")

# Welchæ¤œå®šï¼ˆç­‰åˆ†æ•£ã‚’ä»®å®šã—ãªã„ï¼‰
test_welch = UnequalVarianceTTest(group1, group2)
println("Welchæ¤œå®š: t=$(round(test_welch.t, digits=3)), df=$(round(test_welch.df, digits=2)), p=$(round(pvalue(test_welch), digits=4))")
```

å‡ºåŠ›:
```
ç­‰åˆ†æ•£tæ¤œå®š: t=-17.32, p=0.0000
Welchæ¤œå®š: t=-19.6, df=9.33, p=0.0000
```

#### 3.4.2 ANOVAï¼ˆAnalysis of Varianceï¼‰

**ç”¨é€”**: 3ç¾¤ä»¥ä¸Šã®å¹³å‡å·®ã®æ¤œå®šã€‚

**ä¸€å…ƒé…ç½®ANOVAï¼ˆOne-way ANOVAï¼‰**:

- $H_0$: ã™ã¹ã¦ã®ç¾¤ã®æ¯å¹³å‡ãŒç­‰ã—ã„ $\mu_1 = \mu_2 = \cdots = \mu_k$
- $H_1$: å°‘ãªãã¨ã‚‚1çµ„ã®å¹³å‡ãŒç•°ãªã‚‹

**Fçµ±è¨ˆé‡**:

$$
F = \frac{\text{MS}_{\text{between}}}{\text{MS}_{\text{within}}} = \frac{\text{ç¾¤é–“åˆ†æ•£}}{\text{ç¾¤å†…åˆ†æ•£}} \sim F_{k-1, N-k} \quad \text{under } H_0
$$

