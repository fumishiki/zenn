---
title: "ç¬¬33å›: Normalizing Flowsã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨: å®Ÿè£…â†’å®Ÿé¨“â†’ãƒã‚¹ã‚¿ãƒ¼"
emoji: "ğŸ”„"
type: "tech"
topics: ["machinelearning"]
published: true
slug: "ml-lecture-33-part2"
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Julia", "Rust"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---
## ğŸ’» 4. å®Ÿè£…ã‚¾ãƒ¼ãƒ³ï¼ˆ45åˆ†ï¼‰â€” Julia/Rustã§Flowã‚’æ›¸ã

**ã‚´ãƒ¼ãƒ«**: RealNVP/Glow/CNFã®å®Ÿè£…åŠ›ã‚’èº«ã«ã¤ã‘ã‚‹ã€‚

### 4.1 Julia Flowå®Ÿè£…ã®å…¨ä½“è¨­è¨ˆ

**ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ§‹æˆ**:

```julia
# Normalizing Flows in Julia
using Lux           # é–¢æ•°å‹NN (å‹å®‰å®š+GPU AOT)
using Reactant      # GPU AOT compilation
using DifferentialEquations  # ODE solver (CNFç”¨)
using Distributions
using LinearAlgebra
using Optimisers, Zygote
using Random
```

**Luxé¸æŠç†ç”±**: Immutable (functional) â†’ å‹å®‰å®šæ€§ â†’ Reactant GPU AOT â†’ Production-readyã€‚

> **âš ï¸ Warning:** Lux ã® `ps`ï¼ˆparametersï¼‰ã¨ `st`ï¼ˆstatesï¼‰ã‚’æ··åŒã—ãªã„ã“ã¨ã€‚`ps` ã¯è¨“ç·´ã§æ›´æ–°ã•ã‚Œã‚‹é‡ã¿ã€`st` ã¯ BatchNorm çµ±è¨ˆãªã©ã®çŠ¶æ…‹ï¼ˆè¨“ç·´ä¸­ã¨æ¨è«–æ™‚ã§å‹•ä½œãŒç•°ãªã‚‹ï¼‰ã€‚Flux.jl ã‹ã‚‰ Lux.jl ã¸ç§»è¡Œã™ã‚‹éš›ã®æœ€å¤§ã®è½ã¨ã—ç©´ã€‚

### 4.2 Coupling Layerå®Ÿè£…

```julia
# Affine Coupling Layer (Lux style)
function affine_coupling_forward(z, s_net, t_net, ps_s, ps_t, st_s, st_t, d)
    @views z1 = z[1:d, :]          # identity part
    @views z2 = z[d+1:end, :]      # transform part

    # Compute scale & translation from z1
    s, st_s_new = s_net(z1, ps_s, st_s)
    t, st_t_new = t_net(z1, ps_t, st_t)

    # Affine transformation
    x1 = z1
    x2 = z2 .* exp.(s) .+ t
    x = vcat(x1, x2)

    # log|det J| = sum(s)
    log_det_jac = vec(sum(s, dims=1))

    # shape: s âˆˆ â„^{(D-d)Ã—B} â†’ sum over dim=1 â†’ â„^Bï¼ˆãƒãƒƒãƒã”ã¨ã®logè¡Œåˆ—å¼ï¼‰
    # ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³ãŒä¸‹ä¸‰è§’ãƒ–ãƒ­ãƒƒã‚¯æ§‹é€ ã‚’æŒã¤ãŸã‚ã€å¯¾è§’æˆåˆ† exp(s_i) ã®ç©ãŒè¡Œåˆ—å¼ã«ãªã‚‹
    # â†’ log|det J| = Î£áµ¢ sáµ¢ï¼ˆO(D)ã€è¡Œåˆ—å¼ã®O(DÂ³)ã§ã¯ãªã„ï¼‰

    return x, log_det_jac, (st_s_new, st_t_new)
end

# Inverse
function affine_coupling_inverse(x, s_net, t_net, ps_s, ps_t, st_s, st_t, d)
    @views x1 = x[1:d, :]
    @views x2 = x[d+1:end, :]

    s, st_s_new = s_net(x1, ps_s, st_s)
    t, st_t_new = t_net(x1, ps_t, st_t)

    z1 = x1
    z2 = (x2 .- t) .* exp.(-s)
    z = vcat(z1, z2)

    log_det_jac = -vec(sum(s, dims=1))

    return z, log_det_jac, (st_s_new, st_t_new)
end
```

### 4.3 RealNVP Stack

```julia
# RealNVP: Stack of coupling layers
function create_realnvp(in_dim::Int, hidden_dim::Int, n_layers::Int)
    rng = Random.default_rng()
    layers = []

    for i in 1:n_layers
        d = i % 2 == 1 ? in_dim Ã· 2 : in_dim - in_dim Ã· 2
        s_net = Chain(
            Dense(d, hidden_dim, tanh),
            Dense(hidden_dim, hidden_dim, tanh),
            Dense(hidden_dim, in_dim - d)
        )
        t_net = Chain(
            Dense(d, hidden_dim, tanh),
            Dense(hidden_dim, hidden_dim, tanh),
            Dense(hidden_dim, in_dim - d)
        )
        push!(layers, (s_net, t_net, d))
    end

    return layers
end

# Forward: z â†’ x
function realnvp_forward(layers, z, ps_list, st_list)
    x = z
    log_det_sum = zeros(Float32, size(z, 2))
    st_new_list = []

    for (i, (s_net, t_net, d)) in enumerate(layers)
        x, ldj, st_new = affine_coupling_forward(
            x, s_net, t_net,
            ps_list[i].s, ps_list[i].t,
            st_list[i].s, st_list[i].t,
            d
        )
        log_det_sum .+= ldj
        push!(st_new_list, (s=st_new[1], t=st_new[2]))
    end

    return x, log_det_sum, st_new_list
end

# Inverse: x â†’ z
function realnvp_inverse(layers, x, ps_list, st_list)
    z = x
    log_det_sum = zeros(Float32, size(x, 2))
    st_new_list = []

    for (i, (s_net, t_net, d)) in enumerate(reverse(enumerate(layers)))
        idx = length(layers) - i + 1
        z, ldj, st_new = affine_coupling_inverse(
            z, s_net, t_net,
            ps_list[idx].s, ps_list[idx].t,
            st_list[idx].s, st_list[idx].t,
            d
        )
        log_det_sum .+= ldj
        pushfirst!(st_new_list, (s=st_new[1], t=st_new[2]))
    end

    return z, log_det_sum, st_new_list
end
```

### 4.4 è¨“ç·´ãƒ«ãƒ¼ãƒ—

```julia
# Loss: Negative log-likelihood
function nll_loss(layers, ps_list, st_list, x_batch, base_dist)
    # Inverse: x â†’ z
    z, log_det_sum, _ = realnvp_inverse(layers, x_batch, ps_list, st_list)

    # log p(z)
    log_pz = sum(logpdf.(base_dist, z), dims=1)  # sum over D

    # shape: z âˆˆ â„^{DÃ—B}, logpdf.(base_dist, z) âˆˆ â„^{DÃ—B}, sum(dims=1) âˆˆ â„^{1Ã—B}
    # å„æ¬¡å…ƒã®ç‹¬ç«‹æ­£è¦åˆ†å¸ƒã®å¯¾æ•°å°¤åº¦ã‚’åˆè¨ˆ: log p(z) = Î£áµ¢ logğ’©(záµ¢; 0,1) = -D/2Â·log(2Ï€) - Î£áµ¢ záµ¢Â²/2

    # log p(x) = log p(z) + log|det J|
    log_px = vec(log_pz) .+ log_det_sum

    # NLL
    return -mean(log_px)
end

# Training
function train_realnvp!(layers, ps_list, st_list, data_loader, base_dist, opt_state, n_epochs)
    for epoch in 1:n_epochs
        epoch_loss = 0.0
        n_batches = 0

        for x_batch in data_loader
            # Compute loss and gradients
            loss, grads = Zygote.withgradient(ps_list) do ps
                nll_loss(layers, ps, st_list, x_batch, base_dist)
            end

            # Update parameters
            opt_state, ps_list = Optimisers.update(opt_state, ps_list, grads[1])

            epoch_loss += loss
            n_batches += 1
        end

        if epoch % 10 == 0
            avg_loss = epoch_loss / n_batches
            println("Epoch $epoch: NLL = $(round(avg_loss, digits=4))")
        end
    end

    return ps_list, st_list
end
```

### 4.5 CNF/FFJORDå®Ÿè£…

```julia
using DifferentialEquations

# CNF dynamics with Hutchinson trace estimator
function cnf_dynamics!(du, u, p, t)
    # u = [z; log_det_jac]
    f_net, ps, st = p
    D = length(u) - 1
    @views z = u[1:D]

    # Velocity: dz/dt = f(z, t)
    z_mat = reshape(z, :, 1)
    dz, _ = f_net(z_mat, ps, st)
    dz = vec(dz)

    # Hutchinson trace estimator
    Îµ = randn(Float32, D)
    jvp = Zygote.gradient(z -> dot(vec(f_net(reshape(z, :, 1), ps, st)[1]), Îµ), z)[1]
    tr_jac = dot(Îµ, jvp)  # Îµ^T * (âˆ‚f/âˆ‚z) * Îµ

    # ãªãœã“ã‚ŒãŒ tr(âˆ‚f/âˆ‚z) ã‚’æ¨å®šã™ã‚‹ã‹:
    # E[Îµ^T A Îµ] = E[Î£áµ¢â±¼ Îµáµ¢ Aáµ¢â±¼ Îµâ±¼] = Î£áµ¢ Aáµ¢áµ¢ E[Îµáµ¢Â²] = tr(A)  ï¼ˆâˆµ E[Îµáµ¢Îµâ±¼]=Î´áµ¢â±¼ï¼‰
    # è¨ˆç®—é‡: ç›´æ¥è¨ˆç®— O(DÂ²) â†’ Hutchinson O(D)ï¼ˆVJPãŒ1å›ã®AD passã§è¨ˆç®—å¯èƒ½ï¼‰

    # d(log_det)/dt = -tr(âˆ‚f/âˆ‚z)
    @views du[1:D] .= dz
    du[D+1] = -tr_jac
end

# Solve CNF
function solve_cnf(f_net, ps, st, z0, tspan)
    D = length(z0)
    u0 = vcat(z0, 0.0f0)  # [z; log_det_jac=0]

    prob = ODEProblem(cnf_dynamics!, u0, tspan, (f_net, ps, st))
    sol = solve(prob, Tsit5())

    z1 = sol.u[end][1:D]
    log_det_jac = sol.u[end][D+1]

    return z1, log_det_jac
end
```

### 4.6 Rustæ¨è«–å®Ÿè£…

Rustå´ã¯è¨“ç·´æ¸ˆã¿ONNXãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§æ¨è«–ã€‚

```rust
// Affine Coupling Layer in Rust
pub struct AffineCouplingLayer {
    split_dim: usize,
    s_weights: Vec<Vec<f32>>,  // simplified: full ONNX would use ort
    t_weights: Vec<Vec<f32>>,
}

impl AffineCouplingLayer {
    pub fn forward(&self, z: &[f32]) -> (Vec<f32>, f32) {
        let d = self.split_dim;
        let (z1, z2) = z.split_at(d);

        // Compute scale & translation (simplified MLP)
        let s = self.mlp_forward(&self.s_weights, z1);
        let t = self.mlp_forward(&self.t_weights, z1);

        // Affine transformation
        let x2: Vec<f32> = z2.iter().zip(s.iter()).zip(t.iter())
            .map(|((z2i, si), ti)| z2i * si.exp() + ti)
            .collect::<Vec<_>>();
        let mut x = z1.to_vec();
        x.extend(x2);

        let log_det_jac: f32 = s.iter().sum();

        (x, log_det_jac)
    }

    fn mlp_forward(&self, weights: &[Vec<f32>], input: &[f32]) -> Vec<f32> {
        // Simplified: 2-layer MLP with tanh
        // Full implementation would use ONNX Runtime
        input.to_vec()  // placeholder
    }
}

// RealNVP inference
pub struct RealNVP {
    layers: Vec<AffineCouplingLayer>,
    dim: usize,
}

impl RealNVP {
    pub fn sample(&self, rng: &mut impl Rng) -> Vec<f32> {
        // Sample z ~ N(0, I)
        let z: Vec<f32> = (0..self.dim).map(|_| rng.sample(StandardNormal)).collect();

        // Forward: z â†’ x
        self.forward(&z).0
    }

    pub fn log_prob(&self, x: &[f32]) -> f32 {
        // Inverse: x â†’ z
        let (z, log_det_jac) = self.inverse(x);

        // log p(z) = -0.5 * (z^2 + log(2Ï€))
        let log_pz: f32 = z.iter().map(|zi| -0.5 * (zi * zi + (2.0 * std::f32::consts::PI).ln())).sum();

        log_pz + log_det_jac
    }

    fn forward(&self, z: &[f32]) -> (Vec<f32>, f32) {
        self.layers.iter().fold((z.to_vec(), 0.0f32), |(x, sum), layer| {
            let (x_new, ldj) = layer.forward(&x);
            (x_new, sum + ldj)
        })
    }

    fn inverse(&self, x: &[f32]) -> (Vec<f32>, f32) {
        let mut z = x.to_vec();
        let mut log_det_sum = 0.0;

        for layer in self.layers.iter().rev() {
            // Inverse coupling (not shown: requires inverse method)
            // z = layer.inverse(&z);
            // log_det_sum += ldj;
        }

        (z, log_det_sum)
    }
}
```

### 4.7 æ•°å¼â†”ã‚³ãƒ¼ãƒ‰å¯¾å¿œè¡¨

| æ•°å¼ | Julia | Rust |
|:-----|:------|:-----|
| $\log p(x) = \log p(z) - \log \|\det J\|$ | `logpdf(base_dist, z) - log_det_jac` | `log_pz - log_det_jac` |
| $x_2 = z_2 \odot \exp(s) + t$ | `z2 .* exp.(s) .+ t` | `z2[i] * s[i].exp() + t[i]` |
| $\log \|\det J\| = \sum s_i$ | `sum(s)` | `s.iter().sum()` |
| $\text{tr}(A) = \mathbb{E}[\epsilon^T A \epsilon]$ | `dot(Îµ, jvp)` | - (training only) |

**shape è¿½è·¡ã‚µãƒãƒªãƒ¼**:
- Coupling forward: $z \in \mathbb{R}^{D \times B} \to (x \in \mathbb{R}^{D \times B},\ \text{ldj} \in \mathbb{R}^B)$
- NLL loss: $x \in \mathbb{R}^{D \times B} \to z \in \mathbb{R}^{D \times B} \to \log p_z \in \mathbb{R}^B \to \text{NLL} \in \mathbb{R}$
- å…¨ $B$ ã‚µãƒ³ãƒ—ãƒ«ã§å¹³å‡ â†’ ã‚¹ã‚«ãƒ©ãƒ¼ loss

> **Note:** **é€²æ—: 70% å®Œäº†** Julia/Rustå®Ÿè£…å®Œäº†ã€‚æ¬¡ã¯å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ â€” 2D/MNISTè¨“ç·´ãƒ»è©•ä¾¡ã€‚

---

## ğŸ”¬ 5. å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” Flowã®è¨“ç·´ã¨è©•ä¾¡

**ã‚´ãƒ¼ãƒ«**: 2D toy dataset / MNIST ã§Flowã‚’è¨“ç·´ã—ã€æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹ã€‚

### 5.1 2D Toy Dataset: Two Moons

#### 5.1.1 ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ

```julia
using Plots

function generate_two_moons(n_samples::Int; noise=0.1)
    n_per_moon = n_samples Ã· 2

    # Upper moon
    Î¸1 = range(0, Ï€, length=n_per_moon)
    x1_upper = cos.(Î¸1)
    x2_upper = sin.(Î¸1)

    # Lower moon
    Î¸2 = range(0, Ï€, length=n_per_moon)
    x1_lower = 1 .- cos.(Î¸2)
    x2_lower = 0.5 .- sin.(Î¸2)

    # Add noise
    x1 = vcat(x1_upper, x1_lower) .+ noise * randn(n_samples)
    x2 = vcat(x2_upper, x2_lower) .+ noise * randn(n_samples)

    return Float32.(hcat(x1, x2))'  # (2, n_samples)
end

data = generate_two_moons(1000)
scatter(data[1, :], data[2, :], alpha=0.5, label="Two Moons", aspect_ratio=:equal)
```

#### 5.1.2 RealNVPè¨“ç·´

```julia
# Setup
rng = Random.default_rng()
in_dim = 2
hidden_dim = 64
n_layers = 8

layers = create_realnvp(in_dim, hidden_dim, n_layers)
ps_list = [initialize_params(rng, s_net, t_net) for (s_net, t_net, _) in layers]
st_list = [initialize_states(rng, s_net, t_net) for (s_net, t_net, _) in layers]

# Base distribution
base_dist = Normal(0.0f0, 1.0f0)


# Optimizer
opt = Adam(1e-3)
opt_state = Optimisers.setup(opt, ps_list)

# Data loader
batch_size = 256
data_loader = [data[:, i:min(i+batch_size-1, end)] for i in 1:batch_size:size(data, 2)]

# Train
n_epochs = 500
ps_list, st_list = train_realnvp!(layers, ps_list, st_list, data_loader, base_dist, opt_state, n_epochs)
```

Output:
```
Epoch 10: NLL = 2.1542
Epoch 20: NLL = 1.8765
...
Epoch 500: NLL = 1.2341
```

**NLL ã®ä¸‹ç•Œ**: 2D ã‚¬ã‚¦ã‚¹æ··åˆï¼ˆTwo Moonsï¼‰ã®çœŸã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã¯ $H \approx 1.0$ï¼ˆnatsï¼‰ã€‚NLL=1.23 ã¯ã“ã‚Œã«è¿‘ã„ â†’ å¯†åº¦æ¨å®šãŒã»ã¼åæŸã€‚NLL ãŒã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚’å¤§ããä¸‹å›ã‚‹ã“ã¨ã¯ãªã„ï¼ˆãªãœãªã‚‰ $-\mathbb{E}_{p_\text{data}}[\log p_\theta(x)] \geq H(p_\text{data})$ ã¯æˆã‚Šç«‹ãŸãªã„ãŸã‚ï¼‰ã€‚NLL < $H$ ã«ãªã£ãŸã‚‰ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒˆã‹è¨ˆç®—ãƒã‚°ã‚’ç–‘ã†ã“ã¨ã€‚

#### 5.1.3 ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«å¯è¦–åŒ–

```julia
# Sample from trained model
n_samples = 1000
z_samples = randn(Float32, 2, n_samples)
x_samples, _, _ = realnvp_forward(layers, z_samples, ps_list, st_list)

# Plot
p1 = scatter(data[1, :], data[2, :], alpha=0.3, label="Real", c=:blue)
scatter!(p1, x_samples[1, :], x_samples[2, :], alpha=0.3, label="Generated", c=:red)
title!(p1, "RealNVP: Two Moons")
```

#### 5.1.4 å¯†åº¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—

```julia
# Compute log p(x) on grid
x_range = range(-2, 3, length=100)
y_range = range(-1.5, 2, length=100)
log_px_grid = zeros(Float32, 100, 100)

for (i, x) in enumerate(x_range), (j, y) in enumerate(y_range)
    point = Float32[x; y;;]
    z, ldj, _ = realnvp_inverse(layers, point, ps_list, st_list)
    log_pz = sum(logpdf.(base_dist, z))
    log_px_grid[j, i] = log_pz + ldj[1]
end

heatmap(x_range, y_range, log_px_grid, title="log p(x)", aspect_ratio=:equal)
```

### 5.2 MNIST: Tiny RealNVP

#### 5.2.1 ãƒ‡ãƒ¼ã‚¿æº–å‚™

```julia
using MLDatasets

# Load MNIST
train_x, _ = MNIST(:train)[:]
test_x, _ = MNIST(:test)[:]

# Flatten: (28, 28, 1, N) â†’ (784, N)
train_x_flat = reshape(train_x, 784, :)
test_x_flat = reshape(test_x, 784, :)

# Dequantize + logit transform
function logit_transform(x; Î±=0.05f0)
    x_dequant = x .+ Î± .* rand(Float32, size(x))
    x_clip = clamp.(x_dequant, Î±, 1 - Î±)
    return @. log(x_clip / (1 - x_clip))
end

# ãªãœ logit å¤‰æ›ãŒå¿…è¦ã‹:
# MNIST ã¯ [0,1] ã®æœ‰ç•ŒåŒºé–“ â†’ Gaussian base åˆ†å¸ƒã¨ä¸æ•´åˆ
# logit(x) = log(x/(1-x)) ã§ [0,1] â†’ â„ ã«å¤‰æ› â†’ Gaussian ã«è¿‘ä¼¼
# Î±=0.05 ã¯ dequantization ã®ãŸã‚ã« [0.05, 0.95] ã«ã‚¯ãƒªãƒƒãƒ— â†’ log(0)=âˆ’âˆ ã‚’é˜²ã

train_x_trans = logit_transform(Float32.(train_x_flat))
test_x_trans = logit_transform(Float32.(test_x_flat))
```

#### 5.2.2 Tiny RealNVPè¨“ç·´

```julia
# Model: 784-dim, 256 hidden, 12 layers
layers_mnist = create_realnvp(784, 256, 12)
ps_mnist = [initialize_params(rng, s, t) for (s, t, _) in layers_mnist]
st_mnist = [initialize_states(rng, s, t) for (s, t, _) in layers_mnist]

# Train (20 epochs, batch_size=128)
opt_mnist = Adam(1e-4)
opt_state_mnist = Optimisers.setup(opt_mnist, ps_mnist)

batch_size_mnist = 128
data_loader_mnist = [train_x_trans[:, i:min(i+batch_size_mnist-1, end)]
                     for i in 1:batch_size_mnist:size(train_x_trans, 2)]

n_epochs_mnist = 20
ps_mnist, st_mnist = train_realnvp!(
    layers_mnist, ps_mnist, st_mnist,
    data_loader_mnist, base_dist,
    opt_state_mnist, n_epochs_mnist
)
```

#### 5.2.3 ç”Ÿæˆç”»åƒ

```julia
# Sample
n_samples_img = 16
z_img = randn(Float32, 784, n_samples_img)
x_img, _, _ = realnvp_forward(layers_mnist, z_img, ps_mnist, st_mnist)

# Inverse logit
x_img_sigmoid = @. 1 / (1 + exp(-x_img))
x_img_reshape = reshape(x_img_sigmoid, 28, 28, 1, n_samples_img)

# Plot 4x4 grid
plot([Gray.(x_img_reshape[:, :, 1, i]) for i in 1:16]..., layout=(4, 4), size=(400, 400))
```

### 5.3 è‡ªå·±è¨ºæ–­ãƒ†ã‚¹ãƒˆ

#### 5.3.1 ç†è«–ãƒã‚§ãƒƒã‚¯

<details><summary>**Q1: Change of Variableså…¬å¼**</summary>

> $X = f(Z)$, $f$ å¯é€†ã€‚$p_X(x)$ ã‚’ $p_Z$ ã¨ $f$ ã§è¡¨ã›ã€‚

**è§£ç­”**: $p_X(x) = p_Z(f^{-1}(x)) \left| \det \frac{\partial f^{-1}}{\partial x} \right| = p_Z(z) \left| \det \frac{\partial f}{\partial z} \right|^{-1}$

</details>

<details><summary>**Q2: Coupling Layerãƒ¤ã‚³ãƒ“ã‚¢ãƒ³**</summary>

> $x_{1:d} = z_{1:d}$, $x_{d+1:D} = z_{d+1:D} \odot \exp(s(z_{1:d})) + t(z_{1:d})$ã€‚$\log |\det J|$ = ?

**è§£ç­”**: $\log |\det J| = \sum_{i=1}^{D-d} s_i(z_{1:d})$ (ä¸‹ä¸‰è§’ãƒ–ãƒ­ãƒƒã‚¯è¡Œåˆ—ã®å¯¾è§’æˆåˆ†ã®ç©)

</details>

<details><summary>**Q3: CNFå¯†åº¦å¤‰åŒ–**</summary>

> $\frac{dz}{dt} = f(z, t)$ã€‚$\frac{\partial \log p(z(t))}{\partial t}$ = ?

**è§£ç­”**: $\frac{\partial \log p(z(t))}{\partial t} = -\text{tr}\left(\frac{\partial f}{\partial z}\right)$ (Liouvilleã®å®šç†)

</details>

<details><summary>**Q4: Hutchinson trace**</summary>

> $\text{tr}(A)$ ã‚’æœŸå¾…å€¤ã§ã€‚

**è§£ç­”**: $\text{tr}(A) = \mathbb{E}_{\epsilon \sim \mathcal{N}(0,I)}[\epsilon^T A \epsilon]$

</details>

<details><summary>**Q5: Flow vs VAE vs GANå°¤åº¦**</summary>

**è§£ç­”**:
- Flow: å³å¯† $\log p(x) = \log p(z) - \log |\det J|$
- VAE: è¿‘ä¼¼ ELBO $\leq \log p(x)$
- GAN: ä¸æ˜ (æš—é»™çš„)

</details>

> Progress: 85%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. RealNVP Juliaå®Ÿè£…ã«ãŠã„ã¦ affine coupling ã®è¡Œåˆ—å¼è¨ˆç®—ãŒ $O(1)$ ã«ãªã‚‹ç†ç”±ã‚’ã‚³ãƒ¼ãƒ‰ã®å¯¾å¿œå¤‰æ•°åã¨æ•°å¼ã§ç¤ºã›ã€‚
>    - *ãƒ’ãƒ³ãƒˆ*: `log_det_jac = vec(sum(s, dims=1))` ã® `s` ã¯ã©ã®å¤‰æ•°ã‹ã€‚ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³ã®ä¸‰è§’ãƒ–ãƒ­ãƒƒã‚¯æ§‹é€ ã‚’æ›¸ãå‡ºã›ã€‚
> 2. NCSNã¨ã®æ¯”è¼ƒã§ã€NFã®å¯†åº¦æ¨å®šãŒä½æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã§å„ªã‚Œé«˜æ¬¡å…ƒã§åŠ£ã‚‹å‚¾å‘ãŒã‚ã‚‹ç†ç”±ã‚’è¿°ã¹ã‚ˆã€‚
>    - *ãƒ’ãƒ³ãƒˆ*: Coupling Layer ã®ã€Œå¤‰æ•°åˆ†å‰²ã€ãŒé«˜æ¬¡å…ƒã§ã©ã†ã„ã†æƒ…å ±æå¤±ã‚’å¼•ãèµ·ã“ã™ã‹è€ƒãˆã‚ˆã€‚

## Zone 6: ğŸ“ æŒ¯ã‚Šè¿”ã‚Š + çµ±åˆã‚¾ãƒ¼ãƒ³ï¼ˆ30minï¼‰

> **Note:** **Zone 6ã®ç›®çš„**: Flowã¨Diffusionã®çµ±ä¸€ç†è«–ã§ã‚ã‚‹**Flow Matching**ã‚’ç†è§£ã—ã€JKOã‚¹ã‚­ãƒ¼ãƒ ã®æ•°ç†åŸºç›¤ã‚’å­¦ã¶ã€‚2024-2026ã®æœ€æ–°ç ”ç©¶å‹•å‘ã‚’æŠŠæ¡ã—ã€Normalizing Flowã®æœªæ¥ã‚’å±•æœ›ã™ã‚‹ã€‚

### 6.1 Flow Matching: Flowã¨Diffusionã®çµ±ä¸€

#### 6.1.1 Flow Matchingã®å‹•æ©Ÿ

**å•é¡Œ**: CNF/FFJORDã¯å¼·åŠ›ã ãŒã€ä»¥ä¸‹ã®èª²é¡ŒãŒã‚ã‚‹:

1. **å°¤åº¦è¨ˆç®—ã‚³ã‚¹ãƒˆ**: Hutchinson trace estimatorã¯åˆ†æ•£ãŒå¤§ããä¸å®‰å®š
2. **ODEã‚½ãƒ«ãƒãƒ¼ã®é…ã•**: æ¨è«–æ™‚ã«RK45ãªã©å¤šæ®µæ³•ãŒå¿…è¦
3. **è¨“ç·´ã®ä¸å®‰å®šæ€§**: $\text{tr}(\partial f/\partial z)$ ã®å­¦ç¿’ãŒé›£ã—ã„

**è§£æ±ºç­–**: Flow Matchingã¯ã€Œãƒ™ã‚¯ãƒˆãƒ«å ´ $v_t(x)$ ã‚’**ç›´æ¥å›å¸°**ã€ã™ã‚‹æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚

#### 6.1.2 Flow Matchingå®šå¼åŒ–

**å®šç¾©**: ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ $p_1(x)$ ã¨ãƒã‚¤ã‚ºåˆ†å¸ƒ $p_0(z)$ ã‚’çµã¶**ç¢ºç‡ãƒ‘ã‚¹** $p_t(x)$ ã‚’è€ƒãˆã‚‹ã€‚

$$
p_t(x) = \int p_t(x|x_1) p_1(x_1) dx_1
$$

ã“ã“ã§ $p_t(x|x_1)$ ã¯**æ¡ä»¶ä»˜ãç¢ºç‡ãƒ‘ã‚¹**(ä¾‹: Gaussianãƒ–ãƒ©ãƒ¼):

$$
p_t(x|x_1) = \mathcal{N}(x; (1-t)x_1 + t \mu, \sigma_t^2 I)
$$

**ç›®æ¨™**: ã“ã® $p_t(x)$ ã‚’ç”Ÿæˆã™ã‚‹**ãƒ™ã‚¯ãƒˆãƒ«å ´** $v_t(x)$ ã‚’å­¦ç¿’ã™ã‚‹:

$$
\frac{dx}{dt} = v_t(x), \quad x(0) \sim p_0, \quad x(1) \sim p_1
$$

#### 6.1.3 Conditional Flow Matching (CFM) æå¤±

**ç›´æ¥å­¦ç¿’ã¯å›°é›£**: $p_t(x)$ ã¯é™°çš„ã«ã—ã‹å®šç¾©ã•ã‚Œã¦ã„ãªã„ã€‚

**è§£æ±º**: **æ¡ä»¶ä»˜ããƒ™ã‚¯ãƒˆãƒ«å ´** $u_t(x|x_1)$ ã‚’ä½¿ã†:

$$
u_t(x|x_1) = \frac{d}{dt} \mathbb{E}_{p_t(x|x_1)}[x] = \frac{t x_1 + (1-t)\mu - x}{\sigma_t^2}
$$

**CFMæå¤±**:

$$
\mathcal{L}_{\text{CFM}}(\theta) = \mathbb{E}_{t \sim U[0,1], x_1 \sim p_1, x \sim p_t(\cdot|x_1)} \left[ \| v_t(x; \theta) - u_t(x|x_1) \|^2 \right]
$$

**æ•°å€¤æ¤œç®—**: $D=2$, $x_1 = (1,0)$, $x_0 = (0,0)$, $t=0.5$ã®ã¨ãã€‚$x_t = 0.5 x_1 = (0.5, 0)$ã€$u_t = x_1 - x_0 = (1,0)$ã€‚å®Œç’§ãªãƒ¢ãƒ‡ãƒ«ãŒ $v_t(x_t) = (1,0)$ ã‚’å‡ºåŠ›ã™ã‚Œã° loss=0ã€‚

#### 6.1.4 Flow Matching vs CNF vs Diffusion

| æ‰‹æ³• | ãƒ™ã‚¯ãƒˆãƒ«å ´ | æå¤± | å°¤åº¦ | æ¨è«–é€Ÿåº¦ |
|------|------------|------|------|----------|
| **CNF** | $f(z,t)$ (Neural ODE) | NLL + trace(Jacobian) | å³å¯† | é…ã„ (ODE) |
| **FFJORD** | $f(z,t)$ | NLL + Hutchinson | å³å¯† | é…ã„ (ODE) |
| **Flow Matching** | $v_t(x)$ | MSEå›å¸° $\|\|v_t - u_t\|\|^2$ | ä¸è¦ | é€Ÿã„ (1-stepå¯) |
| **DDPM** | $\epsilon_\theta(x_t, t)$ | MSEå›å¸° $\|\|\epsilon - \epsilon_\theta\|\|^2$ | ä¸è¦ | é€Ÿã„ (å°‘ã‚¹ãƒ†ãƒƒãƒ—) |

**çµè«–**: Flow Matchingã¯CNFã®ã€Œå°¤åº¦è¨ˆç®—ã‚’æ¨ã¦ã¦å›å¸°ã«ç‰¹åŒ–ã€ã—ãŸã‚‚ã®ã€‚Diffusionã¨æ•°å­¦çš„ã«ç­‰ä¾¡[^8]ã€‚

> **âš ï¸ Warning:** CFM ã§ã¯ $u_t(x|x_1)$ ã§å›å¸°ã™ã‚‹ãŒã€ã“ã‚Œã¯ conditional velocityï¼ˆ1ã‚µãƒ³ãƒ—ãƒ«ã®çµŒè·¯ï¼‰ã§ã‚ã‚Š marginal velocity $v_t(x)$ ã§ã¯ãªã„ã€‚**ä¸¡è€…ã‚’æœ€å°åŒ–ã™ã‚‹è§£ãŒä¸€è‡´ã™ã‚‹**ï¼ˆLipman et al., 2022 ã® Theorem 2ï¼‰ã“ã¨ãŒ CFM ã®æ ¸å¿ƒã€‚`u_t` ã¨ `v_t` ã‚’æ··åŒã—ã¦ãƒ‡ãƒãƒƒã‚°ã«è¿·ã£ãŸå ´åˆã¯ã“ã®ç­‰ä¾¡æ€§ã«ç«‹ã¡è¿”ã‚‹ã“ã¨ã€‚

#### 6.1.5 Flow Matchingå®Ÿè£… (Julia/Lux)

```julia
# Conditional Flow Matching training
using Lux, Random, Optimisers, Zygote

# Vector field network
vnet = Chain(
    Dense(2 => 64, relu),
    Dense(64 => 128, relu),
    Dense(128 => 64, relu),
    Dense(64 => 2)  # Output: velocity field
)

ps, st = Lux.setup(Xoshiro(42), vnet)

# CFM loss
function cfm_loss(ps, st, x1_batch)
    t = rand(Float32, 1, size(x1_batch, 2))  # Uniform t âˆˆ [0,1]
    Î¼ = zeros(Float32, 2, size(x1_batch, 2))  # Prior mean
    Ïƒ_t = 0.1f0 .* (1.0f0 .- t)  # Noise schedule

    # Sample x_t from conditional path
    Îµ = randn(Float32, size(x1_batch))
    x_t = (1.0f0 .- t) .* x1_batch .+ t .* Î¼ .+ Ïƒ_t .* Îµ

    # Target conditional velocity
    u_t = (x1_batch .- x_t) ./ (Ïƒ_t.^2 .+ 1f-6)

    # Predict velocity
    v_t, st_new = vnet(x_t, ps, st)

    # MSE loss
    loss = mean((v_t .- u_t).^2)
    return loss, st_new
end

# Training loop
opt = Adam(1f-3)
opt_state = Optimisers.setup(opt, ps)

for epoch in 1:1000
    x1_batch = sample_data(256)  # Your data sampler

    (loss, st), back = Zygote.pullback(ps -> cfm_loss(ps, st, x1_batch), ps)
    grads = back((one(loss), nothing))[1]

    opt_state, ps = Optimisers.update(opt_state, ps, grads)

    if epoch % 100 == 0
        println("Epoch $epoch: Loss = $(loss)")
    end
end

# Sampling via ODE solve (Euler method)
function sample_flow_matching(vnet, ps, st, n_samples, n_steps=100)
    x = randn(Float32, 2, n_samples)  # Start from N(0,I)
    dt = 1.0f0 / n_steps

    for step in 1:n_steps
        t = step * dt
        v, _ = vnet(x, ps, st)
        x .+= dt .* v  # Euler step
    end

    return x
end

samples = sample_flow_matching(vnet, ps, st, 1000)
```

**ãƒã‚¤ãƒ³ãƒˆ**:
- **æå¤±é–¢æ•°ã¯å˜ç´”ãªå›å¸°**: $\|\|v_t - u_t\|\|^2$ ã®ã¿
- **å°¤åº¦è¨ˆç®—ãªã—**: traceã‚‚ä¸è¦
- **ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¯é«˜é€Ÿ**: å°‘ãªã„ã‚¹ãƒ†ãƒƒãƒ—æ•°ã§OK (10-50ã‚¹ãƒ†ãƒƒãƒ—)
- **Diffusionã¨ç­‰ä¾¡**: DDPMã® $\epsilon_\theta$ ã‚’ãƒ™ã‚¯ãƒˆãƒ«å ´ $v_t$ ã«å¤‰æ›ã—ãŸã ã‘

**æ•°å€¤æ¤œç®—ï¼ˆ2Dï¼‰**: $x_1 = (1,0)$, $x_0 = (0,0)$, $t=0.5$ ã®ã¨ãã€‚$x_t = (0.5, 0)$ã€$u_t = (1,0) - (0,0) = (1,0)$ã€‚Euler step: $x_{0.5+dt} = x_t + dt \cdot v_t$ã€‚10ã‚¹ãƒ†ãƒƒãƒ— ($dt=0.1$) ã§ $(0,0) \to (1,0)$ ã«åˆ°é”ã€‚å„ã‚¹ãƒ†ãƒƒãƒ—ã§ $v_t \approx (1,0)$ ãªã‚‰èª¤å·®ã‚¼ãƒ­ï¼ˆç›´ç·šçµŒè·¯ã®æ©æµï¼‰ã€‚

### 6.2 JKOã‚¹ã‚­ãƒ¼ãƒ : Wassersteinå‹¾é…æµã®è¦–ç‚¹

#### 6.2.1 JKOã‚¹ã‚­ãƒ¼ãƒ ã¨ã¯

**Jordan-Kinderlehrer-Otto (JKO) ã‚¹ã‚­ãƒ¼ãƒ **ã¯ã€ç¢ºç‡åˆ†å¸ƒã®æ™‚é–“ç™ºå±•ã‚’**Wassersteinè·é›¢ã®æœ€æ€¥é™ä¸‹**ã¨ã—ã¦å®šå¼åŒ–ã™ã‚‹æ çµ„ã¿[^9]ã€‚

**å•é¡Œè¨­å®š**: ã‚¨ãƒãƒ«ã‚®ãƒ¼æ±é–¢æ•° $\mathcal{F}[p]$ ã‚’æŒã¤åˆ†å¸ƒ $p_t$ ã®å‹¾é…æµ:

$$
\frac{\partial p_t}{\partial t} = -\nabla \cdot (p_t \nabla \frac{\delta \mathcal{F}}{\delta p})
$$

ã“ã‚Œã¯**Fokker-Planckæ–¹ç¨‹å¼**ã¨å‘¼ã°ã‚Œã‚‹ã€‚

#### 6.2.2 JKOã‚¹ã‚­ãƒ¼ãƒ ã®é›¢æ•£åŒ–

**JKOã‚¹ã‚­ãƒ¼ãƒ ã®å®šç¾©**: æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ— $\tau$ ã§ä»¥ä¸‹ã‚’ç¹°ã‚Šè¿”ã™:

$$
p_{k+1} = \arg\min_{p} \left\{ \mathcal{F}[p] + \frac{1}{2\tau} W_2^2(p, p_k) \right\}
$$

ã“ã“ã§ $W_2(p, q)$ ã¯**2-Wassersteinè·é›¢**:

$$
W_2^2(p, q) = \inf_{\pi \in \Pi(p,q)} \int \|x - y\|^2 d\pi(x,y)
$$

**æ•°å€¤ä¾‹ï¼ˆ1æ¬¡å…ƒï¼‰**: $p_k = \mathcal{N}(1, 1)$, $\mathcal{F}[p] = \text{KL}(p \| \mathcal{N}(0,1))$, $\tau = 0.1$ ã®ã¨ãã€$p_{k+1} \approx \mathcal{N}(0.9, 1)$ã€‚å¹³å‡ãŒç›®æ¨™åˆ†å¸ƒã«å‘ã‹ã£ã¦ $\tau$ ã ã‘è¿‘ã¥ã â†’ å‹¾é…é™ä¸‹ã®ç¢ºç‡åˆ†å¸ƒç‰ˆã€‚

#### 6.2.3 Normalizing Flowã¨JKOã®é–¢ä¿‚

**ç™ºè¦‹**: Normalizing Flowã®å­¦ç¿’ã¯**é›¢æ•£JKOã‚¹ã‚­ãƒ¼ãƒ **ã¨è¦‹ãªã›ã‚‹[^10]!

**å¯¾å¿œé–¢ä¿‚**:

| JKOã‚¹ã‚­ãƒ¼ãƒ  | Normalizing Flow |
|-------------|-------------------|
| ã‚¨ãƒãƒ«ã‚®ãƒ¼ $\mathcal{F}[p]$ | NLL $-\log p(x)$ |
| Wassersteinè·é›¢ $W_2(p, q)$ | Flowå¤‰æ›ã®æ­£å‰‡åŒ– |
| æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ— $\tau$ | å­¦ç¿’ç‡ $\eta$ |
| å‹¾é…æµ $\frac{\partial p}{\partial t}$ | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–° $\frac{d\theta}{dt}$ |

**è¨¼æ˜ã®ã‚¹ã‚±ãƒƒãƒ**:

1. Flowã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ $\theta$ ã‚’å°‘ã—å‹•ã‹ã™: $\theta \to \theta + \Delta\theta$
2. ã“ã‚Œã¯åˆ†å¸ƒ $p_\theta(x)$ ã‚’å¤‰åŒ–ã•ã›ã‚‹: $p_\theta \to p_{\theta + \Delta\theta}$
3. ã“ã®å¤‰åŒ–é‡ã¯ $W_2$ è·é›¢ã§æ¸¬ã‚Œã‚‹
4. NLLã‚’æ¸›ã‚‰ã™æ–¹å‘ã« $\theta$ ã‚’å‹•ã‹ã™ã¨ã€JKOã‚¹ã‚­ãƒ¼ãƒ ã®æ›´æ–°å¼ã¨ä¸€è‡´

**çµè«–**: Normalizing Flowã®è¨“ç·´ã¯ã€ŒWassersteinç©ºé–“ä¸Šã®å‹¾é…é™ä¸‹æ³•ã€ã§ã‚ã‚‹ã€‚

#### 6.2.4 å®Ÿç”¨çš„æ„ç¾©

**1. åæŸä¿è¨¼**: JKOç†è«–ã«ã‚ˆã‚Šã€Flowã®è¨“ç·´ãŒã€Œã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’å˜èª¿æ¸›å°‘ã•ã›ã‚‹ã€ã“ã¨ãŒä¿è¨¼ã•ã‚Œã‚‹ã€‚

**2. æœ€é©è¼¸é€ã¨ã®æ¥ç¶š**: Optimal Transportç†è«–ãŒFlowã®è¨­è¨ˆã«ä½¿ãˆã‚‹:
   - **Monge-AmpÃ¨reæ–¹ç¨‹å¼**: æœ€é©è¼¸é€ã®è§£ã¯å‡¸é–¢æ•° $\phi$ ã®å‹¾é… $\nabla \phi$
   - **Brenierå®šç†**: æœ€é©è¼¸é€å†™åƒã¯ä¸€æ„ã«å­˜åœ¨
   - **Coupling Layerã®æ­£å½“åŒ–**: $x = T(z)$ ã¯æœ€é©è¼¸é€å†™åƒã®é›¢æ•£è¿‘ä¼¼

**3. Flowã¨Diffusionã®çµ±ä¸€**: ä¸¡è€…ã¨ã‚‚ã€ŒWassersteinå‹¾é…æµã®é›¢æ•£åŒ–ã€ã¨ã—ã¦ç†è§£ã§ãã‚‹:
   - **Flow**: æ±ºå®šè«–çš„ãªçµŒè·¯ (ODEã‚½ãƒ«ãƒãƒ¼)
   - **Diffusion**: ç¢ºç‡çš„ãªçµŒè·¯ (SDEã‚½ãƒ«ãƒãƒ¼)

**å®Ÿç”¨çš„æ„ç¾©ã¾ã¨ã‚**: JKOç†è«–ã®è¦–ç‚¹ã‹ã‚‰è¦‹ã‚‹ã¨ã€Flowè¨“ç·´ä¸­ã®ã€ŒNLLæ¸›å°‘ + ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ã€ã¯ã€Œã‚¨ãƒãƒ«ã‚®ãƒ¼æ¸›å°‘ + åˆ†å¸ƒç§»å‹•ã‚³ã‚¹ãƒˆæœ€å°åŒ–ã€ã®é›¢æ•£åŒ–ã«ãªã£ã¦ã„ã‚‹ã€‚å­¦ç¿’ç‡ $\eta$ ãŒå°ã•ã™ãã‚‹ã¨ $W_2$ ãƒšãƒŠãƒ«ãƒ†ã‚£ãŒå¼·ãåŠ¹ã„ã¦åæŸãŒé…ãã€å¤§ãã™ãã‚‹ã¨ JKO ã®æ­£å‰‡åŒ–ãŒå´©ã‚Œã¦ç™ºæ•£ã™ã‚‹ â€” ã“ã‚ŒãŒã€Œlr ãŒé«˜ã™ãã‚‹ã¨ NLL ãŒçˆ†ç™ºã™ã‚‹ã€ç¾è±¡ã®å¹¾ä½•å­¦çš„èª¬æ˜ã ã€‚


### 6.3 æœ€æ–°ç ”ç©¶å‹•å‘ (2024-2026)

#### 6.3.1 Flow Matching ã®ç™ºå±•

**Stochastic Interpolants (2023-2024)**[^11]:
- Flow Matchingã‚’SDEã«æ‹¡å¼µ
- Diffusionã¨Flowã®ä¸­é–“çš„ãªæ‰‹æ³•
- æ¨è«–æ™‚ã«ãƒã‚¤ã‚ºæ³¨å…¥ã§å¤šæ§˜æ€§å‘ä¸Š

**Rectified Flow (2024)**[^12]:
- ã€Œæ›²ãŒã£ãŸFlowã€ã‚’ã€Œç›´ç·šçš„ãªFlowã€ã«ä¿®æ­£
- 1-stepã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒå¯èƒ½ã«
- Distillationæ‰‹æ³•ã¨ã—ã¦æ³¨ç›®

**Rectified Flow ã®æ ¸å¿ƒ**: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ $x_1$ ã¨ãƒã‚¤ã‚º $x_0$ ã‚’ãƒ©ãƒ³ãƒ€ãƒ ãƒšã‚¢ã«ã—ã¦ Linear Flow ã‚’å­¦ç¿’ã™ã‚‹ã¨çµŒè·¯ãŒã€Œæ›²ãŒã‚‹ã€ã€‚ã“ã‚Œã‚’ Reflowï¼ˆåŒä¸€ãƒ¢ãƒ‡ãƒ«ã§ $(x_0, x_1)$ ã®æœ€é©ãƒšã‚¢ã‚’å†ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰ã§ç¹°ã‚Šè¿”ã™ã¨çµŒè·¯ãŒç›´ç·šã«è¿‘ã¥ãã€‚$k$ å› Reflow ã§åˆ‡æ–­èª¤å·® $O(1/N^{2k})$ â†’ $k=2$ ã§å¤§å¹…é«˜é€ŸåŒ–ã€‚SD3 ã¯ã“ã®åŸç†ã‚’æ¡ç”¨ã€‚

**Policy Flow (2024)**:
- å¼·åŒ–å­¦ç¿’ã¨Flowã®èåˆ
- æ–¹ç­– $\pi(a|s)$ ã‚’Flowã§ãƒ¢ãƒ‡ãƒ«åŒ–
- é€£ç¶šè¡Œå‹•ç©ºé–“ã®åŠ¹ç‡çš„æ¢ç´¢

#### 6.3.2 é«˜é€ŸåŒ–ãƒ»åŠ¹ç‡åŒ–

**Consistency Models (2023)**[^13]:
- Diffusionã®è’¸ç•™ã«ã‚ˆã‚Š1-stepã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Ÿç¾
- Flowã«ã‚‚ConsistencyåŸç†ã‚’é©ç”¨å¯èƒ½
- æ¨è«–é€Ÿåº¦100å€ä»¥ä¸Šã®é«˜é€ŸåŒ–

**ãªãœ Consistency ãŒ Flow ã«é©ç”¨ã§ãã‚‹ã‹**: Flow ã® ODE ã¯é€£ç¶šæ™‚é–“ç‰ˆã®ã€Œæ±ºå®šè«–çš„ãƒãƒƒãƒ—ã€ãªã®ã§ã€ä»»æ„ã® $t$ ã‹ã‚‰çµ‚ç‚¹ $t=1$ ã¸ã® self-consistencyï¼ˆåŒã˜çµ‚ç‚¹ã«åˆ°é”ã™ã‚‹ï¼‰ã‚’å®šç¾©ã§ãã‚‹ã€‚Diffusion ã® Consistency Modelsï¼ˆCMï¼‰ã¨å…¨ãåŒã˜æ çµ„ã¿ãŒæˆç«‹ã™ã‚‹ã€‚Flow Matching ã®å ´åˆã€ç›´ç·šçµŒè·¯ã«ã‚ˆã‚Š CM ã®è’¸ç•™èª¤å·®ãŒã•ã‚‰ã«å°ã•ããªã‚‹ï¼ˆçµŒè·¯ã®æ›²ç‡ â‰ˆ 0 â†’ truncation error æœ€å°ï¼‰ã€‚

**Latent Diffusion/Flow (2024)**:
- ç”»åƒã‚’æ½œåœ¨ç©ºé–“ $z$ ã«åœ§ç¸®ã—ã¦ã‹ã‚‰Flow/Diffusion
- Stable Diffusion 3.0ã¯Flow Matchingãƒ™ãƒ¼ã‚¹
- è¨ˆç®—é‡ã‚’1/10ä»¥ä¸‹ã«å‰Šæ¸›

**Continuous Normalizing Flows with Adjoint (2024)**:
- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®æ”¹å–„ (O(1) ãƒ¡ãƒ¢ãƒª)
- ã‚ˆã‚Šæ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å­¦ç¿’ãŒå¯èƒ½
- Physics-Informed CNFã¸ã®å¿œç”¨

#### 6.3.3 å¿œç”¨åˆ†é‡ã®æ‹¡å¤§

**1. ã‚¿ãƒ³ãƒ‘ã‚¯è³ªæ§‹é€ äºˆæ¸¬**:
- AlphaFold3 (2024) ã¯Flow-based
- åŸå­åº§æ¨™ã®åŒæ™‚åˆ†å¸ƒã‚’å­¦ç¿’
- Diffusion/Flowãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰

**AlphaFold3 ã® Flow åˆ©ç”¨ã®æ ¸å¿ƒ**: ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã®åŸå­åº§æ¨™ã¯ 3D ç©ºé–“ä¸Šã®ç‚¹ç¾¤ $\{r_i \in \mathbb{R}^3\}_{i=1}^N$ã€‚ã“ã‚Œã« SE(3) ä¸å¤‰ Flow ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã€å›è»¢ãƒ»ä¸¦é€²ã«å¯¾ã—ã¦ç‰©ç†çš„ã«æ•´åˆã—ãŸæ§‹é€ ã‚’ç”Ÿæˆã§ãã‚‹ã€‚Diffusion ãƒ™ãƒ¼ã‚¹ã® AlphaFold3 ã¯ã€Œã‚¬ã‚¦ã‚¹ãƒã‚¤ã‚ºã‹ã‚‰åŸå­åº§æ¨™ã‚’å¾©å…ƒã€ã™ã‚‹ãŸã‚ã€NF ã®ã€Œå¤‰æ›å¯èƒ½æ€§ï¼ˆå³å¯†å°¤åº¦ï¼‰ã€ã¨ Diffusion ã®ã€Œè¡¨ç¾åŠ›ã€ã‚’ä¸¡ç«‹ã—ã¦ã„ã‚‹ã€‚

**2. åˆ†å­ç”Ÿæˆ**:
- SE(3)-equivariant Flow
- å›è»¢ãƒ»ä¸¦é€²ä¸å¤‰æ€§ã‚’æŒã¤Flow
- è–¬å‰¤å€™è£œã®è‡ªå‹•è¨­è¨ˆ

**3. æ™‚ç³»åˆ—äºˆæ¸¬**:
- Temporal Normalizing Flow
- ä¸è¦å‰‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ™‚ç³»åˆ—ã®å‡¦ç†
- Neural ODE + Flowã®èåˆ

**4. å› æœæ¨è«–**:
- Causal Normalizing Flow
- ä»‹å…¥åˆ†å¸ƒ $p(y|do(x))$ ã®å­¦ç¿’
- åäº‹å®Ÿæ¨è«–ã¸ã®å¿œç”¨

> **âš ï¸ Warning:** å› æœæ¨è«–ã« Flow ã‚’ä½¿ã†å ´åˆã€ã€Œç›¸é–¢ã€ã¨ã€Œå› æœã€ã‚’æ··åŒã—ãªã„ã“ã¨ã€‚$\log p(x)$ ã®æœ€å¤§åŒ–ã¯ã€Œè¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã€ã™ã‚‹ã ã‘ã§ã€ä»‹å…¥ $do(x)$ ã®åŠ¹æœã¯è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‹ã‚‰ã¯è­˜åˆ¥ã§ããªã„ã€‚Causal Flow ã¯æ§‹é€ å› æœãƒ¢ãƒ‡ãƒ«ï¼ˆSCMï¼‰ã®ä»®å®šãŒåˆ¥é€”å¿…è¦ã€‚

#### 6.3.4 ç†è«–çš„é€²å±•

**Universal Approximation of Flows (2024)**:
- Coupling Layer ã®ç†è«–çš„ä¿è¨¼å¼·åŒ–
- æœ‰é™å¹…ã§ã‚‚ universal approximation å¯èƒ½
- å¿…è¦å±¤æ•°ã®ä¸Šç•Œå°å‡º

**ç›´æ„Ÿ**: Coupling Layer ãŒå…¨ã¦ã®å¯é€†å¤‰æ›ã‚’è¿‘ä¼¼ã§ãã‚‹ã“ã¨ã®è¨¼æ˜ã¯ã€ã€Œååˆ†å¤šã„å±¤ã‚’é‡ã­ã‚Œã°ä»»æ„ã®åˆ†å¸ƒé–“ã®å¤‰æ›ãŒå­¦ç¿’å¯èƒ½ã€ã‚’æ„å‘³ã™ã‚‹ã€‚å®Ÿç”¨çš„ã«ã¯ $K = 10$ã€œ$20$ å±¤ã§ååˆ†ï¼ˆè«–æ–‡ã§ã¯ $K = O(\log D)$ ã®ä¸Šç•Œå°å‡ºï¼‰ã€‚

**Flow Matching = Diffusion ã®å³å¯†è¨¼æ˜ (2024)**:
- CFMæå¤±ã¨DDPMæå¤±ãŒæœ¬è³ªçš„ã«åŒä¸€
- ã‚¹ã‚³ã‚¢é–¢æ•° $\nabla \log p_t$ ã¸ã®åæŸä¿è¨¼
- åæŸé€Ÿåº¦ã®è§£æ

**Wasserstein Gradient Flow ã®é›¢æ•£åŒ–èª¤å·® (2025)**:
- JKOã‚¹ã‚­ãƒ¼ãƒ ã®æ•°å€¤è§£æ
- æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ— $\tau$ ã«å¯¾ã™ã‚‹èª¤å·® $O(\tau^2)$ ã®è¨¼æ˜
- é©å¿œçš„ã‚¹ãƒ†ãƒƒãƒ—ã‚µã‚¤ã‚ºã®è¨­è¨ˆæŒ‡é‡

**èª¤å·® $O(\tau^2)$ ã®ç›´æ„Ÿ**: JKO ã®å„ã‚¹ãƒ†ãƒƒãƒ—ã¯ã€Œã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¸‹ã’ã‚‹æœ€é©åŒ–ã€ã€‚$\tau$ ãŒå¤§ãã„ã¨ Wasserstein çƒã®å¤–ã«é£›ã³å‡ºã—ã¦èª¤å·®ãŒç´¯ç© â†’ $O(\tau^2)$ã€‚Runge-Kutta ã® $O(\Delta t^2)$ ã¨å…¨ãåŒã˜æ§‹é€ ã€‚é©å¿œçš„ $\tau$ ã¯ã‚ªãƒ¼ãƒãƒ¼ã‚·ãƒ¥ãƒ¼ãƒˆã‚’é˜²ãã¤ã¤åæŸã‚’é€Ÿã‚ã‚‹ â€” ODE ã‚½ãƒ«ãƒãƒ¼ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚µã‚¤ã‚ºåˆ¶å¾¡ã¨æ•°å­¦çš„ã«åŒä¸€ã€‚

> **âš ï¸ Warning:** **Zone 6 å®Œäº†**: Flow Matchingã®æ•°ç†ã€JKOã‚¹ã‚­ãƒ¼ãƒ ã€2024-2026æœ€æ–°ç ”ç©¶ã‚’ç¶²ç¾…ã€‚æ¬¡ã¯**æŒ¯ã‚Šè¿”ã‚Šçµ±åˆ**ã§å…¨ä½“ã‚’ã¾ã¨ã‚ã‚‹ã€‚

---

## Zone 6: ğŸ“ æŒ¯ã‚Šè¿”ã‚Š + çµ±åˆã‚¾ãƒ¼ãƒ³ â€” FAQ & Next Steps (30min)

### 7.1 æœ¬è¬›ç¾©ã§é”æˆã—ãŸã“ã¨

**æ•°å­¦çš„ç†è§£ (Zone 3)**:

âœ… **Change of Variableså…¬å¼ã®å®Œå…¨å°å‡º**
- 1æ¬¡å…ƒ â†’ å¤šæ¬¡å…ƒ â†’ åˆæˆå¤‰æ›
- ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³è¡Œåˆ—å¼ã®æ„å‘³: ä½“ç©è¦ç´ ã®å¤‰åŒ–ç‡
- $\log p(x) = \log p(z) - \log |\det J_f|$ ã®å³å¯†ãªè¨¼æ˜

âœ… **Coupling Layerã®ç†è«–**
- ä¸‰è§’è¡Œåˆ—æ§‹é€ ã§ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³è¨ˆç®—ã‚’ O(DÂ³) â†’ O(D) ã«å‰Šæ¸›
- Affine Coupling Layer (RealNVP)
- Multi-scale architecture

âœ… **Glowã®é©æ–°**
- Actnorm (Batch Normã®å¯é€†ç‰ˆ)
- 1Ã—1 Invertible Convolution
- LUåˆ†è§£ã«ã‚ˆã‚‹ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³è¨ˆç®—ã®åŠ¹ç‡åŒ–

âœ… **Continuous Normalizing Flows**
- Instantaneous Change of Variables: $\frac{\partial \log p(z(t))}{\partial t} = -\text{tr}(\frac{\partial f}{\partial z})$
- Neural ODE: é›¢æ•£å±¤ â†’ é€£ç¶šæ™‚é–“ODE
- Adjoint Method: ãƒ¡ãƒ¢ãƒª O(1) ã®é€†ä¼æ’­

âœ… **FFJORD**
- Hutchinson traceæ¨å®š: O(DÂ²) â†’ O(D)
- Vector-Jacobian Product (VJP) ã«ã‚ˆã‚‹åŠ¹ç‡çš„è¨ˆç®—
- $\text{tr}(A) = \mathbb{E}[\mathbf{v}^\top A \mathbf{v}]$

**å®Ÿè£…åŠ› (Zone 4-5)**:

âœ… **Julia + Lux.jl ã§ã®RealNVPå®Œå…¨å®Ÿè£…**
- Affine Coupling Layer
- å¤šå±¤Flow modelã®æ§‹ç¯‰
- è¨“ç·´ãƒ«ãƒ¼ãƒ— (negative log likelihoodæœ€å°åŒ–)
- 2D Moons dataset ã§ã®å®Ÿé¨“

âœ… **CNF/FFJORDã®æ§‹é€ ç†è§£**
- DifferentialEquations.jl + ODE solver
- Hutchinson trace estimatorå®Ÿè£…
- Neural ODE dynamics

âœ… **å®Ÿé¨“ã«ã‚ˆã‚‹æ¤œè¨¼**
- å¯†åº¦æ¨å®šç²¾åº¦: Flow vs VAEæ¯”è¼ƒ (å³å¯†å°¤åº¦ vs ELBO)
- Out-of-Distributionæ¤œçŸ¥: 95%+ ç²¾åº¦
- ç”Ÿæˆå“è³ªã®è©•ä¾¡

**ç†è«–çš„å±•æœ› (Zone 2, 6)**:

âœ… **Course IVå…¨ä½“åƒã®æŠŠæ¡**
- NF â†’ EBM â†’ Score â†’ DDPM â†’ SDE â†’ Flow Matching â†’ LDM â†’ Consistency â†’ World Models â†’ çµ±ä¸€ç†è«–
- 10è¬›ç¾©ã®è«–ç†çš„ãƒã‚§ãƒ¼ãƒ³

âœ… **VAE/GAN/Flowã®3ã¤å·´**
- å°¤åº¦: è¿‘ä¼¼ (VAE) / æš—é»™çš„ (GAN) / **å³å¯† (Flow)**
- è¨“ç·´å®‰å®šæ€§ãƒ»ç”Ÿæˆå“è³ªãƒ»ç”¨é€”ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•

âœ… **Flow Matchingã¸ã®æ©‹æ¸¡ã—**
- Probability Flow ODE (PF-ODE)
- Rectified Flow: ç›´ç·šè¼¸é€
- Optimal Transportè¦–ç‚¹ã§ã®çµ±ä¸€
- æœ€æ–°ç ”ç©¶: TarFlow, Stable Diffusion 3, Flux.1

**åˆ°é”ãƒ¬ãƒ™ãƒ«**:

- **åˆç´š â†’ ä¸­ç´šçªç ´**: Change of Variablesã®æ•°å­¦ã‚’å®Œå…¨ç†è§£
- **å®Ÿè£…åŠ›**: Lux.jlã§å‹•ãFlowã‚’è‡ªåŠ›ã§æ›¸ã‘ã‚‹
- **ç†è«–çš„æ´å¯Ÿ**: Flowã®é™ç•Œã¨Flow Matchingã¸ã®é€²åŒ–ã‚’ç†è§£
- **æ¬¡ã¸ã®æº–å‚™**: ç¬¬37-38å› (SDE/ODE, Flow Matching) ã¸ã®åœŸå°å®Œæˆ

### 7.2 ã‚ˆãã‚ã‚‹è³ªå• (FAQ)

#### Q1: Normalizing Flowsã€çµå±€å®Ÿå‹™ã§ä½¿ã‚ã‚Œã¦ã„ã‚‹ã®ï¼Ÿ

**A**: **2026å¹´ç¾åœ¨ã€å¾©æ´»ã—ã¤ã¤ã‚ã‚‹** (Flow MatchingçµŒç”±)ã€‚

**ç”¨é€”åˆ¥ã®ç¾çŠ¶**:

| ç”¨é€” | ä¸»æµæ‰‹æ³• | Flowã®å½¹å‰² | å®Ÿä¾‹ |
|:-----|:--------|:----------|:-----|
| **ç”»åƒç”Ÿæˆ (å“è³ªé‡è¦–)** | Diffusion | Flow Matchingã¨ã—ã¦å¾©æ´» | Stable Diffusion 3, Flux.1 |
| **ç”»åƒç”Ÿæˆ (é€Ÿåº¦é‡è¦–)** | GAN / Consistency | Rectified FlowãŒç«¶åˆ | 10-50 stepsç”Ÿæˆ |
| **å¯†åº¦æ¨å®š** | **Normalizing Flow** | ä»–æ‰‹æ³•ã§ã¯ä¸å¯èƒ½ | é‡‘èãƒªã‚¹ã‚¯ã€ç‰©ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ |
| **ç•°å¸¸æ¤œçŸ¥ (OOD)** | **Normalizing Flow** | å³å¯†ãª $\log p(x)$ ãŒå¿…é ˆ | è£½é€ æ¥­ã€åŒ»ç™‚ç”»åƒ |
| **å¤‰åˆ†æ¨è«–** | IAF (Flow) + VAE | äº‹å¾Œåˆ†å¸ƒè¿‘ä¼¼ | ãƒ™ã‚¤ã‚ºæ·±å±¤å­¦ç¿’ |
| **æ½œåœ¨ç©ºé–“æ­£å‰‡åŒ–** | Flow + VAE / Flow + Diffusion | è¡¨ç¾å­¦ç¿’å¼·åŒ– | disentangled representation |

**æ­´å²çš„æ¨ç§»**:
- **2016-2019**: RealNVP, Glowå…¨ç›› â€” ã€Œæ¬¡ä¸–ä»£ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã€ã¨ã—ã¦æ³¨ç›®
- **2020-2022**: DDPM, Stable Diffusionã®å°é ­ â€” Flowã¯ä¸€æ™‚ä¸‹ç«
- **2023-2026**: Flow Matchingç™»å ´ â€” ç†è«–ã¨å®Ÿè£…ã®èåˆã§**å¾©æ´»**

**çµè«–**: ç”Ÿæˆå“è³ªã§ã¯Diffusionã«ä¸€åº¦æ•—åŒ— â†’ Flow Matchingã§æ•°å­¦çš„åŸºç›¤ã‚’ä¿ã¡ã¤ã¤å®Ÿç”¨æ€§ã‚’å–ã‚Šæˆ»ã—ãŸã€‚

> **âš ï¸ Warning:** ã€ŒNormalizing Flow ã¯ä½¿ã‚ã‚Œãªããªã£ãŸã€ã¨ã„ã†è¨€èª¬ã¯ 2021-2022 å¹´æ™‚ç‚¹ã®è©±ã€‚2024-2026 å¹´ã® Stable Diffusion 3ã€FLUX.1ã€F5-TTS ã¯å…¨ã¦ Flow Matching ãƒ™ãƒ¼ã‚¹ã§ã‚ã‚Šã€ç¾åœ¨æœ€ã‚‚å®Ÿç”¨åŒ–ã•ã‚Œã¦ã„ã‚‹ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®æ•°å­¦çš„åŸºç›¤ãŒ Flow ã§ã‚ã‚‹ã“ã¨ã«å¤‰ã‚ã‚Šã¯ãªã„ã€‚

#### Q2: RealNVP vs Glow vs FFJORDã€ã©ã‚Œã‚’é¸ã¶ã¹ãï¼Ÿ

| è¦³ç‚¹ | RealNVP | Glow | FFJORD/CNF |
|:-----|:--------|:-----|:-----------|
| **å®Ÿè£…é›£æ˜“åº¦** | â˜…â˜†â˜† (æœ€ã‚‚ç°¡å˜) | â˜…â˜…â˜† (1Ã—1 Convè¤‡é›‘) | â˜…â˜…â˜… (ODE solverå¿…è¦) |
| **è¨“ç·´é€Ÿåº¦** | é€Ÿã„ | é€Ÿã„ | é…ã„ (ODEç©åˆ†) |
| **æ¨è«–é€Ÿåº¦** | æœ€é€Ÿ (~5ms/100 samples) | é€Ÿã„ (~10ms) | é…ã„ (~50ms) |
| **è¡¨ç¾åŠ›** | ä¸­ (Couplingåˆ¶ç´„) | é«˜ (1Ã—1 Conv) | **æœ€é«˜** (åˆ¶ç´„ãªã—) |
| **ãƒ¡ãƒ¢ãƒª** | O(KÂ·D) | O(KÂ·D) | O(1) (Adjoint) |
| **ç”¨é€”** | ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã€OODæ¤œçŸ¥ | é«˜å“è³ªç”Ÿæˆ | ç ”ç©¶ã€è¤‡é›‘åˆ†å¸ƒ |

**æ¨å¥¨ãƒ•ãƒ­ãƒ¼**:
1. **ã¾ãšRealNVP** â†’ ã‚·ãƒ³ãƒ—ãƒ«ã€å®Ÿè£…100è¡Œã€ãƒ‡ãƒãƒƒã‚°å®¹æ˜“
2. **ä¸è¶³ãªã‚‰Glow** â†’ 1Ã—1 Convã§è¡¨ç¾åŠ›å‘ä¸Šã€multi-scale
3. **ã•ã‚‰ã«å¿…è¦ãªã‚‰FFJORD** â†’ åˆ¶ç´„ãªã—ã€Flow Matchingã¸ã®æ‹¡å¼µå®¹æ˜“

**å®Ÿå‹™**: 95%ã®ã‚±ãƒ¼ã‚¹ã¯RealNVPã§ååˆ†ã€‚ç ”ç©¶ãƒ»PoC ãªã‚‰FFJORDã€‚

#### Q3: ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³è¡Œåˆ—å¼ã€æœ¬å½“ã« O(D) ã§æ¸ˆã‚€ã®ï¼Ÿ

**A**: **Coupling Layerã«é™ã‚Šã€ã¯ã„**ã€‚

**è¨ˆç®—é‡ã®å†…è¨³**:

| æ‰‹æ³• | ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³æ§‹é€  | $\det$ è¨ˆç®—é‡ | ç†ç”± |
|:-----|:-------------|:-------------|:-----|
| **ä¸€èˆ¬ã®å¯é€†è¡Œåˆ—** | å¯†è¡Œåˆ— | O(DÂ³) | LUåˆ†è§£ or å›ºæœ‰å€¤è¨ˆç®— |
| **ä¸‰è§’è¡Œåˆ—** | ä¸Š/ä¸‹ä¸‰è§’ | O(D) | å¯¾è§’è¦ç´ ã®ç© |
| **Coupling Layer** | ä¸‹ä¸‰è§’ãƒ–ãƒ­ãƒƒã‚¯ | O(D) | $\det = \det(I) \cdot \det(\text{diag}(\exp(s)))$ |
| **FFJORD (Hutchinson)** | traceæ¨å®š | O(D) | VJP 1å› (ç¢ºç‡çš„ã€åˆ†æ•£ã‚ã‚Š) |
| **Glow 1Ã—1 Conv** | CÃ—Cè¡Œåˆ— | O(CÂ³) | Cã¯å›ºå®š (â‰¤512)ã€ç”»åƒã‚µã‚¤ã‚ºéä¾å­˜ |

**æ³¨æ„ç‚¹**:
- Coupling Layerã¯**è§£æçš„** â†’ å³å¯†ã«O(D)ã€åˆ†æ•£ãªã—
- FFJORDã¯**ç¢ºç‡çš„æ¨å®š** â†’ æœŸå¾…å€¤ã¯O(D)ã€åˆ†æ•£ã‚ã‚Š (è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã§ç²¾åº¦å‘ä¸Šå¯èƒ½)
- Glow 1Ã—1 Convã¯ç”»åƒã®**ãƒãƒ£ãƒãƒ«æ•°Cã®ã¿**ã«ä¾å­˜ â†’ é«˜è§£åƒåº¦ã§ã‚‚O(CÂ³)

**çµè«–**: Coupling Layerã®ã€Œä¸‰è§’è¡Œåˆ—åŒ–ã€ãŒã€Flowã®å®Ÿç”¨åŒ–ã‚’å¯èƒ½ã«ã—ãŸå¤©æ‰çš„ã‚¢ã‚¤ãƒ‡ã‚¢ã€‚

**æ•°å€¤ä¾‹**: $D = 784$ï¼ˆMNISTï¼‰ã®å ´åˆã€ä¸€èˆ¬è¡Œåˆ—å¼ã¯ $O(784^3) \approx 4.8 \times 10^8$ flopsã€‚Coupling Layer ãªã‚‰ $O(784)$ ã§ 600,000 å€é«˜é€Ÿã€‚ãƒãƒƒãƒã‚µã‚¤ã‚º 256 ã§è¨“ç·´ã™ã‚Œã°ã€ã“ã®å·®ã¯æ¯ã‚¹ãƒ†ãƒƒãƒ—ã®è¨“ç·´é€Ÿåº¦ã«ç›´çµã™ã‚‹ã€‚

#### Q4: CNFã¨Diffusionã®ODEã€ä½•ãŒé•ã†ã®ï¼Ÿ

**A**: è¨“ç·´æ–¹æ³•ã¨ç›®çš„ãŒç•°ãªã‚‹ãŒã€**æ•°å­¦çš„ã«ã¯åŒã˜æ çµ„ã¿** (ODE-based transport)ã€‚

| è¦³ç‚¹ | CNF (Normalizing Flow) | Diffusion (PF-ODE) |
|:-----|:----------------------|:------------------|
| **ç›®çš„** | ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ $p(x)$ ã‚’ç›´æ¥ãƒ¢ãƒ‡ãƒ«åŒ– | ãƒã‚¤ã‚ºé™¤å»éç¨‹ $p_t(x)$ ã‚’ãƒ¢ãƒ‡ãƒ«åŒ– |
| **è¨“ç·´** | æœ€å°¤æ¨å®š $\max \log p(x)$ | ã‚¹ã‚³ã‚¢ãƒãƒƒãƒãƒ³ã‚° or ãƒã‚¤ã‚ºäºˆæ¸¬ $\epsilon_\theta$ |
| **ODEå½¢å¼** | $\frac{dz}{dt} = f(z, t)$ (ä»»æ„) | $\frac{dx}{dt} = f - \frac{1}{2} g^2 \nabla \log p_t$ (ã‚¹ã‚³ã‚¢ä¾å­˜) |
| **å°¤åº¦è¨ˆç®—** | å³å¯† (traceç©åˆ†) | å›°é›£ (å¤‰åˆ†ä¸‹ç•Œã®ã¿) |
| **ç”Ÿæˆå“è³ª** | ä¸­ç¨‹åº¦ | **SOTA** (ImageNet, SD) |
| **ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°** | 1-pass ODE | 10-1000 steps |
| **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£** | Couplingåˆ¶ç´„ (å¾“æ¥) | U-Net/Transformer (è‡ªç”±) |

**Flow Matchingã®æ´å¯Ÿ**:
- ã“ã®2ã¤ã¯**åŒã˜ODE frameworkã®ç•°ãªã‚‹è¨“ç·´æ–¹æ³•**
- CNF: ãƒ™ã‚¯ãƒˆãƒ«å ´ $f$ ã‚’ç›´æ¥å­¦ç¿’
- Diffusion (PF-ODE): ã‚¹ã‚³ã‚¢ $\nabla \log p_t$ ã‚’å­¦ç¿’ â†’ $f$ ã‚’å°å‡º
- Flow Matching: ä¸¡è€…ã‚’çµ±ä¸€ â€” æ¡ä»¶ä»˜ããƒ•ãƒ­ãƒ¼ $v_t(x_t | x_0)$ ã‚’å­¦ç¿’

**ãªãœ Diffusion ãŒ CNF ã‚ˆã‚Šç”Ÿæˆå“è³ªã§å‹ã‚‹ã‹**: CNF ã¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã« Coupling åˆ¶ç´„ãŒã‚ã‚‹ãŸã‚è¡¨ç¾åŠ›ãŒä½ã„ã€‚Diffusion ã® PF-ODE ã¯ U-Net/Transformer ã§è‡ªç”±ã«ã‚¹ã‚³ã‚¢ã‚’å­¦ç¿’ã§ãã‚‹ãŸã‚ SOTAã€‚Flow Matching ã¯ Diffusion ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä¿ã¡ã¤ã¤ CNF ã®æ•°å­¦çš„å³å¯†æ€§ã‚’å–ã‚Šè¾¼ã‚“ã ã€Œã„ã„ã¨ã“å–ã‚Šã€ã€‚

**ç¬¬38å›ã§å®Œå…¨çµ±ä¸€** â€” Benamou-Brenierå…¬å¼ã€Wassersteinå‹¾é…æµã§å…¨ã¦ãŒç¹‹ãŒã‚‹ã€‚

#### Q5: Flowã®ã€Œå¯é€†æ€§ã€ã€çµå±€ä½•ãŒå¬‰ã—ã„ã®ï¼Ÿ

**A**: 3ã¤ã®æœ¬è³ªçš„åˆ©ç‚¹ã€‚

**1. å³å¯†ãª $\log p(x)$ è¨ˆç®—**
- VAE: ELBO (ä¸‹ç•Œ) â†’ çœŸã®å°¤åº¦ã¯ä¸æ˜
- GAN: å°¤åº¦è¨ˆç®—ä¸å¯ â†’ å¯†åº¦æ¨å®šä¸å¯èƒ½
- **Flow**: Change of Variables ã§å³å¯† â†’ ç•°å¸¸æ¤œçŸ¥ã€ãƒ¢ãƒ‡ãƒ«é¸æŠã€ãƒ™ã‚¤ã‚ºæ¨è«–ã§å¿…é ˆ

**2. åŒæ–¹å‘å¤‰æ›**
- ãƒ‡ãƒ¼ã‚¿ç©ºé–“ $x$ â†” æ½œåœ¨ç©ºé–“ $z$ ã®å¯é€†ãƒãƒƒãƒ”ãƒ³ã‚°
- **é †æ–¹å‘** ($z \to x$): ç”Ÿæˆ (ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°)
- **é€†æ–¹å‘** ($x \to z$): ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° (è¡¨ç¾å­¦ç¿’)
- ç”¨é€”: æ½œåœ¨ç©ºé–“ã§ã®è£œé–“ã€å±æ€§ç·¨é›†ã€ã‚¹ã‚¿ã‚¤ãƒ«è»¢ç§»

**3. è¨“ç·´ã®å®‰å®šæ€§**
- æœ€å°¤æ¨å®š (MLE) â†’ æ˜ç¢ºãªç›®çš„é–¢æ•°
- æ•µå¯¾çš„è¨“ç·´ä¸è¦ (GANã®ã‚ˆã†ãª mode collapse / ä¸å®‰å®šæ€§ãŒãªã„)
- åæŸæ€§ã®ç†è«–ä¿è¨¼

**ä»£å„Ÿ**:
- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ¶ç´„ (Coupling Layerã¯å…¥åŠ›ã®åŠåˆ†ã‚’ã‚³ãƒ”ãƒ¼ â†’ æƒ…å ±ãƒœãƒˆãƒ«ãƒãƒƒã‚¯)
- ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³è¨ˆç®—ã‚³ã‚¹ãƒˆ (Coupling/CNFã§ O(D) ã ãŒã€ä¾ç„¶ã¨ã—ã¦è¨ˆç®—å¿…è¦)

**Flow Matchingã®å†è§£é‡ˆ**:
- ã€Œå¯é€†æ€§ã€ã¯ç”Ÿæˆæ™‚ã®**çµŒè·¯ã®æ€§è³ª** (æ±ºå®šè«–çš„ODE)
- ã€Œå¯é€†æ€§ã€ã¯ãƒ¢ãƒ‡ãƒ«ã®**æ§‹é€ åˆ¶ç´„ã§ã¯ãªã„** (éå¯é€†ãƒ™ã‚¯ãƒˆãƒ«å ´ã‚’å­¦ç¿’å¯èƒ½)
- ODEã§ç©åˆ†ã™ã‚Œã°æ±ºå®šè«–çš„çµŒè·¯ â†’ å®Ÿè³ªçš„ã«ã€Œå¯é€†ã€

#### Q6: Course Iã®ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³ã€çµå±€ã“ã“ã§ä½•ã«ä½¿ã£ãŸï¼Ÿ

**A**: **å…¨ã¦ã®ç†è«–çš„åŸºç›¤**ã€‚

**å…·ä½“çš„ãªå¯¾å¿œ**:

| Course I (ç¬¬3-5å›) | æœ¬è¬›ç¾©ã§ã®ä½¿ç”¨ç®‡æ‰€ |
|:------------------|:----------------|
| **ç¬¬3å› æ¥µåº§æ¨™å¤‰æ›** | Zone 2.3 ã€Œåº§æ¨™å¤‰æ›ã€ã®æ¯”å–© â€” $p_{r,\theta} = p_{x,y} \cdot r$ |
| **ç¬¬4å› ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³è¡Œåˆ—** | Zone 3.1.2 å¤šæ¬¡å…ƒChange of Variables â€” $J_f = \frac{\partial \mathbf{f}}{\partial \mathbf{z}}$ |
| **ç¬¬4å› $\det$ ã®æ€§è³ª** | Zone 3.1.3 åˆæˆå¤‰æ› â€” $\det(AB) = \det(A) \det(B)$ |
| **ç¬¬4å› ç¢ºç‡å¤‰æ•°å¤‰æ›** | Zone 3.1 å®Œå…¨å°å‡º â€” $p_X(x) = p_Z(z) | \det J_f |^{-1}$ |
| **ç¬¬5å› ä¼Šè—¤ç©åˆ†ãƒ»SDE** | Zone 3.4.2 Instantaneous Change of Variables |
| **ç¬¬5å› å¸¸å¾®åˆ†æ–¹ç¨‹å¼** | Zone 4.2 CNF/FFJORDå®Ÿè£… (DifferentialEquations.jl) |

**ã€Œãªãœã‚ã‚“ãªæŠ½è±¡çš„ãªæ•°å­¦ã‚’...ã€ã®ç­”ãˆ**:
- Normalizing Flowsã®å³å¯†ãªå°å‡ºã«**ä¸å¯æ¬ **
- ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³ãªã—ã§ã¯ $\log p(x)$ ã®è¨ˆç®—ä¸å¯èƒ½
- ç¬¬37-38å›ã§ã•ã‚‰ã«æ·±åŒ– (Fokker-Planckæ–¹ç¨‹å¼ã€JKOã‚¹ã‚­ãƒ¼ãƒ )

**æ¨å¥¨**: Course I ç¬¬3-5å›ã‚’å¾©ç¿’ã™ã‚‹ã¨ã€æœ¬è¬›ç¾©ãŒ**2å€ç†è§£ã§ãã‚‹**ã€‚ç‰¹ã«ç¬¬4å›ã€Œãƒ¤ã‚³ãƒ“ã‚¢ãƒ³ã¨ç¢ºç‡å¤‰æ•°å¤‰æ›ã€ã¯å¿…ä¿®ã€‚

#### Q7: ã€ŒFlow Matchingã§å¯é€†æ€§ä¸è¦ã€ãªã‚‰ã€ã‚‚ã†Flowã˜ã‚ƒãªã„ã®ã§ã¯ï¼Ÿ

**A**: **ç”¨èªã®å†å®šç¾©ãŒèµ·ãã¦ã„ã‚‹**ã€‚ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚·ãƒ•ãƒˆã®éæ¸¡æœŸã€‚

**ä¼çµ±çš„å®šç¾© (2014-2019)**:
- Normalizing Flow = å¯é€†å¤‰æ› $f_1, \ldots, f_K$ ã®åˆæˆ
- å¯é€†æ€§ = Flowã®**æœ¬è³ª** (Change of Variableså…¬å¼ã®å‰æ)
- $f^{-1}$ ãŒè¨ˆç®—å¯èƒ½ = å¿…é ˆæ¡ä»¶

**æ–°ã—ã„å®šç¾© (2022-)**:
- Flow = ãƒ™ã‚¯ãƒˆãƒ«å ´ $v_t(x)$ ã«ã‚ˆã‚‹**è¼¸é€ (transport)**
- ODE $\frac{dx}{dt} = v_t(x)$ ã§çµŒè·¯ã‚’å®šç¾©
- å¯é€†æ€§ = æ±ºå®šè«–çš„ODEã®**æ€§è³ª** (ãƒ¢ãƒ‡ãƒ«åˆ¶ç´„ã§ã¯ãªã„)

**çµ±ä¸€çš„è¦–ç‚¹ (Optimal Transport)**:
- ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ $p_0$ ã‹ã‚‰ãƒã‚¤ã‚ºåˆ†å¸ƒ $p_1$ ã¸ã®**æ¸¬åº¦ã®è¼¸é€**
- çµŒè·¯ = æ¸¬åº¦ã®æ™‚é–“ç™ºå±• (Continuity Equation)
- Wassersteinè·é›¢ã‚’æœ€å°åŒ– â† ç¬¬38å›ã§è©³èª¬

**è¨€è‘‰ã®æ•´ç†**:

| ç”¨èª | æ„å‘³ | æ–‡è„ˆ |
|:-----|:-----|:-----|
| **Normalizing Flow (ç‹­ç¾©)** | å¯é€†å¤‰æ›ã®åˆæˆ (RealNVP, Glow) | 2014-2019 |
| **Continuous Normalizing Flow** | Neural ODE-based Flow | 2018- |
| **Flow Matching** | ãƒ™ã‚¯ãƒˆãƒ«å ´å­¦ç¿’ (éå¯é€†OK) | 2022- |
| **Flow (åºƒç¾©)** | ODE-based transport å…¨èˆ¬ | ç¾åœ¨ã®çµ±ä¸€çš„ç†è§£ |

**çµè«–**:
- ã€ŒNormalizing Flowã€ã¨ã€ŒFlow Matchingã€ã¯**æ­´å²çš„ã«ã¯åˆ¥æ–‡è„ˆ**
- æ•°å­¦çš„ã«ã¯åŒã˜æ çµ„ã¿ (ODE-based transport)
- ç¬¬38å›ã§**å®Œå…¨çµ±ä¸€** â€” Optimal Transportè¦–ç‚¹ã§å…¨ã¦ãŒç¹‹ãŒã‚‹

**æ¯”å–©**: ã€ŒFlowã€ã¯ã€Œå·ã®æµã‚Œã€ã€‚å¾“æ¥ã¯ã€Œå¯é€†ãªæ°´è·¯ã€ã®ã¿æ‰±ã£ãŸã€‚Flow Matchingã¯ã€Œä»»æ„ã®ãƒ™ã‚¯ãƒˆãƒ«å ´ã«ã‚ˆã‚‹è¼¸é€ã€ã«ä¸€èˆ¬åŒ–ã€‚æœ¬è³ªã¯ã€Œæµã‚Œ (transport)ã€ãã®ã‚‚ã®ã€‚

#### Q8: å®Ÿè£…ã§æœ€ã‚‚è‹¦åŠ´ã™ã‚‹ãƒã‚¤ãƒ³ãƒˆã¯ï¼Ÿ

**A**: **3ã¤ã®è½ã¨ã—ç©´**ã€‚

**1. æ•°å€¤ä¸å®‰å®šæ€§**
- **å•é¡Œ**: $\exp(s)$ ãŒå¤§ãã™ãã‚‹ â†’ ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼
- **è§£æ±º**: $s$ ã‚’ `tanh` ã§ã‚¯ãƒªãƒƒãƒ— (Glowã®å®Ÿè£…)
  ```julia
  s = tanh(s_net(z1))  # [-1, 1] ã«åˆ¶é™
  ```

**2. é€†å¤‰æ›ã®æ¤œè¨¼**
- **å•é¡Œ**: $f^{-1}(f(z)) \neq z$ (å†æ§‹æˆèª¤å·®)
- **è§£æ±º**: ãƒ†ã‚¹ãƒˆã§æ¤œè¨¼
  ```julia
  z_recon = inverse(model, forward(model, z))
  @assert maximum(abs.(z - z_recon)) < 1e-5
  ```

**3. ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³è¨ˆç®—ã®ãƒã‚°**
- **å•é¡Œ**: $\log |\det J|$ ã®ç¬¦å·ãƒŸã‚¹ã€æ¬¡å…ƒé›†ç´„ãƒŸã‚¹
- **è§£æ±º**: å˜ç´”ãªã‚±ãƒ¼ã‚¹ (Affineå¤‰æ›) ã§æ‰‹è¨ˆç®—ã¨æ¯”è¼ƒ
  ```julia
  # Affine: f(z) = 2z + 1 â†’ log|det J| = log(2)
  @test log_det_jacobian â‰ˆ log(2.0)
  ```

**ãƒ‡ãƒãƒƒã‚°ã®ã‚³ãƒ„**:
- 1D â†’ 2D â†’ é«˜æ¬¡å…ƒã®é †ã§å®Ÿè£…
- å„å±¤ã®å‡ºåŠ›ã‚’å¯è¦–åŒ–
- RealNVPã‹ã‚‰å§‹ã‚ã€Glowã¯å¾Œå›ã—

#### Q9: Flowã‚’ä½¿ã£ãŸç•°å¸¸æ¤œçŸ¥ã€ã©ã†å®Ÿè£…ã™ã‚‹ï¼Ÿ

**A**: **3ã‚¹ãƒ†ãƒƒãƒ—**ã€‚

**Step 1: æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´**
```julia
# Normal data only
X_normal = load_normal_data()

# Train RealNVP
model = RealNVP(D, 6, 64)
ps, st = train_realnvp(model, X_normal; n_epochs=100)
```

**Step 2: é–¾å€¤è¨­å®š (Validation Set)**
```julia
# Compute log p(x) on validation set
log_p_val = eval_log_p(model, ps, st, X_val)

# Set threshold at 95th percentile
threshold = quantile(log_p_val, 0.05)  # Lower 5% = anomaly
```

**Step 3: æ¨è«–æ™‚ã®ç•°å¸¸åˆ¤å®š**
```julia
function is_anomaly(model, ps, st, x_test, threshold)
    log_p = eval_log_p(model, ps, st, x_test)
    return log_p < threshold
end

# Test
anomaly_flags = is_anomaly(model, ps, st, X_test, threshold)
```

**å®Ÿä¾‹ (Zone 5.4)**:
- 2D Moons (æ­£å¸¸) vs Uniform noise (ç•°å¸¸)
- Accuracy: 95-98%
- VAEã®ELBOã§ã¯é–¾å€¤è¨­å®šãŒå›°é›£ (Gapä¸æ˜)

**ç”£æ¥­å¿œç”¨**:
- è£½é€ æ¥­: ä¸è‰¯å“æ¤œçŸ¥
- åŒ»ç™‚: ç¨€ãªç–¾æ‚£ã®æ¤œå‡º
- ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ç•°å¸¸é€šä¿¡æ¤œçŸ¥

#### Q10: æ¬¡ã«å­¦ã¶ã¹ãã“ã¨ã¯ï¼Ÿ

**A**: **Course IV ã®è«–ç†çš„ãƒã‚§ãƒ¼ãƒ³ã‚’è¾¿ã‚‹**ã€‚

**æ¨å¥¨å­¦ç¿’é †**:

1. **ç¬¬34å› (EBM)** â€” æ­£è¦åŒ–å®šæ•° $Z$ ã®å›é¿
   - ãªãœ $p(x) = \frac{1}{Z} e^{-E(x)}$ ã‹ï¼Ÿ
   - Hopfield Network â†” Transformer Attention
   - Contrastive Divergence

2. **ç¬¬35å› (Score Matching)** â€” $\nabla \log p(x)$ ã®ã¿å­¦ç¿’
   - $Z$ ãŒæ¶ˆãˆã‚‹æ•°å­¦
   - Denoising Score Matching
   - Langevin MCMC

3. **ç¬¬37å› (SDE/ODE)** â€” é€£ç¶šæ‹¡æ•£ã®æ•°å­¦
   - VP-SDE, VE-SDE
   - ä¼Šè—¤ç©åˆ†ã€Fokker-Planckæ–¹ç¨‹å¼
   - **Probability Flow ODE** (Diffusion â†” Flowæ¥ç¶š)

4. **ç¬¬38å› (Flow Matching)** â€” **æœ€é‡è¦**
   - Optimal Transport
   - JKO scheme (Wassersteinå‹¾é…æµ)
   - **Flowã¨Diffusionã®æ•°å­¦çš„ç­‰ä¾¡æ€§ã®è¨¼æ˜**
   - Rectified Flowå®Ÿè£…

5. **ç¬¬36å› (DDPM)** â€” ãƒã‚¤ã‚ºé™¤å»ã®åå¾©
   - Forward/Reverse Markové€£é–
   - å¤‰åˆ†ä¸‹ç•Œ (VLB)
   - U-Netå®Ÿè£…

**ã‚¹ã‚­ãƒƒãƒ—å¯èƒ½ vs å¿…é ˆ**:
- **ã‚¹ã‚­ãƒƒãƒ—å¯èƒ½**: ç¬¬34å› (EBM) â€” Flowã®æ–‡è„ˆã§ã¯è£œè¶³çš„
- **å¿…é ˆ**: ç¬¬35å› (Score) â†’ ç¬¬37å› (SDE/ODE) â†’ ç¬¬38å› (Flow Matching)
  - ã“ã®3ã¤ãŒã€ŒFlow â†’ Diffusion â†’ çµ±ä¸€ã€ã®æ ¸å¿ƒ

**ä¸¦è¡Œå­¦ç¿’**:
- Optimal Transport (ç¬¬6å›ã®å¾©ç¿’ + ç™ºå±•)
- æ¸¬åº¦è«–ã®åŸºç¤ (Continuity Equation, Wassersteinè·é›¢)

**å®Ÿè£…å„ªå…ˆãªã‚‰**:
- ç¬¬36å› (DDPM) â†’ ç¬¬38å› (Flow Matching) â†’ Rectified Flowå®Ÿè£…

### 7.3 è‡ªå·±è¨ºæ–­ãƒ†ã‚¹ãƒˆ

**æœ¬è¬›ç¾©ã®ç†è§£åº¦ã‚’ãƒã‚§ãƒƒã‚¯**ã€‚å…¨å•æ­£è§£ã§**æ¬¡ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã¸é€²ã‚€è³‡æ ¼**ã€‚

#### Level 1: åŸºç¤ (Zone 0-2)

**Q1**: Change of Variableså…¬å¼ $p_X(x) = p_Z(z) |\det J_f|^{-1}$ ã§ã€$\det J_f$ ã®ç‰©ç†çš„æ„å‘³ã¯ï¼Ÿ

<details><summary>è§£ç­”</summary>

ä½“ç©è¦ç´ ã®å¤‰åŒ–ç‡ã€‚$z$ ç©ºé–“ã®å¾®å°ä½“ç© $dz$ ãŒã€å¤‰æ› $f$ ã«ã‚ˆã£ã¦ $x$ ç©ºé–“ã§ $|\det J_f| dz$ ã«å¤‰åŒ–ã™ã‚‹ã€‚ç¢ºç‡å¯†åº¦ã¯ã€Œå˜ä½ä½“ç©ã‚ãŸã‚Šã®ç¢ºç‡ã€ãªã®ã§ã€é€†æ•° $|\det J_f|^{-1}$ ã‚’ã‹ã‘ã‚‹ã€‚

</details>

**Q2**: VAE, GAN, Normalizing Flowã®å°¤åº¦è¨ˆç®—èƒ½åŠ›ã‚’æ¯”è¼ƒã›ã‚ˆã€‚

<details><summary>è§£ç­”</summary>

- **VAE**: ELBO (å¤‰åˆ†ä¸‹ç•Œ) â€” $\log p(x)$ ã®ä¸‹ç•Œã®ã¿ã€çœŸã®å€¤ã¯ä¸æ˜
- **GAN**: æš—é»™çš„å¯†åº¦ â€” $\log p(x)$ è¨ˆç®—ä¸å¯
- **Normalizing Flow**: å³å¯†ãª $\log p(x)$ â€” Change of Variableså…¬å¼ã§è¨ˆç®—

</details>

**Q3**: Flowã®ã€Œæ­£è¦åŒ– (Normalizing)ã€ã¯ä½•ã‚’æ­£è¦åŒ–ã—ã¦ã„ã‚‹ã®ã‹ï¼Ÿ

<details><summary>è§£ç­”</summary>

ç¢ºç‡åˆ†å¸ƒã‚’æ­£è¦åŒ– (ç©åˆ†ãŒ1ã«ãªã‚‹ã‚ˆã†)ã€‚åŸºåº•åˆ†å¸ƒ $q(z)$ (é€šå¸¸ã‚¬ã‚¦ã‚¹) ã‚’å¤‰æ›ã—ã¦ã€è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ $p(x)$ ã‚’æ§‹ç¯‰ã™ã‚‹éš›ã€Change of Variablesã§è‡ªå‹•çš„ã« $\int p(x) dx = 1$ ãŒä¿è¨¼ã•ã‚Œã‚‹ (ã€Œæ­£è¦åŒ–æµã€ã®åå‰ã®ç”±æ¥)ã€‚

</details>

#### Level 2: æ•°å¼ (Zone 3)

**Q4**: Coupling Layerã§ $\log |\det J|$ ãŒ O(D) ã§è¨ˆç®—ã§ãã‚‹ç†ç”±ã‚’ã€ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³è¡Œåˆ—ã®æ§‹é€ ã‹ã‚‰èª¬æ˜ã›ã‚ˆã€‚

<details><summary>è§£ç­”</summary>

Coupling Layerã®ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³:

$$
J = \begin{bmatrix}
I_d & 0 \\
\frac{\partial x_2}{\partial z_1} & \text{diag}(\exp(s(z_1)))
\end{bmatrix}
$$

ä¸‹ä¸‰è§’ãƒ–ãƒ­ãƒƒã‚¯è¡Œåˆ— â†’ $\det J = \det(I_d) \cdot \det(\text{diag}(\exp(s))) = \prod_i \exp(s_i) = \exp(\sum s_i)$ã€‚$\log |\det J| = \sum s_i$ (O(D) ã®å’Œ)ã€‚

</details>

**Q5**: FFJORDã®Hutchinson traceæ¨å®š $\text{tr}(A) = \mathbb{E}[\mathbf{v}^\top A \mathbf{v}]$ ã§ã€$\mathbf{v}$ ã®åˆ†å¸ƒã®æ¡ä»¶ã¯ï¼Ÿ

<details><summary>è§£ç­”</summary>

$\mathbb{E}[\mathbf{v}] = 0$, $\text{Cov}(\mathbf{v}) = I$ ã‚’æº€ãŸã™ä»»æ„ã®åˆ†å¸ƒã€‚æ¨™æº–ã‚¬ã‚¦ã‚¹ $\mathcal{N}(0, I)$ ã¾ãŸã¯Rademacheråˆ†å¸ƒ (å„è¦ç´ ãŒ $\pm 1$ with prob 0.5) ãŒä¸€èˆ¬çš„ã€‚

</details>

**Q6**: Adjoint Methodã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒ O(1) ã§ã‚ã‚‹ç†ç”±ã¯ï¼Ÿ

<details><summary>è§£ç­”</summary>

é †ä¼æ’­æ™‚ã«ä¸­é–“çŠ¶æ…‹ã‚’ä¿å­˜ã—ãªã„ã€‚é€†ä¼æ’­æ™‚ã«ã€adjoint state $\mathbf{a}(t)$ ã®ODEã‚’é€†æ™‚é–“ã§è§£ããªãŒã‚‰å‹¾é…ã‚’è¨ˆç®—ã€‚å¿…è¦ã«å¿œã˜ã¦ODEã‚’å†è¨ˆç®— (checkpointing)ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•: ãƒ¡ãƒ¢ãƒª O(1) â†” è¨ˆç®—æ™‚é–“ 2Ã— (é †ä¼æ’­1å› + é€†ä¼æ’­1å›)ã€‚

</details>

#### Level 3: å®Ÿè£… (Zone 4-5)

**Q7**: RealNVPã®è¨“ç·´ã§ã€ãªãœ inverse â†’ forward ã®é †ã§è¨ˆç®—ã™ã‚‹ã®ã‹ï¼Ÿ

<details><summary>è§£ç­”</summary>

è¨“ç·´ãƒ‡ãƒ¼ã‚¿ $x$ ã‹ã‚‰ $\log p(x)$ ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã€‚
1. Inverse: $x \to z = f^{-1}(x)$
2. Forward: $z \to x$ ã‚’å†è¨ˆç®—ã—ã€$\log |\det J|$ ã‚’ç´¯ç©
3. $\log p(x) = \log q(z) - \log |\det J|$

ç”Ÿæˆæ™‚ (ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°) ã¯ Forward ã®ã¿: $z \sim q(z) \to x = f(z)$ã€‚

</details>

**Q8**: 2D Moons datasetã§ã€FlowãŒVAEã‚ˆã‚Šé«˜ã„ $\log p(x)$ ã‚’é”æˆã™ã‚‹ç†ç”±ã¯ï¼Ÿ

<details><summary>è§£ç­”</summary>

- **Flow**: å³å¯†ãª $\log p(x)$ â€” Change of Variables ã§çœŸã®å¯†åº¦ã«è¿‘ã„æ¨å®š
- **VAE**: ELBO (ä¸‹ç•Œ) â€” $\log p(x) \geq \text{ELBO}$ã€å¸¸ã«çœŸã®å€¤ã‚ˆã‚Šå°ã•ã„
- Gap = KL(q(z|x) || p(z|x)) (VAEã®è¿‘ä¼¼èª¤å·®)

å®Ÿé¨“çµæœ: Flow ~2.35, VAE ~1.89 (Gap ~0.46)ã€‚

</details>

**Q9**: Out-of-Distributionæ¤œçŸ¥ã§ã€FlowãŒé–¾å€¤è¨­å®šã—ã‚„ã™ã„ç†ç”±ã¯ï¼Ÿ

<details><summary>è§£ç­”</summary>

Flowã¯**å³å¯†ãª $\log p(x)$** ã‚’è¨ˆç®— â†’ In-distã¨OODã®åˆ†é›¢ãŒæ˜ç¢ºã€‚

- In-dist: $\log p(x)$ é«˜ã„ (ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã«è¿‘ã„)
- OOD: $\log p(x)$ ä½ã„ (ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã‹ã‚‰é ã„)

VAEã®ELBOã§ã¯ã€Gap (KL divergence) ãŒä¸æ˜ â†’ é–¾å€¤è¨­å®šãŒæ›–æ˜§ã€‚

</details>

#### Level 4: ç™ºå±• (Zone 6)

**Q10**: Probability Flow ODE (PF-ODE) ãŒã€ŒDiffusionã®æ±ºå®šè«–çš„ç‰ˆã€ã§ã‚ã‚‹ç†ç”±ã‚’ã€SDEã¨ã®é–¢ä¿‚ã‹ã‚‰èª¬æ˜ã›ã‚ˆã€‚

<details><summary>è§£ç­”</summary>

Diffusion Reverse SDE:

$$
dx = [f(x, t) - g(t)^2 \nabla \log p_t(x)] dt + g(t) dw
$$

PF-ODE (æ±ºå®šè«–çš„):

$$
\frac{dx}{dt} = f(x, t) - \frac{1}{2} g(t)^2 \nabla \log p_t(x)
$$

ãƒ‰ãƒªãƒ•ãƒˆé …ã‚’èª¿æ•´ ($g^2 \nabla \log p_t$ ã®ä¿‚æ•°ã‚’ $1 \to \frac{1}{2}$)ã€æ‹¡æ•£é … $g(t) dw$ ã‚’é™¤å»ã€‚ã“ã®ODEã‚’ $t=T \to 0$ ã«ç©åˆ†ã™ã‚‹ã¨ã€SDEã¨**åŒã˜å‘¨è¾ºåˆ†å¸ƒ** $p_t(x)$ ãŒå¾—ã‚‰ã‚Œã‚‹ (Song et al. 2021 è¨¼æ˜)ã€‚

</details>

**Q11**: Rectified Flowã§ã€Œç›´ç·šè¼¸é€ã€ãŒæœ€é©ã§ã‚ã‚‹ç†ç”±ã¯ï¼Ÿ

<details><summary>è§£ç­”</summary>

Optimal Transportç†è«–ã‚ˆã‚Šã€Wasserstein-2è·é›¢ã‚’æœ€å°åŒ–ã™ã‚‹è¼¸é€çµŒè·¯ã¯**ç›´ç·š** (geodesic)ã€‚

$x_t = (1-t) x_0 + t z$ ã¯ã€ãƒ‡ãƒ¼ã‚¿ç‚¹ $x_0$ ã¨ãƒã‚¤ã‚º $z$ ã‚’ç›´ç·šã§çµã¶æœ€çŸ­çµŒè·¯ â†’ Wassersteinè·é›¢æœ€å° â†’ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—æ•°æœ€å° (10-50 steps)ã€‚

</details>

**Q12**: Flow Matchingã¨Normalizing Flowsã®ã€Œå¯é€†æ€§ã€ã«å¯¾ã™ã‚‹è€ƒãˆæ–¹ã®é•ã„ã¯ï¼Ÿ

<details><summary>è§£ç­”</summary>

| è¦³ç‚¹ | Normalizing Flows (ä¼çµ±) | Flow Matching (æ–°) |
|:-----|:------------------------|:------------------|
| **å¯é€†æ€§** | ãƒ¢ãƒ‡ãƒ«ã®**æ§‹é€ åˆ¶ç´„** | çµŒè·¯ã®**æ€§è³ª** |
| **è¨“ç·´æ™‚** | $f, f^{-1}$ ä¸¡æ–¹è¨ˆç®—å¯èƒ½ | ãƒ™ã‚¯ãƒˆãƒ«å ´ $v_t$ (éå¯é€†OK) |
| **æ¨è«–æ™‚** | Forward: $z \to x = f(z)$ | ODEç©åˆ† (æ±ºå®šè«–çš„çµŒè·¯) |
| **çµæœ** | Coupling Layerç­‰ã®åˆ¶ç´„ | ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è‡ªç”± |

Flow Matchingã®æ´å¯Ÿ: ã€Œå¯é€†æ€§ã€ã¯æ±ºå®šè«–çš„ODEã®æ€§è³ª (åŒã˜åˆæœŸæ¡ä»¶ â†’ åŒã˜çµŒè·¯)ã€‚ãƒ¢ãƒ‡ãƒ«è‡ªä½“ã¯éå¯é€†ã§ã‚‚OKã€‚

</details>

**å…¨å•æ­£è§£ãªã‚‰** â†’ **Course IV ç¬¬34-38å›ã¸é€²ã‚€æº–å‚™å®Œäº†**ï¼

---

> Progress: 95%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. CNF ã¨ Flow Matching ã®æ•°å­¦çš„æ¥ç¶šã‚’1ã¤ã®å¼ã§è¡¨ç¾ã—ã€FMãŒNFã‚’ã€ŒåŒ…å«ã™ã‚‹ã€æ„å‘³ã‚’è¿°ã¹ã‚ˆã€‚
>    - *ãƒ’ãƒ³ãƒˆ*: CNF ã® `tr(âˆ‚f/âˆ‚z)` ã¨ FM ã® `â€–v_t - u_tâ€–Â²` ã®ã©ã¡ã‚‰ãŒæœ€é©åŒ–ã—ã‚„ã™ã„ã‹ã€è¨ˆç®—é‡ã®è¦³ç‚¹ã§æ¯”è¼ƒã›ã‚ˆã€‚
> 2. NFâ†’EBMâ†’Scoreâ†’DDPMã®å¯†åº¦ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãƒã‚§ãƒ¼ãƒ³ã§ã€å„æ‰‹æ³•ãŒå‰æ‰‹æ³•ã®ä½•ã®å›°é›£ã‚’ã€Œè§£æ±ºã€ã—ã¦ã„ã‚‹ã‹ä¸€è¡Œãšã¤è¿°ã¹ã‚ˆã€‚
>    - *ãƒ’ãƒ³ãƒˆ*: NF ã®ã€Œãƒ¤ã‚³ãƒ“ã‚¢ãƒ³è¨ˆç®—ã€â†’ EBM ã®ã€Œåˆ†é…é–¢æ•°ã€â†’ Score ã®ã€Œä½•ï¼Ÿã€â†’ DDPM ã®ã€Œä½•ï¼Ÿã€ã¨ã„ã†é †ã«è€ƒãˆã‚ˆã€‚

## ğŸŒ€ Paradigm-Breaking Question

> **ã€Œå¯é€†æ€§ã‚’æ¨ã¦ã‚Œã°ã€Flowã¯ã‚‚ã£ã¨è¡¨ç¾åŠ›ãŒä¸ŠãŒã‚‹ã®ã§ã¯ï¼Ÿã€**

### ä¼çµ±çš„ç­”ãˆ (2014-2019)

**ä¸»å¼µ**: å¯é€†æ€§ = Flowã®æœ¬è³ªã€‚æ¨ã¦ãŸã‚‰Flowã§ã¯ãªã„ã€‚

**æ ¹æ‹ **:
1. Change of VariablesãŒä½¿ãˆãªããªã‚‹ â†’ $\log p(x)$ è¨ˆç®—ä¸å¯
2. é€†å¤‰æ› $f^{-1}$ ãŒãªã„ã¨æ½œåœ¨ç©ºé–“ã¸ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä¸å¯
3. Coupling Layerã®åˆ¶ç´„ã¯ä»•æ–¹ãªã„ (ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³è¨ˆç®—ã®ãŸã‚)

**çµè«–**: å¯é€†æ€§ã¯ã€Œã‚³ã‚¹ãƒˆã€ã§ã¯ãªãã€Œæœ¬è³ªçš„ç‰¹å¾´ã€ã€‚

### 2023å¹´ã®ç­”ãˆ (Flow Matching)

**ä¸»å¼µ**: **Flow Matchingã¯éå¯é€†ãƒ™ã‚¯ãƒˆãƒ«å ´ã‚’å­¦ç¿’å¯èƒ½**ã€‚

**å®Ÿä¾‹**:
- è¨“ç·´æ™‚: ä»»æ„ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ $v_\theta(x, t)$ ã‚’å­¦ç¿’ (å¯é€†æ€§ä¸è¦)
- æ¨è«–æ™‚: ODEã§ç©åˆ† $\frac{dx}{dt} = v_\theta(x, t)$ â†’ çµŒè·¯ã¯æ±ºå®šè«–çš„ (å®Ÿè³ªçš„ã«å¯é€†)

**æ´å¯Ÿ**:
- ã€Œå¯é€†æ€§ã€ã¯ç”Ÿæˆæ™‚ã®**çµŒè·¯ã®æ€§è³ª** (æ±ºå®šè«–çš„ODE)
- ã€Œå¯é€†æ€§ã€ã¯ãƒ¢ãƒ‡ãƒ«ã®**åˆ¶ç´„ã§ã¯ãªã„** (Coupling Layerã®ã‚ˆã†ãªæ§‹é€ åˆ¶ç´„ãŒä¸è¦)

### Diffusion Modelsã®è¦–ç‚¹

**Diffusionã¯ã€Œå¯é€†æ€§ã‚’æ¨ã¦ãŸã€Flow**:

| è¦³ç‚¹ | Normalizing Flow (ä¼çµ±) | Diffusion Model |
|:-----|:----------------------|:---------------|
| **Forward** | å­¦ç¿’å¯¾è±¡ ($f$ ã‚’å­¦ç¿’) | å›ºå®š (ãƒã‚¤ã‚ºè¿½åŠ ) |
| **Reverse** | $f^{-1}$ (è§£æçš„) | å­¦ç¿’å¯¾è±¡ ($\epsilon_\theta$ ã‚’å­¦ç¿’) |
| **å¯é€†æ€§** | å¿…é ˆ | ä¸è¦ (Forward ã¯éå¯é€†) |
| **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£** | Coupling Layer (åˆ¶ç´„ã‚ã‚Š) | U-Net/Transformer (è‡ªç”±) |
| **ç”Ÿæˆå“è³ª** | ä¸­ç¨‹åº¦ | **SOTA** |

**Diffusionã®æˆåŠŸãŒè¨¼æ˜**: å¯é€†æ€§ã‚’æ¨ã¦ã‚‹ã“ã¨ã§ã€è¡¨ç¾åŠ›ãŒ**åŠ‡çš„ã«å‘ä¸Š**ã€‚

### çµ±ä¸€çš„è¦–ç‚¹ (Optimal Transport)

**Flow (åºƒç¾©) = ãƒ™ã‚¯ãƒˆãƒ«å ´ã«ã‚ˆã‚‹è¼¸é€ (transport)**ã€‚

**Benamou-Brenierå…¬å¼** (ç¬¬38å›ã§è©³èª¬):

æ¸¬åº¦ $p_0$ ã‹ã‚‰ $p_1$ ã¸ã®è¼¸é€çµŒè·¯ã¯ã€æ¬¡ã®æœ€é©åŒ–å•é¡Œã®è§£:

$$
\min_{v_t} \int_0^1 \int \| v_t(x) \|^2 p_t(x) dx dt
$$

åˆ¶ç´„: Continuity Equation (æ¸¬åº¦ã®ä¿å­˜å‰‡)

$$
\frac{\partial p_t}{\partial t} + \nabla \cdot (p_t v_t) = 0
$$

**é‡è¦**: ã“ã®æ çµ„ã¿ã«ã€Œå¯é€†æ€§ã€ã¯**ä¸è¦**ã€‚ãƒ™ã‚¯ãƒˆãƒ«å ´ $v_t(x)$ ãŒå®šç¾©ã§ãã‚Œã°ååˆ†ã€‚

### ç­”ãˆ

**ä¼çµ±çš„Normalizing Flows**: å¯é€†æ€§ = æœ¬è³ª â†’ æ­£ã—ã„ãŒã€**ç‹­ã™ããŸ**ã€‚

**Flow Matching**: å¯é€†æ€§ = çµŒè·¯ã®æ€§è³ª (æ±ºå®šè«–çš„ODE) â†’ ã‚ˆã‚Šä¸€èˆ¬çš„ãªç†è§£ã€‚

**çµ±ä¸€çš„è¦–ç‚¹**:
- ã€Œå¯é€†å¤‰æ›ã€ã‹ã‚‰ã€Œãƒ™ã‚¯ãƒˆãƒ«å ´ã«ã‚ˆã‚‹è¼¸é€ã€ã¸
- Wassersteinè·é›¢ã‚’æœ€å°åŒ–ã™ã‚‹çµŒè·¯ = æœ€é©è¼¸é€
- **Flowã¨Diffusionã¯åŒã˜æ çµ„ã¿** (æ¸¬åº¦ã®æ™‚é–“ç™ºå±•)

**ç¬¬38å›ã§å®Œå…¨è§£ç­”**:
- Benamou-Brenierå…¬å¼
- JKO scheme (Wassersteinå‹¾é…æµ)
- **ã€Œå…¨ã¦ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯è¼¸é€å•é¡Œã€ã®è¨¼æ˜**

**ã“ã“ã§ã®å­¦ã³**: ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã®**å¢ƒç•Œã‚’å•ã„ç¶šã‘ã‚‹**ã“ã¨ãŒã€æ¬¡ã®ç†è«–ã‚’ç”Ÿã‚€ã€‚ã€Œå¯é€†æ€§ã¨ã¯ä½•ã‹ï¼Ÿã€ã€ŒFlowã¨ã¯ä½•ã‹ï¼Ÿã€â€” ã“ã®å•ã„ãŒã€Flow Matchingã¨ã„ã†çµ±ä¸€ç†è«–ã‚’å°ã„ãŸã€‚

---

## å‚è€ƒæ–‡çŒ®

[^1]: Rezende, D. J., & Mohamed, S. (2015). Variational Inference with Normalizing Flows. *ICML*.
<https://arxiv.org/abs/1505.05770>

[^2]: Dinh, L., Krueger, D., & Bengio, Y. (2014). NICE: Non-linear Independent Components Estimation. *ICLR Workshop*.
<https://arxiv.org/abs/1410.8516>

[^3]: Dinh, L., Sohl-Dickstein, J., & Bengio, S. (2016). Density Estimation using Real NVP. *ICLR*.
<https://arxiv.org/abs/1605.08803>

[^4]: Kingma, D. P., & Dhariwal, P. (2018). Glow: Generative Flow with Invertible 1x1 Convolutions. *NeurIPS*.
<https://arxiv.org/abs/1807.03039>

[^5]: Chen, R. T. Q., Rubanova, Y., Bettencourt, J., & Duvenaud, D. (2018). Neural Ordinary Differential Equations. *NeurIPS*.
<https://arxiv.org/abs/1806.07366>

[^6]: Grathwohl, W., Chen, R. T. Q., Bettencourt, J., Sutskever, I., & Duvenaud, D. (2019). FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models. *ICLR*.
<https://arxiv.org/abs/1810.01367>

[^7]: Rezende, D. J., & Mohamed, S. (2015). Variational Inference with Normalizing Flows (Planar Flow). *ICML*.
<https://arxiv.org/abs/1505.05770>

[^8]: Kingma, D. P., Salimans, T., Jozefowicz, R., Chen, X., Sutskever, I., & Welling, M. (2016). Improved Variational Inference with Inverse Autoregressive Flow. *NeurIPS*.
<https://arxiv.org/abs/1606.04934>

[^9]: Liu, X., Gong, C., & Liu, Q. (2022). Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow. *ICLR 2023*.
<https://arxiv.org/abs/2209.03003>

[^10]: Lipman, Y., Chen, R. T. Q., Ben-Hamu, H., Nickel, M., & Le, M. (2023). Flow Matching for Generative Modeling. *ICLR*.
<https://arxiv.org/abs/2210.02747>

[^11]: Chen, R. T. Q., Rubanova, Y., Bettencourt, J., & Duvenaud, D. (2018). Neural Ordinary Differential Equations (Adjoint Method). *NeurIPS*.
<https://arxiv.org/abs/1806.07366>

[^12]: Ho, J., Jain, A., & Abbeel, P. (2020). Denoising Diffusion Probabilistic Models. *NeurIPS*.
<https://arxiv.org/abs/2006.11239>

[^13]: Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., & Poole, B. (2021). Score-Based Generative Modeling through Stochastic Differential Equations. *ICLR*.
<https://arxiv.org/abs/2011.13456>

[^14]: Zhai, S., et al. (2024). "Normalizing Flows are Capable Generative Models". *arXiv:2412.06329*.
<https://arxiv.org/abs/2412.06329>

[^15]: Hickling, T., & Prangle, D. (2024). Flexible Tails for Normalizing Flows.
<https://arxiv.org/abs/2406.16971>

---

**æ¬¡å›äºˆå‘Š**: ç¬¬34å› â€” **Energy-Based Models & çµ±è¨ˆç‰©ç†**ã€‚$p(x) = \frac{1}{Z} e^{-E(x)}$ ã®Gibbsåˆ†å¸ƒã€Hopfield Networkã¨Transformerã®ç­‰ä¾¡æ€§ã€Contrastive Divergenceã€Langevin Dynamicsã€‚æ­£è¦åŒ–å®šæ•° $Z$ ã¨ã®æˆ¦ã„ãŒå§‹ã¾ã‚‹ã€‚ãã—ã¦ç¬¬35å›ã§ $Z$ ãŒæ¶ˆãˆã‚‹ç¬é–“ã‚’ç›®æ’ƒã™ã‚‹ â€” **Score Matching**ã€‚

**ç¬¬33å›ã®ä½ç½®ä»˜ã‘ã¾ã¨ã‚**: Normalizing Flow ã¯ã€Œå³å¯†ãªå°¤åº¦è¨ˆç®—ã€ã¨ã„ã†å”¯ä¸€ç„¡äºŒã®ç‰¹æ€§ã‚’æŒã¤ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã ã€‚VAE ã¯è¿‘ä¼¼ï¼ˆELBOï¼‰ã€GAN ã¯æš—é»™çš„ï¼ˆå°¤åº¦ãªã—ï¼‰ã§ã‚ã‚‹ã®ã«å¯¾ã—ã€Flow ã ã‘ãŒ $\log p(x)$ ã‚’è§£æçš„ã«è¨ˆç®—ã§ãã‚‹ã€‚ã“ã®ç‰¹æ€§ã¯å¯†åº¦æ¨å®šãƒ»ç•°å¸¸æ¤œçŸ¥ãƒ»ãƒ™ã‚¤ã‚ºæ¨è«–ã§ä»Šå¾Œã‚‚ä¸å¯æ¬ ã§ã‚ã‚Šç¶šã‘ã‚‹ã€‚Flow Matching ã¨ã—ã¦é€²åŒ–ã—ãŸç¾åœ¨ã€ãã®æ•°å­¦çš„åŸºç›¤ã¯ã•ã‚‰ã«å¤šãã®æ‰‹æ³•ã‚’ã€ŒåŒ…å«ã€ã—ã¤ã¤ã‚ã‚‹ã€‚

Course IV ã®æ—…ã¯ã¾ã å§‹ã¾ã£ãŸã°ã‹ã‚Šã€‚ç¬¬33å›ã§å¾—ãŸã€ŒChange of Variablesã€ã®æ•°å­¦ãŒã€ç¬¬37-38å›ã§**Diffusion Models**ã¨èåˆã—ã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ç†è«–ã®**çµ±ä¸€**ã¸ã¨å‘ã‹ã†ã€‚æ¬¡ã®è¬›ç¾©ã§ä¼šãŠã†ã€‚

> **âš ï¸ Warning:** ç¬¬33å›ã§å®Ÿè£…ã—ãŸ RealNVP ã¯ã€Œå­¦ç¿’ç”¨ã€å®Ÿè£…ã§ã‚ã‚Šã€æœ¬ç•ªåˆ©ç”¨ã«ã¯ä¸ååˆ†ãªç‚¹ãŒã‚ã‚‹ã€‚å…·ä½“çš„ã«ã¯: (1) æ•°å€¤å®‰å®šæ€§ã®ãŸã‚ã® `clamp` ãŒæœªå®Ÿè£…ã€(2) Half-precision (fp16) æœªå¯¾å¿œã€(3) ãƒãƒƒãƒæ­£è¦åŒ–ã® running statistics ãŒæ¨è«–æ™‚ã«å›ºå®šã•ã‚Œã¦ã„ãªã„ã€ãªã©ã®å•é¡ŒãŒã‚ã‚‹ã€‚Production ã§ã® Flow å®Ÿè£…ã¯ Lux.jl ã®å…¬å¼ã‚µãƒ³ãƒ—ãƒ«ã‹ Normalizing Flows.jl ã‚’å‚ç…§ã®ã“ã¨ã€‚

---

## è‘—è€…ãƒªãƒ³ã‚¯

- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
