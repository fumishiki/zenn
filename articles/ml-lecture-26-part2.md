---
title: "ç¬¬26å›: è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
slug: "ml-lecture-26-part2"
emoji: "ğŸ“Š"
type: "tech"
topics: ["machinelearning", "evaluation", "rust", "rust", "statistics"]
published: true
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Rust", "Elixir"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---

> **ç¬¬26å›ã€å‰ç·¨ã€‘**: [ç¬¬26å›ã€å‰ç·¨ã€‘](https://zenn.dev/fumishiki/ml-lecture-26-part1)


## ğŸ’» Z5. è©¦ç·´ï¼ˆå®Ÿè£…ï¼‰ï¼ˆ45åˆ†ï¼‰â€” Rustçµ±è¨ˆåˆ†æ + Rust Criterion

### 4.1 Rustçµ±è¨ˆåˆ†æçµ±åˆ

ç¬¬24å›ã§å­¦ã‚“ã çµ±è¨ˆæ¤œå®šã‚’è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«çµ±åˆã™ã‚‹ã€‚

#### 4.1.1 FIDã®ä¿¡é ¼åŒºé–“

FIDæ¨å®šé‡ $\widehat{\text{FID}}$ ã¯æœ‰é™ã‚µãƒ³ãƒ—ãƒ«ã§ã®æ¨å®š â†’ ä¸ç¢ºå®Ÿæ€§ãŒã‚ã‚‹ã€‚

çœŸã® FID ã‚’ $\text{FID}^*$ ã¨ã™ã‚‹ã¨ã€$n$ ã‚µãƒ³ãƒ—ãƒ«ã§ã®æ¨å®šèª¤å·®ã¯ $|\widehat{\text{FID}} - \text{FID}^*| = O(1/\sqrt{n})$ ã®ã‚ªãƒ¼ãƒ€ãƒ¼ã§æ¸›å°‘ã™ã‚‹ã€‚$n=50$ ã¨ $n=5000$ ã§ã¯æ¨å®šç²¾åº¦ãŒ $\sqrt{100} = 10$ å€ç•°ãªã‚‹ã€‚

> **âš ï¸ Warning:** è«–æ–‡ã§ã€ŒFID=3.12ã€ã¨å ±å‘Šã™ã‚‹å ´åˆã€ä¿¡é ¼åŒºé–“ã‚’ç¤ºã•ãªã„ã¨ç„¡æ„å‘³ã€‚ç‰¹ã« FID å·®ãŒå°ã•ã„å ´åˆï¼ˆä¾‹: 3.12 vs 3.08ï¼‰ã¯çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’å¿…ãšç¢ºèªã™ã‚‹ã“ã¨ã€‚

**Bootstrapæ³•ã§ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—**:

```rust
use ndarray::{Array1, Array2};
// use rand::seq::SliceRandom;

/// FID confidence interval via bootstrap resampling.
/// Extracts features once and resamples indices to estimate FID distribution.
fn fid_with_ci(
    feats_real: &Array2<f64>,  // (n_real, d) â€” pre-extracted Inception features
    feats_gen: &Array2<f64>,   // (n_gen, d)
    n_bootstrap: usize,
    confidence: f64,
) -> (f64, f64, f64, Vec<f64>) {
    // Point estimate
    let (mu_r, sigma_r) = compute_statistics(feats_real);
    let (mu_g, sigma_g) = compute_statistics(feats_gen);
    let fid_point = frechet_distance(&mu_r.view(), &sigma_r.view(),
                                     &mu_g.view(), &sigma_g.view());

    // Bootstrap resampling
    // use rand::thread_rng; use rand::seq::index::sample;
    let n_real = feats_real.nrows();
    let n_gen  = feats_gen.nrows();

    let fid_samples: Vec<f64> = (0..n_bootstrap).map(|_| {
        // Subsample with replacement (placeholder: use rand::seq in production)
        let idx_r: Vec<usize> = (0..n_real).map(|i| i % n_real).collect();
        let idx_g: Vec<usize> = (0..n_gen).map(|i| i % n_gen).collect();

        let real_b = feats_real.select(ndarray::Axis(0), &idx_r);
        let gen_b  = feats_gen.select(ndarray::Axis(0), &idx_g);
        let (mu_rb, sigma_rb) = compute_statistics(&real_b);
        let (mu_gb, sigma_gb) = compute_statistics(&gen_b);
        frechet_distance(&mu_rb.view(), &sigma_rb.view(),
                         &mu_gb.view(), &sigma_gb.view())
    }).collect();

    // Confidence interval (percentile method)
    let mut sorted = fid_samples.clone();
    sorted.sort_by(|a, b| a.partial_cmp(b).unwrap());
    let alpha = 1.0 - confidence;
    let ci_lower = sorted[(alpha / 2.0 * n_bootstrap as f64) as usize];
    let ci_upper = sorted[((1.0 - alpha / 2.0) * n_bootstrap as f64) as usize];

    (fid_point, ci_lower, ci_upper, fid_samples)
}

/// Compute mean and diagonal covariance from feature matrix.
fn compute_statistics(feats: &Array2<f64>) -> (Array1<f64>, Array2<f64>) {
    let n = feats.nrows() as f64;
    let mu = feats.mean_axis(ndarray::Axis(0)).unwrap();
    // Diagonal covariance (full covariance requires O(dÂ²) memory)
    let sigma_diag: Array1<f64> = feats.columns().into_iter().map(|col| {
        let m = col.sum() / n;
        col.iter().map(|x| (x - m).powi(2)).sum::<f64>() / (n - 1.0)
    }).collect();
    let sigma = Array2::from_diag(&sigma_diag);
    (mu, sigma)
}
```

#### 4.1.2 ãƒ¢ãƒ‡ãƒ«é–“æ¯”è¼ƒ â€” æœ‰æ„å·®æ¤œå®š

2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®FIDã‚’æ¯”è¼ƒ â†’ çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ãŒã‚ã‚‹ã‹ï¼Ÿ

**Welch's t-test** (ç¬¬24å›):

$$
t = \frac{\bar{x}_A - \bar{x}_B}{\sqrt{\frac{s_A^2}{n_A} + \frac{s_B^2}{n_B}}}
$$

è‡ªç”±åº¦ã¯ Welch-Satterthwaite è¿‘ä¼¼ $\nu \approx \frac{(s_A^2/n_A + s_B^2/n_B)^2}{(s_A^2/n_A)^2/(n_A-1) + (s_B^2/n_B)^2/(n_B-1)}$ ã§è¨ˆç®—ã™ã‚‹ã€‚Student's t-testï¼ˆç­‰åˆ†æ•£ä»®å®šï¼‰ã¨ã®é•ã„ã¯åˆ†æ¯ã®åˆ†æ•£æ¨å®šé‡ã§ã‚ã‚Šã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«é–“ã® FID æ¯”è¼ƒã§ã¯åˆ†æ•£ãŒç•°ãªã‚‹ã“ã¨ãŒå¤šã„ãŸã‚ Welch ãŒé©åˆ‡ã€‚

**Cohen's d (åŠ¹æœé‡)**: på€¤ã ã‘ã§ã¯ã€Œæ”¹å–„ã®å¤§ãã•ã€ãŒã‚ã‹ã‚‰ãªã„ã€‚Cohen's d ã¯æ¨™æº–åŒ–ã—ãŸå·®ã§ã‚ã‚Šã€|d| < 0.2 = å°ã€0.2-0.5 = ä¸­ã€> 0.8 = å¤§ã¨è§£é‡ˆã™ã‚‹ã€‚FID ã§ d=0.3 ã¯ã€Œä¸­ç¨‹åº¦ã®æ”¹å–„ã€â†’ è«–æ–‡å ±å‘Šã«ã¯ på€¤ã¨ä½µè¨˜ãŒæœ›ã¾ã—ã„ã€‚

```rust

/// Compare two models' FID distributions using Welch's t-test.
/// Returns (p_value, cohens_d, is_significant).
fn compare_models_fid(fid_a: &[f64], fid_b: &[f64], alpha: f64) -> (f64, f64, bool) {
    let mean_f = |v: &[f64]| v.iter().sum::<f64>() / v.len() as f64;
    let std_f = |v: &[f64]| {
        let m = mean_f(v);
        (v.iter().map(|x| (x - m).powi(2)).sum::<f64>() / (v.len() as f64 - 1.0)).sqrt()
    };

    let mu_a = mean_f(fid_a);
    let mu_b = mean_f(fid_b);
    let s_a = std_f(fid_a);
    let s_b = std_f(fid_b);
    let na = fid_a.len() as f64;
    let nb = fid_b.len() as f64;

    // Welch's t-statistic
    let se = (s_a * s_a / na + s_b * s_b / nb).sqrt();
    let t_stat = (mu_a - mu_b) / se;

    // Welch-Satterthwaite degrees of freedom
    let df = (s_a * s_a / na + s_b * s_b / nb).powi(2)
        / ((s_a * s_a / na).powi(2) / (na - 1.0) + (s_b * s_b / nb).powi(2) / (nb - 1.0));

    // Approximate two-tailed p-value (use statrs::distribution::StudentsT in production)
    let p_value = 2.0 * (-t_stat.abs() / df.sqrt()).exp().min(1.0); // rough approximation

    // Effect size (Cohen's d)
    let pooled_std = ((s_a * s_a + s_b * s_b) / 2.0).sqrt();
    let cohens_d = (mu_a - mu_b) / pooled_std;

    println!("Model A FID: {:.2} Â± {:.2}", mu_a, s_a);
    println!("Model B FID: {:.2} Â± {:.2}", mu_b, s_b);
    println!("p-value: {:.4}", p_value);
    println!("Significant? {} (Î±={:.2})", p_value < alpha, alpha);
    println!("Effect size (Cohen's d): {:.3}", cohens_d);

    (p_value, cohens_d, p_value < alpha)
}

// Usage:
// let fid_a: Vec<f64> = (0..100).map(|_| 15.0 + 2.0 * rng.sample(Normal)).collect();
// let fid_b: Vec<f64> = (0..100).map(|_| 13.0 + 1.5 * rng.sample(Normal)).collect();
// compare_models_fid(&fid_a, &fid_b, 0.05);
```

#### 4.1.3 å¤šé‡æ¯”è¼ƒè£œæ­£ â€” Bonferroni/FDR

è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ï¼ˆNå€‹ï¼‰ã‚’æ¯”è¼ƒ â†’ å¤šé‡æ¤œå®šå•é¡Œï¼ˆç¬¬24å›ï¼‰ã€‚

**Bonferroniè£œæ­£**: $\alpha' = \alpha / N$

**ãªãœå¿…è¦ã‹**: $N=6$ ãƒšã‚¢æ¯”è¼ƒã‚’ $\alpha=0.05$ ã§è¡Œã†ã¨ã€å¸°ç„¡ä»®èª¬ãŒå…¨ã¦çœŸã§ã‚‚å°‘ãªãã¨ã‚‚1ã¤ã®å½é™½æ€§ãŒå‡ºã‚‹ç¢ºç‡ã¯ $1 - (1-0.05)^6 \approx 0.26$ã€‚è£œæ­£å¾Œã¯ $1 - (1-\alpha')^6 = 1 - (1-0.0083)^6 \approx 0.049 < 0.05$ ã«æŠ‘ãˆã‚‰ã‚Œã‚‹ã€‚

> **âš ï¸ Warning:** Bonferroni ã¯ä¿å®ˆçš„ã™ãã‚‹å ´åˆãŒã‚ã‚‹ï¼ˆæ¤œå‡ºåŠ›ãŒä¸‹ãŒã‚‹ï¼‰ã€‚ã‚ˆã‚Šç·©ã‚„ã‹ãª Holm-Bonferroni ã‚„ Benjamini-Hochberg (FDR) è£œæ­£ã‚‚æ¤œè¨ã™ã‚‹ã“ã¨ã€‚

```rust
/// Multiple model comparison with Bonferroni correction.
/// Returns vec of (i, j, p_value, significant).
fn compare_multiple_models(fid_list: &[Vec<f64>], alpha: f64) -> Vec<(usize, usize, f64, bool)> {
    let n_models = fid_list.len();
    let n_comparisons = n_models * (n_models - 1) / 2;
    let alpha_bonf = alpha / n_comparisons as f64;

    println!("Comparing {} models ({} pairwise tests)", n_models, n_comparisons);
    println!("Bonferroni-corrected Î±: {:.5}", alpha_bonf);

    let mut results = Vec::new();
    for i in 0..n_models {
        for j in (i + 1)..n_models {
            let (p_val, _, _) = compare_models_fid(&fid_list[i], &fid_list[j], alpha_bonf);
            let is_sig = p_val < alpha_bonf;
            println!("Model {} vs {}: p={:.4}, significant={}", i + 1, j + 1, p_val, is_sig);
            results.push((i, j, p_val, is_sig));
        }
    }
    results
}

// Usage:
// let fid_list = vec![fid_model1, fid_model2, fid_model3, fid_model4];
// compare_multiple_models(&fid_list, 0.05);
```

### 4.2 Rust Criterion ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

**Criterion.rs** [^criterion] ã¯Rustã®çµ±è¨ˆçš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚

å†…éƒ¨ã§ã¯å„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–¢æ•°ã‚’ç¹°ã‚Šè¿”ã—å®Ÿè¡Œã—ã€å®Ÿè¡Œæ™‚é–“ã®åˆ†å¸ƒã‚’æ¨å®šã™ã‚‹ã€‚ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¾Œã«æ¸¬å®šã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’è¨­ã‘ã€å¹³å‡ãƒ»æ¨™æº–åå·®ãƒ»[ä¸‹é™, æ¨å®šå€¤, ä¸Šé™] ã®3ç‚¹ä¿¡é ¼åŒºé–“ï¼ˆBootstrapãƒ™ãƒ¼ã‚¹ï¼‰ã‚’å‡ºåŠ›ã™ã‚‹ã€‚ã€Œperformance regression detected (p=0.03)ã€ã¯å‰å›ã¨ã®å·®ãŒWelch tæ¤œå®šã§ $p < 0.05$ ã«ãªã£ãŸã“ã¨ã‚’æ„å‘³ã™ã‚‹ã€‚

**ç‰¹å¾´**:
- çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå‡ºï¼ˆå›å¸°æ¤œå‡ºï¼‰
- è‡ªå‹• outlier é™¤å»
- CIçµ±åˆå¯èƒ½

#### 4.2.1 Rust FIDå®Ÿè£…ã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

```rust
// Cargo.toml
// [dependencies]
// ndarray = "0.16"
// ndarray-linalg = "0.19"
// [dev-dependencies]
// criterion = "0.5"

use ndarray::{Array1, Array2};
use ndarray_linalg::*;

/// Compute FrÃ©chet distance between two Gaussians
pub fn frechet_distance(
    mu1: &Array1<f64>,
    sigma1: &Array2<f64>,
    mu2: &Array1<f64>,
    sigma2: &Array2<f64>,
) -> Result<f64, Box<dyn std::error::Error>> {
    // Mean difference term
    let diff = mu1 - mu2;
    let mean_term = diff.dot(&diff);

    // Covariance term: Tr(Î£1 + Î£2 - 2(Î£1 Î£2)^{1/2})
    let product = sigma1.dot(sigma2);

    // shape: sigma1, sigma2 âˆˆ â„^{dÃ—d}, product âˆˆ â„^{dÃ—d}  (d=2048 å…¸å‹)
    // è¡Œåˆ—å¹³æ–¹æ ¹ã®è¨ˆç®—ãŒæ”¯é…çš„ã‚³ã‚¹ãƒˆ: å›ºæœ‰å€¤åˆ†è§£ O(dÂ³) â‰ˆ 8.6Ã—10â¹ flops (d=2048)

    // Matrix square root via eigen decomposition
    let (eigenvalues, eigenvectors) = product.eigh(UPLO::Lower)?;
    let sqrt_eig = eigenvalues.mapv(|x| x.abs().sqrt());
    let sqrt_product = &eigenvectors * &Array2::from_diag(&sqrt_eig) * &eigenvectors.t();

    let trace_term = sigma1.diag().sum() + sigma2.diag().sum() - 2.0 * sqrt_product.diag().sum();

    Ok(mean_term + trace_term)
}

#[cfg(test)]
mod benches {
    use super::*;
    use criterion::{black_box, criterion_group, criterion_main, Criterion};
    use ndarray::Array;

    fn benchmark_fid(c: &mut Criterion) {
        let d = 2048;  // Inception feature dim
        let mu1 = Array1::zeros(d);
        let mu2 = Array1::ones(d) * 0.1;
        let sigma1 = Array2::eye(d);
        let sigma2 = Array2::eye(d) * 1.1;

        c.bench_function("fid_2048d", |b| {
            b.iter(|| {
                frechet_distance(
                    black_box(&mu1),
                    black_box(&sigma1),
                    black_box(&mu2),
                    black_box(&sigma2),
                ).unwrap()
            })
        });
    }

    criterion_group!(benches, benchmark_fid);
    criterion_main!(benches);
}
```

**å®Ÿè¡Œ**:

```bash
cargo bench
```

**å‡ºåŠ›ä¾‹**:

```
fid_2048d               time:   [12.234 ms 12.456 ms 12.701 ms]
                        change: [-2.3% +0.5% +3.1%] (p = 0.67 > 0.05)
                        No change in performance detected.
```

Criterionã¯è‡ªå‹•ã§:
- è¤‡æ•°å›å®Ÿè¡Œï¼ˆwarmup + measurementï¼‰
- çµ±è¨ˆé‡è¨ˆç®—ï¼ˆå¹³å‡ã€æ¨™æº–åå·®ã€ä¿¡é ¼åŒºé–“ï¼‰
- å‰å›ã¨ã®æ¯”è¼ƒï¼ˆå›å¸°æ¤œå‡ºï¼‰

**å‡ºåŠ›ã®èª­ã¿æ–¹**: `[12.234 ms 12.456 ms 12.701 ms]` ã¯ [ä¸‹é™, æ¨å®šå€¤, ä¸Šé™] ã®95%ä¿¡é ¼åŒºé–“ã€‚`change: [-2.3% +0.5% +3.1%] (p = 0.67 > 0.05)` ã¯å›å¸°ãªã—ï¼ˆp > 0.05ï¼‰ã€‚`p < 0.05` ãŒå‡ºãŸã‚‰æ€§èƒ½åŠ£åŒ–ç¢ºå®šã¨åˆ¤æ–­ã™ã‚‹ã€‚

#### 4.2.2 è‡ªå‹•ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

**CIçµ±åˆ**: GitHub Actions ã§è‡ªå‹•ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ + å›å¸°ã‚¢ãƒ©ãƒ¼ãƒˆã€‚

```yaml
# .github/workflows/bench.yml
name: Benchmark

on: [push, pull_request]

jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
      - name: Run benchmarks
        run: cargo bench --bench fid_bench
      - name: Upload results
        uses: actions/upload-artifact@v2
        with:
          name: criterion-results
          path: target/criterion/
```

### 4.3 è‡ªå‹•è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­è¨ˆ

**ãƒ•ãƒ­ãƒ¼**:

```mermaid
graph LR
    A[ãƒ¢ãƒ‡ãƒ«è¨“ç·´] --> B[ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜]
    B --> C[ç”»åƒç”Ÿæˆ<br/>n=5000]
    C --> D[ç‰¹å¾´æŠ½å‡º<br/>Inception/CLIP]
    D --> E1[FIDè¨ˆç®—]
    D --> E2[ISè¨ˆç®—]
    D --> E3[LPIPSè¨ˆç®—]
    D --> E4[P&Rè¨ˆç®—]
    D --> E5[CMMDè¨ˆç®—]
    E1 & E2 & E3 & E4 & E5 --> F[çµ±è¨ˆæ¤œå®š<br/>CI+t-test]
    F --> G[ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ<br/>JSON/HTML]
    G --> H[CI Artifact]
    style F fill:#fff3e0
    style G fill:#c8e6c9
```

**å®Ÿè£…** (Rust):

```rust
use serde::{Deserialize, Serialize};
use std::path::Path;
// use serde_json;
// use std::time::SystemTime;

#[derive(Debug, Serialize, Deserialize)]
struct EvaluationResult {
    fid: f64,
    fid_ci: (f64, f64),
    is_score: f64,
    cmmd: f64,
    precision: f64,
    recall: f64,
    timestamp: String,
}

fn evaluate_model(
    model_checkpoint: &str,
    feats_real: &Array2<f64>,  // pre-extracted Inception features
    n_gen: usize,
) -> EvaluationResult {
    println!("Evaluating model: {}", model_checkpoint);

    // Step 1: Generate features (placeholder â€” replace with actual model inference)
    println!("Generating {} images...", n_gen);
    let feats_gen: Array2<f64> = Array2::zeros((n_gen, feats_real.ncols())); // placeholder

    // Step 2: Compute FID with CI
    println!("Computing FID...");
    let (fid_val, fid_l, fid_u, _) = fid_with_ci(feats_real, &feats_gen, 200, 0.95);

    // Step 3: Compute additional metrics (placeholder implementations)
    println!("Computing IS, CMMD, Precision-Recall...");
    let is_val = 1.0_f64;     // replace with inception_score(&feats_gen)
    let cmmd_val = 0.0_f64;   // replace with cmmd(&feats_real, &feats_gen)
    let (prec, rec) = (0.0_f64, 0.0_f64); // replace with precision_recall(...)

    let result = EvaluationResult {
        fid: fid_val,
        fid_ci: (fid_l, fid_u),
        is_score: is_val,
        cmmd: cmmd_val,
        precision: prec,
        recall: rec,
        timestamp: "2024-01-01T00:00:00Z".to_string(), // use chrono::Utc::now() in production
    };

    // Step 4: Save to JSON
    let output_path = format!("eval_results_{}.json",
        Path::new(model_checkpoint).file_name().unwrap_or_default().to_string_lossy());
    // serde_json::to_writer_pretty(std::fs::File::create(&output_path)?, &result)?;
    println!("âœ… Evaluation complete. Results saved to {}", output_path);

    result
}
```

> **Note:** **é€²æ—: 70% å®Œäº†** å®Ÿè£…ã‚¾ãƒ¼ãƒ³å®Œäº† â€” Rustçµ±è¨ˆåˆ†æ + Rust Criterion + è‡ªå‹•è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚ã“ã“ã‹ã‚‰å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ã¸ â€” VAE/GAN/GPTçµ±åˆè©•ä¾¡ã€‚

---


> Progress: [85%]
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. Criterion.rsãŒã€Œçµ±è¨ˆçš„æœ‰æ„ãªå›å¸°ã€ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã«Welch tæ¤œå®šã‚’ç”¨ã„ã‚‹ç†ç”±ã¯ï¼Ÿ
>    - *ãƒ’ãƒ³ãƒˆ*: ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å‰å¾Œã®å®Ÿè¡Œæ™‚é–“åˆ†å¸ƒãŒç­‰åˆ†æ•£ã ã¨ä»®å®šã§ãã‚‹ã‹è€ƒãˆã‚ˆã€‚
> 2. FIDè¨ˆç®—ã§Inceptionç‰¹å¾´é‡ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ãªã„ã¨è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒé‡ããªã‚‹è¨ˆç®—é‡çš„ç†ç”±ã¯ï¼Ÿ
>    - *ãƒ’ãƒ³ãƒˆ*: Inception-v3ã® forward pass ãŒ1ç”»åƒã‚ãŸã‚Šä½• FLOP ã‹ã€5000ã‚µãƒ³ãƒ—ãƒ«ã§ä½•å›èµ°ã‚‹ã‹è¨ˆç®—ã›ã‚ˆã€‚

### ğŸ”¬ å®Ÿé¨“ãƒ»æ¤œè¨¼ï¼ˆ30åˆ†ï¼‰â€” VAE/GAN/GPTçµ±åˆè©•ä¾¡

### 5.1 æ¼”ç¿’: 3ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æ¯”è¼ƒ

**èª²é¡Œ**: VAE, GAN, GPT (autoregressive) ã®3ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ã€æ¯”è¼ƒã›ã‚ˆã€‚

**æœŸå¾…ã•ã‚Œã‚‹çµæœã®äº‹å‰ãƒã‚§ãƒƒã‚¯**: FID(VAE) > FID(GAN) â‰ˆ FID(AR) ãŒå…¸å‹ã€‚VAE ã¯ã¼ã‚„ã‘ãŸç”»åƒã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ FID ãŒæ‚ªããªã‚‹ã€‚ãŸã ã— Recall(VAE) > Recall(GAN) ã¨ãªã‚‹ã“ã¨ãŒå¤šã„ï¼ˆVAE ã¯å¤šæ§˜æ€§é«˜ã„ãŒã¼ã‚„ã‘ã€GAN ã¯é®®æ˜ã ãŒ mode collapseï¼‰ã€‚å®Ÿé¨“å‰ã«ã€Œã©ã®æŒ‡æ¨™ãŒå¤§ãããªã‚‹/å°ã•ããªã‚‹ã€ã‚’ä»®èª¬ã¨ã—ã¦æ›¸ã„ã¦ã‹ã‚‰å®Ÿé¨“ã™ã‚‹ã“ã¨ã€‚

**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: MNIST (ç°¡æ˜“ç‰ˆ)

#### 5.1.1 ãƒ¢ãƒ‡ãƒ«å®Ÿè£…ï¼ˆç°¡ç•¥ç‰ˆï¼‰

```rust
// Simplified model stubs for evaluation demo.
// For production: use the `candle` or `burn` deep learning crate.

/// Tiny VAE: encoder â†’ (Î¼, logÏƒ) â†’ reparameterize â†’ decoder
struct TinyVAE {
    latent_dim: usize,
    input_dim: usize,
}

impl TinyVAE {
    fn new(input_dim: usize, latent_dim: usize) -> Self { Self { latent_dim, input_dim } }

    /// Forward: encode â†’ sample z â†’ decode. Returns (x_recon, mu, logÏƒ).
    fn forward(&self, _x: &[f64]) -> (Vec<f64>, Vec<f64>, Vec<f64>) {
        let mu    = vec![0.0; self.latent_dim];
        let log_s = vec![0.0; self.latent_dim];
        // z = Î¼ + exp(logÏƒ) * Îµ,  Îµ ~ N(0,1)
        let z: Vec<f64> = mu.iter().zip(&log_s).map(|(m, ls)| m + ls.exp()).collect();
        let x_recon = vec![0.0; self.input_dim]; // placeholder decode(z)
        (x_recon, mu, log_s)
    }

    fn generate(&self) -> Vec<f64> {
        // Sample z ~ N(0,I), then decode
        let z = vec![0.0_f64; self.latent_dim]; // use rand_distr::Normal
        vec![0.0; self.input_dim] // placeholder decode(z)
    }
}

/// Tiny GAN: sample latent â†’ generator
struct TinyGAN { latent_dim: usize, output_dim: usize }
impl TinyGAN {
    fn new(latent_dim: usize, output_dim: usize) -> Self { Self { latent_dim, output_dim } }
    fn generate(&self, _n: usize) -> Vec<Vec<f64>> {
        // z ~ N(0,I) â†’ generator(z)
        vec![vec![0.0; self.output_dim]] // placeholder
    }
}

/// Tiny autoregressive model: step-by-step token sampling
struct TinyAR { seq_len: usize }
impl TinyAR {
    fn generate_sequence(&self) -> Vec<f64> {
        let mut x = vec![0.0_f64; self.seq_len];
        for t in 1..self.seq_len {
            // p(x_t | x_{1:t-1}) â€” placeholder
            x[t] = (x[t - 1] * 0.9).max(0.0);
        }
        x
    }
}
```

#### 5.1.2 çµ±åˆè©•ä¾¡

```rust
use std::collections::HashMap;

/// Unified evaluation for 3 model types: VAE, GAN, AR.
fn evaluate_all_models(
    feats_real: &Array2<f64>,
    n_gen: usize,
) -> HashMap<&'static str, HashMap<&'static str, f64>> {
    println!("ğŸ”¬ Evaluating 3 models: VAE, GAN, AR");

    let model_names = ["VAE", "GAN", "AR"];
    let mut results: HashMap<&'static str, HashMap<&'static str, f64>> = HashMap::new();

    for name in model_names {
        println!("\nğŸ“Š Evaluating {}...", name);

        // Generate placeholder feature vectors (replace with actual model inference)
        let feats_gen = Array2::zeros((n_gen, feats_real.ncols()));

        let (fid_val, _, _, _) = fid_with_ci(feats_real, &feats_gen, 100, 0.95);
        let is_val   = 1.0_f64; // inception_score(&feats_gen)
        let cmmd_val = 0.0_f64; // cmmd(feats_real, &feats_gen)
        let (prec, rec) = (0.0_f64, 0.0_f64); // precision_recall(feats_real, &feats_gen, 5)

        let mut m = HashMap::new();
        m.insert("FID",       fid_val);
        m.insert("IS",        is_val);
        m.insert("CMMD",      cmmd_val);
        m.insert("Precision", prec);
        m.insert("Recall",    rec);
        results.insert(name, m);
    }

    // Display comparison table
    println!("\nğŸ“‹ Comparison Table:");
    println!("| Model | FID â†“ | IS â†‘ | CMMD â†“ | Precision â†‘ | Recall â†‘ |");
    println!("|:------|:------|:-----|:-------|:------------|:---------|");
    for name in model_names {
        let m = &results[name];
        println!("| {} | {:.2} | {:.2} | {:.4} | {:.3} | {:.3} |",
            name, m["FID"], m["IS"], m["CMMD"], m["Precision"], m["Recall"]);
    }

    results
}
```

**æœŸå¾…ã•ã‚Œã‚‹çµæœãƒ‘ã‚¿ãƒ¼ãƒ³**:

| Model | FID â†“ | IS â†‘ | CMMD â†“ | Precision â†‘ | Recall â†‘ | ç‰¹å¾´ |
|:------|:------|:-----|:-------|:------------|:---------|:-----|
| VAE | ä¸­ | ä¸­ | ä¸­ | ä¸­ | **é«˜** | å¤šæ§˜æ€§é«˜ã„ãŒã¼ã‚„ã‘ã‚‹ |
| GAN | **ä½** | **é«˜** | **ä½** | **é«˜** | ä½ | é«˜å“è³ªã ãŒmode collapse |
| AR | ä½-ä¸­ | é«˜ | ä½ | é«˜ | é«˜ | å“è³ªã‚‚å¤šæ§˜æ€§ã‚‚è‰¯ã„ãŒé…ã„ |

> **âš ï¸ Warning:** ã“ã®çµæœãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ç†æƒ³åŒ–ã•ã‚ŒãŸã‚‚ã®ã€‚å®Ÿéš›ã® MNIST ã§ã¯å…¨ãƒ¢ãƒ‡ãƒ«ãŒé¡ä¼¼ã® FID ã‚’ç¤ºã™ã“ã¨ã‚‚å¤šã„ã€‚å·®ãŒå‡ºã‚‹ã®ã¯ CIFAR-10 ã‚„ CelebA ãªã©ã®è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§é¡•è‘—ã«ãªã‚‹ã€‚å°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡ã™ã‚‹éš›ã¯ Bootstrap ã§ä¿¡é ¼åŒºé–“ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã€‚

### 5.2 äººé–“è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«è¨­è¨ˆ

**å®šé‡è©•ä¾¡ã®é™ç•Œ** â†’ äººé–“è©•ä¾¡ãŒå¿…è¦ã€‚

#### 5.2.1 A/Bãƒ†ã‚¹ãƒˆè¨­è¨ˆ

**è³ªå•**: ã€Œã©ã¡ã‚‰ã®ç”»åƒãŒã‚ˆã‚Šè‡ªç„¶ã§ã™ã‹ï¼Ÿã€

**è¨­è¨ˆ**:
1. ãƒšã‚¢wiseæ¯”è¼ƒï¼ˆ2ç”»åƒã‚’æç¤ºï¼‰
2. ç„¡ä½œç‚ºåŒ–ï¼ˆé †åºã€ãƒšã‚¢é¸æŠï¼‰
3. è©•ä¾¡è€…é–“ä¸€è‡´åº¦ï¼ˆInter-rater reliabilityï¼‰

**ã‚µãƒ³ãƒ—ãƒ«æ•°ã®è¦‹ç©ã‚‚ã‚Š**: å·®ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã«å¿…è¦ãªãƒšã‚¢æ•° $n$ ã¯ã€åŠ¹æœé‡ $d$ ã¨æœ‰æ„æ°´æº– $\alpha=0.05$ã€æ¤œå‡ºåŠ› $1-\beta=0.80$ ã‹ã‚‰ $n \approx 16 / d^2$ï¼ˆCohen ã®å…¬å¼ï¼‰ã€‚GAN vs VAE ã®å·®ãŒä¸­ç¨‹åº¦ï¼ˆ$d=0.5$ï¼‰ãªã‚‰ $n \approx 64$ ãƒšã‚¢ãŒå¿…è¦ã€‚

```rust
use std::collections::HashMap;

#[derive(Debug, Clone)]
struct AbTest {
    pair_id: usize,
    img_a_idx: usize,
    img_b_idx: usize,
    model_a: String,
    model_b: String,
}

/// Design randomized A/B test pairs from multiple model sample sets.
fn design_ab_test(
    models: &HashMap<&str, Vec<usize>>,  // model name â†’ sample indices
    n_pairs: usize,
) -> Vec<AbTest> {
    // use rand::seq::SliceRandom;
    let model_names: Vec<&str> = models.keys().cloned().collect();

    (0..n_pairs).map(|i| {
        // Pick two distinct models at random
        let m1 = model_names[i % model_names.len()];
        let m2 = model_names[(i + 1) % model_names.len()];
        let idx1 = models[m1][i % models[m1].len()];
        let idx2 = models[m2][i % models[m2].len()];

        // Randomize A/B order
        if i % 2 == 0 {
            AbTest { pair_id: i, img_a_idx: idx1, img_b_idx: idx2,
                     model_a: m1.to_string(), model_b: m2.to_string() }
        } else {
            AbTest { pair_id: i, img_a_idx: idx2, img_b_idx: idx1,
                     model_a: m2.to_string(), model_b: m1.to_string() }
        }
    }).collect()
}

/// Export A/B test pairs to CSV for crowdsourcing annotation.
fn export_ab_test_csv(tests: &[AbTest], output_path: &str) -> std::io::Result<()> {
    use std::io::Write;
    let mut f = std::fs::File::create(output_path)?;
    writeln!(f, "pair_id,img_a_path,img_b_path,model_a,model_b")?;
    for t in tests {
        writeln!(f, "{},ab_test_{}_a.png,ab_test_{}_b.png,{},{}",
                 t.pair_id, t.pair_id, t.pair_id, t.model_a, t.model_b)?;
    }
    println!("âœ… A/B test CSV exported to {}", output_path);
    Ok(())
}
```

#### 5.2.2 Mean Opinion Score (MOS)

**è³ªå•**: ã€Œã“ã®ç”»åƒã®å“è³ªã‚’1-5ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€

**è¨­è¨ˆ**:
1. Likert scale (1=æœ€æ‚ª, 5=æœ€é«˜)
2. è¤‡æ•°è©•ä¾¡è€…ï¼ˆâ‰¥3äººï¼‰ã§å¹³å‡
3. ä¿¡é ¼åŒºé–“è¨ˆç®—

**MOS ã®çµ±è¨ˆçš„è§£é‡ˆ**: æ¨™æº–èª¤å·® $\text{SE} = \sigma / \sqrt{n_\text{raters} \times n_\text{items}}$ã€‚95% CI $= \mu \pm 1.96 \cdot \text{SE}$ã€‚MOS 3.5 Â± 0.1 ã¯ã€ŒMOS 4.0 ã¨ã®å·®ãŒæœ‰æ„ã€ã‚’ç¤ºã™ï¼ˆCI ãŒé‡ãªã‚‰ãªã„ï¼‰ã€‚GTã¨ã®å·®ãŒ 0.2 ä»¥ä¸‹ãªã‚‰ã€Œå®Ÿç”¨çš„ã«åŒç­‰å“è³ªã€ã¨ã¿ãªã™ã“ã¨ãŒå¤šã„ã€‚

```rust
use std::collections::HashMap;

#[derive(Debug, Clone)]
struct MosResult {
    image_id: usize,
    model: String,
    ratings: Vec<u32>,  // 1-5 from multiple raters
}

/// Analyze MOS (Mean Opinion Score) data across models.
/// Prints table: Model | Mean MOS | Std | 95% CI
fn analyze_mos(results: &[MosResult]) {
    // Group ratings by model
    let mut by_model: HashMap<&str, Vec<u32>> = HashMap::new();
    for r in results {
        by_model.entry(r.model.as_str())
            .or_default()
            .extend_from_slice(&r.ratings);
    }

    println!("ğŸ“Š MOS Analysis:");
    println!("| Model | Mean MOS | Std | 95% CI |");
    println!("|:------|:---------|:----|:-------|");

    let mut model_names: Vec<&str> = by_model.keys().cloned().collect();
    model_names.sort();

    for model in model_names {
        let ratings: Vec<f64> = by_model[model].iter().map(|&r| r as f64).collect();
        let n = ratings.len() as f64;
        let mu = ratings.iter().sum::<f64>() / n;
        let sigma = (ratings.iter().map(|r| (r - mu).powi(2)).sum::<f64>() / (n - 1.0)).sqrt();
        let se = sigma / n.sqrt();
        let ci = 1.96 * se;
        println!("| {} | {:.2} | {:.2} | [{:.2}, {:.2}] |",
                 model, mu, sigma, mu - ci, mu + ci);
    }
}

// Simulate MOS data
fn mos_demo() {
    let mos_data = vec![
        MosResult { image_id: 1, model: "VAE".into(), ratings: vec![3, 3, 4, 3, 3] },
        MosResult { image_id: 2, model: "VAE".into(), ratings: vec![3, 4, 3, 3, 4] },
        MosResult { image_id: 3, model: "GAN".into(), ratings: vec![4, 5, 4, 4, 5] },
        MosResult { image_id: 4, model: "GAN".into(), ratings: vec![5, 4, 5, 4, 5] },
        MosResult { image_id: 5, model: "AR".into(),  ratings: vec![4, 4, 5, 4, 4] },
        MosResult { image_id: 6, model: "AR".into(),  ratings: vec![4, 5, 4, 5, 4] },
    ];
    analyze_mos(&mos_data);
}
```

#### 5.2.3 è©•ä¾¡è€…é–“ä¸€è‡´åº¦ (Inter-rater Reliability)

**Fleiss' Kappa** (ç¬¬24å›) â€” è¤‡æ•°è©•ä¾¡è€…ã®ä¸€è‡´åº¦ã€‚

$$
\kappa = \frac{\bar{P} - P_e}{1 - P_e}
$$

- $\bar{P}$: å®Ÿéš›ã®è©•ä¾¡è€…é–“ä¸€è‡´ç‡ï¼ˆè¦³æ¸¬å€¤ï¼‰
- $P_e$: å¶ç„¶ã«æœŸå¾…ã•ã‚Œã‚‹ä¸€è‡´ç‡ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰
- $\kappa = 1$: å®Œå…¨ä¸€è‡´ã€$\kappa = 0$: å¶ç„¶ã¨åŒã˜ã€$\kappa < 0$: å¶ç„¶ã‚ˆã‚Šæ‚ªã„

**æ•°å€¤ä¾‹**: $\kappa = 0.65$ ãªã‚‰ã€Œå¶ç„¶ã®ä¸€è‡´ã‚’è¶…ãˆãŸä¸€è‡´ç‡ãŒ 65%ã€â†’ Substantialã€‚ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®äººé–“è©•ä¾¡ã§ã¯ $\kappa \geq 0.4$ ã‚’æœ€ä½åŸºæº–ã¨ã™ã‚‹ã“ã¨ã€‚

```rust
/// Fleiss' Kappa for inter-rater reliability.
/// ratings: row = item, col = rater, values = category labels (1-indexed).
fn fleiss_kappa(ratings: &[Vec<u32>]) -> f64 {
    let n_items = ratings.len();
    let n_raters = ratings[0].len();
    let n_categories = ratings.iter().flatten().cloned().max().unwrap_or(1) as usize;

    // P_i: proportion of agreeing pairs per item
    let p_i: Vec<f64> = ratings.iter().map(|row| {
        let counts: Vec<usize> = (1..=n_categories)
            .map(|k| row.iter().filter(|&&r| r == k as u32).count())
            .collect();
        let sum_sq: usize = counts.iter().map(|c| c * c).sum();
        (sum_sq - n_raters) as f64 / (n_raters * (n_raters - 1)) as f64
    }).collect();
    let p_bar = p_i.iter().sum::<f64>() / n_items as f64;

    // P_e: expected agreement by chance
    let total = (n_items * n_raters) as f64;
    let p_e: f64 = (1..=n_categories).map(|k| {
        let count = ratings.iter().flatten().filter(|&&r| r == k as u32).count() as f64;
        (count / total).powi(2)
    }).sum();

    // Îº = (P_bar - P_e) / (1 - P_e)
    let kappa = (p_bar - p_e) / (1.0 - p_e);

    let interpretation = match kappa {
        k if k < 0.2 => "poor",
        k if k < 0.4 => "fair",
        k if k < 0.6 => "moderate",
        k if k < 0.8 => "substantial",
        _             => "almost perfect",
    };
    println!("Fleiss' Kappa: {:.3} ({})", kappa, interpretation);
    kappa
}

// Test:
// let ratings = vec![
//     vec![1, 2, 1, 1],  // item 1: raters gave 1,2,1,1
//     vec![2, 2, 2, 2],  // item 2: all agree on 2
//     vec![3, 3, 4, 3],  // item 3: mostly 3
// ];
// fleiss_kappa(&ratings);
```

> **Note:** **é€²æ—: 85% å®Œäº†** å®Ÿé¨“ã‚¾ãƒ¼ãƒ³å®Œäº† â€” VAE/GAN/ARçµ±åˆè©•ä¾¡ + äººé–“è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã€‚ã“ã“ã‹ã‚‰ç™ºå±•ã‚¾ãƒ¼ãƒ³ã¸ â€” æœ€æ–°ç ”ç©¶å‹•å‘ã€‚

---

## ğŸ”¬ Z6. æ–°ãŸãªå†’é™ºã¸ï¼ˆç ”ç©¶å‹•å‘ï¼‰

### 6.1 FLD+ (Flow-based Likelihood Distance)

**è«–æ–‡** [^7]: FLD+: Data-efficient Evaluation Metric for Generative Models (2024)

**å‹•æ©Ÿ**: FIDã¯2000+ã‚µãƒ³ãƒ—ãƒ«å¿…è¦ â†’ å°‘ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®šã™ã‚‹æŒ‡æ¨™ãŒæ¬²ã—ã„ã€‚

**ã‚¢ã‚¤ãƒ‡ã‚¢**: Normalizing Flowã§å¯†åº¦æ¨å®š â†’ å°¤åº¦ãƒ™ãƒ¼ã‚¹ã®è·é›¢ã€‚

**å®šç¾©**:

$$
\text{FLD}(P_r, P_g) = \mathbb{E}_{x \sim P_r}[-\log q_\theta(x)] - \mathbb{E}_{x \sim P_g}[-\log q_\theta(x)]
$$

ã“ã“ã§ $q_\theta$ ã¯Normalizing Flowã§è¨“ç·´ã•ã‚ŒãŸå¯†åº¦ãƒ¢ãƒ‡ãƒ«ï¼ˆçœŸç”»åƒã§è¨“ç·´ï¼‰ã€‚

**æ•°å€¤ä¾‹**: $q_\theta$ ãŒå®Œç’§ã« $P_r$ ã‚’å­¦ç¿’ã—ãŸå ´åˆï¼ˆ$q_\theta = P_r$ï¼‰ã€ç¬¬1é …ã¯ $\mathcal{H}(P_r)$ï¼ˆãƒ‡ãƒ¼ã‚¿ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼‰ã€ç¬¬2é …ã¯ç”Ÿæˆåˆ†å¸ƒã® $P_r$ ä¸‹ã§ã® cross-entropyã€‚ä¸¡è€…ãŒç­‰ã—ã‘ã‚Œã° FLD=0 â†’ $P_g = P_r$ã€‚FLD $> 0$ ã¯ç”Ÿæˆåˆ†å¸ƒãŒçœŸåˆ†å¸ƒã‹ã‚‰å¤–ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚

**åˆ©ç‚¹**:
- 200-500ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®šï¼ˆFIDã¯2000+å¿…è¦ï¼‰
- ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œå¯èƒ½ï¼ˆåŒ»ç™‚ç”»åƒãªã©ã§å†è¨“ç·´ï¼‰
- å˜èª¿æ€§ãŒå¼·ã„ï¼ˆç”»åƒåŠ£åŒ–ã«å¯¾ã—ã¦ï¼‰

**ãªãœå°‘ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®šã™ã‚‹ã‹**: FID ã¯ $d \times d$ å…±åˆ†æ•£è¡Œåˆ—ï¼ˆ$d=2048$ï¼‰ã®æ¨å®šãŒå¿…è¦ã§ã€ã“ã‚Œã«ã¯ $O(d^2) \approx 4 \times 10^6$ è‡ªç”±ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚‹ã€‚FLD+ ã¯ Normalizing Flow ã®å¯¾æ•°å°¤åº¦ã‚¹ã‚«ãƒ©ãƒ¼1ã¤ã‚’æ¯”è¼ƒã™ã‚‹ã ã‘ â†’ æ¨å®šå¯¾è±¡ã®æ¬¡å…ƒãŒåœ§å€’çš„ã«å°‘ãªã„ã€‚

### 6.2 è©•ä¾¡æŒ‡æ¨™ã®ç ”ç©¶ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢

**2024-2026ã®ãƒˆãƒ¬ãƒ³ãƒ‰**:

| ç ”ç©¶æ–¹å‘ | ä»£è¡¨è«–æ–‡ | æ¦‚è¦ |
|:---------|:---------|:-----|
| **ä»®å®šãªã—æŒ‡æ¨™** | CMMD [^5], NFM [^8] | MMD/Flowãƒ™ãƒ¼ã‚¹ã€æ­£è¦æ€§ä¸è¦ |
| **å°‘ã‚µãƒ³ãƒ—ãƒ«æŒ‡æ¨™** | FLD+ [^7] | 200ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®š |
| **ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œ** | CMMD-CLIP [^5] | Text-to-Imageç”Ÿæˆå¯¾å¿œ |
| **åˆ†é›¢è©•ä¾¡** | Precision-Recall Cover [^9] | å“è³ªãƒ»å¤šæ§˜æ€§ãƒ»è¢«è¦†ç‡ã‚’åˆ†é›¢ |
| **äººé–“è©•ä¾¡äºˆæ¸¬** | ImageReward, PickScore | äººé–“è©•ä¾¡ã‚’ãƒ¢ãƒ‡ãƒ«åŒ– |

**ãƒˆãƒ¬ãƒ³ãƒ‰ã®æ–¹å‘æ€§**: è©•ä¾¡æŒ‡æ¨™ã®é€²åŒ–ã¯ã€Œä»®å®šã®å‰Šæ¸›ã€ã¨ã€Œäººé–“æ•´åˆæ€§ã®å‘ä¸Šã€ã®2æ–¹å‘ã«å‘ã‹ã£ã¦ã„ã‚‹ã€‚FID â†’ CMMD â†’ FLD+ ã¨ã„ã†æµã‚Œã¯å‰è€…ã€ImageReward â†’ PickScore ã¯å¾Œè€…ã€‚ç©¶æ¥µã¯ã€Œäººé–“ã®ä¸»è¦³ã‚’ã‚¼ãƒ­ã‚³ã‚¹ãƒˆã§å†ç¾ã™ã‚‹æŒ‡æ¨™ã€ã ãŒã€äººé–“è©•ä¾¡è‡ªä½“ãŒä¸»è¦³çš„ã§å¤‰å‹•ã™ã‚‹ãŸã‚ã€çµ±è¨ˆçš„ã«ä¿¡é ¼ã§ãã‚‹è‡ªå‹•æŒ‡æ¨™ã®ç ”ç©¶ã¯ä»Šå¾Œã‚‚ç¶šãã€‚

### 6.3 ç”Ÿæˆãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã®ç³»è­œ

```mermaid
graph TD
    A[2014: Inception Score] --> B[2017: FID]
    B --> C[2019: Precision-Recall]
    C --> D[2024: CMMD]
    D --> E[2024: FLD+]

    A2[ä»®å®š: ImageNetåˆ†é¡] -.->|é™ç•Œ| B2[ä»®å®š: ã‚¬ã‚¦ã‚¹æ€§]
    B2 -.->|é™ç•Œ| C2[è¨ˆç®—ã‚³ã‚¹ãƒˆé«˜]
    C2 -.->|é™ç•Œ| D2[ä»®å®šãªã—<br/>CLIPåŸ‹ã‚è¾¼ã¿]
    D2 --> E2[å°‘ã‚µãƒ³ãƒ—ãƒ«<br/>Flowå¯†åº¦]

    style D fill:#c8e6c9
    style E fill:#b3e5fc
```

### 6.4 è©•ä¾¡æŒ‡æ¨™ã®é¸æŠã‚¬ã‚¤ãƒ‰ï¼ˆ2026å¹´ç‰ˆï¼‰

| çŠ¶æ³ | æ¨å¥¨æŒ‡æ¨™ | ç†ç”± |
|:-----|:---------|:-----|
| **æ¨™æº–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆImageNetç­‰ï¼‰** | FID + IS | æ¯”è¼ƒå¯èƒ½æ€§é‡è¦– |
| **æ–°è¦ç ”ç©¶ï¼ˆ2024ä»¥é™ï¼‰** | **CMMD** + FID | FIDã®é™ç•Œã‚’è£œå®Œ [^5] |
| **å°‘ã‚µãƒ³ãƒ—ãƒ«ï¼ˆ<1000ï¼‰** | **FLD+** | 200ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®š [^7] |
| **Text-to-Image** | **CMMD-CLIP** | ãƒ†ã‚­ã‚¹ãƒˆ-ç”»åƒå¯¾å¿œ [^5] |
| **å“è³ªvså¤šæ§˜æ€§åˆ†æ** | **Precision-Recall** | ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å¯è¦–åŒ– [^4] |
| **ãƒšã‚¢wiseæ¯”è¼ƒ** | **LPIPS** | äººé–“çŸ¥è¦šã¨ç›¸é–¢ [^3] |
| **ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ï¼ˆåŒ»ç™‚ç­‰ï¼‰** | FLD+ (å†è¨“ç·´) | ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œ [^7] |
| **äººé–“è©•ä¾¡ä»£æ›¿** | ImageReward / PickScore | äººé–“è©•ä¾¡äºˆæ¸¬ãƒ¢ãƒ‡ãƒ« |

**æŒ‡æ¨™é¸æŠã®åŸå‰‡**: (1) éå»ã®è«–æ–‡ã¨ã®æ¯”è¼ƒãŒå¿…è¦ â†’ FID å¿…é ˆã€(2) æ–°ã—ã„è©•ä¾¡ã®ä¸»å¼µ â†’ CMMD + FID ã®ä¸¡æ–¹å ±å‘Šã€(3) ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„ â†’ FLD+ ã§æ—©æœŸè©•ä¾¡ã—ã¦ã‹ã‚‰ FID è¿½åŠ ã€‚å˜ä¸€æŒ‡æ¨™ã§ãƒ¢ãƒ‡ãƒ«ã‚’åˆ¤æ–­ã™ã‚‹ã®ã¯é¿ã‘ã‚‹ã“ã¨ã€‚

> **Note:** **é€²æ—: 95% å®Œäº†** ç™ºå±•ã‚¾ãƒ¼ãƒ³å®Œäº† â€” æœ€æ–°ç ”ç©¶å‹•å‘ã€‚ã“ã“ã‹ã‚‰æŒ¯ã‚Šè¿”ã‚Šã‚¾ãƒ¼ãƒ³ã¸ã€‚

---


## ğŸ­ Z7. ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ï¼ˆã¾ã¨ã‚ãƒ»FAQãƒ»æ¬¡å›äºˆå‘Šï¼‰

### 6.6 ã¾ã¨ã‚ â€” 5ã¤ã®è¦ç‚¹

1. **è©•ä¾¡ã¯å¤šé¢çš„**: FID/IS/LPIPS/P&R/CMMD â€” å„æŒ‡æ¨™ã¯ç•°ãªã‚‹å´é¢ã‚’æ¸¬å®šã€‚è¤‡æ•°æŒ‡æ¨™ã‚’çµ„ã¿åˆã‚ã›ã¦ç·åˆåˆ¤æ–­ã€‚

2. **æ•°å¼ã®ç†è§£ãŒæœ¬è³ª**: FID = Wassersteinè·é›¢ã®ã‚¬ã‚¦ã‚¹é–‰å½¢å¼ã€‚IS = KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã®æœŸå¾…å€¤ã€‚CMMD = MMD + CLIPã€‚æ•°å¼ã‚’å°å‡ºã™ã‚Œã°ã€æŒ‡æ¨™ã®ä»®å®šã¨é™ç•ŒãŒè¦‹ãˆã‚‹ã€‚

   **å„æŒ‡æ¨™ã®ä»®å®šã¾ã¨ã‚**:
   - FID: $P_r, P_g$ ãŒå¤šå¤‰é‡ã‚¬ã‚¦ã‚¹åˆ†å¸ƒ + Inceptionç‰¹å¾´ãŒ meaningful
   - IS: Inceptionåˆ†é¡å™¨ãŒæ„å‘³ã®ã‚ã‚‹ã‚¯ãƒ©ã‚¹ç¢ºç‡ã‚’å‡ºåŠ› + $p_g(y)$ ãŒä¸€æ§˜
   - LPIPS: VGG/AlexNet ã®ä¸­é–“ç‰¹å¾´ãŒäººé–“çŸ¥è¦šã‚’åæ˜ 
   - P&R: å¤šæ§˜ä½“ä»®å®šï¼ˆé«˜å¯†åº¦é ˜åŸŸãŒé€£çµï¼‰+ k-NN ãŒå¤šæ§˜ä½“ã‚’è¿‘ä¼¼
   - CMMD: CLIP åŸ‹ã‚è¾¼ã¿ãŒæ„å‘³ç©ºé–“ã‚’åæ˜  + RBF ã‚«ãƒ¼ãƒãƒ«ãŒé©åˆ‡

3. **çµ±è¨ˆæ¤œå®šãŒä¸å¯æ¬ **: FIDã®ç‚¹æ¨å®šã ã‘ã§ã¯ä¸ååˆ†ã€‚ä¿¡é ¼åŒºé–“ãƒ»ä»®èª¬æ¤œå®šãƒ»åŠ¹æœé‡ã§å®Ÿè³ªçš„ãªæ”¹å–„ã‚’åˆ¤æ–­ã€‚

4. **2024å¹´ã®è»¢æ›ç‚¹**: FIDã®é™ç•Œ â†’ CMMD/FLD+ç™»å ´ã€‚æ­£è¦æ€§ä»®å®šã®æ’é™¤ãƒ»å°‘ã‚µãƒ³ãƒ—ãƒ«å¯¾å¿œãƒ»ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œã€‚

5. **è‡ªå‹•åŒ–ãŒéµ**: è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆRustçµ±è¨ˆ + Rust Criterionï¼‰ã‚’CIçµ±åˆ â†’ ç¶™ç¶šçš„ãªå“è³ªç›£è¦–ã€‚

> **âš ï¸ Warning:** è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§æœ€ã‚‚ã‚ˆãã‚ã‚‹å¤±æ•—ã¯ã€Œå®Ÿãƒ‡ãƒ¼ã‚¿ã¨ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã§å‰å‡¦ç†ãŒé•ã†ã€ã“ã¨ã€‚Inceptionç‰¹å¾´æŠ½å‡ºå‰ã«åŒã˜ãƒªã‚µã‚¤ã‚ºãƒ»æ­£è¦åŒ–ã‚’é©ç”¨ã—ã¦ã„ã‚‹ã‹å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨ã€‚å‰å‡¦ç†ã®å·®ç•°ã§ FID ãŒæ•°åå˜ä½ãšã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚

<details><summary>Q1: FIDãŒä½ã„ã®ã«ISãŒé«˜ã„ â€” ã©ã¡ã‚‰ã‚’ä¿¡ã˜ã‚‹ã¹ãï¼Ÿ</summary>

**A**: ä¸¡æ–¹ã¨ã‚‚æ­£ã—ã„å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚FIDã¯åˆ†å¸ƒå…¨ä½“ã®è·é›¢ã€ISã¯å“è³ª+å¤šæ§˜æ€§ã®å˜ä¸€ã‚¹ã‚³ã‚¢ã€‚

**ä¾‹**:
- FIDä½ + ISé«˜ â†’ ç†æƒ³çš„ï¼ˆåˆ†å¸ƒä¸€è‡´ + é«˜å“è³ªãƒ»å¤šæ§˜ï¼‰
- FIDä½ + ISä½ â†’ åˆ†å¸ƒã¯è¿‘ã„ãŒã€å“è³ªorå¤šæ§˜æ€§ãŒä½ã„
- FIDé«˜ + ISé«˜ â†’ mode collapseã®å¯èƒ½æ€§ï¼ˆå°‘æ•°ã®é«˜å“è³ªç”»åƒã®ã¿ç”Ÿæˆï¼‰

**å¯¾ç­–**: Precision-Recallã§å“è³ªã¨å¤šæ§˜æ€§ã‚’åˆ†é›¢æ¸¬å®šã€‚

**è¿½åŠ è§£èª¬**: IS ãŒé«˜ã FID ã‚‚ä½ã„ç†æƒ³ã‚±ãƒ¼ã‚¹ã§ã‚‚ã€å®Ÿã¯ mode collapse ãŒèµ·ãã¦ã„ã‚‹å ´åˆãŒã‚ã‚‹ã€‚IS ã¯ç”Ÿæˆåˆ†å¸ƒ $p_g(y|x)$ ã®é®®æ˜ã•ã¨ $p_g(y)$ ã®å¤šæ§˜æ€§ã‚’æ¸¬ã‚‹ãŒã€$x$ ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒåã£ã¦ã„ã¦ã‚‚é«˜ã„ IS ã‚’ç¤ºã—ã†ã‚‹ã€‚FID ã¨ã®çŸ›ç›¾ãŒã‚ã‚Œã° Precision-Recall ã§è©³ç´°ç¢ºèªã™ã‚‹ã“ã¨ã€‚

</details>

<details><summary>Q2: CMMDã¯FIDã‚’å®Œå…¨ã«ç½®ãæ›ãˆã‚‰ã‚Œã‚‹ã‹ï¼Ÿ</summary>

**A**: å ´åˆã«ã‚ˆã‚‹ã€‚

**CMMDã®åˆ©ç‚¹** [^5]:
- æ­£è¦æ€§ä»®å®šãªã—
- äººé–“è©•ä¾¡ã¨ã®ç›¸é–¢ãŒé«˜ã„ï¼ˆ0.72 vs FID 0.56ï¼‰
- ãƒ†ã‚­ã‚¹ãƒˆæ¡ä»¶ä»˜ãç”Ÿæˆã«å¯¾å¿œ

**FIDã®åˆ©ç‚¹**:
- æ¨™æº–åŒ–ã•ã‚Œã¦ã„ã‚‹ï¼ˆéå»ã®ç ”ç©¶ã¨æ¯”è¼ƒå¯èƒ½ï¼‰
- è¨ˆç®—ã‚³ã‚¹ãƒˆä½ï¼ˆè¡Œåˆ—æ¼”ç®—ã®ã¿ï¼‰
- ãƒ„ãƒ¼ãƒ«ãŒè±Šå¯Œï¼ˆtorch-fidelityç­‰ï¼‰

**æ¨å¥¨**: æ–°è¦ç ”ç©¶ã§ã¯**CMMD + FIDä½µè¨˜**ã€‚FIDã¯æ¯”è¼ƒå¯èƒ½æ€§ã®ãŸã‚ã€CMMDã¯å®Ÿè³ªçš„ãªè©•ä¾¡ã®ãŸã‚ã€‚

**ãªãœäººé–“è©•ä¾¡ã¨ã®ç›¸é–¢ãŒ CMMD > FID ã‹**: FID ã®ã‚¬ã‚¦ã‚¹ä»®å®šãŒå´©ã‚Œã‚‹å¤šæ§˜ãªç”Ÿæˆç‰©ï¼ˆStyle GAN ã®å¤šå³°åˆ†å¸ƒï¼‰ã§ã¯ãƒ•ãƒ¬ã‚·ã‚§è·é›¢ãŒéå¤§è©•ä¾¡ã•ã‚Œã‚‹ã€‚CLAP/CLIP ãƒ™ãƒ¼ã‚¹ã® MMD ã¯éç·šå½¢ã‚«ãƒ¼ãƒãƒ«ã§åˆ†å¸ƒå½¢çŠ¶ã«ä¾å­˜ã—ãªã„ãŸã‚ã€äººé–“ã®ã€Œè‡ªç„¶ã•ã€çŸ¥è¦šã«è¿‘ã„è·é›¢ã‚’è¨ˆç®—ã§ãã‚‹ã€‚

</details>

<details><summary>Q3: ã‚µãƒ³ãƒ—ãƒ«æ•°ã¯ã©ã‚Œãã‚‰ã„å¿…è¦ï¼Ÿ</summary>

**A**: æŒ‡æ¨™ã«ã‚ˆã£ã¦ç•°ãªã‚‹ã€‚

| æŒ‡æ¨™ | æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•° | æ¨å¥¨ã‚µãƒ³ãƒ—ãƒ«æ•° | ç†ç”± |
|:-----|:--------------|:--------------|:-----|
| FID | 2000 | 5000+ | å…±åˆ†æ•£è¡Œåˆ—ã®å®‰å®šæ¨å®šã«å¿…è¦ |
| IS | 1000 | 5000+ | å‘¨è¾ºåˆ†å¸ƒ $p(y)$ ã®æ¨å®š |
| LPIPS | 1ãƒšã‚¢ | N/A | ãƒšã‚¢wiseæ¯”è¼ƒ |
| P&R | 1000 | 5000+ | k-NNå¤šæ§˜ä½“ã®å®‰å®šæ¨å®š |
| CMMD | 500 | 2000+ | MMDã¯FIDã‚ˆã‚Šå°‘ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®š |
| FLD+ | **200** | 1000 | Normalizing Flowã§åŠ¹ç‡çš„ [^7] |

**å°‘ã‚µãƒ³ãƒ—ãƒ«ã®å ´åˆ**: FLD+ [^7] ã‚’ä½¿ç”¨ã€‚

> **âš ï¸ Warning:** FID ã®ã€Œæœ€å°2000ã‚µãƒ³ãƒ—ãƒ«ã€ã¯éå…¬å¼ãªçµŒé¨“å‰‡ã€‚å®Ÿéš›ã«ã¯ç”Ÿæˆåˆ†å¸ƒãŒè¤‡é›‘ï¼ˆå¤šå³°ãƒ»é«˜æ¬¡å…ƒï¼‰ãªã»ã©å¿…è¦ã‚µãƒ³ãƒ—ãƒ«æ•°ã¯å¢—ãˆã‚‹ã€‚StyleGAN2 ã® FFHQï¼ˆé«˜è§£åƒåº¦é¡”ï¼‰ã§ã¯ 5000ã€œ10000 ã‚µãƒ³ãƒ—ãƒ«ã§ã‚‚ä¿¡é ¼åŒºé–“ãŒåºƒã„ã“ã¨ãŒã‚ã‚‹ã€‚å°‘ã‚µãƒ³ãƒ—ãƒ«ã—ã‹ç”Ÿæˆã§ããªã„å ´åˆï¼ˆè¨ˆç®—ã‚³ã‚¹ãƒˆåˆ¶ç´„ï¼‰ã¯å¿…ãš Bootstrap CI ã‚’å ±å‘Šã™ã‚‹ã“ã¨ã€‚

</details>

<details><summary>Q4: åŒ»ç™‚ç”»åƒã‚„ã‚¢ãƒ¼ãƒˆç”»åƒã§FIDã‚’ä½¿ã£ã¦ã„ã„ã‹ï¼Ÿ</summary>

**A**: æ³¨æ„ãŒå¿…è¦ã€‚

**å•é¡Œ**: Inception-v3ã¯ImageNetã§è¨“ç·´ â†’ è‡ªç„¶ç”»åƒãƒã‚¤ã‚¢ã‚¹ã€‚åŒ»ç™‚ç”»åƒï¼ˆXç·šã€MRIï¼‰ã‚„ã‚¢ãƒ¼ãƒˆç”»åƒã§ã¯ä¸é©åˆ‡ã€‚

**è§£æ±ºç­–**:
1. **ãƒ‰ãƒ¡ã‚¤ãƒ³å°‚ç”¨ã®ç‰¹å¾´æŠ½å‡ºå™¨ã‚’ä½¿ã†**: åŒ»ç™‚ãªã‚‰ RadImageNet è¨“ç·´ãƒ¢ãƒ‡ãƒ«ã€ã‚¢ãƒ¼ãƒˆç”»åƒãªã‚‰ CLIP ViT-L/14
2. **FLD+ ã§ãƒ‰ãƒ¡ã‚¤ãƒ³å†è¨“ç·´**: $q_\theta$ ã‚’å¯¾è±¡ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã§å†è¨“ç·´ â†’ ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œã—ãŸå¯†åº¦ãƒ¢ãƒ‡ãƒ«
3. **ã‚«ãƒ¼ãƒãƒ«æŒ‡æ¨™ï¼ˆKID/CMMDï¼‰**: ç‰¹å¾´æŠ½å‡ºå™¨ã‚’å·®ã—æ›¿ãˆã‚‹ã ã‘ã§æµç”¨å¯èƒ½

**æ•°å€¤ä¾‹**: èƒ¸éƒ¨ X ç·šãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ Inception FID = 120ï¼ˆImageNet ãƒã‚¤ã‚¢ã‚¹ã§ highï¼‰ã€RadImageNet FID = 15ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³é©åˆ‡ãªè©•ä¾¡ï¼‰â†’ 8å€ã®å·®ã€‚å ±å‘Šã™ã‚‹éš›ã¯å¿…ãšä½¿ç”¨ç‰¹å¾´æŠ½å‡ºå™¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨ã€‚

</details>

| æ—¥ | å†…å®¹ | æ™‚é–“ | æˆæœç‰© |
|:---|:-----|:-----|:-------|
| 1æ—¥ç›® | Zone 0-2: æŒ‡æ¨™ã‚’è§¦ã‚‹ | 2h | 5æŒ‡æ¨™ã®è¨ˆç®—ã‚³ãƒ¼ãƒ‰ |
| 2-3æ—¥ç›® | Zone 3: æ•°å¼ä¿®è¡Œ | 4h | FID/IS/LPIPS/MMDå®Œå…¨å°å‡º |
| 4æ—¥ç›® | Zone 4: Rustçµ±è¨ˆåˆ†æ | 3h | ä¿¡é ¼åŒºé–“ãƒ»t-testå®Ÿè£… |
| 5æ—¥ç›® | Zone 4: Rust Criterion | 2h | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ |
| 6æ—¥ç›® | Zone 5: çµ±åˆè©•ä¾¡ | 3h | VAE/GAN/ARæ¯”è¼ƒ |
| 7æ—¥ç›® | Zone 6-7: æœ€æ–°ç ”ç©¶+å¾©ç¿’ | 2h | ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ |

**å­¦ç¿’ã®å„ªå…ˆé †ä½**: 7æ—¥é–“ã¯ç†æƒ³ã€‚æœ€å°é™ã§ 3æ—¥ã§ã‚‚ Zone 3ï¼ˆFID/CMMD æ•°å¼ï¼‰+ Zone 4ï¼ˆBootstrap CI + t-testï¼‰+ å•5 ã® Welch t-test å®Ÿè£…ã¾ã§å®Œèµ°ã™ã‚Œã°ã€è«–æ–‡èª­è§£ã¨è©•ä¾¡è¨­è¨ˆã«ååˆ†ãªåŸºç¤ãŒã§ãã‚‹ã€‚ã€ŒæŒ‡æ¨™ã‚’è¨ˆç®—ã§ãã‚‹ã€ã‹ã‚‰ã€ŒæŒ‡æ¨™ã‚’è¨­è¨ˆã§ãã‚‹ã€ã¸ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚¢ãƒƒãƒ—ãŒæœ¬è¬›ç¾©ã®æ ¸å¿ƒã€‚

### 6.9 æ¬¡å›äºˆå‘Š â€” ç¬¬27å›: æ¨è«–æœ€é©åŒ– & Productionå“è³ª

**ç¬¬26å›ã§è©•ä¾¡åŸºç›¤ã‚’æ§‹ç¯‰ã—ãŸã€‚æ¬¡ã¯æ§‹ç¯‰ã—ãŸã‚·ã‚¹ãƒ†ãƒ ã®æ¨è«–ã‚’é«˜é€ŸåŒ–ã—ã€æœ¬ç•ªå“è³ªã¸å¼•ãä¸Šã’ã‚‹ã€‚**

**ç¬¬27å›ã®å†…å®¹**:
- INT4 / FP8 é‡å­åŒ–å®Œå…¨ç‰ˆ
- Speculative Decodingï¼ˆ2.5xé«˜é€ŸåŒ–ï¼‰
- Knowledge Distillationï¼ˆè’¸ç•™ï¼‰
- Productionå“è³ª Rust ãƒ©ã‚¤ãƒ–ãƒ©ãƒªè¨­è¨ˆï¼ˆthiserror / tracing / Prometheusï¼‰
- Elixir æ¨è«–åˆ†æ•£ãƒ»è€éšœå®³æ€§è¨­è¨ˆï¼ˆCircuit Breaker / Auto-scalingï¼‰
- ğŸ¦€ Rustå®Ÿè£…: é‡å­åŒ–æ¨è«–ã‚µãƒ¼ãƒãƒ¼

**ç¬¬26å›ã‹ã‚‰ç¬¬28å›ã¸ã®æ¶ã‘æ©‹**: è©•ä¾¡åŸºç›¤ã‚’æŒã¤ã“ã¨ã§ã€Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ”¹å–„ãŒç”Ÿæˆå“è³ªã«ã©ã†å½±éŸ¿ã™ã‚‹ã‹ã€ã‚’å®šé‡è©•ä¾¡ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚ç¬¬28å›ã§ã¯ã€Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆA vs ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆBã€ã®æ¯”è¼ƒã‚’ç¬¬26å›ã§å­¦ã‚“ã  Bootstrap tæ¤œå®šã¨ FID/CMMD ã§è¡Œã†å®Ÿé¨“ãŒç™»å ´ã™ã‚‹ã€‚è©•ä¾¡ãªã—ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ã¯æ„Ÿè¦šè«–ã§ã—ã‹ãªã„ãŒã€è©•ä¾¡ã‚ã‚Šãªã‚‰ç§‘å­¦ã ã€‚

```mermaid
graph LR
    A["ç¬¬26å›<br/>è©•ä¾¡åŸºç›¤"] --> B["ç¬¬28å›<br/>ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"]
    B --> C["ç¬¬29å›<br/>RAG"]
    C --> D["ç¬¬30å›<br/>ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"]
    D --> E["ç¬¬32å›<br/>çµ±åˆPJ"]
    style B fill:#fff3e0
    style E fill:#c8e6c9
```

> **Note:** **é€²æ—: 100% å®Œäº†ï¼ğŸ‰** ç¬¬26å›å®Œäº†ã€‚è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ â€” FID/IS/LPIPS/P&R/CMMD/MMDã®ç†è«–ã¨å®Ÿè£…ã‚’ãƒã‚¹ã‚¿ãƒ¼ã—ãŸã€‚
>
> </details>
>
> ---
>
> ### 6.11 ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„
>
> > **æ•°å€¤ãŒæ”¹å–„ã™ã‚Œã°"è‰¯ã„"ãƒ¢ãƒ‡ãƒ«ã‹ï¼Ÿ**
>
> **å¾“æ¥**: FIDâ†“ + ISâ†‘ = è‰¯ã„ãƒ¢ãƒ‡ãƒ«
>
> **è»¢æ›**:
>
> 1. **å®šé‡æŒ‡æ¨™ã¯å¿…è¦æ¡ä»¶ã€ååˆ†æ¡ä»¶ã§ã¯ãªã„**
>    - FID=5ã§ã‚‚äººé–“ãŒè¦‹ã¦ä¸è‡ªç„¶ãªç”»åƒã¯"æ‚ªã„"ãƒ¢ãƒ‡ãƒ«
>    - äººé–“è©•ä¾¡ã¨å®šé‡æŒ‡æ¨™ã®ä¹–é›¢ã‚’å¸¸ã«æ„è­˜
>
> 2. **æŒ‡æ¨™ã¯ä»®å®šã‚’æŒã¤ â€” ä»®å®šãŒå´©ã‚Œã‚Œã°æŒ‡æ¨™ã‚‚å´©ã‚Œã‚‹**
>    - FIDã®ã‚¬ã‚¦ã‚¹æ€§ä»®å®š â†’ å¤šå³°åˆ†å¸ƒã§å¤±æ•—
>    - ISã®ImageNetåˆ†é¡ä¾å­˜ â†’ ãƒ‰ãƒ¡ã‚¤ãƒ³å¤–ã§ç„¡æ„å‘³
>    - **æŒ‡æ¨™ã®æ•°å¼ã‚’ç†è§£ = ä»®å®šã‚’ç†è§£ = é™ç•Œã‚’çŸ¥ã‚‹**
>
> 3. **è©•ä¾¡ã¯å¤šé¢çš„ â€” ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å¯è¦–åŒ–ã›ã‚ˆ**
>    - Precision-Recallã§å“è³ªvså¤šæ§˜æ€§ã‚’åˆ†é›¢
>    - å˜ä¸€ã‚¹ã‚³ã‚¢ã«é›†ç´„ã™ã‚‹ãªï¼ˆISã®ç½ ï¼‰
>
> **ã‚ãªãŸã¸ã®å•ã„**:
>
> - è«–æ–‡ã®FIDæ”¹å–„ã‚’è¦‹ãŸã¨ãã€ã€Œã‚µãƒ³ãƒ—ãƒ«æ•°ã¯ï¼Ÿã€ã€Œä¿¡é ¼åŒºé–“ã¯ï¼Ÿã€ã€Œäººé–“è©•ä¾¡ã¨ã®ç›¸é–¢ã¯ï¼Ÿã€ã¨å•ãˆã‚‹ã‹ï¼Ÿ
> - è‡ªåˆ†ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹ã¨ãã€è¤‡æ•°æŒ‡æ¨™ã‚’è¦‹ã¦ç·åˆåˆ¤æ–­ã§ãã‚‹ã‹ï¼Ÿ
> - æ–°ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆåŒ»ç™‚ç”»åƒã€éŸ³å£°ï¼‰ã§ã€é©åˆ‡ãªè©•ä¾¡æŒ‡æ¨™ã‚’é¸æŠãƒ»è¨­è¨ˆã§ãã‚‹ã‹ï¼Ÿ
>
> **æ¬¡ã®ä¸€æ­©**: è©•ä¾¡ã¯æ‰‹æ®µã§ã‚ã£ã¦ç›®çš„ã§ã¯ãªã„ã€‚è©•ä¾¡åŸºç›¤ã‚’æ•´ãˆãŸä»Šã€**ä½•ã‚’ä½œã‚‹ã‹**ã«é›†ä¸­ã›ã‚ˆã€‚ç¬¬32å›ã®çµ±åˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã€è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿæˆ¦æŠ•å…¥ã™ã‚‹ã€‚
>
> **æœ¬è³ªçš„ãªå§¿å‹¢**: FID æ”¹å–„ã¯çµæœã§ã‚ã£ã¦ç›®æ¨™ã§ã¯ãªã„ã€‚ã€Œã©ã†ã„ã†éŸ³å£°/ç”»åƒã‚’ç”Ÿæˆã—ãŸã„ã‹ã€ã¨ã„ã†ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹å®šç¾©ãŒå…ˆã«ã‚ã‚Šã€ãã‚Œã«åˆã£ãŸæŒ‡æ¨™ã‚’é¸ã¶ã¹ãã ã€‚FID ã‚’ä¸‹ã’ã‚‹ãŸã‚ã«è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’æ°´å¢—ã—ã™ã‚‹ã€ŒæŒ‡æ¨™ãƒãƒƒã‚­ãƒ³ã‚°ã€ã¯ã€ç¾å®Ÿã®å“è³ªæ”¹å–„ã¨ã¯å…¨ãåˆ¥ç‰©ã€‚è©•ä¾¡æŒ‡æ¨™ã®æ•°å¼ã‚’ç†è§£ã™ã‚‹ã“ã¨ã¯ã€ã“ã†ã—ãŸè½ã¨ã—ç©´ã‚’é¿ã‘ã‚‹ãŸã‚ã®æœ€ä½é™ã®ç´ é¤Šã ã€‚
>
> ### 6.6 è‡ªå‹•è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰
>
> Productionç’°å¢ƒã§ã¯ã€è©•ä¾¡ã‚’**è‡ªå‹•åŒ–ãƒ»ç¶™ç¶šçš„å®Ÿè¡Œ**ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
>
> #### 6.6.1 CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¸ã®çµ±åˆ
>
> **GitHub Actionsä¾‹** (ç–‘ä¼¼YAML):
>
> ```yaml
> name: Model Evaluation Pipeline
>
> on:
>   push:
>     branches: [main]
>     paths: ['models/**', 'data/**']
>
> jobs:
>   evaluate:
>     runs-on: ubuntu-latest
>     steps:
>       - uses: actions/checkout@v3
>
>       - name: Setup Rust
>         uses: julia-actions/setup-julia@v1
>         with:
>           version: '1.10'
>
>       - name: Install dependencies
>         run: |
>           julia --project=. -e 'using Pkg; Pkg.instantiate()'
>
>       - name: Download test dataset
>         run: |
>           wget https://example.com/test_images.tar.gz
>           tar -xzf test_images.tar.gz
>
>       - name: Run evaluation
>         run: |
>           julia --project=. scripts/evaluate.jl \
>             --model models/generator.jld2 \
>             --real-data data/test_real/ \
>             --output results/metrics.json
>
>       - name: Upload results
>         uses: actions/upload-artifact@v3
>         with:
>           name: evaluation-results
>           path: results/
>
>       - name: Quality gate check
>         run: |
>           julia --project=. scripts/check_quality.jl \
>             --metrics results/metrics.json \
>             --fid-threshold 15.0 \
>             --is-threshold 8.0
> ```
>
> **å“è³ªã‚²ãƒ¼ãƒˆ (Quality Gate)**:
>
> ```rust
> // scripts/check_quality.rs
> // Cargo.toml: serde_json = "1", clap = { version = "4", features = ["derive"] }
>
> use serde_json::Value;
> use std::collections::HashMap;
>
> fn check_quality_gate(
>     metrics: &Value,
>     fid_threshold: f64,
>     is_threshold: f64,
> ) -> bool {
>     let checks: HashMap<&str, bool> = [
>         ("FID",       metrics["FID"].as_f64().unwrap_or(f64::INFINITY) < fid_threshold),
>         ("IS",        metrics["IS"]["mean"].as_f64().unwrap_or(0.0) > is_threshold),
>         ("Precision", metrics["Precision"].as_f64().unwrap_or(0.0) > 0.65),
>         ("Recall",    metrics["Recall"].as_f64().unwrap_or(0.0) > 0.55),
>     ].into_iter().collect();
>
>     let all_pass = checks.values().all(|&v| v);
>
>     for (name, pass) in &checks {
>         println!("{}: {}", name, if *pass { "âœ… PASS" } else { "âŒ FAIL" });
>     }
>
>     if !all_pass {
>         eprintln!("
âŒ Quality gate FAILED. Model does not meet minimum criteria.");
>     } else {
>         println!("
âœ… Quality gate PASSED. Model approved for deployment.");
>     }
>     all_pass
> }
>
> // CLI usage via clap (see clap docs for full derive-based arg parsing):
> // cargo run -- --metrics results/metrics.json --fid-threshold 15.0 --is-threshold 8.0
> fn main() -> Result<(), Box<dyn std::error::Error>> {
>     let metrics_path = std::env::args().nth(1).unwrap_or("metrics.json".into());
>     let raw = std::fs::read_to_string(&metrics_path)?;
>     let metrics: Value = serde_json::from_str(&raw)?;
>     let ok = check_quality_gate(&metrics, 15.0, 8.0);
>     std::process::exit(if ok { 0 } else { 1 });
> }
> ```
>
> #### 6.6.2 è©•ä¾¡çµæœã®å¯è¦–åŒ–ã¨ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
>
> **Weights & Biasesçµ±åˆ**:
>
> ```rust
> // Weights & Biases integration via HTTP API (or use wandb CLI + subprocess).
> // For native Rust W&B support, use the `wandb` crate or log JSON and upload with CLI.
> // Cargo.toml: reqwest = { version = "0.11", features = ["json", "blocking"] }
> //             serde_json = "1"
>
> use serde_json::{json, Value};
>
> struct WandbRun {
>     project: String,
>     run_name: String,
>     config: Value,
> }
>
> impl WandbRun {
>     fn new(project: &str, run_name: &str, config: Value) -> Self {
>         eprintln!("W&B run initialized: project={}, name={}", project, run_name);
>         Self { project: project.into(), run_name: run_name.into(), config }
>     }
>
>     /// Log scalar metrics (serialized to JSON for W&B upload)
>     fn log(&self, metrics: &Value) {
>         eprintln!("W&B log: {}", serde_json::to_string_pretty(metrics).unwrap_or_default());
>     }
>
>     fn finish(&self) {
>         eprintln!("W&B run finished: {}", self.run_name);
>     }
> }
>
> // Usage:
> // let run = WandbRun::new("gan-evaluation", "experiment-2024-01-01",
> //     json!({"model": "StyleGAN3", "dataset": "FFHQ", "batch_size": 64}));
> // run.log(&json!({"FID": fid_score, "IS_mean": is_mean, "Precision": precision, "Recall": recall}));
> // run.finish();
> ```
>
> **å¯è¦–åŒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ§‹æˆ**:
>
> 1. **æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰**: FID/IS/LPIPS ã®è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®å¤‰åŒ–
> 2. **Precision-Recallæ›²ç·š**: å“è³ªvså¤šæ§˜æ€§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•
> 3. **ã‚µãƒ³ãƒ—ãƒ«ç”»åƒ**: Real vs Generated ã®æ¯”è¼ƒã‚°ãƒªãƒƒãƒ‰
> 4. **ç‰¹å¾´é‡åˆ†å¸ƒ**: Inceptionç‰¹å¾´é‡ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
> 5. **ã‚¢ãƒ©ãƒ¼ãƒˆ**: å“è³ªã‚²ãƒ¼ãƒˆé•åæ™‚ã®é€šçŸ¥
>
> #### 6.6.3 A/Bãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
>
> è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒè©•ä¾¡ã™ã‚‹ä»•çµ„ã¿:
>
> ```rust
> use std::collections::HashMap;
>
> struct ModelVariant {
>     name: String,
>     /// Callable that produces feature vectors for generated samples
>     // generator: Box<dyn Fn() -> Vec<f64>>,
> }
>
> struct ComparisonResult {
>     fid_diff: f64,
>     ci: (f64, f64),
>     significant: bool,
>     winner: String,
> }
>
> /// A/B test: evaluate multiple model variants and compare pairwise.
> fn ab_test_models(
>     variants: &[ModelVariant],
>     feats_real: &Array2<f64>,
>     n_samples: usize,
>     significance_level: f64,
> ) -> (HashMap<String, HashMap<&'static str, f64>>,
>       HashMap<String, ComparisonResult>) {
>     let mut results: HashMap<String, HashMap<&'static str, f64>> = HashMap::new();
>
>     for variant in variants {
>         // Generate feature vectors (placeholder â€” replace with model inference)
>         let feats_gen = Array2::zeros((n_samples, feats_real.ncols()));
>         let (fid, _, _, _) = fid_with_ci(feats_real, &feats_gen, 100, 1.0 - significance_level);
>         let is_score = 1.0_f64;   // compute_is(&feats_gen)
>         let (prec, rec) = (0.0_f64, 0.0_f64); // precision_recall(...)
>
>         let mut m = HashMap::new();
>         m.insert("FID", fid);
>         m.insert("IS",  is_score);
>         m.insert("Precision", prec);
>         m.insert("Recall",    rec);
>         results.insert(variant.name.clone(), m);
>     }
>
>     // Pairwise statistical comparisons (bootstrap CI for FID difference)
>     let mut comparisons: HashMap<String, ComparisonResult> = HashMap::new();
>     let names: Vec<&String> = variants.iter().map(|v| &v.name).collect();
>     for i in 0..names.len() {
>         for j in (i + 1)..names.len() {
>             let fid_i = results[names[i]]["FID"];
>             let fid_j = results[names[j]]["FID"];
>             let diff  = fid_i - fid_j;
>             // Bootstrap CI placeholder: use fid_with_ci on bootstrap samples
>             let ci = (diff - 1.0, diff + 1.0);
>             let significant = !(ci.0 < 0.0 && ci.1 > 0.0); // 0 not in CI
>             let winner = if diff < 0.0 { names[i].clone() } else { names[j].clone() };
>             let key = format!("{}_vs_{}", names[i], names[j]);
>             comparisons.insert(key, ComparisonResult { fid_diff: diff, ci, significant, winner });
>         }
>     }
>
>     // Print report
>     println!("=== A/B Test Results ===");
>     for (name, m) in &results {
>         println!("
{}:", name);
>         for (metric, val) in m { println!("  {}: {:.3}", metric, val); }
>     }
>     println!("
=== Statistical Comparisons ===");
>     for (pair, comp) in &comparisons {
>         if comp.significant {
>             println!("âœ… {}: {} wins (FID diff={:.2})", pair, comp.winner, comp.fid_diff);
>         } else {
>             println!("â– {}: No significant difference", pair);
>         }
>     }
>
>     (results, comparisons)
> }
> ```
>
> #### 6.6.4 è©•ä¾¡ã‚³ã‚¹ãƒˆã®æœ€é©åŒ–
>
> **èª²é¡Œ**: FIDè¨ˆç®—ã¯é‡ã„ï¼ˆInception forward pass Ã— å…¨ã‚µãƒ³ãƒ—ãƒ«ï¼‰
>
> **å®šé‡åŒ–**: Inception-v3 ã¯ 1æšã® 299Ã—299 ç”»åƒã§ç´„ 5.7 GFLOPsã€‚10,000 ã‚µãƒ³ãƒ—ãƒ«ã§ 57 TFLOPs â†’ A100 (312 TFLOPS) ã§ç´„ 0.2 ç§’ã€‚ãŸã ã— CPU ã§ã¯ 10 GFLOPS â†’ ç´„ 5700 ç§’ï¼ˆ1.5æ™‚é–“ï¼‰ã€‚è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§æœ€ã‚‚æ™‚é–“ãŒã‹ã‹ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ã®ãŸã‚ã€ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã¨æ—©æœŸçµ‚äº†ãŒé‡è¦ã€‚
>
> **è§£æ±ºç­–1: æ—©æœŸçµ‚äº† (Early Stopping)**
>
> ```rust
> /// Adaptive FID estimation with early stopping on convergence.
> /// Doubles sample count each iteration until std of last 3 estimates < tolerance.
> fn adaptive_fid_estimation(
>     feats_real: &Array2<f64>,
>     feats_gen: &Array2<f64>,
>     initial_samples: usize,
>     max_samples: usize,
>     tolerance: f64,
> ) -> (f64, usize) {
>     let n_real = feats_real.nrows();
>     let n_gen  = feats_gen.nrows();
>     let mut fid_history: Vec<f64> = Vec::new();
>     let mut n_samples = initial_samples;
>
>     while n_samples <= max_samples {
>         // Subsample (use rand::seq::index::sample for true shuffle in production)
>         let r = n_samples.min(n_real);
>         let g = n_samples.min(n_gen);
>         let idx_r: Vec<usize> = (0..r).collect();
>         let idx_g: Vec<usize> = (0..g).collect();
>
>         let real_sub = feats_real.select(ndarray::Axis(0), &idx_r);
>         let gen_sub  = feats_gen.select(ndarray::Axis(0), &idx_g);
>         let (mu_r, sigma_r) = compute_statistics(&real_sub);
>         let (mu_g, sigma_g) = compute_statistics(&gen_sub);
>         let fid = frechet_distance(&mu_r.view(), &sigma_r.view(),
>                                    &mu_g.view(), &sigma_g.view());
>         fid_history.push(fid);
>
>         // Check convergence: std of last 3 estimates < tolerance
>         if fid_history.len() >= 3 {
>             let recent = &fid_history[fid_history.len() - 3..];
>             let mean = recent.iter().sum::<f64>() / 3.0;
>             let std  = (recent.iter().map(|x| (x - mean).powi(2)).sum::<f64>() / 3.0).sqrt();
>             if std < tolerance {
>                 println!("Converged at {} samples (std={:.4})", n_samples, std);
>                 return (fid, n_samples);
>             }
>         }
>
>         n_samples = (n_samples * 2).min(max_samples);
>         if n_samples == max_samples && fid_history.len() > 3 { break; }
>     }
>
>     (*fid_history.last().unwrap_or(&0.0), n_samples)
> }
> ```
>
> **è§£æ±ºç­–2: ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°**
>
> ```rust
> // Cache Inception features to avoid recomputation across evaluation runs.
> use std::path::{Path, PathBuf};
>
> struct FeatureCache {
>     cache_dir: PathBuf,
> }
>
> impl FeatureCache {
>     fn new(dir: &str) -> Self { Self { cache_dir: Path::new(dir).to_path_buf() } }
>
>     /// Load cached features or compute and cache them.
>     fn get_or_compute<F>(&self, key: &str, compute: F) -> std::io::Result<Vec<u8>>
>     where F: FnOnce() -> Vec<u8>
>     {
>         let cache_file = self.cache_dir.join(format!("{}.bin", key));
>         if cache_file.exists() {
>             eprintln!("Loading cached features from {}", cache_file.display());
>             std::fs::read(&cache_file)
>         } else {
>             eprintln!("Computing features for {}", key);
>             let features = compute();
>             std::fs::create_dir_all(&self.cache_dir)?;
>             std::fs::write(&cache_file, &features)?;
>             Ok(features)
>         }
>     }
> }
>
> // Usage:
> // let cache = FeatureCache::new("./feature_cache");
> // let real_feats = cache.get_or_compute("real_ffhq_10k", || extract_inception_features(&real_images))?;
> // // Only compute for generated images (no caching â€” they change each run):
> // let gen_feats = extract_inception_features(&generated_images);
> ```
>
> #### 6.6.5 ãƒãƒ«ãƒGPUä¸¦åˆ—è©•ä¾¡
>
> ```rust
> // Multi-GPU parallel evaluation using Rayon thread pool.
> // Cargo.toml: rayon = "1.7"
> // use rayon::prelude::*;
>
> use std::collections::HashMap;
>
> #[derive(Debug, Clone)]
> struct BatchMetrics {
>     fid: f64,
>     is_score: f64,
> }
>
> /// Evaluate a batch of real/gen features on one thread (GPU in production).
> fn evaluate_batch(
>     real_chunk: &Array2<f64>,
>     gen_chunk: &Array2<f64>,
>     _gpu_id: usize,
> ) -> BatchMetrics {
>     let (mu_r, sigma_r) = compute_statistics(real_chunk);
>     let (mu_g, sigma_g) = compute_statistics(gen_chunk);
>     let fid = frechet_distance(&mu_r.view(), &sigma_r.view(),
>                                &mu_g.view(), &sigma_g.view());
>     BatchMetrics { fid, is_score: 1.0 /* inception_score placeholder */ }
> }
>
> /// Parallel evaluation across N GPUs/threads using Rayon.
> fn parallel_evaluation(
>     feats_real: &Array2<f64>,
>     feats_gen:  &Array2<f64>,
>     n_workers: usize,
> ) -> HashMap<&'static str, f64> {
>     let n = feats_real.nrows();
>     let chunk_size = n / n_workers;
>
>     // Split into chunks and evaluate in parallel
>     let results: Vec<BatchMetrics> = (0..n_workers)
>         // .into_par_iter()  // enable with rayon
>         .into_iter()
>         .map(|i| {
>             let start = i * chunk_size;
>             let end   = ((i + 1) * chunk_size).min(n);
>             let real_c = feats_real.slice(ndarray::s![start..end, ..]).to_owned();
>             let gen_c  = feats_gen.slice(ndarray::s![start..end, ..]).to_owned();
>             evaluate_batch(&real_c, &gen_c, i)
>         })
>         .collect();
>
>     // Aggregate
>     let fid_mean = results.iter().map(|r| r.fid).sum::<f64>() / results.len() as f64;
>     let is_mean  = results.iter().map(|r| r.is_score).sum::<f64>() / results.len() as f64;
>
>     let mut out = HashMap::new();
>     out.insert("FID", fid_mean);
>     out.insert("IS",  is_mean);
>     out
> }
> ```
>
> **é«˜é€ŸåŒ–çµæœ**:
>
> | æ‰‹æ³• | ã‚µãƒ³ãƒ—ãƒ«æ•° | GPUs | æ™‚é–“ | é«˜é€ŸåŒ– |
> |:-----|:----------|:-----|:-----|:-------|
> | Baseline | 10,000 | 1 | 45åˆ† | 1x |
> | ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚° | 10,000 | 1 | 12åˆ† | 3.75x |
> | æ—©æœŸçµ‚äº† | ~2,000 | 1 | 5åˆ† | 9x |
> | ãƒãƒ«ãƒGPU | 10,000 | 4 | 3åˆ† | 15x |
>
> #### 6.6.6 è©•ä¾¡ã®å†ç¾æ€§ç¢ºä¿
>
> **æ±ºå®šè«–çš„å®Ÿè¡Œ**:
>
> ```rust
> // Deterministic evaluation: fix all RNG seeds for reproducibility.
> // Cargo.toml: rand = "0.8"
>
> use rand::SeedableRng;
> use rand::rngs::StdRng;
>
> fn set_seed_all(seed: u64) {
>     // Seed Rust RNG (per-thread)
>     let _rng = StdRng::seed_from_u64(seed);
>     // For CUDA: set via environment variable before initializing the CUDA context
>     std::env::set_var("CUBLAS_WORKSPACE_CONFIG", ":4096:8");
>     eprintln!("RNG seed set to {}", seed);
> }
>
> fn deterministic_evaluation<F>(
>     generator: F,
>     feats_real: &Array2<f64>,
>     seed: u64,
>     n_gen: usize,
> ) -> std::collections::HashMap<&'static str, f64>
> where F: Fn(&mut StdRng) -> Vec<f64>
> {
>     set_seed_all(seed);
>     let mut rng = StdRng::seed_from_u64(seed);
>
>     // Generate with fixed seed
>     let gen_samples: Vec<Vec<f64>> = (0..n_gen).map(|_| generator(&mut rng)).collect();
>
>     // Compute metrics (placeholder)
>     let feats_gen = Array2::zeros((n_gen, feats_real.ncols()));
>     let (fid, _, _, _) = fid_with_ci(feats_real, &feats_gen, 100, 0.95);
>
>     let mut results = std::collections::HashMap::new();
>     results.insert("FID", fid);
>     results.insert("seed", seed as f64);
>     results
> }
> ```
>
> **ãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼**:
>
> ```rust
> // Checksum verification for evaluation data integrity.
> // Cargo.toml: sha2 = "0.10"
> // use sha2::{Sha256, Digest};
>
> fn verify_data_integrity(data_path: &str, expected_sha256: &str) -> std::io::Result<()> {
>     use std::io::Read;
>     // use sha2::{Sha256, Digest};
>
>     let mut file = std::fs::File::open(data_path)?;
>     let mut bytes = Vec::new();
>     file.read_to_end(&mut bytes)?;
>
>     // Compute SHA-256 (requires sha2 crate in production)
>     // let mut hasher = Sha256::new();
>     // hasher.update(&bytes);
>     // let actual = format!("{:x}", hasher.finalize());
>     let actual = format!("{:x}", bytes.len()); // placeholder (use sha2 in production)
>
>     if actual != expected_sha256 {
>         return Err(std::io::Error::new(
>             std::io::ErrorKind::InvalidData,
>             format!("Data integrity check failed!
Expected: {}
Actual: {}", expected_sha256, actual),
>         ));
>     }
>     eprintln!("âœ… Data integrity verified: {}", data_path);
>     Ok(())
> }
>
> // Before evaluation:
> // verify_data_integrity("test_data.bin", "a1b2c3d4...")?;
> ```
>
> > **Note:** **é€²æ—: 100% å®Œäº†** ğŸ‰ è¬›ç¾©å®Œèµ°ï¼è‡ªå‹•è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ã€CI/CDçµ±åˆã€A/Bãƒ†ã‚¹ãƒˆã€æœ€é©åŒ–æ‰‹æ³•ã¾ã§å®Œå…¨å®Ÿè£…ã—ãŸã€‚
>
> **Progress: [95%]**
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. FLD+ï¼ˆãƒ•ãƒ­ãƒ¼ãƒ™ãƒ¼ã‚¹å°¤åº¦è·é›¢ï¼‰ãŒFIDã‚ˆã‚Šå°‘ãªã„ã‚µãƒ³ãƒ—ãƒ«ã§å®‰å®šã™ã‚‹æ•°å­¦çš„ç†ç”±ã¯ï¼Ÿ
>    - *ãƒ’ãƒ³ãƒˆ*: FIDã¯ $d \times d$ å…±åˆ†æ•£è¡Œåˆ—ï¼ˆ$d=2048$ï¼‰ã‚’æ¨å®šã™ã‚‹ãŒã€FLD+ã¯ä½•æ¬¡å…ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¨å®šã™ã‚‹ã‹ï¼Ÿ
> 2. ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã§FID/IS/LPIPS/CMMDã®4æŒ‡æ¨™ã‚’çµ„ã¿åˆã‚ã›ã‚‹å¿…è¦æ€§ã‚’å„æŒ‡æ¨™ã®é™ç•Œã‹ã‚‰è¿°ã¹ã‚ˆã€‚

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., & Hochreiter, S. (2017). GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium. *NeurIPS 2017*.
<https://arxiv.org/abs/1706.08500>

[^2]: Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., & Chen, X. (2016). Improved Techniques for Training GANs. *NeurIPS 2016*.
<https://arxiv.org/abs/1609.03126>

[^3]: Zhang, R., Isola, P., Efros, A. A., Shechtman, E., & Wang, O. (2018). The Unreasonable Effectiveness of Deep Features as a Perceptual Metric. *CVPR 2018*.
<https://arxiv.org/abs/1801.03924>

[^4]: KynkÃ¤Ã¤nniemi, T., Karras, T., Laine, S., Lehtinen, J., & Aila, T. (2019). Improved Precision and Recall Metric for Assessing Generative Models. *NeurIPS 2019*.
<https://arxiv.org/abs/1904.06991>

[^5]: Jayasumana, S., Ramalingam, S., Veit, A., Glasner, D., Chakrabarti, A., & Kumar, S. (2024). Rethinking FID: Towards a Better Evaluation Metric for Image Generation. *CVPR 2024*.
<https://arxiv.org/abs/2401.09603>

[^6]: Gretton, A., Borgwardt, K. M., Rasch, M. J., SchÃ¶lkopf, B., & Smola, A. (2012). A Kernel Two-Sample Test. *Journal of Machine Learning Research*.
<https://www.jmlr.org/papers/v13/gretton12a.html>

[^7]: Jeevan, P., Nixon, N., & Sethi, A. (2024). FLD+: Data-efficient Evaluation Metric for Generative Models. *arXiv:2411.15584*.
<https://arxiv.org/abs/2411.15584>

[^8]: Pranav, P., et al. (2024). Normalizing Flow-Based Metric for Image Generation. *arXiv:2410.02004*.
<https://arxiv.org/abs/2410.02004>

[^9]: Cheema, G. S., et al. (2023). Unifying and Extending Precision Recall Metrics for Assessing Generative Models. *AISTATS 2023*.
<https://proceedings.mlr.press/v206/cheema23a.html>

### å®Ÿè£…ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

- [torch-fidelity](https://github.com/toshas/torch-fidelity) â€” PyTorch FID/ISå®Ÿè£…
- [lpips](https://github.com/richzhang/PerceptualSimilarity) â€” LPIPSå…¬å¼å®Ÿè£…
- [Criterion.rs](https://github.com/bheisler/criterion.rs) â€” Rustçµ±è¨ˆçš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
- [statrs](https://github.com/RustStats/statrs) â€” Rustçµ±è¨ˆæ¤œå®š

**å•5**: Welch's t-testã§2ã¤ã®FIDã‚µãƒ³ãƒ—ãƒ«ã‚’æ¯”è¼ƒã›ã‚ˆã€‚

**å‰æã®ç¢ºèª**: FID sample A = [12.3, 11.8, 12.7, 13.1, 11.5]ï¼ˆn=5ï¼‰ã€FID sample B = [15.2, 14.8, 15.6, 16.0, 14.5]ï¼ˆn=5ï¼‰ã€‚æœŸå¾…ã•ã‚Œã‚‹çµæœ: p < 0.01ï¼ˆæ˜ç¢ºãªå·®ï¼‰, Cohen's d â‰ˆ 3ï¼ˆlarge effectï¼‰ã€‚

<details><summary>è§£ç­”</summary>

```rust
use std::collections::HashMap;

/// Welch's t-test for FID comparison + Cohen's d effect size.
fn compare_fid(fid_a: &[f64], fid_b: &[f64], alpha: f64) -> HashMap<&'static str, f64> {
    let mean_f = |v: &[f64]| v.iter().sum::<f64>() / v.len() as f64;
    let std_f  = |v: &[f64]| {
        let m = mean_f(v);
        (v.iter().map(|x| (x - m).powi(2)).sum::<f64>() / (v.len() as f64 - 1.0)).sqrt()
    };

    let mu_a = mean_f(fid_a);
    let mu_b = mean_f(fid_b);
    let s_a = std_f(fid_a);
    let s_b = std_f(fid_b);
    let na = fid_a.len() as f64;
    let nb = fid_b.len() as f64;

    // Welch's t-statistic
    let se = (s_a * s_a / na + s_b * s_b / nb).sqrt();
    let t  = (mu_a - mu_b) / se;

    // Approximate p-value (use statrs::distribution::StudentsT for exact value)
    let p_val = 2.0 * (-t.abs()).exp().min(1.0);
    let is_sig = if p_val < alpha { 1.0 } else { 0.0 };

    // Cohen's d
    let pooled_std = ((s_a * s_a + s_b * s_b) / 2.0).sqrt();
    let cohens_d   = (mu_a - mu_b) / pooled_std;

    let mut out = HashMap::new();
    out.insert("p_value",    p_val);
    out.insert("significant", is_sig);
    out.insert("cohens_d",   cohens_d);
    out
}
```

</details>

#### 7.5.3 å®Ÿè£…ãƒãƒ£ãƒ¬ãƒ³ã‚¸ï¼ˆ2å•ï¼‰

**ãƒãƒ£ãƒ¬ãƒ³ã‚¸1**: è‡ªå‹•è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè£…ã—ã€VAE/GAN/ARã®3ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒã›ã‚ˆã€‚å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: JSONï¼ˆFID/IS/CMMD/Precision/Recallï¼‰

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ä¾‹**:
```json
{
  "VAE": {"FID": 45.2, "IS": 4.1, "CMMD": 0.023, "Precision": 0.71, "Recall": 0.82},
  "GAN": {"FID": 18.7, "IS": 7.3, "CMMD": 0.008, "Precision": 0.88, "Recall": 0.54},
  "AR":  {"FID": 22.1, "IS": 6.9, "CMMD": 0.012, "Precision": 0.85, "Recall": 0.76}
}
```

ã“ã‚Œã‚’è¦‹ã‚Œã°ã€ŒGAN ãŒ FID/CMMD ã§æœ€è‰¯ã ãŒ Recall ã§æœ€æ‚ª â†’ mode collapse ã®å…†å€™ã€ãŒä¸€ç›®ã§ã‚ã‹ã‚‹ã€‚

<details><summary>ãƒ’ãƒ³ãƒˆ</summary>

**æ‰‹é †**:
1. å„ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰1000ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆ
2. Inceptionç‰¹å¾´æŠ½å‡º
3. å„æŒ‡æ¨™ã‚’è¨ˆç®—ï¼ˆFID, IS, CMMD, P&Rï¼‰
4. çµ±è¨ˆæ¤œå®šï¼ˆä¿¡é ¼åŒºé–“ã€t-testï¼‰
5. JSONå‡ºåŠ›

**ã‚³ãƒ¼ãƒ‰éª¨æ ¼**:

```rust
/// Auto evaluation pipeline skeleton.
fn auto_eval_pipeline(
    model_generators: &[(&str, Box<dyn Fn() -> Vec<f64>>)],
    feats_real: &Array2<f64>,
    n_gen: usize,
) -> std::collections::HashMap<String, std::collections::HashMap<&'static str, f64>> {
    model_generators.iter().map(|(name, gen_fn)| {
        // Generate samples and extract features (placeholder)
        let _samples: Vec<Vec<f64>> = (0..n_gen).map(|_| gen_fn()).collect();
        let feats_gen = Array2::zeros((n_gen, feats_real.ncols()));

        let (fid, ci_l, ci_u, _) = fid_with_ci(feats_real, &feats_gen, 100, 0.95);
        let is_val = 1.0_f64; // inception_score(&feats_gen)
        // ... compute other metrics (CMMD, Precision, Recall)

        let mut m = std::collections::HashMap::new();
        m.insert("fid",    fid);
        m.insert("fid_ci_l", ci_l);
        m.insert("fid_ci_u", ci_u);
        m.insert("is",     is_val);
        (name.to_string(), m)
    }).collect()
}
```

</details>

**ãƒãƒ£ãƒ¬ãƒ³ã‚¸2**: Rust Criterionã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè£…ã—ã€FIDè¨ˆç®—ã®æ€§èƒ½å›å¸°ã‚’æ¤œå‡ºã›ã‚ˆã€‚

<details><summary>ãƒ’ãƒ³ãƒˆ</summary>

**Cargo.toml**:

```toml
[dev-dependencies]
criterion = "0.5"
ndarray = "0.16"
ndarray-linalg = "0.19"

[[bench]]
name = "fid_bench"
harness = false
```

**benches/fid_bench.rs**:

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};
use ndarray::{Array1, Array2};

fn benchmark_fid(c: &mut Criterion) {
    let d = 2048;
    let mu1 = Array1::zeros(d);
    let mu2 = Array1::ones(d) * 0.1;
    let sigma1 = Array2::eye(d);
    let sigma2 = Array2::eye(d) * 1.1;

    c.bench_function("fid_2048d", |b| {
        b.iter(|| frechet_distance(
            black_box(&mu1), black_box(&sigma1),
            black_box(&mu2), black_box(&sigma2)
        ).unwrap())
    });
}

criterion_group!(benches, benchmark_fid);
criterion_main!(benches);
```

**å®Ÿè¡Œ**: `cargo bench` â†’ CIçµ±åˆã§è‡ªå‹•å›å¸°æ¤œå‡º

</details>

### 6.6 é€²æ—ãƒˆãƒ©ãƒƒã‚«ãƒ¼ï¼ˆè‡ªå·±è©•ä¾¡ï¼‰

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ** â€” å„é …ç›®ã‚’é”æˆã—ãŸã‚‰ãƒã‚§ãƒƒã‚¯:

```rust
// Progress tracker â€” self-evaluation checklist
fn progress_tracker() {
    let checklist = [
        "âœ… Zone 0: FIDã‚’3è¡Œã§è¨ˆç®—ã§ãã‚‹",
        "âœ… Zone 1: 5ã¤ã®æŒ‡æ¨™ï¼ˆFID/IS/LPIPS/P&R/CMMDï¼‰ã‚’è§¦ã£ãŸ",
        "âœ… Zone 2: è©•ä¾¡ã®3ã¤ã®å›°é›£ã‚’ç†è§£ã—ãŸ",
        "âœ… Zone 3: FIDã®æ•°å¼ã‚’å®Œå…¨å°å‡ºã§ãã‚‹",
        "âœ… Zone 3: ISã®KLç™ºæ•£ã‚’å°å‡ºã§ãã‚‹",
        "âœ… Zone 3: LPIPSã®channel-wise normalizationã‚’ç†è§£ã—ãŸ",
        "âœ… Zone 3: Precision-Recallã®å¤šæ§˜ä½“ãƒ™ãƒ¼ã‚¹å®šç¾©ã‚’ç†è§£ã—ãŸ",
        "âœ… Zone 3: MMDã®ã‚«ãƒ¼ãƒãƒ«å±•é–‹ã‚’å°å‡ºã§ãã‚‹",
        "âœ… Zone 3: âš”ï¸ Boss Battle: CMMDè«–æ–‡ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰ã‚’å†å®Ÿè£…ã—ãŸ",
        "âœ… Zone 4: Rustã§ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—ã§ãã‚‹",
        "âœ… Zone 4: Rustã§Welch t-testã‚’å®Ÿè£…ã§ãã‚‹",
        "âœ… Zone 4: Rust Criterionã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè£…ã§ãã‚‹",
        "âœ… Zone 5: VAE/GAN/ARã®çµ±åˆè©•ä¾¡ã‚’å®Ÿè£…ã—ãŸ",
        "âœ… Zone 5: A/Bãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’è¨­è¨ˆã—ãŸ",
        "âœ… Zone 5: MOSã‚’é›†è¨ˆãƒ»åˆ†æã—ãŸ",
        "âœ… Zone 6: CMMD/FLD+ã®æœ€æ–°ç ”ç©¶ã‚’ç†è§£ã—ãŸ",
        "âœ… Zone 7: è‡ªå·±è¨ºæ–­ãƒ†ã‚¹ãƒˆã‚’å…¨å•è§£ã„ãŸ",
        "âœ… Zone 7: å®Ÿè£…ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã‚’å®Œäº†ã—ãŸ",
    ];

    let completed = checklist.iter().filter(|x| x.starts_with("âœ…")).count();
    let total = checklist.len();
    let progress = 100.0 * completed as f64 / total as f64;

    println!("Progress: {}/{} ({:.1}%)", completed, total, progress);
    if progress >= 100.0 {
        println!("ğŸ‰ ç¬¬26å›å®Œå…¨åˆ¶è¦‡ï¼");
    }
}
```

**ç›®æ¨™é”æˆåŸºæº–**:

| ãƒ¬ãƒ™ãƒ« | é”æˆç‡ | åˆ°é”ç‚¹ |
|:-------|:------|:-------|
| **Level 1: ä½¿ãˆã‚‹** | 40% | FID/IS/LPIPSã‚’è¨ˆç®—ã§ãã‚‹ |
| **Level 2: ç†è§£ã—ã¦ã„ã‚‹** | 70% | æ•°å¼ã‚’å®Œå…¨å°å‡ºã§ãã‚‹ |
| **Level 3: è¨­è¨ˆã§ãã‚‹** | 100% | è‡ªå‹•è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã§ãã‚‹ |

**Level 3 ã®æ„ç¾©**: ã€ŒæŒ‡æ¨™ã‚’è¨­è¨ˆã§ãã‚‹ã€ã¨ã¯ã€æ–°ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆåŒ»ç™‚ç”»åƒã€éŸ³å£°ç”Ÿæˆã€ã‚¿ãƒ³ãƒ‘ã‚¯è³ªè¨­è¨ˆï¼‰ã«å¯¾ã—ã¦ã€Œã©ã®ä»®å®šãŒæˆç«‹ã™ã‚‹ã‹ã€ã‚’åˆ¤æ–­ã—ã€ãã‚Œã«é©ã—ãŸè©•ä¾¡æŒ‡æ¨™ã‚’é¸æŠãƒ»ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã‚‹ã“ã¨ã‚’æ„å‘³ã™ã‚‹ã€‚FID ã‚’ä½¿ã† â†’ CMMD ã‚’æ¤œè¨ â†’ FLD+ ã§å°‘ã‚µãƒ³ãƒ—ãƒ«å¯¾å¿œ â†’ å¿…è¦ãªã‚‰ç‹¬è‡ªã‚«ãƒ¼ãƒãƒ«ã‚’è¨­è¨ˆã€ã¨ã„ã†æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ãŒ Level 3 ã®ã‚³ã‚¢ã‚¹ã‚­ãƒ«ã€‚

---

## è‘—è€…ãƒªãƒ³ã‚¯
- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

**ğŸ“ ç¬¬26å›å®Œäº†ï¼æ¬¡å›: ç¬¬27å› æ¨è«–æœ€é©åŒ– & Productionå“è³ª â€” è©•ä¾¡æ¸ˆã¿ã‚·ã‚¹ãƒ†ãƒ ã‚’æœ¬ç•ªé€Ÿåº¦ã¸**