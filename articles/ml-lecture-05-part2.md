---
title: "ç¬¬5å›: æ¸¬åº¦è«–çš„ç¢ºç‡è«–ãƒ»ç¢ºç‡éç¨‹å…¥é–€: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
emoji: "ğŸ“"
type: "tech"
topics: ["machinelearning", "deeplearning", "measuretheory", "stochasticprocesses", "python"]
published: true
slug: "ml-lecture-05-part2"
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Python"]
keywords: ["MCMC", "importance sampling", "SDE", "Langevin dynamics", "Fokker-Planck equation"]
---

> **ğŸ“˜ æœ¬è¨˜äº‹ã¯å¾Œç·¨ï¼ˆå®Ÿè£…ç·¨ï¼‰ã§ã™**: [å‰ç·¨ï¼ˆç†è«–ç·¨ï¼‰ã¯ã“ã¡ã‚‰](/articles/ml-lecture-05-part1)

## Learning Objectives

ã“ã®å¾Œç·¨ã‚’ä¿®äº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚¹ã‚­ãƒ«ãŒèº«ã«ã¤ãã¾ã™:

- [ ] Monte Carloç©åˆ†ã‚’å®Ÿè£…ã—ã€ `$O(1/\sqrt{N})$` ã®åæŸãƒ¬ãƒ¼ãƒˆã‚’ç¢ºèªã§ãã‚‹
- [ ] åˆ†æ•£ä½æ¸›æ³•ï¼ˆé‡ç‚¹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€å±¤åŒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€åˆ¶å¾¡å¤‰é‡æ³•ï¼‰ã‚’ä½¿ã„ã“ãªã›ã‚‹
- [ ] Kernel Density Estimationã‚’å®Ÿè£…ã—ã€Radon-Nikodymå°é–¢æ•°ã¨ã—ã¦ç†è§£ã§ãã‚‹
- [ ] Metropolis-Hastingsæ³•ã§MCMCã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å®Ÿè£…ã§ãã‚‹
- [ ] Browné‹å‹•ã®5ã¤ã®æ€§è³ªã‚’ã‚³ãƒ¼ãƒ‰ã§æ¤œè¨¼ã§ãã‚‹
- [ ] Euler-Maruyamaæ³•ã§SDEã‚’æ•°å€¤çš„ã«è§£ã‘ã‚‹
- [ ] Ornstein-Uhlenbeckéç¨‹ã‚’å®Ÿè£…ã—ã€å®šå¸¸åˆ†å¸ƒã¸ã®åæŸã‚’ç¢ºèªã§ãã‚‹
- [ ] Langevin dynamicsã§ã‚¹ã‚³ã‚¢é–¢æ•°ã‚’ç”¨ã„ãŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒã§ãã‚‹
- [ ] Fokker-Planckæ–¹ç¨‹å¼ã‚’ç†è§£ã—ã€SDEã¨å¯†åº¦æ™‚é–“ç™ºå±•ã®é–¢ä¿‚ã‚’èª¬æ˜ã§ãã‚‹

---

> **Note:** Part1ï¼ˆç†è«–ç·¨ï¼‰ã¨åˆã‚ã›ã¦èª­ã‚€ã“ã¨ã‚’æ¨å¥¨ã€‚ç‰¹ã« Â§4.5 Radon-Nikodym, Â§4.8 Markové€£é–, Â§4.10 ä¼Šè—¤ç©åˆ†ã¯æœ¬Part2ã§ç›´æ¥å®Ÿè£…ã™ã‚‹å†…å®¹ã¨1:1å¯¾å¿œã—ã¦ã„ã‚‹ã€‚

## ğŸ’» Z5. å®Ÿè£…ã‚¾ãƒ¼ãƒ³ï¼ˆ45åˆ†ï¼‰â€” æ¸¬åº¦è«–ã‚’ Python ã«ç¿»è¨³ã™ã‚‹

> **Zone 5 ç›®æ¨™**: æ¸¬åº¦è«–ã®æŠ½è±¡æ¦‚å¿µã‚’å…·ä½“çš„ãªã‚³ãƒ¼ãƒ‰ã«è½ã¨ã—è¾¼ã‚€ã€‚Monte Carloç©åˆ†ã€KDEã€Markové€£é–ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€Browné‹å‹•ãƒ‘ã‚¹ç”Ÿæˆã‚’å®Ÿè£…ã™ã‚‹ã€‚

### 5.1 Monte Carlo ç©åˆ† â€” Lebesgueç©åˆ†ã®è¿‘ä¼¼

ç†è«–ã§ã¯ `$\int f \, d\mu$` ã¨æ›¸ããŒã€å®Ÿå‹™ã§ã¯Monte Carloæ³•ã§è¿‘ä¼¼ã™ã‚‹ã€‚å¤§æ•°ã®æ³•å‰‡ãŒåæŸã‚’ä¿è¨¼ã™ã‚‹ã€‚

```math
\int f(x) \, p(x) \, dx \approx \frac{1}{N} \sum_{i=1}^{N} f(X_i), \quad X_i \sim p
```

**è¨˜å·å¯¾å¿œ**:

| æ•°å¼ | ã‚³ãƒ¼ãƒ‰å¤‰æ•° | shape |
|:-----|:----------|:------|
| `$f(X_i)$` | `f(x)` | `(N,)` |
| `$\hat{I}_N = \frac{1}{N}\sum_i f(X_i)$` | `np.mean(f(x))` | scalar |
| `$\text{Var}[\hat{I}_N] = \sigma^2/N$` | `f(x).var()/n` | scalar |
| `$X_i \sim p$` | `sampler(n)` | `(N,)` |

**åæŸé€Ÿåº¦**: æ¨™æº–èª¤å·® `$\text{SE} = \sigma/\sqrt{N}$`ã€‚`$N$` ã‚’10å€ã«ã™ã‚‹ã¨SEã¯ `$\sqrt{10}$` å€æ¸›å°‘ã€‚æ¬¡å…ƒã«ä¾å­˜ã—ãªã„ï¼ˆæ¬¡å…ƒã®å‘ªã„ã‹ã‚‰ã®è§£æ”¾ï¼‰ã€‚


```python
import numpy as np

def monte_carlo_integrate(f, sampler, n_samples: int, n_trials: int = 20):
    """Monte Carlo integration.

    E[f(X)] â‰ˆ (1/N) Î£ f(X_i)
    Variance: Var[estimate] = Var[f(X)] / N
    """
    est = []
    for _ in range(n_trials):
        x = sampler(n_samples)
        est.append(float(np.mean(f(x))))
    est = np.array(est, dtype=np.float64)
    return float(est.mean()), float(est.std(ddof=1))

# E[X^2] where X ~ N(0,1) should be 1
f = lambda x: x * x
rng = np.random.default_rng(42)
sampler = lambda n: rng.standard_normal(n)

for n in [100, 1_000, 10_000]:
    mean, std = monte_carlo_integrate(f, sampler, n)
    print(f"N={n:>6d}  mean={mean:.4f}  std={std:.4f}")
```

> **è¦³å¯Ÿ**: `$N$` ãŒ10å€ã«ãªã‚‹ã¨StdãŒ `$\sqrt{10} \approx 3.16$` å€å°ã•ããªã‚‹ â€” Monte Carloã® `$O(1/\sqrt{N})$` åæŸãƒ¬ãƒ¼ãƒˆã€‚

**åæŸé€Ÿåº¦ã®å®Ÿè¨¼çš„æ¤œè¨¼**:

```python
import numpy as np

rng = np.random.default_rng(0)
print("N         mean    std     SE_theory")
print("-" * 45)
for N in [100, 1_000, 10_000, 100_000, 1_000_000]:
    x = rng.standard_normal((50, N))  # 50 trials
    f_vals = x**2
    estimates = f_vals.mean(axis=1)  # shape (50,)
    se_empiric = estimates.std(ddof=1)
    se_theory = 1.0 / np.sqrt(N)  # sigma^2=Var[X^2]=2 for X~N(0,1), /sqrt(N)
    # exact: Var[X^2] = E[X^4] - (E[X^2])^2 = 3 - 1 = 2
    se_theory_exact = np.sqrt(2) / np.sqrt(N)
    print(f"N={N:>8d}: mean={estimates.mean():.4f}  SE_emp={se_empiric:.5f}  SE_th={se_theory_exact:.5f}")
```

`$\text{SE} = \sqrt{\text{Var}[f(X)]/N}$`ã€‚`$f(X) = X^2$` ã§ `$X \sim \mathcal{N}(0,1)$` ã®ã¨ã `$\text{Var}[X^2] = E[X^4] - (E[X^2])^2 = 3 - 1 = 2$`ï¼ˆ4æ¬¡ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆã‚’ä½¿ã†ï¼‰ã€‚

**åæŸè¨¼æ˜ï¼ˆä¸­å¿ƒæ¥µé™å®šç†ï¼‰**:

`$Y_i = f(X_i)$` ã¨ã™ã‚‹ã¨ `$\hat{I}_N = \bar{Y}_N = (1/N)\sum_i Y_i$`ã€‚CLTã‚ˆã‚Š:

```math
\sqrt{N}(\hat{I}_N - \mu) \xrightarrow{d} \mathcal{N}(0, \sigma^2), \quad \sigma^2 = \text{Var}[f(X)]
```

æ¨™æº–èª¤å·® `$\text{SE} = \sigma/\sqrt{N}$`ã€‚ç²¾åº¦ `$\epsilon$` ã‚’é”æˆã™ã‚‹ã®ã«å¿…è¦ãªã‚µãƒ³ãƒ—ãƒ«æ•°: `$N = \sigma^2/\epsilon^2$`ã€‚**æ¬¡å…ƒæ•°ã«éä¾å­˜** â€” ã“ã‚ŒãŒMonte CarloãŒé«˜æ¬¡å…ƒç©åˆ†ã«ä½¿ã‚ã‚Œã‚‹ç†ç”±ã€‚æ•°å€¤ç©åˆ†æ³•ï¼ˆSimpsonå‰‡ãªã©ï¼‰ã¯ `$O(N^{-k/d})$`ï¼ˆ`$d$`ï¼šæ¬¡å…ƒæ•°ï¼‰ã§æ¬¡å…ƒã®å‘ªã„ã‚’å—ã‘ã‚‹ã€‚

**åˆ†æ•£ã®æ¨å®š**:

```math
\hat{\sigma}^2 = \frac{1}{N-1}\sum_{i=1}^N (f(X_i) - \hat{I}_N)^2
```

åŒºé–“æ¨å®šï¼ˆ95%ä¿¡é ¼åŒºé–“ï¼‰: `$\hat{I}_N \pm 1.96 \hat{\sigma}/\sqrt{N}$`ã€‚Lebesgueç©åˆ†ã®è¿‘ä¼¼ã¨ã—ã¦: æ¸¬åº¦ `$p d\lambda$` ã®ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­è¿‘ä¼¼ã¯æ¸¬åº¦ã‚’çµŒé¨“æ¸¬åº¦ `$\hat{P}_N = (1/N)\sum_i \delta_{X_i}$` ã§ç½®æ›ã™ã‚‹ã“ã¨ã¨ç­‰ä¾¡ã€‚

### 5.2 `%timeit` ãƒ‡ãƒ“ãƒ¥ãƒ¼ â€” ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆæ¸¬

ç¬¬5å›ã‹ã‚‰ `%timeit` ã‚’ä½¿ã„å§‹ã‚ã‚‹ã€‚è¨ˆç®—ã‚³ã‚¹ãƒˆã®æ„Ÿè¦šã‚’é¤ŠãŠã†ã€‚


```python
import numpy as np, time
N = 1_000_000
rng = np.random.default_rng(0)
x = rng.standard_normal(N)
def sum_loop(arr):
    s = 0.0
    for v in arr: s += v * v
    return s / len(arr)
def sum_vec(arr): return (arr * arr).mean()
t0=time.perf_counter(); r1=sum_loop(x); t1=time.perf_counter()
t2=time.perf_counter(); r2=sum_vec(x);  t3=time.perf_counter()
print(f"loop={1000*(t1-t0):.1f}ms  vec={1000*(t3-t2):.1f}ms  result={r2:.4f}")
print(f"speedup={(t1-t0)/(t3-t2):.0f}x")  # E[X^2]=1
```


> **æ•™è¨“**: ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¯é€šå¸¸ **50-100å€** é«˜é€Ÿã€‚æ¸¬åº¦è«–ã®ç†è«–ã§ã¯summation orderã¯ç„¡é–¢ä¿‚ã ãŒã€å®Ÿè£…ã§ã¯**ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³**ãŒæ”¯é…çš„ã€‚

### 5.2.1 åˆ†æ•£ä½æ¸›æ³• â€” Monte Carloã‚’è³¢ãã™ã‚‹

Monte Carloã® `$O(1/\sqrt{N})$` åæŸã¯å¤‰ãˆã‚‰ã‚Œãªã„ãŒã€**åˆ†æ•£ã®å®šæ•°å› å­**ã‚’æ¸›ã‚‰ã›ã‚‹ã€‚



**å±¤åŒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°**: ç©åˆ†åŸŸã‚’ K å±¤ã«åˆ†å‰²ã—å„å±¤ã‹ã‚‰å‡ç­‰ã‚µãƒ³ãƒ—ãƒ«ã€‚

```math
\hat{I}_{\text{strat}} = \sum_{k=1}^K \frac{1}{K} \cdot \frac{K}{N} \sum_{i \in \text{layer}\,k} f(X_i)
```

```python
import numpy as np

def stratified_mc(f, lo, hi, n_total=100_000, n_strata=100):
    n_each = n_total // n_strata
    total = 0.0
    for k in range(n_strata):
        a = lo + k*(hi-lo)/n_strata
        b = a + (hi-lo)/n_strata
        total += f(np.random.uniform(a, b, n_each)).mean() * (hi-lo)/n_strata
    return total

f = lambda x: np.exp(-x**2)
crude = f(np.random.uniform(0, 1, 100_000)).mean()
strat = stratified_mc(f, 0, 1)
print(f"crude={crude:.5f}  stratified={strat:.5f}  exact=0.74682")
```


### 5.3 é‡ç‚¹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (Importance Sampling) â€” æ¸¬åº¦ã®å¤‰æ›

Radon-Nikodymå°é–¢æ•°ã®å®Ÿç”¨ç‰ˆã€‚`$p$` ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒé›£ã—ã„å ´åˆã€åˆ¥ã®åˆ†å¸ƒ `$q$` ã‚’ä½¿ã†:

```math
\mathbb{E}_p[f(X)] = \mathbb{E}_q\left[f(X) \frac{p(X)}{q(X)}\right] = \mathbb{E}_q\left[f(X) \frac{dP}{dQ}(X)\right]
```

`$\frac{p(x)}{q(x)}$` ãŒã¾ã•ã« **Radon-Nikodymå°é–¢æ•°** `$\frac{dP}{dQ}(x)$` ã§ã‚ã‚‹ã€‚



**è¨˜å·å¯¾å¿œ**:

| æ•°å¼ | ã‚³ãƒ¼ãƒ‰å¤‰æ•° | æ„å‘³ |
|:-----|:----------|:-----|
| `$w(x) = p(x)/q(x)$` | `np.exp(p_logpdf - q_logpdf)` | Radon-Nikodymå°é–¢æ•° |
| `$\tilde{w}(x) = w(x)/\sum w$` | `w / w.sum()` | æ­£è¦åŒ–é‡ã¿ |
| `$\hat{I}_{\text{IS}} = \sum_i \tilde{w}_i f(X_i)$` | `w @ f(x)` | ISæ¨å®šé‡ |
| ESS | `1 / sum(w_tilde^2)` | æœ‰åŠ¹ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º |


```python
import numpy as np
from scipy.stats import norm

def importance_sampling(f, p_logpdf, q_sampler, q_logpdf, n=50_000):
    x = q_sampler(n)
    log_w = p_logpdf(x) - q_logpdf(x)
    log_w -= log_w.max()
    w = np.exp(log_w); w /= w.sum()
    est = float(w @ f(x))
    ess_pct = 1.0 / float((w**2).sum()) / n * 100
    return est, ess_pct

est, ess = importance_sampling(
    f=lambda x: x,
    p_logpdf=lambda x: norm.logpdf(x, 5, 1),
    q_sampler=lambda n: norm.rvs(0, 3, size=n),
    q_logpdf=lambda x: norm.logpdf(x, 0, 3))
print(f"IS={est:.4f}  (true=5.0)  ESS={ess:.1f}%")
```

> **Note:** `$w(x) = p(x)/q(x)$` ãŒ Radon-Nikodym å°é–¢æ•° `$dP/dQ(x)$` ãã®ã‚‚ã®ã€‚ESS < 10% ãªã‚‰ææ¡ˆåˆ†å¸ƒ `$q$` ãŒ `$p$` ã®ã‚µãƒãƒ¼ãƒˆã‚’ã‚«ãƒãƒ¼ã§ãã¦ã„ãªã„ã€‚

**Self-Normalized IS (SNIS)**: æ­£è¦åŒ–å®šæ•° `$Z = \int p^*(x)dx$` ãŒæœªçŸ¥ã®å ´åˆ:

```math
\hat{I}_{\text{SNIS}} = \frac{\sum_i w_i f(X_i)}{\sum_j w_j}, \quad w_i = \frac{p^*(X_i)}{q(X_i)}
```

SNISã¯ãƒã‚¤ã‚¢ã‚¹ã‚’æŒã¤ãŒï¼ˆ`$\mathbb{E}[\hat{I}_{\text{SNIS}}] \neq \mu$`ï¼‰ã€`$N \to \infty$` ã§ä¸€è‡´æ¨å®šé‡ã«ãªã‚‹ã€‚VAEã®ELBOã‚’ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­æ¨å®šã™ã‚‹ã¨ãã€ã“ã®SNISãŒIMPORTANCE WEIGHTED AE (IWAE) ã®åŸºç¤ã«ãªã‚‹ã€‚

**SNISã¨KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã®é–¢ä¿‚**:

```math
D_{\mathrm{KL}}(q \| p) = \mathbb{E}_q\left[\log\frac{q(X)}{p(X)}\right] = -\mathbb{E}_q[\log w(X)] + \text{const}
```

Importance weight ã®å¯¾æ•°å¹³å‡ãŒKLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¨ç›´çµã€‚VAEã®å¤‰åˆ†ä¸‹ç•Œ ELBO = `$-D_{\mathrm{KL}}(q \| p) + \mathbb{E}_q[\log p(x|z)]$` ã¯ã“ã®æ§‹é€ ã‹ã‚‰æ¥ã¦ã„ã‚‹ã€‚

**IWAEï¼ˆImportance Weighted Autoencoderï¼‰**:

```math
\mathcal{L}_K^{\text{IWAE}} = \mathbb{E}_{z_1, \ldots, z_K \sim q_\phi(z|x)}\left[\log \frac{1}{K}\sum_{k=1}^K \frac{p_\theta(x, z_k)}{q_\phi(z_k|x)}\right]
```

ã“ã‚Œã¯Kå€‹ã®SNISæ¨å®šé‡ã®å¯¾æ•°ã€‚`$K=1$` ã§ELBOã€`$K \to \infty$` ã§ `$\log p(x)$`ï¼ˆçœŸã®å¯¾æ•°å°¤åº¦ï¼‰ã«åæŸã€‚æ¸¬åº¦è«–çš„ã«ã¯: Kå€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰æ¸¬åº¦ `$p(z|x)$` ã‚’æ¨å®šã—ã€ãã®æ­£è¦åŒ–å®šæ•° `$\log p(x) = \log \int p(x,z)dz$` ã‚’è¿‘ä¼¼ã—ã¦ã„ã‚‹ã€‚


### 5.4 ã‚«ãƒ¼ãƒãƒ«å¯†åº¦æ¨å®š (KDE) â€” Radon-Nikodymå°é–¢æ•°ã®æ¨å®š

ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç¢ºç‡å¯†åº¦é–¢æ•°ï¼ˆ= Lebesgueæ¸¬åº¦ã«é–¢ã™ã‚‹Radon-Nikodymå°é–¢æ•°ï¼‰ã‚’æ¨å®šã™ã‚‹ã€‚

```math
\hat{f}_h(x) = \frac{1}{nh} \sum_{i=1}^{n} K\left(\frac{x - X_i}{h}\right)
```

ãƒãƒ³ãƒ‰å¹… `$h$` ã¯ã€Œæ¸¬åº¦ã®è§£åƒåº¦ã€ã‚’æ±ºã‚ã‚‹ã€‚



**è¨˜å·å¯¾å¿œ**:

| æ•°å¼ | ã‚³ãƒ¼ãƒ‰å¤‰æ•° | æ„å‘³ |
|:-----|:----------|:-----|
| `$h$` | `h` | ãƒãƒ³ãƒ‰å¹…ï¼ˆè§£åƒåº¦ï¼‰ |
| `$K(u) = \phi(u)$` | `exp(-0.5*d^2)/sqrt(2pi)` | ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ã‚«ãƒ¼ãƒãƒ« |
| `$\hat{f}_h(x) = \frac{1}{nh}\sum K((x-X_i)/h)$` | `kernels.mean(axis=1)/h` | KDEæ¨å®šå€¤ |
| `$h_{\text{Silverman}} = 1.06\hat{\sigma}n^{-1/5}$` | `1.06*std*n**(-0.2)` | æœ€é©ãƒãƒ³ãƒ‰å¹… |


```python
import numpy as np

def gaussian_kde(data, h=None):
    n = len(data)
    h = h or 1.06 * data.std(ddof=1) * n**(-0.2)
    def estimate(x_eval):
        d = (x_eval[:, None] - data[None, :]) / h
        return (np.exp(-0.5*d**2) / np.sqrt(2*np.pi)).mean(axis=1) / h
    return estimate, h

rng = np.random.default_rng(42)
n = 500
data = np.where(rng.random(n)<0.7, rng.standard_normal(n), rng.normal(4, 0.5, n))
kde_fn, h = gaussian_kde(data)
x_eval = np.linspace(-4, 7, 200)
density = kde_fn(x_eval)
dx = x_eval[1] - x_eval[0]
print(f"h={h:.3f}  integral={float(density.sum()*dx):.4f}  (should=1.0)")
```


### 5.5 Markové€£é–ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ â€” å®šå¸¸åˆ†å¸ƒã¸ã®åæŸ

å®šå¸¸åˆ†å¸ƒ `$\boldsymbol{\pi}$` ã¸ã®åæŸã‚’å¯è¦–åŒ–ã™ã‚‹ã€‚



```python
import numpy as np

P = np.array([[0.7, 0.2, 0.1],[0.3, 0.4, 0.3],[0.1, 0.3, 0.6]])
vals, vecs = np.linalg.eig(P.T)
idx = np.argmin(np.abs(vals - 1)); pi = np.abs(vecs[:, idx]); pi /= pi.sum()
print(f"exact   pi = {pi}")
print(f"P^100 row0 = {np.linalg.matrix_power(P,100)[0]}")

def simulate_markov(P, n_steps=100_000, x0=0):
    n = len(P); x = x0; hist = np.zeros(n, int)
    for _ in range(n_steps):
        x = np.random.choice(n, p=P[x]); hist[x] += 1
    return hist / n_steps
print(f"empiric pi = {simulate_markov(P)}")
```


### 5.6 Metropolis-Hastings â€” MCMC ã®åŸºç¤

è©³ç´°é‡£ã‚Šåˆã„æ¡ä»¶ã‚’ä½¿ã£ã¦ã€ä»»æ„ã®ç›®æ¨™åˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã€‚

```math
\alpha(x, x') = \min\left(1, \frac{\pi(x') q(x \mid x')}{\pi(x) q(x' \mid x)}\right)
```

```python
import numpy as np

def metropolis_hastings(log_target, proposal_std, x0, n_samples, burnin=1000):
    """Metropolis-Hastings MCMC sampler.

    Detailed balance: Ï€(x) P(xâ†’x') = Ï€(x') P(x'â†’x)
    Acceptance: Î± = min(1, Ï€(x')q(x|x') / Ï€(x)q(x'|x))
    For symmetric proposal: Î± = min(1, Ï€(x')/Ï€(x))
    """
    x = x0
    samples = []
    accepted = 0

    for i in range(n_samples + burnin):
        # Symmetric proposal: q(x'|x) = N(x, ÏƒÂ²)
        x_proposed = x + proposal_std * np.random.randn()

        # Log acceptance ratio (symmetric â†’ simplifies)
        log_alpha = log_target(x_proposed) - log_target(x)

        if np.log(np.random.rand()) < log_alpha:
            x = x_proposed
            if i >= burnin:
                accepted += 1

        if i >= burnin:
            samples.append(x)

    acceptance_rate = accepted / n_samples
    return np.array(samples), acceptance_rate

# Target: mixture of Gaussians (unnormalized)
def log_target_mixture(x):
    """Log of unnormalized mixture density."""
    return np.logaddexp(
        -0.5 * (x + 2)**2 / 0.5**2,
        -0.5 * (x - 3)**2 / 1.0**2
    )

np.random.seed(42)
samples, rate = metropolis_hastings(log_target_mixture, proposal_std=1.0, x0=0.0, n_samples=20_000)
print(f"accept%={rate*100:.1f}%  mean={samples.mean():.3f}  std={samples.std():.3f}")
```

`$\pi$` ã®æ­£è¦åŒ–å®šæ•°ã‚’çŸ¥ã‚‰ãªãã¦ã‚‚ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ãã‚‹ â€” ã“ã‚ŒãŒãƒ™ã‚¤ã‚ºæ¨è«–ã§é‡è¦ã€‚

**è©³ç´°é‡£ã‚Šåˆã„æ¡ä»¶ã®ç¢ºèª**:

```math
\pi(x) \cdot \alpha(x, x') \cdot q(x' | x) = \pi(x') \cdot \alpha(x', x) \cdot q(x | x')
```

ã“ã‚ŒãŒæˆç«‹ã™ã‚‹ã®ã¯å®šç¾©ã‹ã‚‰: `$\alpha(x, x') = \min(1, \pi(x')q(x|x')/\pi(x)q(x'|x))$` ã¨è¨­å®šã—ãŸã‹ã‚‰ã€‚å¯¾ç§°ææ¡ˆ `$q(x'|x) = q(x|x')$` ã®ã¨ã `$\alpha(x, x') = \min(1, \pi(x')/\pi(x))$` ã«ç°¡ç•¥åŒ–ã•ã‚Œã‚‹ã€‚

**æœ€é©å—ç†ç‡**: Roberts et al. (1997) [^5] ã¯é«˜æ¬¡å…ƒã‚¬ã‚¦ã‚¹ç›®æ¨™åˆ†å¸ƒã«å¯¾ã—ã¦æœ€é©å—ç†ç‡ `$\approx 23.4\%$` ã‚’ç¤ºã—ãŸã€‚ææ¡ˆåˆ†å¸ƒã®å¹…ã‚’å—ç†ç‡ãŒ 20-25% ã«ãªã‚‹ã‚ˆã†èª¿æ•´ã™ã‚‹ã®ãŒå®Ÿè·µçš„ãªãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ã‚¯ã‚¹ã€‚

**MALA (Metropolis-Adjusted Langevin Algorithm)**: Langevin Dynamicsã«ãƒ¡ãƒˆãƒ­ãƒãƒªã‚¹è£œæ­£ã‚’åŠ ãˆã€ãƒã‚¤ã‚¢ã‚¹ã‚’é™¤ã„ãŸã‚‚ã®ã€‚ULAã«æ¯”ã¹ã¦ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤§å¹…å‰Šæ¸›ã§ãã‚‹:

```math
x' = x + \frac{\epsilon}{2} \nabla \log \pi(x) + \sqrt{\epsilon} Z, \quad \text{then accept/reject with } \alpha(x, x')
```

MALAã¯ULAã‚ˆã‚ŠåŠ¹ç‡çš„ï¼ˆ`$d$ æ¬¡å…ƒã§ã®æœ€é©ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒ `$\epsilon = O(d^{-1/3})$` vs ULAã® `$O(d^{-1})$`ï¼‰ã€‚æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®è¨­è¨ˆã«ç›´æ¥å½±éŸ¿ã™ã‚‹ã€‚

**Gibbs Samplerã¨ã®æ¯”è¼ƒ**: Gibbs Samplerã¯é«˜æ¬¡å…ƒã®å ´åˆã«å…¨å¤‰æ•°ã‚’ä¸€åº¦ã«ã‚µãƒ³ãƒ—ãƒ«ã›ãšã€å„å¤‰æ•° `$x_i$` ã‚’ä»–ã®å¤‰æ•°ã‚’å›ºå®šã—ã¦æ¡ä»¶ä»˜ã `$p(x_i | \mathbf{x}_{-i})$` ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã™ã‚‹:

```math
x_i^{(t+1)} \sim p(x_i \mid x_1^{(t+1)}, \ldots, x_{i-1}^{(t+1)}, x_{i+1}^{(t)}, \ldots, x_d^{(t)})
```

**ç‰¹æ€§æ¯”è¼ƒ**:

| ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  | å—ç†åˆ¤å®š | å¿…è¦æƒ…å ± | é«˜æ¬¡å…ƒ | ç›¸é–¢å¤‰æ•° |
|-------------|---------|---------|--------|----------|
| MH (çƒå½¢ææ¡ˆ) | ã‚ã‚Š | `$\log \pi$` | â–³ ã‚¹ãƒ†ãƒƒãƒ—å°ã•ã | â–³ |
| MALA | ã‚ã‚Š | `$\nabla \log \pi$` | â—‹ `$O(d^{-1/3})$` | â—‹ |
| HMC/NUTS | ã‚ã‚Š | `$\nabla \log \pi$` | â— `$O(d^{-1/4})$` | â— |
| Gibbs | ãªã—ï¼ˆå¸¸ã«å—ç†ï¼‰ | æ¡ä»¶ä»˜ãå¯†åº¦ | â—‹ï¼ˆç‹¬ç«‹æˆåˆ†ï¼‰ | âœ• |
| ULA | ãªã—ï¼ˆãƒã‚¤ã‚¢ã‚¹ã‚ã‚Šï¼‰ | `$\nabla \log \pi$` | â—‹ | â—‹ |

Gibbs Samplerã®**è©³ç´°é‡£ã‚Šåˆã„è¨¼æ˜**: æ¡ä»¶ä»˜ãåˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã™ã‚‹ã®ã§ã€ä¸€ã¤ã®æˆåˆ†ã‚’æ›´æ–°ã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ã®è©³ç´°é‡£ã‚Šåˆã„ã¯è‡ªæ˜ã«æˆç«‹ï¼ˆ`$\pi(x_i|\mathbf{x}_{-i})$` ã‹ã‚‰ç›´æ¥ã‚µãƒ³ãƒ—ãƒ«ã™ã‚‹ã‹ã‚‰ï¼‰ã€‚å…¨æˆåˆ†ã‚’ä¸€å‘¨ã™ã‚‹ã¨ï¼ˆSystematic Gibbsï¼‰å®šå¸¸åˆ†å¸ƒ `$\pi$` ã«åæŸã€‚

**æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¥ç¶š**: DDPM ã®ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚° `$p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)$` ã¯ã€æ™‚ç³»åˆ—ã‚’æ¡ä»¶ä»˜ãç¢ºç‡ã®ç©ã«åˆ†è§£ã™ã‚‹Gibbsçš„æ§‹é€ ã ã€‚ãŸã ã—å„ã‚¹ãƒ†ãƒƒãƒ—ã§ç‹¬ç«‹ã«ã‚µãƒ³ãƒ—ãƒ«ã™ã‚‹ãŸã‚ Gibbs Sampler ã¨ã¯ç•°ãªã‚Šã€Score SDE ã®é€†éç¨‹ã¨åŒå€¤ã€‚

### 5.7 Browné‹å‹•ãƒ‘ã‚¹ç”Ÿæˆ â€” é›¢æ•£è¿‘ä¼¼

`$W(t_{k+1}) = W(t_k) + \sqrt{\Delta t} \cdot Z_k, \quad Z_k \sim \mathcal{N}(0,1)$`



```python
import numpy as np

T, n_steps, n_paths = 1.0, 1000, 200
rng = np.random.default_rng(42)
dt = T / n_steps
dW = rng.standard_normal((n_steps, n_paths)) * np.sqrt(dt)
W = np.vstack([np.zeros(n_paths), np.cumsum(dW, axis=0)])
qv = (dW**2).sum(axis=0)  # quadratic variation: should -> T
print(f"W(T): mean={W[-1].mean():.3f}  std={W[-1].std():.3f}  (theory: 0, 1)")
print(f"[W]_T: mean={qv.mean():.4f}  std={qv.std():.4f}  (theory: 1.0, 0)")
```


### 5.8 å¹¾ä½•Browné‹å‹• (GBM) â€” ItÃ´ã®å…¬å¼ã®å®Ÿè·µ

æ ªä¾¡ãƒ¢ãƒ‡ãƒ«ã®å¤å…¸:

```math
dS = \mu S \, dt + \sigma S \, dW
```

ItÃ´ã®å…¬å¼ã«ã‚ˆã‚Šè§£æè§£ãŒå¾—ã‚‰ã‚Œã‚‹:

```math
S(t) = S(0) \exp\left(\left(\mu - \frac{\sigma^2}{2}\right)t + \sigma W(t)\right)
```

`$-\frac{\sigma^2}{2}$` ã® **ItÃ´è£œæ­£é …** ã«æ³¨æ„ â€” ã“ã‚ŒãŒä¼Šè—¤ç©åˆ†ã®éç›´æ„Ÿçš„ãªéƒ¨åˆ†ã€‚


```python
import numpy as np

S0, mu, sigma, T, n_steps = 100.0, 0.05, 0.20, 1.0, 252
n_paths = 5000
rng = np.random.default_rng(0)
dt = T / n_steps
dW = rng.standard_normal((n_steps, n_paths)) * np.sqrt(dt)
log_S = np.log(S0) + ((mu - 0.5*sigma**2)*dt + sigma*dW).sum(axis=0)
S_T = np.exp(log_S)
print(f"E[S(T)] empiric={S_T.mean():.2f}  analytic={S0*np.exp(mu*T):.2f}")
log_ret = np.log(S_T/S0)
print(f"log-ret mean={log_ret.mean():.4f}  std={log_ret.std():.4f}")
print(f"  theory  mean={(mu-0.5*sigma**2):.4f}  std={sigma:.4f}")
```

**ItÃ´è£œæ­£ã®å¿…è¦æ€§**:

ç´ æœ´ãª `$d(\log S) = dS/S$` ã®è¨ˆç®—ã§ã¯ ItÃ´ è£œæ­£ `$-\sigma^2/2$` ãŒå‡ºãªã„ã€‚ã‚³ãƒ¼ãƒ‰ã§ç¢ºèªã™ã‚‹ã¨ `E[S(T)] = S0 * exp(mu*T)` ãŒæˆç«‹ã™ã‚‹ï¼ˆæ­£ã—ã„ï¼‰ãŒã€`$\sigma^2/2$` ã‚’è½ã¨ã™ã¨ `E[S(T)]` ãŒèª¤ã£ãŸå€¤ã«ãªã‚‹ã€‚



ç´ æœ´ãª `$d(\log S) = dS/S = \mu dt + \sigma dW$` ã¨ç©åˆ†ã™ã‚‹ã¨ `$S(T) = S_0 \exp(\mu T + \sigma W_T)$` ã¨ãªã‚Šã€`$\mathbb{E}[S(T)] = S_0 e^{\mu T} e^{\sigma^2 T/2} \neq S_0 e^{\mu T}$`ã€‚ItÃ´è£œæ­£ `$-\sigma^2/2$` ã¯ `$\mathbb{E}[S(T)] = S_0 e^{\mu T}$`ï¼ˆãƒªã‚¹ã‚¯ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«è©•ä¾¡ï¼‰ã‚’ä¿è¨¼ã™ã‚‹ãŸã‚ã«å¿…è¦ã€‚ã“ã®è£œæ­£ãªã—ã«é‡‘èæ´¾ç”Ÿå•†å“ã®ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã¯æˆã‚Šç«‹ãŸãªã„ã€‚

**å¯¾æ•°æ­£è¦æ€§ã®æ¤œè¨¼**: `$\log(S_T/S_0) \sim \mathcal{N}((\mu-\sigma^2/2)T, \sigma^2 T)$` ãŒæˆç«‹ã™ã‚‹ã“ã¨ã‚’ã‚³ãƒ¼ãƒ‰ã§ç¢ºèªã—ãŸã€‚å¹³å‡ `$\mu T$` ã§ãªã `$(\mu-\sigma^2/2)T$` ã«ãªã‚‹ã®ãŒItÃ´ç©åˆ†ã®éç›´æ„Ÿçš„ãªæ ¸å¿ƒã ã€‚

### 5.9 Ornstein-Uhlenbeckéç¨‹ â€” DDPMã®é€£ç¶šæ¥µé™

Diffusion modelã®é€£ç¶šæ¥µé™ã¯Ornstein-Uhlenbeck (OU) éç¨‹:

```math
dX_t = -\theta X_t \, dt + \sigma \, dW_t
```

å¹³å‡å›å¸°æ€§ï¼ˆmean-revertingï¼‰ã‚’æŒã¡ã€å®šå¸¸åˆ†å¸ƒã¯ `$\mathcal{N}(0, \sigma^2/(2\theta))$`ã€‚



```python
import numpy as np

theta, sigma, x0, T, n_steps, n_paths = 1.0, 1.0, 5.0, 10.0, 10_000, 2000
rng = np.random.default_rng(42)
dt = T / n_steps
X = np.full(n_paths, x0, dtype=float)
for k in range(n_steps):
    X += -theta * X * dt + sigma * np.sqrt(dt) * rng.standard_normal(n_paths)
stat_var = sigma**2 / (2*theta)  # N(0, sigma^2/(2*theta))
print(f"final: mean={X.mean():.3f}  var={X.var():.3f}  (stat.var={stat_var:.3f})")
```


### 5.10 Langevin Dynamics â€” Scoreé–¢æ•°ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

Score function `$\nabla_x \log p(x)$` ã‚’ä½¿ã£ã¦ç›®æ¨™åˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹Langevin Monte Carloæ³•:

```math
X_{k+1} = X_k + \frac{\epsilon}{2} \nabla_x \log p(X_k) + \sqrt{\epsilon} \, Z_k, \quad Z_k \sim \mathcal{N}(0, I)
```

`$\epsilon \to 0$`ã€`$K \to \infty$` ã§ `$X_K \sim p$` ã«åæŸã™ã‚‹[^2]ã€‚



```python
import numpy as np
from scipy.stats import norm

def ula(score_fn, x0=0.0, eps=0.005, n=100_000, burnin=10_000, seed=42):
    rng = np.random.default_rng(seed)
    x = float(x0); samples = []
    for i in range(n + burnin):
        x += 0.5*eps*score_fn(x) + np.sqrt(eps)*rng.standard_normal()
        if i >= burnin: samples.append(x)
    return np.array(samples)

def log_p(x):
    return float(np.logaddexp(norm.logpdf(x, -2, 0.5), norm.logpdf(x, 3, 1.0)))
def score(x, h=1e-4): return (log_p(x+h)-log_p(x-h))/(2*h)

s = ula(score)
print(f"mean={s.mean():.3f}  std={s.std():.3f}")
```

**Fokker-Planckæ¥ç¶š**: Langevin SDE `$dX = \nabla\log p(X)dt + \sqrt{2}dW$` ã®FPå®šå¸¸è§£ã¯ `$q_\infty = p$`ã€‚


### 5.11 Euler-Maruyamaæ³• â€” SDEã®æ•°å€¤è§£æ³•

SDEã®å³å¯†è§£ãŒå¾—ã‚‰ã‚Œã‚‹ã‚±ãƒ¼ã‚¹ï¼ˆGBMã€OUéç¨‹ï¼‰ã¯å°‘æ•°æ´¾ã ã€‚ä¸€èˆ¬ã®SDEã§ã¯**æ•°å€¤è§£æ³•**ãŒå¿…è¦ã«ãªã‚‹ã€‚æœ€ã‚‚åŸºæœ¬çš„ãªæ‰‹æ³•ãŒEuler-Maruyamaæ³• â€” ODE ã®Euleræ³•ã‚’SDEã«æ‹¡å¼µã—ãŸã‚‚ã®ã€‚

#### é›¢æ•£åŒ–ã‚¹ã‚­ãƒ¼ãƒ 

SDE `$dX_t = f(X_t) \, dt + g(X_t) \, dW_t$` ã‚’æ™‚é–“å¹… `$\Delta t$` ã§é›¢æ•£åŒ–ã™ã‚‹:

```math
X_{n+1} = X_n + f(X_n) \Delta t + g(X_n) \sqrt{\Delta t} \, Z_n, \quad Z_n \sim \mathcal{N}(0, 1)
```

`$\sqrt{\Delta t} \, Z_n$` ãŒ Browné‹å‹•å¢—åˆ† `$\Delta W_n = W_{t_{n+1}} - W_{t_n} \sim \mathcal{N}(0, \Delta t)$` ã«å¯¾å¿œã€‚

ã“ã‚Œã¯ Euler æ³•ã®ç¢ºç‡ç‰ˆã ã€‚

**è¨˜å·å¯¾å¿œ**:

| æ•°å¼ | ã‚³ãƒ¼ãƒ‰å¤‰æ•° | shape |
|:-----|:----------|:------|
| `$f(X_n)$` | `f(X)` | `(n_paths,)` |
| `$g(X_n)$` | `g(X)` | `(n_paths,)` |
| `$\Delta t$` | `dt` | scalar |
| `$Z_n \sim \mathcal{N}(0,1)$` | `rng.standard_normal(n_paths)` | `(n_paths,)` |

```python
import numpy as np

def euler_maruyama(f, g, x0, T=1.0, n_steps=1000, n_paths=2000, seed=0):
    rng = np.random.default_rng(seed)
    dt = T / n_steps
    sqrt_dt = np.sqrt(dt)
    X = np.full(n_paths, x0, dtype=float)
    for _ in range(n_steps):
        Z = rng.standard_normal(n_paths)
        X = X + f(X)*dt + g(X)*sqrt_dt*Z
    return X

# OU: dX = -X dt + dW -> stationary N(0, (1-e^{-2T})/2)
X_T = euler_maruyama(f=lambda x: -x, g=lambda x: np.ones_like(x), x0=5.0)
stat_var = (1 - np.exp(-2.0)) / 2
print(f"X(T) mean={X_T.mean():.3f}  var={X_T.var():.3f}  (stat.var={stat_var:.3f})")
```

#### å¼·åæŸã¨å¼±åæŸ

| åæŸã®ç¨®é¡ | å®šç¾© | Euler-Maruyama | æ„å‘³ |
|:---------|:----|:-------------|:-----|
| å¼·åæŸ | `$\mathbb{E}[\|X_N - X(T)\|] \leq C \Delta t^{1/2}$` | `$O(\sqrt{\Delta t})$` | ãƒ‘ã‚¹ãŒè¿‘ã„ |
| å¼±åæŸ | `$\|\mathbb{E}[h(X_N)] - \mathbb{E}[h(X(T))]\| \leq C \Delta t$` | `$O(\Delta t)$` | çµ±è¨ˆé‡ãŒè¿‘ã„ |

- **å¼·åæŸ**: å€‹ã€…ã®ãƒ‘ã‚¹ãŒçœŸã®è§£ã«è¿‘ã„ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»å¯è¦–åŒ–ã«é‡è¦ï¼‰
- **å¼±åæŸ**: æœŸå¾…å€¤ã‚„åˆ†å¸ƒã®æ€§è³ªãŒæ­£ã—ã„ï¼ˆçµ±è¨ˆé‡ã®æ¨å®šã«ååˆ†ï¼‰

æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã§ã¯å¤šãã®å ´åˆã€**å¼±åæŸã§ååˆ†**ï¼ˆç”Ÿæˆç”»åƒã®åˆ†å¸ƒãŒæ­£ã—ã‘ã‚Œã°ã‚ˆã„ï¼‰ã€‚DDPM ã®é›¢æ•£ã‚¹ãƒ†ãƒƒãƒ—æ•° `$T = 1000$` ã¯å¼±åæŸã®ç²¾åº¦ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã€‚

**Milsteinæ³•ï¼ˆ1æ¬¡ç²¾åº¦ï¼‰**: Euler-Maruyamaã‚’æ”¹å–„ã—ãŸé«˜ç²¾åº¦ã‚¹ã‚­ãƒ¼ãƒ :

```math
X_{n+1} = X_n + f(X_n)\Delta t + g(X_n)\Delta W_n + \frac{1}{2}g(X_n)g'(X_n)[(\Delta W_n)^2 - \Delta t]
```

è¿½åŠ é … `$\frac{1}{2}g g'[(\Delta W)^2 - \Delta t]$` ãŒItÃ´è£œæ­£ã‹ã‚‰æ¥ã¦ã„ã‚‹ï¼ˆ`$(dW)^2 = dt$` ã®æ¬¡ã®é …ï¼‰ã€‚å¼·åæŸãŒ `$O(\Delta t)$` ã«æ”¹å–„ï¼ˆEuler-Maruyamaã® `$O(\sqrt{\Delta t})$` ã‹ã‚‰ï¼‰ã€‚

`$g$` ãŒå®šæ•°ï¼ˆOUéç¨‹ã€DDPMï¼‰ã®å ´åˆ: `$g' = 0$` ãªã®ã§Milstein = Euler-Maruyamaã€‚ã¤ã¾ã‚ŠDDPMã§ã¯ä¸¡è€…ãŒç­‰ä¾¡ã§ã€Euler-Maruyamaã§ååˆ†ã€‚



### 5.12 åæŸå®šç†ã®æ•°å€¤æ¤œè¨¼ â€” MCT vs DCT vs Fatou

3ã¤ã®åæŸå®šç†ã‚’åŒæ™‚ã«æ¤œè¨¼ã™ã‚‹ã€‚

```python
import numpy as np

rng = np.random.default_rng(0)
x = rng.uniform(0, 10, 200_000)
print("MCT (-> 50):")
for n in [1, 2, 5, 10]:
    print(f"  n={n}: {(x*(x<=n)).mean()*10:.2f}")

x2 = rng.uniform(0, 20, 200_000)
print("DCT (-> 1.0):")
for n in [2, 10, 100]:
    gn = (1+x2/n)**(-n)
    print(f"  n={n}: {gn.mean()*20:.4f}")

x3 = rng.uniform(0, 5, 200_000)
print("No domination (stays ~0.5):")
for n in [1, 5, 50]:
    hn = n * x3 * np.exp(-n * x3**2)
    print(f"  n={n}: {hn.mean()*5:.4f}")
```


### Quick Check â€” Z5

<details><summary>Q1: Importance Samplingã§w(x)=p(x)/q(x)ãŒã€ŒRadon-Nikodymå°é–¢æ•°ã€ã«ãªã‚‹ç†ç”±ã‚’èª¬æ˜ã›ã‚ˆã€‚</summary>

**A**: Radon-Nikodymå®šç†ã¯ã€Œ`$P \ll Q$` ã®ã¨ã `$P(A) = \int_A \frac{dP}{dQ} dQ$` ã‚’æº€ãŸã™å¯æ¸¬é–¢æ•°ãŒä¸€æ„å­˜åœ¨ã™ã‚‹ã€ã¨è¨€ã†ã€‚Importance weightingã®ç­‰å¼:

```math
\mathbb{E}_P[f] = \int f \, dP = \int f \frac{dP}{dQ} dQ = \mathbb{E}_Q\left[f \cdot \frac{p}{q}\right]
```

ã® `$p(x)/q(x)$` ãŒã¾ã•ã« `$dP/dQ(x)$`ã€‚`$p \ll q$`ï¼ˆã‚µãƒãƒ¼ãƒˆã®åŒ…å«ï¼‰ãŒ Radon-Nikodym ã®å‰ææ¡ä»¶ã«å¯¾å¿œã—ã€ã“ã‚ŒãŒå´©ã‚Œã‚‹ã¨ ESS ãŒ 0 ã«è¿‘ã¥ãã€‚

</details>

<details><summary>Q2: Browné‹å‹•ã®äºŒæ¬¡å¤‰å‹• [W]_T = T ã‚’æ•°å€¤çš„ã«æ¤œè¨¼ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã®æ„å›³ã‚’èª¬æ˜ã›ã‚ˆã€‚</summary>

**A**: äºŒæ¬¡å¤‰å‹•ã®å®šç¾©ã¯ `$[W]_T = \lim_{\|P\| \to 0} \sum_k (W_{t_{k+1}} - W_{t_k})^2$`ã€‚ã‚³ãƒ¼ãƒ‰ä¸­ã® `(dW**2).sum(axis=0)` ã¯ã“ã®å’Œã®é›¢æ•£è¿‘ä¼¼ã€‚`$\Delta t \to 0$` ã®ã¨ã `$\sum (\Delta W)^2 \to T$`ï¼ˆç¢ºç‡åæŸï¼‰ã€‚ã“ã‚ŒãŒ `$(dW)^2 = dt$` ã¨ã„ã†ä¼Šè—¤ã®è£œé¡Œã®2æ¬¡é …ã®èµ·æºã§ã‚ã‚Šã€é€šå¸¸ã®å¾®ç©åˆ†ã§ã¯æ¶ˆãˆã‚‹ `$dx^2 = 0$` ã¨ã®æœ¬è³ªçš„é•ã„ã€‚

</details>

<details>
<summary>Quick Check ç­”ãˆåˆã‚ã›</summary>

ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†:

1. Monte Carloç©åˆ†ã®åæŸãƒ¬ãƒ¼ãƒˆã¯ `$O(1/\sqrt{N})$` â€” ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’100å€ã«ã™ã‚‹ã¨èª¤å·®ã¯10å€å°ã•ããªã‚‹
2. é‡ç‚¹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ESS < 10%ã®å ´åˆã€æ¨å®šçµæœã¯ä¿¡é ¼ã§ããªã„
3. KDEã®ãƒãƒ³ãƒ‰å¹… `$h$` ã¯ã€Œæ¸¬åº¦ã®è§£åƒåº¦ã€ã‚’æ±ºã‚ã‚‹ â€” å°ã•ã™ãã‚‹ã¨ãƒã‚¤ã‚¸ãƒ¼ã€å¤§ãã™ãã‚‹ã¨ã¼ã‚„ã‘ã‚‹
4. Metropolis-Hastingsã®å—ç†ç‡ã¯23%å‰å¾ŒãŒæœ€é©ï¼ˆå¤šæ¬¡å…ƒã‚¬ã‚¦ã‚¹ç›®æ¨™ã®å ´åˆï¼‰
5. Browné‹å‹•ã®äºŒæ¬¡å¤‰å‹• `$[W]_T = T$` â€” ã“ã‚ŒãŒItÃ´è£œæ­£ã®æºæ³‰
6. Euler-Maruyamaæ³•ã¯å¼·åæŸ `$O(\sqrt{\Delta t})$`ã€å¼±åæŸ `$O(\Delta t)$`

</details>

<details><summary>Q3: Euler-Maruyamaæ³•ã§Î”tã‚’åŠåˆ†ã«ã™ã‚‹ã¨èª¤å·®ã¯ã©ã†å¤‰ã‚ã‚‹ã‹ï¼Ÿå¼·åæŸã¨å¼±åæŸã§ç­”ãˆã‚ˆã€‚</summary>

**A**:
- **å¼·åæŸ** (`$\mathbb{E}[|X_T^{\Delta t} - X_T|^2]^{1/2}$`): `$O(\sqrt{\Delta t})$`ã€‚`$\Delta t$` ã‚’åŠåˆ†ã«ã™ã‚‹ã¨èª¤å·®ã¯ `$1/\sqrt{2} \approx 0.707$` å€ã€‚
- **å¼±åæŸ** (`$|\mathbb{E}[f(X_T^{\Delta t})] - \mathbb{E}[f(X_T)]|$`): `$O(\Delta t)$`ã€‚`$\Delta t$` ã‚’åŠåˆ†ã«ã™ã‚‹ã¨èª¤å·®ã¯ `$1/2$` å€ã€‚

ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã¯å¼±åæŸï¼ˆåˆ†å¸ƒã®è¿‘ä¼¼ï¼‰ã§ååˆ†ãªãŸã‚ã€DDPMã® `$T=1000$` ã¯å¼±åæŸç²¾åº¦ `$O(1/T) = O(10^{-3})$` ã‚’ç‹™ã£ã¦ã„ã‚‹ã€‚å¼·åæŸã¯å„ã‚µãƒ³ãƒ—ãƒ«ãƒ‘ã‚¹ã®ç²¾åº¦ã«é–¢ä¿‚ã—ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä¾¡æ ¼è¨ˆç®—ã®ã‚ˆã†ãªç”¨é€”ã§é‡è¦ã€‚
</details>

<details><summary>Q4: KDEã®ãƒãƒ³ãƒ‰å¹… h ã‚’å°ã•ãã—ã™ãã‚‹ã¨ã©ã†ãªã‚‹ã‹ï¼Ÿæ¸¬åº¦è«–çš„ã«èª¬æ˜ã›ã‚ˆã€‚</summary>

**A**: KDE ã¯ `$\hat{p}_h(x) = \frac{1}{Nh}\sum_{i=1}^N K\left(\frac{x-X_i}{h}\right)$` ã§å®šç¾©ã•ã‚Œã‚‹ã€‚`$h \to 0$` ã®ã¨ãã€å„ã‚«ãƒ¼ãƒãƒ« `$K(\cdot/h)/h$` ã¯ãƒ‡ãƒ¼ã‚¿ç‚¹ `$X_i$` ã«é›†ä¸­ã™ã‚‹ Dirac delta `$\delta_{X_i}$` ã«åæŸï¼ˆåˆ†å¸ƒåæŸã®æ„å‘³ã§ï¼‰ã€‚ã¤ã¾ã‚Š `$\hat{p}_h \to \frac{1}{N}\sum_i \delta_{X_i}$`ï¼ˆçµŒé¨“æ¸¬åº¦ï¼‰ã«ãªã‚Šã€é€£ç¶šå¯†åº¦ãŒæ¨å®šã§ããªããªã‚‹ã€‚`$h$` ã¯ã€ŒLebesgueæ¸¬åº¦ã«å¯¾ã™ã‚‹çµŒé¨“æ¸¬åº¦ã®å¹³æ»‘åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ã§ã€Silvermanãƒ«ãƒ¼ãƒ« `$h = 1.06\hat{\sigma}N^{-1/5}$` ã¯MISEï¼ˆå¹³å‡ç©åˆ†äºŒä¹—èª¤å·®ï¼‰æœ€å°åŒ–ã®æ¼¸è¿‘æœ€é©è§£ã€‚
</details>



### 5.13 æ•°å¼â†’ã‚³ãƒ¼ãƒ‰ç¿»è¨³ãƒ‘ã‚¿ãƒ¼ãƒ³é›†

| æ•°å¼ | Python | æ³¨æ„ç‚¹ |
|:--|:--|:--|
| `$\int f \, d\mu$` | `np.mean(f(samples))` | Monte Carloè¿‘ä¼¼ |
| `$\frac{dP}{dQ}(x)$` | `p.pdf(x) / q.pdf(x)` | Importance weight |
| `$\hat{f}_h(x)$` | `kde_estimate(data, x, h)` | ãƒãƒ³ãƒ‰å¹…é¸æŠãŒé‡è¦ |
| `$P^n$` | `np.linalg.matrix_power(P, n)` | å®šå¸¸åˆ†å¸ƒã¸åæŸ |
| `$W(t)$` | `np.cumsum(np.sqrt(dt)*Z)` | `$Z \sim \mathcal{N}(0,1)$` |
| `$\sum (\Delta W)^2$` | `np.sum(np.diff(W)**2)` | `$\to T$`ï¼ˆäºŒæ¬¡å¤‰å‹•ï¼‰ |
| `$dX = a \, dt + b \, dW$` | `X[i+1] = X[i] + a*dt + b*dW` | Euler-Maruyama |
| `$e^{-\theta t}$` | `np.exp(-theta*t)` | OUéç¨‹ã®å¹³å‡å›å¸° |
| `$\frac{1}{nh}\sum K(\cdot)$` | `np.mean(kernel) / h` | KDE |
| `$\boldsymbol{\pi} P = \boldsymbol{\pi}$` | `eig(P.T)` ã§å›ºæœ‰å€¤1ã®å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ« | å·¦å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ« |

### 5.14 Monte Carlo ä¿¡é ¼åŒºé–“ã®æ§‹æˆ

**ä¸­å¿ƒæ¥µé™å®šç†ã«ã‚ˆã‚‹åŒºé–“æ¨å®š**: æ¨å®šé‡ `$\hat{\mu}_N = \frac{1}{N}\sum_{i=1}^N f(X_i)$` ã«å¯¾ã™ã‚‹ 95% ä¿¡é ¼åŒºé–“:

```math
\hat{\mu}_N \pm z_{0.025} \cdot \frac{\hat{\sigma}}{\sqrt{N}}, \quad \hat{\sigma}^2 = \frac{1}{N-1}\sum_{i=1}^N (f(X_i) - \hat{\mu}_N)^2
```

- `$\hat{\mu}_N$`: æ¨™æœ¬å¹³å‡ï¼ˆMCæ¨å®šå€¤ï¼‰ â€” ã‚³ãƒ¼ãƒ‰ã® `f_vals.mean()`
- `$z_{0.025} = 1.96$`: æ¨™æº–æ­£è¦åˆ†å¸ƒã®97.5%ç‚¹
- `$\hat{\sigma}^2$`: æ¨™æœ¬åˆ†æ•£ï¼ˆä¸åæ¨å®šé‡ã€`ddof=1`ï¼‰
- `$\hat{\sigma}/\sqrt{N}$`: æ¨™æº–èª¤å·®ï¼ˆSEï¼‰â€” `f_vals.std(ddof=1) / np.sqrt(N)`

```python
import numpy as np

rng = np.random.default_rng(0)
N = 10_000
X = rng.standard_normal(N)
# f(X) = exp(-X^2/2)/sqrt(2pi) ã‚’ N(0,1) ã§ç©åˆ† â†’ integral phi^2 dx = 1/(2*sqrt(pi))
f_vals = np.exp(-X**2 / 2) / np.sqrt(2 * np.pi)
true_val = 1.0 / (2 * np.sqrt(np.pi))  # = 0.28209...

mean_est = f_vals.mean()            # mu_hat
se = f_vals.std(ddof=1) / np.sqrt(N)  # sigma_hat / sqrt(N)
ci_lo = mean_est - 1.96 * se
ci_hi = mean_est + 1.96 * se
print(f"Estimate : {mean_est:.5f}")
print(f"95% CI   : [{ci_lo:.5f}, {ci_hi:.5f}]")
print(f"True val : {true_val:.5f}  in CI: {ci_lo <= true_val <= ci_hi}")
# â†’ 95å›/100è©¦è¡Œã§CIãŒçœŸå€¤ã‚’å«ã‚€
```

> **âš ï¸ Warning:** `$f(X)^2$` ãŒ `$q$` ã«é–¢ã—ã¦å¯ç©åˆ†ï¼ˆ`$\mathbb{E}_q[f^2] < \infty$`ï¼‰ã§ãªã„ã¨CLTãŒé©ç”¨ä¸å¯ã€‚ä¾‹ãˆã°é‡è¦åº¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ `$p/q$` ãŒè£¾ã§çˆ†ç™ºã™ã‚‹å ´åˆã€‚

---

> Progress: 85%

---

## ğŸ”¬ Z6. ç ”ç©¶ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ï¼ˆ20åˆ†ï¼‰â€” æ¸¬åº¦è«–ã®æœ€å‰ç·š

> **Zone 6 ç›®æ¨™**: æœ¬è¬›ç¾©ã§å­¦ã‚“ã æ¸¬åº¦è«–ãƒ»ç¢ºç‡éç¨‹ã‚’åŸºç›¤ã¨ã™ã‚‹æœ€æ–°ç ”ç©¶ã‚’ä¿¯ç°ã™ã‚‹ã€‚

### 6.1 Score SDE ã®ç†è«–çš„å®Œæˆ â€” Song et al. 2020

Score SDE [^2] ã¯DDPMã‚’VP-SDEï¼ˆVariance Preserving SDEï¼‰ã¨ã—ã¦å®šå¼åŒ–ã—ãŸé‡‘å­—å¡”ã ã€‚

```math
d\mathbf{x} = -\frac{\beta(t)}{2} \mathbf{x} \, dt + \sqrt{\beta(t)} \, d\mathbf{W}
```

**VP-SDE ã®æ¸¬åº¦è«–çš„æ„å‘³**: ã“ã® SDE ã¯ã€æ¨™æœ¬ `$\mathbf{x}_0 \sim p_0$` ã‹ã‚‰å§‹ã¾ã‚Š `$t \to \infty$` ã§ `$\mathcal{N}(\mathbf{0}, \mathbf{I})$` ã«åæŸã™ã‚‹OUéç¨‹ã€‚å„æ™‚åˆ»ã®åˆ†å¸ƒ `$p_t$` ã¯ Fokker-Planck æ–¹ç¨‹å¼ã«å¾“ã†ã€‚Score SDE ã®é©æ–°ã¯ **ã“ã®é€£ç¶šæ— `$\{p_t\}_{t \in [0,T]}$` å…¨ä½“ã‚’1æœ¬ã®SDEã§è¨˜è¿°ã§ãã‚‹** ç‚¹ã«ã‚ã‚‹ã€‚DDPM ã¯é›¢æ•£è¿‘ä¼¼ã§ã—ã‹ãªã‹ã£ãŸãŒã€Score SDE ã§ã¯ä»»æ„ã®æ™‚åˆ» `$t$` ã§ `$\nabla \log p_t$` ãŒå®šç¾©ã•ã‚Œã‚‹ã€‚

Andersonï¼ˆ1982ï¼‰[^9] ã®Reverse SDEå®šç†ã‚’ä½¿ã†ã¨ã€é€†æ™‚é–“éç¨‹ã¯:

```math
d\mathbf{x} = \left[-\frac{\beta(t)}{2} \mathbf{x} - \beta(t) \nabla_{\mathbf{x}} \log p_t(\mathbf{x})\right] dt + \sqrt{\beta(t)} \, d\bar{\mathbf{W}}
```

Scoreé–¢æ•° `$\nabla_{\mathbf{x}} \log p_t(\mathbf{x})$` ã‚’**ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯** `$s_\theta(\mathbf{x}, t)$` ã§è¿‘ä¼¼ã—ã€é€†SDEã‚’è§£ãã“ã¨ã§ `$p_0$`ï¼ˆãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒï¼‰ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ãã‚‹ã€‚

**å­¦ç¿’ç›®çš„é–¢æ•°ï¼ˆDenoising Score Matchingï¼‰**:

```math
\mathcal{L}_{\text{DSM}} = \mathbb{E}_{t, \mathbf{x}_0, \boldsymbol{\epsilon}}\left[\lambda(t) \left\| s_\theta(\mathbf{x}_t, t) - \nabla_{\mathbf{x}_t} \log q_t(\mathbf{x}_t | \mathbf{x}_0) \right\|^2 \right]
```

ã‚¬ã‚¦ã‚¹é·ç§»æ ¸ã®å ´åˆã€`$\nabla_{\mathbf{x}_t} \log q_t(\mathbf{x}_t | \mathbf{x}_0) = -\boldsymbol{\epsilon}/\sigma_t$`ï¼ˆ`$\boldsymbol{\epsilon}$`ã¯ãƒã‚¤ã‚ºï¼‰ã¨ãªã‚Šã€DDPMã® `$\epsilon$`-predictionã¨ç­‰ä¾¡ã«ãªã‚‹ã€‚ã“ã®äº‹å®Ÿã¯Radon-Nikodymå°é–¢æ•°ãŒã‚¬ã‚¦ã‚¹å¯†åº¦ã®å¯¾æ•°å¾®åˆ†ã«å¸°ç€ã™ã‚‹ã“ã¨ã‹ã‚‰ç›´æ¥å°ã‹ã‚Œã‚‹ã€‚

**å°å‡º**: ã‚¬ã‚¦ã‚¹é·ç§»æ ¸ `$q_t(\mathbf{x}_t|\mathbf{x}_0) = \mathcal{N}(\sqrt{\bar{\alpha}_t}\mathbf{x}_0, (1-\bar{\alpha}_t)\mathbf{I})$` ã®å¯¾æ•°:

```math
\log q_t(\mathbf{x}_t|\mathbf{x}_0) = -\frac{d}{2}\log(2\pi(1-\bar{\alpha}_t)) - \frac{\|\mathbf{x}_t - \sqrt{\bar{\alpha}_t}\mathbf{x}_0\|^2}{2(1-\bar{\alpha}_t)}
```

`$\mathbf{x}_t$` ã§å¾®åˆ†:

```math
\nabla_{\mathbf{x}_t} \log q_t = -\frac{\mathbf{x}_t - \sqrt{\bar{\alpha}_t}\mathbf{x}_0}{1-\bar{\alpha}_t} = -\frac{\boldsymbol{\epsilon}}{\sqrt{1-\bar{\alpha}_t}}
```

ã“ã“ã§ `$\mathbf{x}_t = \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}$`ï¼ˆå†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ï¼‰ã‚’ä½¿ã£ãŸã€‚ã¤ã¾ã‚Š `$s_\theta \approx -\boldsymbol{\epsilon}/\sigma_t$`ã€`$\epsilon$`-predictionã¨Scoreé–¢æ•°ã®1:1å¯¾å¿œãŒæ˜ç¢ºã«ãªã£ãŸã€‚

### 6.2 VP-SDEåæŸç†è«– â€” GrÃ¶nwallä¸ç­‰å¼ã®å¿œç”¨

æœ€æ–°ã®ç†è«–ç ”ç©¶ [^10] ã¯Euler-Maruyamaé›¢æ•£åŒ–ã®èª¤å·®ã‚’åˆ¶å¾¡ã™ã‚‹ãŸã‚ã«GrÃ¶nwallä¸ç­‰å¼ã‚’ä½¿ã†ã€‚

**GrÃ¶nwallä¸ç­‰å¼**: éè² é–¢æ•° `$u(t)$` ãŒ:

```math
u(t) \leq \alpha(t) + \int_0^t \beta(s) u(s) \, ds
```

ã‚’æº€ãŸã™ãªã‚‰ã°:

```math
u(t) \leq \alpha(t) + \int_0^t \alpha(s) \beta(s) \exp\left(\int_s^t \beta(r) \, dr\right) ds
```

ã“ã‚Œã‚’VP-SDEã®KL divergenceèª¤å·®ã«é©ç”¨ã™ã‚‹ã¨ã€ã‚¹ãƒ†ãƒƒãƒ—å¹… `$\Delta t$` ã«å¯¾ã™ã‚‹é›¢æ•£åŒ–èª¤å·®ã®ä¸Šç•Œ:

**è¨¼æ˜ã‚¹ã‚±ãƒƒãƒ** (by induction):

`$u_n = D_{\mathrm{KL}}(p_n \| q_n)$`ï¼ˆ`$n$`ã‚¹ãƒ†ãƒƒãƒ—å¾Œã®KLï¼‰ã¨ã™ã‚‹ã¨ã€1ã‚¹ãƒ†ãƒƒãƒ—ã®KLèª¤å·® `$\delta_n \leq C \cdot \Delta t^2$` ã‚ˆã‚Š:

```math
u_{n+1} \leq (1 + \beta \Delta t) u_n + C \Delta t^2
```

ã“ã‚Œã‚’ç¹°ã‚Šè¿”ã—é©ç”¨ï¼ˆ`$N = T/\Delta t$` å›ï¼‰:

```math
u_N \leq (1 + \beta \Delta t)^N u_0 + C \Delta t^2 \sum_{k=0}^{N-1} (1+\beta \Delta t)^k \leq e^{\beta T} \cdot C \Delta t^2 \cdot \frac{e^{\beta T}-1}{\beta \Delta t}
```

æœ€çµ‚çš„ã« `$D_{\mathrm{KL}} \leq O(\Delta t)$`ï¼ˆå¼±åæŸã®ç›´æ¥è¨¼æ˜ï¼‰ã€‚

```math
D_{\mathrm{KL}}(p_{\theta,\Delta t} \| p_{\text{data}}) \leq C \cdot \Delta t^2 \cdot \int_0^T \mathbb{E}[\|\nabla \log p_t\|^2] \, dt
```

ãŒå°å‡ºã•ã‚Œã‚‹ã€‚ã“ã‚Œã¯ **Euler-Maruyamaæ³•ã®å¼±åæŸ `$O(\Delta t)$`** ã®ç†è«–çš„æ ¹æ‹ ã§ã‚ã‚Šã€DDPMã®ã‚¹ãƒ†ãƒƒãƒ—æ•° `$T$` ã‚’å¢—ã‚„ã™ã»ã©ç²¾åº¦ãŒä¸ŠãŒã‚‹ç†ç”±ã ã€‚

**ã‚¹ã‚³ã‚¢èª¤å·®ã¸ã®æ¥ç¶š**: å¼ã®å³è¾º `$\int_0^T \mathbb{E}[\|\nabla \log p_t\|^2] dt$` ã¯ã€Score Matchingã®æå¤±é–¢æ•°ã®ç©åˆ†ç‰ˆã ã€‚ã¤ã¾ã‚Šã€Œå­¦ç¿’ã•ã‚ŒãŸã‚¹ã‚³ã‚¢é–¢æ•°ã®ç²¾åº¦ãŒç”Ÿæˆå“è³ªã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã€ã§ã‚ã‚‹ã“ã¨ãŒç†è«–çš„ã«ä¿è¨¼ã•ã‚Œã‚‹ã€‚ã‚¹ã‚³ã‚¢èª¤å·®ã‚’ `$\epsilon$` ä»¥ä¸‹ã«ã™ã‚Œã°ã€æœ€çµ‚KLã¯ `$O(\epsilon + \Delta t)$` â€” å­¦ç¿’èª¤å·®ã¨é›¢æ•£åŒ–èª¤å·®ã®å’Œã€‚

**GrÃ¶nwallä¸ç­‰å¼ã®ä¸€èˆ¬å½¢**ï¼ˆé€£ç¶šç‰ˆï¼‰:

```math
\frac{d}{dt} u(t) \leq \beta(t) u(t) + \gamma(t) \implies u(t) \leq e^{\int_0^t \beta(s)ds} u(0) + \int_0^t e^{\int_s^t \beta(r)dr} \gamma(s) ds
```

ã“ã‚Œã¯SDEåæŸè§£æã«é™ã‚‰ãšã€ODEå®‰å®šæ€§è§£æãƒ»åå¾®åˆ†æ–¹ç¨‹å¼ã®ä¸€æ„æ€§è¨¼æ˜ãƒ»æ©Ÿæ¢°å­¦ç¿’ã®ä¸€èˆ¬åŒ–èª¤å·®ãƒã‚¦ãƒ³ãƒ‰ãªã©å¹…åºƒãä½¿ã‚ã‚Œã‚‹ä¸ç­‰å¼ã€‚å¾®åˆ†ä¸ç­‰å¼ã®ç©åˆ†ã‚’æŒ‡æ•°é–¢æ•°ã§ä¸Šã‹ã‚‰æŠ‘ãˆã‚‹ã¨ã„ã†ã€ã€Œæƒ…å ±é‡ã®åˆ¶å¾¡ã€ã®åŸºæœ¬æŠ€è¡“ã€‚

### 6.3 é›¢æ•£æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®KLåæŸä¿è¨¼

é€£ç¶šæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€é›¢æ•£çŠ¶æ…‹ç©ºé–“ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³ãªã©ï¼‰ã§ã®æ‹¡æ•£éç¨‹ [^11] ã®KLåæŸ:

**é›¢æ•£æ‹¡æ•£ã®æ¸¬åº¦è«–çš„åŸºç¤**: é›¢æ•£çŠ¶æ…‹ç©ºé–“ `$\mathcal{X}$` ä¸Šã®ç¢ºç‡æ¸¬åº¦ã¯PMFã§è¡¨ç¾ã•ã‚Œã‚‹ãŒã€Chapman-Kolmogorovæ–¹ç¨‹å¼ã¨é·ç§»æ ¸ã®ç©ã¨ã—ã¦ã®åŒæ™‚åˆ†å¸ƒã¨ã„ã†æ§‹é€ ã¯é€£ç¶šã®å ´åˆã¨å…¨ãåŒã˜ã ã€‚é‡è¦ãªã®ã¯:

```math
q(x_t | x_0) = \sum_{x_1, \ldots, x_{t-1}} \prod_{s=1}^t q(x_s | x_{s-1})
```

ã“ã‚Œã¯ `$Q_t = Q_1^t$`ï¼ˆé·ç§»è¡Œåˆ—ã® `$t$` ä¹—ï¼‰ã§è¡¨ç¾ã§ãã€DDPM ã® closed-form `$q(\mathbf{x}_t | \mathbf{x}_0)$` ã®é›¢æ•£é¡ä¼¼ã ã€‚

**VQDM, MaskDiffusion, MDLM**: ãƒ†ã‚­ã‚¹ãƒˆå‘ã‘é›¢æ•£æ‹¡æ•£ã®æœ€è¿‘ã®ç³»è­œã€‚Maskãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã€Œå¸åçŠ¶æ…‹ã€ã¨ã™ã‚‹Markové€£é–ã‚’ä½¿ã„ã€å„ãƒˆãƒ¼ã‚¯ãƒ³ãŒç‹¬ç«‹ã« mask â†’ demask ã•ã‚Œã‚‹ã€‚æ¸¬åº¦è«–çš„ã«ã¯ `$q_t(x_t | x_0) = \text{Cat}((1-\beta_t)\delta_{x_t=x_0} + \beta_t \delta_{x_t=[\text{MASK}]})$`ã€‚

**KLåæŸè¨¼æ˜ã®æ¸¬åº¦è«–çš„æ ¸å¿ƒ**: [^11] ã®åæŸè¨¼æ˜ã¯ä»¥ä¸‹ã®åˆ†è§£ã‚’ä½¿ã†:

```math
D_{\mathrm{KL}}(q(x_{0:T}) \| p_\theta(x_{0:T})) = \sum_{t=1}^T \mathbb{E}_{q(x_{t+1})}[D_{\mathrm{KL}}(q(x_t|x_{t+1}, x_0) \| p_\theta(x_t|x_{t+1}))]
```

ã“ã®ã‚¹ãƒ†ãƒƒãƒ—æ¯KLåˆ†è§£ã¯ **Chain Ruleã®æ¸¬åº¦è«–çš„ç‰ˆ** â€” çµåˆæ¸¬åº¦ã®KLãŒæ¡ä»¶ä»˜ãKLã®å’Œã«ç­‰ã—ã„:

```math
D_{\mathrm{KL}}(P(X,Y) \| Q(X,Y)) = D_{\mathrm{KL}}(P(X) \| Q(X)) + \mathbb{E}_{P(X)}[D_{\mathrm{KL}}(P(Y|X) \| Q(Y|X))]
```

ã“ã‚Œã¯Radon-Nikodymå°é–¢æ•°ã®é€£é–å¾‹ `$\frac{dP}{dQ} = \frac{dP_X}{dQ_X} \cdot \frac{dP_{Y|X}}{dQ_{Y|X}}$` ã®æœŸå¾…å€¤ã‚’å–ã£ãŸçµæœã ã€‚



```math
D_{\mathrm{KL}}(q_t(x_t) \| p_\theta(x_t)) \leq \sum_{s=1}^{t} D_{\mathrm{KL}}(q(x_s | x_{s-1}, x_0) \| p_\theta(x_s | x_{s+1}))
```

ã“ã®ä¸ç­‰å¼ã¯Markové€£é–ã®æ¸¬åº¦è«–çš„æ§‹é€  â€” å…·ä½“çš„ã«ã¯é·ç§»æ ¸ã®ç©ã¨æ¡ä»¶ä»˜ãæœŸå¾…å€¤ã®ã‚¿ãƒ¯ãƒ¼æ€§è³ª â€” ã‹ã‚‰ç›´æ¥å°ã‹ã‚Œã‚‹ã€‚ã€Œé›¢æ•£ã€ã§ã‚‚ã€Œé€£ç¶šã€ã§ã‚‚ã€æ¸¬åº¦è«–ã®è¨€èªã¯åŒä¸€ã ã€‚

### 6.4 Flow Matching ã®æ¸¬åº¦è«–çš„åŸºç¤

Flow Matching [^7] ã¯ç¢ºç‡ãƒ‘ã‚¹ `$p_t$` ã‚’ç›´æ¥è¨­è¨ˆã™ã‚‹ã€‚

**æ¡ä»¶ä»˜ãç¢ºç‡ãƒ‘ã‚¹**: å„ `$\mathbf{x}_1 \sim p_1$`ï¼ˆãƒ‡ãƒ¼ã‚¿ç‚¹ï¼‰ã«å¯¾ã—:

```math
p_t(\mathbf{x} | \mathbf{x}_1) = \mathcal{N}(t \mathbf{x}_1, (1 - (1-\sigma_{\min})t)^2 \mathbf{I})
```

æ¡ä»¶ä»˜ãé€Ÿåº¦å ´ `$u_t(\mathbf{x} | \mathbf{x}_1)$` ã§ç¢ºç‡ãƒ•ãƒ­ãƒ¼ODEã‚’å®šç¾©:

```math
d\mathbf{x} = u_t(\mathbf{x}) \, dt, \quad u_t(\mathbf{x}) = \mathbb{E}[u_t(\mathbf{x} | \mathbf{x}_1) | \mathbf{x}_t = \mathbf{x}]
```

å‘¨è¾ºé€Ÿåº¦å ´ `$u_t$` ã¯æ¡ä»¶ä»˜ãé€Ÿåº¦å ´ã®æœŸå¾…å€¤ â€” ã“ã‚Œã¯æ¸¬åº¦è«–çš„æ¡ä»¶ä»˜ãæœŸå¾…å€¤ã®å°„å½±è§£é‡ˆãŒæœ¬è³ªçš„ã«ä½¿ã‚ã‚Œã¦ã„ã‚‹ã€‚

**Flow Matching ã®æå¤±é–¢æ•°**:

```math
\mathcal{L}_{\text{FM}} = \mathbb{E}_{t, \mathbf{x}_0, \mathbf{x}_1}\left[\| v_\theta(\mathbf{x}_t, t) - u_t(\mathbf{x}_t | \mathbf{x}_1) \|^2\right]
```

ã“ã“ã§ `$\mathbf{x}_t = (1-t)\mathbf{x}_0 + t\mathbf{x}_1$`ï¼ˆç·šå½¢è£œé–“ï¼‰ã€æ¡ä»¶ä»˜ãé€Ÿåº¦å ´ `$u_t(\mathbf{x}_t | \mathbf{x}_1) = \mathbf{x}_1 - \mathbf{x}_0$`ï¼ˆå®šæ•°ï¼ï¼‰ã€‚ã“ã‚Œã‚’å­¦ç¿’ã—ãŸ `$v_\theta$` ã§ ODE `$d\mathbf{x}/dt = v_\theta(\mathbf{x}_t, t)$` ã‚’ç©åˆ†ã™ã‚Œã° `$p_0 \to p_1$` ã®è¼¸é€ãŒå¾—ã‚‰ã‚Œã‚‹ã€‚

**Rectified Flow ã¨ã®æ¯”è¼ƒ**: Rectified Flow ã¯ `$\mathbf{x}_t = (1-t)\mathbf{x}_0 + t\mathbf{x}_1$` ã®åŒã˜æ§‹é€ ã ãŒã€ãƒ‘ã‚¹ã®ã€Œã¾ã£ã™ãã•ã€ã‚’è¨“ç·´å¾Œã®reflowã§æ”¹å–„ã™ã‚‹ã€‚FLUX.1 (Black Forest, 2024) ãŒã“ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã€‚

**ãªãœFlow Matchingã¯SDEã‚ˆã‚Šé€Ÿã„ã‹**: SDEã¯ãƒ©ãƒ³ã‚¸ãƒ¥ãƒãƒ³åŠ›å­¦çš„ãªãƒã‚¤ã‚ºã‚’æŒã¤ãŒã€Flow Matchingã¯ODEï¼ˆç¢ºå®šè«–çš„ï¼‰ã€‚ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ™‚ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’10-30å€å‰Šæ¸›ã§ãã‚‹ã€‚ã—ã‹ã—æ•°å­¦çš„åŸºç›¤ï¼ˆç¢ºç‡ãƒ‘ã‚¹ã®æ§‹æˆãƒ»åæŸä¿è¨¼ï¼‰ã¯Fokker-Planckæ–¹ç¨‹å¼ã¨åŒæ§˜ã®æ¸¬åº¦è«–ãŒå¿…è¦ã€‚

**å‘¨è¾ºé€Ÿåº¦å ´ã®æ¸¬åº¦è«–çš„æ­£å½“åŒ–**: æå¤±é–¢æ•°ã§æ¡ä»¶ä»˜ãé€Ÿåº¦å ´ `$u_t(\mathbf{x}|\mathbf{x}_1)$` ã®æœŸå¾…å€¤ãŒå‘¨è¾ºé€Ÿåº¦å ´ `$u_t(\mathbf{x})$` ã¨ä¸€è‡´ã™ã‚‹ã“ã¨ã®è¨¼æ˜:

```math
\mathbb{E}_{\mathbf{x}_1 | \mathbf{x}_t = \mathbf{x}}[u_t(\mathbf{x} | \mathbf{x}_1)] = u_t(\mathbf{x})
```

ã“ã‚Œã¯Continuity Equation:

```math
\partial_t p_t + \nabla \cdot (p_t u_t) = 0
```

ã®ç·šå½¢æ€§ã‹ã‚‰æ¥ã‚‹ã€‚æ¡ä»¶ä»˜ããƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ `$\mathbf{x}_1$` ã§ç©åˆ†ã™ã‚‹ã¨ãã€Fubiniã®å®šç†ã§ç©åˆ†ã¨å¾®åˆ†ã‚’äº¤æ›ã§ãã‚‹ï¼ˆ`$p_t$` ã®å¯ç©åˆ†æ€§ãŒæ¡ä»¶ï¼‰ã€‚ã“ã®ã€Œæ¡ä»¶ä»˜ãâ†’å‘¨è¾ºã¸ã®å°„å½±ã€ã¯Part1ã§å­¦ã‚“ã æ¡ä»¶ä»˜ãæœŸå¾…å€¤ã®å°„å½±æ€§è³ªãã®ã‚‚ã®ã ã€‚

### 6.4b Stochastic Interpolants â€” æ¸¬åº¦è«–çš„æœ€çµ‚çµ±ä¸€

Albergo & Vanden-Eijnden (2023) ã® Stochastic Interpolants ã¯ Flow Matching ã¨æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’çµ±ä¸€ã™ã‚‹æ¡†æ¶ã ã€‚

**å®šç¾©ï¼ˆStochastic Interpolantï¼‰**: ã‚½ãƒ¼ã‚¹åˆ†å¸ƒ `$\rho_0$` ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒ `$\rho_1$` ã®é–“ã®è£œé–“:

```math
\mathbf{x}(t) = \alpha(t) \mathbf{x}_0 + \beta(t) \mathbf{x}_1 + \gamma(t) \boldsymbol{\xi}, \quad \boldsymbol{\xi} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})
```

- `$\alpha(0)=1, \alpha(1)=0$`ï¼ˆã‚½ãƒ¼ã‚¹ã‚’æ¶ˆã™ï¼‰
- `$\beta(0)=0, \beta(1)=1$`ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«è‡³ã‚‹ï¼‰
- `$\gamma(t) \geq 0$`ï¼ˆãƒã‚¤ã‚ºã®å¤§ãã•ã€‚`$\gamma=0$` ã§ Flow Matchingã€`$\gamma > 0$` ã§æ‹¡æ•£çš„ï¼‰

**çµ±ä¸€æ€§**: é©åˆ‡ãª `$\alpha, \beta, \gamma$` ã‚’é¸ã¶ã¨:
- `$\gamma = 0$`: Flow Matching / Rectified Flow
- `$\gamma = \sqrt{t(1-t)}$`: Bridge Matching
- `$\gamma(t) = \sqrt{1-\bar{\alpha}_t}$`: DDPM / Score SDE

**æ¸¬åº¦è«–çš„è¦–ç‚¹**: `$\mathbf{x}(t)$` ã®å„æ™‚åˆ»ã®åˆ†å¸ƒ `$\rho_t = \text{Law}(\mathbf{x}(t))$` ãŒãƒ‘ã‚¹ã®æ—ï¼ˆç¢ºç‡ã‚«ãƒ¼ãƒãƒ«ï¼‰ã‚’å®šç¾©ã™ã‚‹ã€‚ãƒ™ã‚¯ãƒˆãƒ«å ´ `$b_t$` ã¯æ¡ä»¶ä»˜ãé€Ÿåº¦å ´ã®æ¡ä»¶ä»˜ãæœŸå¾…å€¤ã¨ã—ã¦å®šã¾ã‚‹ â€” ã“ã‚Œã¯Radon-Nikodymå®šç†ã¨æ¡ä»¶ä»˜ãæœŸå¾…å€¤ã®å°„å½±æ€§è³ªã®ç›´æ¥å¿œç”¨ã ã€‚

**å­¦ç¿’ç›®çš„é–¢æ•°ã®å°å‡º**: è¨“ç·´ã™ã‚‹é‡ã¯ãƒ™ã‚¯ãƒˆãƒ«å ´ `$b_\theta(\mathbf{x}, t)$`:

```math
\mathcal{L}(\theta) = \mathbb{E}_{t, \mathbf{x}_0, \mathbf{x}_1, \boldsymbol{\xi}}\left[\| b_\theta(\mathbf{x}(t), t) - \dot{\mathbf{x}}(t) \|^2\right]
```

ã“ã“ã§ `$\dot{\mathbf{x}}(t) = \dot{\alpha}(t)\mathbf{x}_0 + \dot{\beta}(t)\mathbf{x}_1 + \dot{\gamma}(t)\boldsymbol{\xi}$`ï¼ˆè£œé–“ã®æ™‚é–“å¾®åˆ†ï¼‰ã€‚`$\gamma=0$` ã®ã¨ã Flow Matching ã®æå¤±ã«å¸°ç€ã€‚`$\gamma > 0$` ã®ã¨ã `$\boldsymbol{\xi}$ ãŒåŠ ã‚ã‚Šã‚¹ã‚³ã‚¢é–¢æ•°çš„ãªæˆåˆ†ãŒç¾ã‚Œã‚‹ã€‚

**ã‚¹ã‚³ã‚¢é–¢æ•°ã¨ã®æ¥ç¶š**: `$\gamma(t) > 0$` ã®ã¨ãã€æ¡ä»¶ä»˜ãæœŸå¾…å€¤ã®å°„å½±ã‹ã‚‰:

```math
b_t(\mathbf{x}) = v_t(\mathbf{x}) - \frac{\dot{\gamma}(t)}{\gamma(t)} \cdot \sigma_t^2 \nabla_\mathbf{x} \log \rho_t(\mathbf{x})
```

ç¬¬1é …ãŒé€Ÿåº¦å ´ï¼ˆFlow Matchingã®å¯„ä¸ï¼‰ã€ç¬¬2é …ãŒã‚¹ã‚³ã‚¢é–¢æ•°ï¼ˆæ‹¡æ•£ã®å¯„ä¸ï¼‰ã€‚`$\gamma \to 0$` ã§ã‚¹ã‚³ã‚¢é …ãŒæ¶ˆãˆç´”ç²‹ãªFlow Matchingã«ã€`$v_t \to 0$` ã§ç´”ç²‹ãªScore SDEã«é€€åŒ–ã™ã‚‹ã€‚Stochastic Interpolantsã¯ã€ŒFlow Matchingã¨æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®é–“ã‚’é€£ç¶šçš„ã«è£œé–“ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ—ã€ã¨ã—ã¦ç†è§£ã§ãã‚‹ã€‚

### 6.5 ç ”ç©¶ç³»è­œå›³

```mermaid
graph TD
    RN["Radon-Nikodym<br/>å®šç† (1913/1930)"] --> KL["KL Divergence<br/>Kullback-Leibler 1951"]
    ITO["ä¼Šè—¤ç©åˆ†<br/>ItÃ´ 1944"] --> SDE["SDEç†è«–<br/>1950s-"]
    SDE --> REVS["Reverse SDE<br/>Anderson 1982"]
    SDE --> FP["Fokker-Planck<br/>æ–¹ç¨‹å¼"]
    
    REVS --> DDPM["DDPM<br/>Ho+ 2020"]
    FP --> SCORE["Score SDE<br/>Song+ 2020"]
    RN --> SCORE
    SCORE -->|"ODE sampler"| FLOW["Flow Matching<br/>Lipman+ 2022"]
    SCORE -->|"ç›´ç·šåŒ–"| RF["Rectified Flow<br/>Liu+ 2022"]
    
    KL --> VAE["VAE<br/>Kingma+ 2013"]
    KL --> GAN["GAN<br/>Goodfellow+ 2014"]
    
    FLOW --> STABLE["Stable Diffusion 3<br/>Esser+ 2024"]
    RF --> FLUX["FLUX<br/>Black Forest 2024"]
    
    style ITO fill:#fff9c4
    style REVS fill:#e3f2fd
    style SCORE fill:#c8e6c9
    style STABLE fill:#f3e5f5
    style FLUX fill:#f3e5f5
    SI["Stochastic Interpolants<br/>Albergo+ 2023"] --> UNIFIED["çµ±ä¸€æ¡†æ¶"]
    FLOW --> SI
    DDPM --> SCORE
    GAN -->|"GANæ­»äº¡?"| DDPM
```

**ç³»è­œã®èª­ã¿æ–¹**: ç¸¦è»¸ã¯æ™‚é–“ï¼ˆä¸Š=å¤ã„ï¼‰ã€‚è‰²ã¯: é»„=æ•°å­¦åŸºç¤ã€é’=ç†è«–çªç ´ã€ç·‘=å®Ÿç”¨åŒ–ã€ç´«=å¿œç”¨ã‚·ã‚¹ãƒ†ãƒ ã€‚

å„ãƒãƒ¼ãƒ‰ã®æ¸¬åº¦è«–çš„æ ¸å¿ƒ:
- **ItÃ´ç©åˆ† (1944)**: é©åˆéç¨‹ã®ç¢ºç‡ç©åˆ† â€” Brownian filtrationã«å¯¾ã™ã‚‹martingale
- **Reverse SDE (1982)**: Girsanovå¤‰æ› + Radon-Nikodym â€” æ™‚é–“åè»¢ã®æ¸¬åº¦å¤‰æ›
- **Score SDE (2020)**: Fokker-Planck + ã‚¹ã‚³ã‚¢é–¢æ•° â€” å¯†åº¦ã®å¯¾æ•°å¾®åˆ†
- **Flow Matching (2022)**: Continuity Equation + æ¡ä»¶ä»˜ãæœŸå¾…å€¤ â€” æ¸¬åº¦è¼¸é€ã®ODEè¨˜è¿°
- **Stochastic Interpolants (2023)**: SDEã¨ODEã®çµ±ä¸€ â€” Girsanov + Pushforward

> Progress: 95%

### Z6 ç†è§£åº¦ãƒã‚§ãƒƒã‚¯

**ãƒã‚§ãƒƒã‚¯ 1**: Score SDE ã®é€†æ™‚é–“éç¨‹ã‚’ç”Ÿæˆã«ä½¿ã†ã«ã¯ã€å„æ™‚åˆ» `$t$` ã®ã‚¹ã‚³ã‚¢ `$\nabla \log p_t(\mathbf{x})$` ãŒå¿…è¦ã ã€‚ã—ã‹ã—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ `$p_t$` ãŒåˆ†ã‹ã‚‰ãªã„å ´åˆã€ã©ã†ã‚„ã£ã¦ã‚¹ã‚³ã‚¢ã‚’è¿‘ä¼¼ã™ã‚‹ã‹ï¼Ÿ

<details><summary>ãƒ’ãƒ³ãƒˆ: Tweedieå…¬å¼</summary>

**Tweedieå…¬å¼**: `$q(\mathbf{x}_t | \mathbf{x}_0) = \mathcal{N}(\sqrt{\bar{\alpha}_t}\mathbf{x}_0, (1-\bar{\alpha}_t)\mathbf{I})$` ã®ã¨ã:

```math
\nabla \log p_t(\mathbf{x}_t) = -\frac{\mathbf{x}_t - \sqrt{\bar{\alpha}_t}\,\mathbb{E}[\mathbf{x}_0 | \mathbf{x}_t]}{1 - \bar{\alpha}_t}
```

ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ `$\epsilon_\theta(\mathbf{x}_t, t)$` ã§ `$\mathbb{E}[\epsilon | \mathbf{x}_t]$` ã‚’äºˆæ¸¬ â†’ ã‚¹ã‚³ã‚¢ `$\approx -\epsilon_\theta / \sqrt{1-\bar{\alpha}_t}$`ã€‚Denoising Score Matchingã®æœ¬è³ªã¯ã“ã‚Œã€‚
</details>

**ãƒã‚§ãƒƒã‚¯ 2**: Flow Matchingã§ `$(\mathbf{x}_0, \mathbf{x}_1)$` ã‚’ç‹¬ç«‹ã‚µãƒ³ãƒ—ãƒ«ï¼ˆã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ãªã—ï¼‰ã§ç›´ç·šè£œé–“ã™ã‚‹ã¨ã€ç”Ÿæˆå“è³ªãŒä¸‹ãŒã‚‹ç†ç”±ã‚’æ¸¬åº¦è«–çš„ã«èª¬æ˜ã›ã‚ˆã€‚

<details><summary>ç­”ãˆ</summary>

ç‹¬ç«‹ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ã§ã¯ `$p_{0 \times 1}(\mathbf{x}_0, \mathbf{x}_1) = p_0(\mathbf{x}_0) p_1(\mathbf{x}_1)$`ã€‚ç›´ç·šè£œé–“ `$\mathbf{x}_t = (1-t)\mathbf{x}_0 + t\mathbf{x}_1$` ã®è»Œè·¡ãŒ **äº¤å·®**ï¼ˆåŒã˜ `$\mathbf{x}_t$` ã‹ã‚‰ç•°ãªã‚‹ `$\mathbf{x}_1$` ã«å‘ã‹ã†è¤‡æ•°ã®è»Œè·¡ï¼‰ã™ã‚‹ãŸã‚ã€é€Ÿåº¦å ´ `$u_t(\mathbf{x})$` ãŒã€Œå¹³å‡åŒ–ã€ã•ã‚Œç›´ç·šçš„ã§ãªããªã‚‹ã€‚Conditional OT ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ï¼ˆ`$W_2$` è·é›¢æœ€å°åŒ–ï¼‰ã¯äº¤å·®ã‚’æœ€å°åŒ–ã—ã€ã€Œã¾ã£ã™ããªã€è»Œè·¡ã‚’ä¸ãˆã‚‹ã€‚
</details>


## ğŸš€ Z7. æŒ¯ã‚Šè¿”ã‚Šã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” ã¾ã¨ã‚ã¨æ¬¡å›äºˆå‘Š

### 7.1 Fokker-Planckæ–¹ç¨‹å¼ã®ç›´æ„Ÿ â€” SDEã‹ã‚‰ç¢ºç‡å¯†åº¦ã®PDEã¸

SDEã¯**å€‹ã€…ã®ãƒ‘ã‚¹**ï¼ˆã‚µãƒ³ãƒ—ãƒ«è»Œé“ï¼‰ã‚’è¨˜è¿°ã™ã‚‹ã€‚ã ãŒç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®æœ¬è³ªçš„ãªå•ã„ã¯ã€Œç¢ºç‡å¯†åº¦ `$p(x, t)$` ãŒæ™‚é–“ã¨ã¨ã‚‚ã«ã©ã†å¤‰åŒ–ã™ã‚‹ã‹ã€ã ã€‚Fokker-Planckæ–¹ç¨‹å¼ï¼ˆKolmogorovå‰å‘ãæ–¹ç¨‹å¼ï¼‰ã¯ã€SDEã‚’ãƒ‘ã‚¹ã®é›†å›£ï¼ˆç¢ºç‡å¯†åº¦ï¼‰ã®è¨€è‘‰ã«ç¿»è¨³ã™ã‚‹ã€‚

#### SDEã‹ã‚‰Fokker-Planckã¸ã®å¯¾å¿œ

SDEã¨Fokker-Planckæ–¹ç¨‹å¼ã¯1å¯¾1å¯¾å¿œã™ã‚‹ã€ŒåŒå¯¾è¨€èªã€ã ã€‚

| SDEè¦–ç‚¹ | Fokker-Planckè¦–ç‚¹ | æ„å‘³ |
|:--------|:-----------------|:-----|
| `$X_t(\omega)$` ã¯ç¢ºç‡çš„ãƒ‘ã‚¹ | `$p(x, t)$` ã¯ç¢ºç‡å¯†åº¦ | 1ç²’å­ vs ç²’å­ã®é›² |
| `$f(X_t) dt$` ã¯drift | `$-\partial_x(f \cdot p)$` ã¯ç¢ºç‡ãƒ•ãƒ©ãƒƒã‚¯ã‚¹ | æµã‚Œã®æº |
| `$g(X_t) dW_t$` ã¯diffusion | `$\frac{1}{2}\partial_{xx}(g^2 p)$` ã¯æ‹¡æ•£é … | åºƒãŒã‚Šã®æº |
| ItÃ´è£œæ­£ | æ‹¡æ•£é …ã®å‡ºç¾ | åŒä¸€ç¾è±¡ã®2ã¤ã®é¡” |

SDE:
```math
dX_t = f(X_t) \, dt + g(X_t) \, dW_t
```

ã«å¯¾å¿œã™ã‚‹Fokker-Planckæ–¹ç¨‹å¼ (FPE):

```math
\frac{\partial p}{\partial t}(x, t) = -\frac{\partial}{\partial x}\big[f(x) \, p(x, t)\big] + \frac{1}{2}\frac{\partial^2}{\partial x^2}\big[g^2(x) \, p(x, t)\big]
```

- ç¬¬1é …: `$-\partial_x(fp)$` â€” **ãƒ‰ãƒªãƒ•ãƒˆé …**ï¼ˆç¢ºç‡ã®æµã‚Œï¼‰
- ç¬¬2é …: `$\frac{1}{2}\partial_x^2(g^2 p)$` â€” **æ‹¡æ•£é …**ï¼ˆç¢ºç‡ã®åºƒãŒã‚Šï¼‰

> **ä¸€è¨€ã§è¨€ãˆã°**: SDEãŒã€Œ1ã¤ã®ç²’å­ãŒã©ã†å‹•ãã‹ã€ã‚’è¨˜è¿°ã™ã‚‹ã®ã«å¯¾ã—ã€Fokker-Planckæ–¹ç¨‹å¼ã¯ã€Œç²’å­ã®é›²ï¼ˆç¢ºç‡å¯†åº¦ï¼‰ãŒã©ã†å¤‰å½¢ã™ã‚‹ã‹ã€ã‚’è¨˜è¿°ã™ã‚‹ã€‚

#### å°å‡ºã®ç›´æ„Ÿï¼ˆå¤šæ¬¡å…ƒã¯ç¬¬30å›ï¼‰

ç¢ºç‡ã®ä¿å­˜å‰‡ï¼ˆé€£ç¶šã®æ–¹ç¨‹å¼ï¼‰ã‹ã‚‰å‡ºç™ºã™ã‚‹ã€‚`$J(x, t)$` ã‚’ç¢ºç‡ãƒ•ãƒ©ãƒƒã‚¯ã‚¹ï¼ˆç¢ºç‡ã®æµã‚Œï¼‰ã¨ã™ã‚‹ã¨:

```math
\frac{\partial p}{\partial t} = -\frac{\partial J}{\partial x}
```

ItÃ´ã®å…¬å¼ã‹ã‚‰ã€ãƒ•ãƒ©ãƒƒã‚¯ã‚¹ã¯:

```math
J(x, t) = f(x) p(x, t) - \frac{1}{2}\frac{\partial}{\partial x}\big[g^2(x) p(x, t)\big]
```

ãƒ‰ãƒªãƒ•ãƒˆã«ã‚ˆã‚‹æµã‚Œ `$fp$` ã¨ã€æ‹¡æ•£ã«ã‚ˆã‚‹åºƒãŒã‚Š `$-\frac{1}{2}\partial_x(g^2 p)$` ã®å’Œã€‚ã“ã‚Œã‚’é€£ç¶šã®æ–¹ç¨‹å¼ã«ä»£å…¥ã™ã‚‹ã¨FPEãŒå¾—ã‚‰ã‚Œã‚‹ã€‚

#### OUéç¨‹ã®å ´åˆ

`$dX_t = -\theta X_t \, dt + \sigma \, dW_t$` ã®FPE:

**å®šå¸¸è§£ã®å°å‡º**:

`$\partial_t p = 0$` ã¨ã™ã‚‹ã¨:

```math
0 = \theta \partial_x(xp_\infty) + \frac{\sigma^2}{2} \partial_{xx} p_\infty
```

è©¦é¨“è§£ `$p_\infty(x) \propto \exp(-\theta x^2/\sigma^2)$` ã‚’ä»£å…¥:

```math
\partial_x p_\infty = -\frac{2\theta x}{\sigma^2} p_\infty, \quad \partial_{xx} p_\infty = \left(-\frac{2\theta}{\sigma^2} + \frac{4\theta^2 x^2}{\sigma^4}\right) p_\infty
```

FPEã«ä»£å…¥ã—ã¦ç¢ºèª:

```math
\theta \partial_x(x p_\infty) + \frac{\sigma^2}{2}\partial_{xx} p_\infty = \left[\theta - \frac{2\theta^2 x^2}{\sigma^2} + \frac{\sigma^2}{2}\left(-\frac{2\theta}{\sigma^2} + \frac{4\theta^2 x^2}{\sigma^4}\right)\right] p_\infty = 0 \checkmark
```

æ­£è¦åŒ–: `$p_\infty(x) = \mathcal{N}(0, \sigma^2/(2\theta))$`ã€‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ç¢ºèªã—ãŸå®šå¸¸åˆ†æ•£ `$\sigma^2/(2\theta)$` ãŒå³å¯†ã«å°å‡ºã•ã‚ŒãŸã€‚

```math
\frac{\partial p}{\partial t} = \theta \frac{\partial}{\partial x}(x \, p) + \frac{\sigma^2}{2}\frac{\partial^2 p}{\partial x^2}
```

å®šå¸¸è§£: `$p_\infty(x) = \mathcal{N}(0, \sigma^2/(2\theta))$`ã€‚Zone 5.9ã§æ•°å€¤ç¢ºèªã—ãŸOUå®šå¸¸åˆ†å¸ƒãŒFPEè§£ã¨ã—ã¦å³å¯†å°å‡ºã€‚

#### SDE â†” Fokker-Planck â†” Score SDE ã®ä¸‰è§’é–¢ä¿‚

```mermaid
graph TD
    SDE["SDE<br/>dX = f dt + g dW<br/>ãƒ‘ã‚¹ã®è¨˜è¿°"] -->|ItÃ´'s formula| FPE["Fokker-Planck<br/>âˆ‚p/âˆ‚t = -âˆ‚(fp) + Â½âˆ‚Â²(gÂ²p)<br/>å¯†åº¦ã®æ™‚é–“ç™ºå±•"]
    FPE -->|å®šå¸¸è§£ âˆ‚p/âˆ‚t=0| STAT["å®šå¸¸åˆ†å¸ƒ<br/>pâˆ(x)"]
    SDE -->|Anderson 1982| REV["Reverse SDE<br/>dX = [f - gÂ²âˆ‡log p]dt + g dWÌ„"]
    FPE -->|âˆ‡log p_t| SCORE["Score function<br/>âˆ‡ log p_t(x)"]
    SCORE --> REV
    REV -->|generative model| GEN["Score SDE<br/>Song+ 2020"]

    style SDE fill:#e3f2fd
    style FPE fill:#fff9c4
    style GEN fill:#c8e6c9
```

| è¦–ç‚¹ | è¨˜è¿°å¯¾è±¡ | æ•°å­¦çš„å¯¾è±¡ | ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã®å½¹å‰² |
|:-----|:--------|:---------|:---------------|
| SDE | 1ã¤ã®ãƒ‘ã‚¹ | `$X_t(\omega)$` | Forward/Reverse process |
| Fokker-Planck | ç¢ºç‡å¯†åº¦ã®æ™‚é–“ç™ºå±• | `$p(x, t)$` | ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­è¨ˆ |
| Score function | å¯†åº¦ã®å‹¾é… | `$\nabla \log p_t$` | NN ã§å­¦ç¿’ã™ã‚‹å¯¾è±¡ |

**æ•°å€¤çš„Fokker-Planckæ¤œè¨¼**:

FPæ–¹ç¨‹å¼ã®å®šå¸¸è§£ `$p_\infty(x) \propto \exp(-\theta x^2/\sigma^2)$` ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ç¢ºèªã™ã‚‹:

```python
import numpy as np
from scipy.stats import norm

theta, sigma = 1.0, 1.0
stat_var = sigma**2 / (2*theta)
stat_std = np.sqrt(stat_var)

# FP predicts: p_inf(x) = N(0, sigma^2/(2*theta))
rng = np.random.default_rng(0)
X = np.full(5000, 0.0)  # start at 0 (already stationary)
dt = 0.01
for _ in range(10_000):
    X += -theta*X*dt + sigma*np.sqrt(dt)*rng.standard_normal(5000)

# Chi-square goodness of fit test: bins
bins = np.linspace(-4, 4, 20)
counts, _ = np.histogram(X, bins=bins)
expected = norm.cdf(bins[1:], 0, stat_std) - norm.cdf(bins[:-1], 0, stat_std)
expected *= len(X)
chi2 = float(((counts - expected)**2 / expected).sum())
print(f"X(inf): mean={X.mean():.3f}  std={X.std():.3f}  stat_std={stat_std:.3f}")
print(f"chi2 statistic={chi2:.1f}  (expected ~18 for 18 dof)")
```

> **Note:** **ç¬¬30å›ã¸ã®äºˆå‘Š**: ã“ã“ã§ã¯1æ¬¡å…ƒãƒ»OUéç¨‹ã®å ´åˆã®Fokker-Planckã‚’å‘³è¦‹ã—ãŸã€‚ç¬¬30å›ã€ŒDiffusion Models IIã€ã§ã¯ã€å¤šæ¬¡å…ƒFPE ã®å®Œå…¨å°å‡ºã€reverse SDE ã®å³å¯†è¨¼æ˜ï¼ˆGirsanovå¤‰æ›ï¼‰ã€ãã—ã¦FPEã‹ã‚‰Score SDEã®å­¦ç¿’ç›®çš„é–¢æ•°ï¼ˆdenoising score matchingï¼‰ã‚’å°ãã€‚Fokker-Planckã¯æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ç†è«–ã®ã€Œè£ãƒœã‚¹ã€ã ã€‚

### 7.2 ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®æ¸¬åº¦è«–çš„çµ±ä¸€

**Pushforwardæ¸¬åº¦**:

å¯æ¸¬å†™åƒ `$T: (\mathcal{X}, \mathcal{F}) \to (\mathcal{Y}, \mathcal{G})$` ã¨æ¸¬åº¦ `$\mu$` ã«å¯¾ã—ã€Pushforwardæ¸¬åº¦ `$T_\# \mu$` ã¯:

```math
(T_\# \mu)(B) = \mu(T^{-1}(B)) \quad \forall B \in \mathcal{G}
```

ç›´æ„Ÿ: `$T$` ã§å¤‰æ›ã—ãŸå¾Œã®æ¸¬åº¦ã€‚`$T$` ãŒå¯é€†ã‹ã¤å¾®åˆ†å¯èƒ½ãªã‚‰å¤‰æ•°å¤‰æ›å…¬å¼:

```math
\int_\mathcal{Y} f \, d(T_\# \mu) = \int_\mathcal{X} (f \circ T) \, d\mu
```

Normalizing Flowsã®ç¢ºç‡å¯†åº¦å¤‰æ›ï¼ˆ`$p_z$` â†’ `$p_x = |\det J_T|^{-1} p_z \circ T^{-1}$`ï¼‰ã¯ã“ã®å…¬å¼ã®ç›´æ¥é©ç”¨ã€‚

**ã™ã¹ã¦ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯æ¸¬åº¦è¼¸é€**: ã‚½ãƒ¼ã‚¹æ¸¬åº¦ `$\mu_0$`ï¼ˆã‚¬ã‚¦ã‚¹ãƒã‚¤ã‚ºï¼‰ã‹ã‚‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ¸¬åº¦ `$\mu_1$`ï¼ˆãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒï¼‰ã¸ã€‚

- Normalizing Flow: æ±ºå®šè«–çš„ãƒ»å¯é€†ãªå†™åƒ `$T$`ï¼ˆ`$T_\# \mu_0 = \mu_1$`ï¼‰
- VAE: ç¢ºç‡çš„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ `$q_\phi(z|x)` ã¨ ãƒ‡ã‚³ãƒ¼ãƒ€ `$p_\theta(x|z)$` ã®é–“æ¥çš„è¼¸é€
- Diffusion: SDEã® forward/reverse ã§æ¸¬åº¦ã‚’å¤‰å½¢
- Flow Matching: ODEã®ãƒ™ã‚¯ãƒˆãƒ«å ´ `$v_t$` ã§ç¢ºç‡ãƒ‘ã‚¹ `$\mu_t$` ã‚’è¨­è¨ˆï¼ˆ`$\mu_0 \to \mu_1$`ï¼‰

```mermaid
graph TD
    A["æ¸¬åº¦è¼¸é€<br/>T#pâ‚€ = pâ‚"] --> B["Normalizing Flows<br/>å¯é€†å¤‰æ› T"]
    A --> C["VAE<br/>æ½œåœ¨ç©ºé–“ã®æ¸¬åº¦"]
    A --> D["Diffusion<br/>SDE forward/reverse"]
    A --> E["Flow Matching<br/>ç¢ºç‡ãƒ‘ã‚¹ p_t"]

    D --> F["Score SDE<br/>âˆ‡log p_t"]
    E --> G["Rectified Flow<br/>ç›´ç·šåŒ–ãƒ‘ã‚¹"]
    E --> H["Stochastic Interpolants<br/>ä¸€èˆ¬åŒ–è£œé–“"]

    I["Radon-Nikodym<br/>dP/dQ"] -.-> D
    I -.-> F
    J["Pushforward<br/>T#Î¼"] -.-> B
    J -.-> E
    K["Markov Chain<br/>é·ç§»æ ¸"] -.-> D
```

> ã™ã¹ã¦ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯ã€**ã‚½ãƒ¼ã‚¹æ¸¬åº¦ `$p_0$`ï¼ˆé€šå¸¸ã¯ã‚¬ã‚¦ã‚¹ãƒã‚¤ã‚ºï¼‰ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ¸¬åº¦ `$p_1$`ï¼ˆãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒï¼‰ã«è¼¸é€ã™ã‚‹å†™åƒ**ã¨ã—ã¦çµ±ä¸€çš„ã«ç†è§£ã§ãã‚‹ã€‚æ¸¬åº¦è«–ã¯ã“ã®çµ±ä¸€çš„è¦–ç‚¹ã‚’ä¸ãˆã‚‹è¨€èªã§ã‚ã‚‹ã€‚

**Wassersteinè·é›¢**: æ¸¬åº¦é–“ã®è·é›¢ã¨ã—ã¦æœ€ã‚‚è‡ªç„¶ãªã®ãŒ `$W_p$` è·é›¢:

```math
W_p(\mu, \nu) = \left(\inf_{\gamma \in \Gamma(\mu, \nu)} \int \|x - y\|^p \, d\gamma(x, y)\right)^{1/p}
```

ã“ã“ã§ `$\Gamma(\mu, \nu)$` ã¯ `$\mu$`, `$\nu$` ã‚’å‘¨è¾ºåˆ†å¸ƒã«æŒã¤çµåˆåˆ†å¸ƒï¼ˆã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ï¼‰å…¨ä½“ã®é›†åˆã€‚`$W_2$`ï¼ˆ`$p=2$`ï¼‰ã¯æœ€é©è¼¸é€ã‚³ã‚¹ãƒˆï¼ˆåœ°çƒã‚’å‹•ã‹ã™ã‚³ã‚¹ãƒˆï¼‰ã€‚KLã¨ç•°ãªã‚Šã‚µãƒãƒ¼ãƒˆãŒé‡ãªã‚‰ãªãã¦ã‚‚æœ‰é™å€¤ã‚’æŒã¤ï¼ˆGANã®è¨“ç·´ã«æœ‰åˆ©ï¼‰ã€‚

**å„ãƒ¢ãƒ‡ãƒ«ã®ä½¿ã†ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°**:
- GAN: å¶ç„¶ã®ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ï¼ˆGANã¯æš—é»™çš„ã«æœ€é©è¼¸é€ã‚’ã—ã¦ã„ã‚‹ã€ã¨ã„ã†è¦–ç‚¹ï¼‰
- Flow Matching (COT): `$W_2$` æœ€é©ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚° â†’ ã¾ã£ã™ããªè»Œè·¡
- æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«: ã‚¬ã‚¦ã‚¹åŠ ç®—ãƒã‚¤ã‚ºï¼ˆç¢ºç‡çš„ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ï¼‰
- Normalizing Flow: æ±ºå®šè«–çš„ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ï¼ˆå¯é€†å†™åƒï¼‰

Wassersteinè·é›¢ã®è¨ˆç®—ã¯ä¸€èˆ¬ã« `$O(n^3)$` ã®ç·šå½¢è¨ˆç”»å•é¡Œã ãŒã€Sinkhorn algorithmï¼ˆã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ­£å‰‡åŒ–ï¼‰ã§ `$O(n^2/\epsilon^2)$` ã«å‰Šæ¸›ã§ãã‚‹ã€‚ã“ã‚Œã‚‚Lebesgueç©åˆ†ãƒ»æ¸¬åº¦è«–ã®è¨€èªãªã—ã«ã¯å®šå¼åŒ–ã§ããªã„ã€‚

### 7.3 ä»Šå›ã®å†’é™ºã®åç©«

| Zone | ä½•ã‚’å­¦ã‚“ã ã‹ | ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ |
|:--:|:--|:--|
| 0 (Part1) | ãªãœæ¸¬åº¦è«–ãŒå¿…è¦ã‹ | Cantoré›†åˆã€Riemannç©åˆ†ã®é™ç•Œã€æ··åˆåˆ†å¸ƒ |
| 1-4 (Part1) | æ¸¬åº¦ç©ºé–“ã¨ç†è«– | `$\sigma$`-åŠ æ³•æ—ã€Lebesgueç©åˆ†ã€MCT/DCTã€Radon-Nikodymã€pushforwardã€åæŸã€ç¢ºç‡éç¨‹ã€ä¼Šè—¤è§£æ |
| 5 (Part2) | å®Ÿè£… | Monte Carlo `$O(1/\sqrt{N})$`ã€IS (Radon-Nikodym)ã€KDE (Silvermanãƒ«ãƒ¼ãƒ«)ã€MHæ³• (è©³ç´°é‡£ã‚Šåˆã„)ã€Browné‹å‹• (äºŒæ¬¡å¤‰å‹•)ã€GBM (ItÃ´è£œæ­£)ã€OUéç¨‹ (å¹³å‡å›å¸°)ã€Langevin (Score)ã€Euler-Maruyama (å¼·/å¼±åæŸ) |
| 6 (Part2) | ç ”ç©¶å‹•å‘ | Score SDE (VP-SDE)ã€VP-SDEåæŸ (GrÃ¶nwall)ã€é›¢æ•£æ‹¡æ•£ (KLä¿è¨¼)ã€Flow Matching (æ¡ä»¶ä»˜ããƒ™ã‚¯ãƒˆãƒ«å ´) |
| 7 (Part2) | ã¾ã¨ã‚ | Fokker-Planck (SDEâ†”å¯†åº¦)ã€æ¸¬åº¦è¼¸é€çµ±ä¸€ã€FAQ |

**ä»Šå›ã®æœ¬è³ªçš„æ´å¯Ÿ5é¸**:

1. **æ¸¬åº¦è«–ã¯ã‚³ãƒ¼ãƒ‰ã®ãƒã‚°äºˆé˜²æ¥ç¨®** â€” æ¸¬åº¦ã‚¼ãƒ­ã€çµ¶å¯¾é€£ç¶šã€Radon-Nikodymã€Fatouã®è£œé¡Œã‚’çŸ¥ã‚‹ã“ã¨ã§ã€ŒãªãœNaNãŒå‡ºã‚‹ã‹ã€ãŒåˆ†ã‹ã‚‹
2. **$O(1/\sqrt{N})$ ã¯Monte Carloã®å£** â€” ã“ã‚Œã‚’è¶…ãˆã‚‹ã«ã¯åˆ†æ•£å‰Šæ¸›ï¼ˆIS/å±¤åŒ–ï¼‰ã‹è§£æçš„è¨ˆç®—ãŒå¿…è¦ã€‚æ¬¡å…ƒã®å‘ªã„ã¨çµ„ã¿åˆã‚ã•ã‚‹ã¨ `$O(N^{-1/d})$` ã«è½ã¡ã‚‹
3. **SDE â†” ç¢ºç‡å¯†åº¦ã®PDE** â€” Fokker-Planckæ–¹ç¨‹å¼ã¯ã€Œå€‹ã€…ã®ç²’å­ã®è»Œè·¡ï¼ˆSDEï¼‰ã€ã¨ã€Œé›†å›£ã®å¯†åº¦é€²åŒ–ï¼ˆPDEï¼‰ã€ã®æ©‹æ¸¡ã—
4. **Scoreé–¢æ•° = ç¢ºç‡å¯†åº¦ã®å‹¾é…** â€” ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®æœ¬è³ªã¯ã€Œã©ã“ã«ç¢ºç‡å¯†åº¦ãŒé«˜ã„ã‹ã€ã‚’çŸ¥ã‚‹ã“ã¨ã€‚Langevin dynamicsã¯ç¢ºç‡ã®ã€Œä¸Šã‚Šå‚ã€ã‚’ç™»ã‚‹
5. **æ·±å±¤ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯ç¢ºç‡ç©ºé–“é–“ã®å†™åƒ** â€” VAE/GAN/æ‹¡æ•£/Flowã¯å…¨ã¦pushforwardæ¸¬åº¦ã®è¨€èªã§çµ±ä¸€ã—ã¦ç†è§£ã§ãã‚‹

### 7.4 æ•°å¼è¨˜å·å¯¾ç…§è¡¨

| è¨˜å· | æ„å‘³ | åˆå‡º |
|:-----|:-----|:-----|
| `$(\Omega, \mathcal{F}, P)$` | ç¢ºç‡ç©ºé–“ï¼ˆæ¨™æœ¬ç©ºé–“ã€Ïƒ-åŠ æ³•æ—ã€ç¢ºç‡æ¸¬åº¦ï¼‰ | Z1 |
| `$P \ll Q$` | çµ¶å¯¾é€£ç¶š `$Q(A)=0 \Rightarrow P(A)=0$` | Z1 |
| `$\frac{dP}{dQ}$` | Radon-Nikodymå°é–¢æ•°ï¼ˆç¢ºç‡å¯†åº¦ã®å³å¯†å®šç¾©ï¼‰ | Z1 |
| `$X_n \xrightarrow{a.s.} X$` | æ¦‚åæŸ `$P(\lim X_n = X) = 1$` | Z1 |
| `$X_n \xrightarrow{d} X$` | åˆ†å¸ƒåæŸï¼ˆæœ€å¼±ã€CLTã¯ã“ã‚Œï¼‰ | Z1 |
| `$[W]_t = t$` | Browné‹å‹•ã®äºŒæ¬¡å¤‰å‹•ï¼ˆä¼Šè—¤è£œæ­£ã®æºæ³‰ï¼‰ | Z1 |
| `$dX = \mu dt + \sigma dW$` | ç¢ºç‡å¾®åˆ†æ–¹ç¨‹å¼ï¼ˆSDEï¼‰ | Z1 |
| `$\boldsymbol{\pi} P = \boldsymbol{\pi}$` | å®šå¸¸åˆ†å¸ƒã®å›ºæœ‰æ–¹ç¨‹å¼ | Z1 |
| `$\nabla_x \log p(x)$` | Scoreé–¢æ•°ï¼ˆLangevin / Score SDE ã®æ ¸å¿ƒï¼‰ | Z5 |
| `$v_t(x)$` | Flow Matchingã®é€Ÿåº¦å ´ | Z6 |
| `$\text{ESS}$` | æœ‰åŠ¹ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºï¼ˆISå“è³ªæŒ‡æ¨™ï¼‰ | Z5 |
| `$\alpha(x, x')$` | MHæ³•ã®å—ç†ç¢ºç‡ | Z5 |
| `$\partial_t p = -\partial_x(fp) + \frac{1}{2}\partial_{xx}(g^2 p)$` | Fokker-Planckæ–¹ç¨‹å¼ | Z6 |

### 7.5 æ•°å¼â†’ã‚³ãƒ¼ãƒ‰ 1:1 å¯¾ç…§

| æ•°å¼æ“ä½œ | Python | æ•°å€¤çš„è½ã¨ã—ç©´ |
|:---------|:-------|:--------------|
| `$\int f \, d\mu \approx \frac{1}{N}\sum_i f(X_i)$` | `np.mean(f(x))` | Nã¯1e4ä»¥ä¸Šæ¨å¥¨ |
| `$w(x) = p(x)/q(x)$` | `np.exp(logp - logq)` | logç©ºé–“ã§è¨ˆç®—ï¼ˆoverflowé˜²æ­¢ï¼‰|
| `$[W]_T = \sum (\Delta W)^2$` | `(dW**2).sum(axis=0)` | dtãŒå°ã•ã„ã»ã©ç²¾ç¢º |
| `$X_{n+1} = X_n + f\Delta t + g\sqrt{\Delta t}Z$` | `X + f(X)*dt + g(X)*sqrt_dt*Z` | Brownian incrementã¯N(0,dt)|
| `$-\theta X dt + \sigma dW$` | `-theta*X*dt + sigma*sqrt_dt*Z` | å¹³å‡å›å¸°ã¯æ­£ã®thetaã§ä¿è¨¼ |
| `$\min(1, \pi(x')/\pi(x))$` | `min(0, log_pi_new - log_pi_old)` | logæ¯”è¼ƒã§ overflow å›é¿ |
| `$\partial_t p + \nabla \cdot (pu) = 0$` | `(dp_dt + np.gradient(p*u, dx)).sum()` | é€£ç¶šæ€§æ–¹ç¨‹å¼ã®æ•°å€¤æ¤œè¨¼ |
| `$\mathbb{E}[f(X)] \pm 1.96 \hat{\sigma}/\sqrt{N}$` | `mean Â± 1.96*std(ddof=1)/sqrt(N)` | CLTå‰æã€`$N \geq 30$` æ¨å¥¨ |
| `$e^{\mu T + \sigma W_T - \sigma^2T/2}$` | `S0*np.exp((mu - 0.5*sigma**2)*T + sigma*W_T)` | ItÃ´è£œæ­£ `-sigmaÂ²/2` å¿…é ˆ |
| `$\sum_i w_i^2 / (\sum_i w_i)^2$` | `1 / ((w/w.sum())**2).sum()` | ESS = effective sample size |
| `$\sigma(\{A\}) = \{\emptyset, A, A^c, \Omega\}$` | `frozenset({frozenset(), A, Omega-A, Omega})` | æœ€å°Ïƒ-åŠ æ³•æ— |

### 7.7 æœ€é‡è¦ãƒ†ã‚¤ã‚¯ã‚¢ã‚¦ã‚§ã‚¤

> **âš ï¸ Warning:** **3ã¤ã®æ ¸å¿ƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**
>
> 1. **æ¸¬åº¦è«–ã¯ã€Œç©åˆ†ã§ãã‚‹å¯¾è±¡ã€ã‚’æœ€å¤§é™ã«åºƒã’ã‚‹è¨€èª** â€” Riemannç©åˆ†ã§ã¯æ‰±ãˆãªã„é–¢æ•°ï¼ˆDirichleté–¢æ•°ã€æ··åˆåˆ†å¸ƒï¼‰ã‚’Lebesgueç©åˆ†ãŒå‡¦ç†ã™ã‚‹ã€‚ç¢ºç‡è«–ã¯ã“ã®ä¸Šã«æ§‹ç¯‰ã•ã‚Œã‚‹ã€‚
>
> 2. **Radon-Nikodymå°é–¢æ•°ã¯æ¸¬åº¦ã®ã€Œæ¯”è¼ƒã€ã‚’å¯èƒ½ã«ã™ã‚‹** â€” PDFã¯ `$dP/d\lambda$`ã€å°¤åº¦æ¯”ã¯ `$dP/dQ$`ã€importance weightã‚‚ `$dP/dQ$`ã€‚ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®lossã¯å¸¸ã«æ¸¬åº¦é–“ã®ã€Œè·é›¢ã€ã‚’æœ€å°åŒ–ã—ã¦ã„ã‚‹ã€‚
>
> 3. **ç¢ºç‡éç¨‹ã¯ã€Œæ™‚é–“çš„ã«ç¹‹ãŒã£ãŸæ¸¬åº¦ã®æ—ã€** â€” Markové€£é–ã¯é›¢æ•£æ™‚é–“ã€Browné‹å‹•ã¯é€£ç¶šæ™‚é–“ã€‚DDPMã¯é›¢æ•£Markové€£é–ã€Score SDEã¯é€£ç¶šSDEã€‚æ¸¬åº¦è«–ãŒä¸¡è€…ã‚’çµ±ä¸€ã™ã‚‹ã€‚

**å®Ÿè£…ã¸ã®ç›´æ¥ç¤ºå”†**:

| æ¸¬åº¦è«–ã®æ¦‚å¿µ | å®Ÿè£…ä¸Šã®æ„å‘³ | ç„¡è¦–ã—ãŸå ´åˆã®ãƒã‚° |
|:------------|:------------|:-----------------|
| `$P \ll Q$`ï¼ˆçµ¶å¯¾é€£ç¶šï¼‰ | ISé‡ã¿ãŒæœ‰é™ | NaN / Inf é‡ã¿ |
| DCT | å‹¾é…ã¨æœŸå¾…å€¤ã®äº¤æ› | èª¤ã£ãŸå‹¾é…æ¨å®š |
| äºŒæ¬¡å¤‰å‹• `$[W]_t = t$` | `dW ~ N(0, dt)` | `dt`å¿˜ã‚Œï¼ˆ`sqrt(dt)`ã®æ¬ å¦‚ï¼‰ |
| ItÃ´è£œæ­£ | GBMã® `$-\sigma^2/2$` é … | `E[S_T] â‰  S_0 e^{Î¼T}` |
| Radon-Nikodym | å¯¾æ•°ç©ºé–“ã§ISè¨ˆç®— | æ•°å€¤ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ |
| Fokker-Planck | å®šå¸¸åˆ†å¸ƒ `$p_\infty \propto e^{-U}$` | éå®šå¸¸ã‚µãƒ³ãƒ—ãƒ«ã§ã®åã‚Š |
| Girsanovå¤‰æ› | æ¸¬åº¦å¤‰æ›ã®å°¤åº¦æ¯” | Novikovæ¡ä»¶æœªç¢ºèªã§ç™ºæ•£ |

> **Note:** ä¸Šè¨˜ã®ãƒã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯å…¨ã¦ã€Œæ¸¬åº¦è«–çš„æ¦‚å¿µã‚’ç„¡è¦–ã—ãŸå®Ÿè£…ã€ãŒåŸå› ã ã€‚æ¸¬åº¦è«–ã®å­¦ç¿’ã‚³ã‚¹ãƒˆã¯ã€Œãƒã‚°ä¿®æ­£ã«ã‹ã‹ã‚‹ã‚³ã‚¹ãƒˆã€ã¸ã®å…ˆè¡ŒæŠ•è³‡ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚

å®Ÿéš›ã€å®Ÿè£…ã®ãƒã‚°ã‚’è¿½ã„ã‹ã‘ã¦ã„ã‚‹ã¨ã€Œãªãœã“ã†ãªã‚‹ã®ã‹ã€ã¨ã„ã†å•ã„ã¯å¿…ãšæ¸¬åº¦è«–çš„ãªæ¦‚å¿µã«è¡Œãç€ãã€‚

### 7.8 FAQ

<details><summary>Q1: æ¸¬åº¦è«–ã‚’å­¦ã°ãªãã¦ã‚‚æ·±å±¤ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®è«–æ–‡ã¯èª­ã‚ã¾ã™ã‹ï¼Ÿ</summary>
**A**: å®Ÿè£…ãƒ¬ãƒ™ãƒ«ã§ã¯å¯èƒ½ã€‚ã—ã‹ã—Score SDE [^2]ã€Flow Matching [^7]ã€Rectified Flow [^6] ã®ã‚ˆã†ãªç†è«–çš„ã«æ·±ã„è«–æ–‡ã¯ã€æ¸¬åº¦è«–ãªã—ã§ã¯ã€Œãªãœã“ã®å¼ãŒæ­£ã—ã„ã‹ã€ãŒç†è§£ã§ããªã„ã€‚ç‰¹ã«Radon-Nikodymå°é–¢æ•°ã¨pushforward measureã¯å¿…é ˆã®æ¦‚å¿µã€‚
</details>

<details><summary>Q2: ItÃ´ç©åˆ†ã¨Stratonovichç©åˆ†ã®é•ã„ã¯ï¼Ÿ</summary>
**A**: ItÃ´ç©åˆ†ã¯å·¦ç«¯ç‚¹è©•ä¾¡ã€Stratonovichã¯ä¸­ç‚¹è©•ä¾¡ã€‚ItÃ´ã¯ã€Œæœªæ¥ã‚’çŸ¥ã‚‰ãªã„ã€ï¼ˆé©åˆéç¨‹ï¼‰ãŒé€£é–å¾‹ã«ItÃ´è£œæ­£ãŒå¿…è¦ã€‚Stratonovichã¯é€£é–å¾‹ãŒé€šå¸¸é€šã‚Šã ãŒãƒãƒ«ãƒãƒ³ã‚²ãƒ¼ãƒ«æ€§ã‚’å¤±ã†ã€‚é‡‘èãƒ»MLã§ã¯ItÃ´ãŒæ¨™æº–ã€‚
</details>

<details><summary>Q3: DDPMã§Markové€£é–ã‚’ä½¿ã†ç†ç”±ã¯ï¼Ÿ</summary>
**A**: Markovæ€§ã«ã‚ˆã‚Š (1) åŒæ™‚åˆ†å¸ƒãŒé·ç§»æ ¸ã®ç©ã«åˆ†è§£ã€(2) å„ã‚¹ãƒ†ãƒƒãƒ—ç‹¬ç«‹è¨­è¨ˆã€(3) reverse processã‚‚Markovã€‚éMarkovã ã¨å…¨ã‚¹ãƒ†ãƒƒãƒ—åŒæ™‚æœ€é©åŒ–ãŒå¿…è¦ã§è¨ˆç®—ä¸å¯èƒ½ã€‚
</details>

<details><summary>Q4: çµ¶å¯¾é€£ç¶š `$P \ll Q$` ã®é‡è¦æ€§ã¯ï¼Ÿ</summary>
**A**: `$P \ll Q$` ã®ã¨ã `$dP/dQ$` ãŒå­˜åœ¨ã€‚ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ `$p_\theta$` ã¨ `$p_{\text{data}}$` ãŒç›¸äº’çµ¶å¯¾é€£ç¶šã§ãªã„ã¨KL divergenceãŒ `$+\infty$`ã€‚GANã®mode collapse ã®ä¸€å› ã€‚
</details>

<details><summary>Q5: Euler-Maruyamaæ³•ã®æ™‚é–“å¹…Î”tã‚’ã©ã†é¸ã¶ã‹ï¼Ÿ</summary>
**A**: å¼±åæŸ `$O(\Delta t)$` ã‚ˆã‚Šã€ç²¾åº¦ `$\epsilon$` ã‚’é”æˆã™ã‚‹ã«ã¯ `$\Delta t = O(\epsilon)$`ã€ã‚¹ãƒ†ãƒƒãƒ—æ•° `$T/\Delta t = O(T/\epsilon)$`ã€‚DDPMã® `$T=1000$` ã¯ `$\epsilon = 10^{-3}$` ç¨‹åº¦ã®ç²¾åº¦ã«å¯¾å¿œã€‚å®Ÿéš›ã«ã¯å­¦ç¿’ã•ã‚ŒãŸé€†éç¨‹ã®å“è³ªãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã‚‹ã®ã§ã€`$T$` ãŒå¤§ãã™ãã¦ã‚‚å“è³ªã¯é£½å’Œã™ã‚‹ã€‚DDIM [^12] ã¯ `$T$` ã‚’10-50ã«å‰Šæ¸›ã§ãã‚‹ã€Œå¼±åæŸã§ååˆ†ã€ã®å¥½ä¾‹ã€‚
</details>

<details><summary>Q6: Scoreé–¢æ•° âˆ‡log p(x) ã¯ä½•ã‚’è¡¨ã™ã‹ï¼Ÿ</summary>
**A**: ç¢ºç‡å¯†åº¦ã®å¯¾æ•°å¾®åˆ†ã€‚é«˜ç¢ºç‡é ˜åŸŸã«å‘ã‹ã†æ–¹å‘ã‚’æŒ‡ã™ã€‚ç›´æ„Ÿçš„ã«ã¯ã€Œä»Šã„ã‚‹å ´æ‰€ã‹ã‚‰æœ€ã‚‚ç¢ºç‡ãŒé«˜ã„å ´æ‰€ã¸ã®å‹¾é…ã€ã€‚Fisheræƒ…å ±é‡ `$I(\theta) = \mathbb{E}[(\nabla \log p_\theta)^2]$` ã®è¢«ç©åˆ†é–¢æ•°ã§ã‚‚ã‚ã‚‹ã€‚Stein Identity: `$\mathbb{E}_p[s(x)f(x)] = -\mathbb{E}_p[\nabla f(x)]$`ï¼ˆ`$s = \nabla \log p$`ï¼‰ãŒScore Matchingã®ç†è«–çš„åŸºç¤ã€‚
</details>

<details><summary>Q7: Girsanovå¤‰æ›ã‚’å®Ÿè£…ã™ã‚‹éš›ã®æ³¨æ„ç‚¹ã¯ï¼Ÿ</summary>

**A**: Girsanovå¤‰æ›ã¯æ¸¬åº¦å¤‰æ›ã§ã‚ã‚Šã€å®Ÿè£…ã§ã¯ **å°¤åº¦æ¯”ï¼ˆRadon-Nikodymå°é–¢æ•°ï¼‰ã®æ•°å€¤å®‰å®šæ€§** ãŒæœ€å¤§ã®å•é¡Œã€‚å°¤åº¦æ¯”ã¯:

```math
\frac{dQ}{dP}\bigg|_{\mathcal{F}_T} = \exp\left(\int_0^T \theta_t \, dW_t - \frac{1}{2}\int_0^T \theta_t^2 \, dt\right)
```

å•é¡Œç‚¹: æœŸå¾…å€¤ `$\mathbb{E}_P[dQ/dP] = 1$` ãŒæˆã‚Šç«‹ã¤ã¯ãšã ãŒã€æœ‰é™ã‚µãƒ³ãƒ—ãƒ«ã§ã¯çˆ†ç™ºã—ã‚„ã™ã„ã€‚`$\theta_t^2$` ãŒå¤§ãã„ã¨ãã€æŒ‡æ•°ã®åˆ†æ•£ãŒçˆ†ç™ºã™ã‚‹ï¼ˆlognormalåˆ†å¸ƒã®åˆ†æ•£ã¯ `$e^{\sigma^2}(e^{\sigma^2}-1)$` ã§`$\sigma$` å¤§ã§çˆ†ç™ºï¼‰ã€‚

**å®Ÿè£…çš„è§£æ±º**: `log-sum-exp` ã§å¯¾æ•°ç©ºé–“ã§è¨ˆç®—ã™ã‚‹ã€‚Novikovæ¡ä»¶ `$\mathbb{E}[\exp(\frac{1}{2}\int_0^T \theta_t^2 dt)] < \infty$` ãŒæˆç«‹ã™ã‚‹ã‹ã‚’äº‹å‰ç¢ºèªã™ã‚‹ã“ã¨ã€‚
</details>

<details><summary>Q8: æ·±å±¤ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®ãƒã‚°ã®å¤šãã¯æ¸¬åº¦è«–çš„ã‚¨ãƒ©ãƒ¼ã¨ã„ã†ä¸»å¼µã«ã¤ã„ã¦</summary>

**A**: èª‡å¼µã§ã¯ãªã„ã€‚å®Ÿéš›ã«ã‚ˆãã‚ã‚‹3ãƒ‘ã‚¿ãƒ¼ãƒ³:

1. **Trap: `$dP/dQ$` ãŒå­˜åœ¨ã—ãªã„çŠ¶æ³ã§KLã‚’è¨ˆç®—**: `$\text{support}(p) \not\subseteq \text{support}(q)$` ã®ã¨ã KL = +âˆã€‚å®Ÿè£…ã§ã¯ NaN/Inf ãŒå‡ºã‚‹ã€‚GANã®è¨“ç·´åˆæœŸä¸å®‰å®šã®åŸå› ã®ä¸€ã¤ã€‚

2. **Trap: scoreé–¢æ•°ã®è©•ä¾¡ç‚¹ãŒå¯¾æ•°å¯†åº¦ã®å®šç¾©å¤–**: `$\nabla_x \log p(x)$` ã¯ `$p(x) > 0$` ã®ç‚¹ã§ã®ã¿å®šç¾©ã€‚å¢ƒç•Œä»˜è¿‘ã§ã‚¹ã‚³ã‚¢ãŒçˆ†ç™ºã™ã‚‹ã€‚DDPM ã¯å°ã•ãª `$\sigma_{\min} > 0$` ã§å›é¿ã€‚

3. **Trap: Fokker-Planckã®å¢ƒç•Œæ¡ä»¶å¿˜ã‚Œ**: åŠç„¡é™åŒºé–“ `$[0, \infty)$` ã®FPã¯ `$x=0$` ã§ã®å¢ƒç•Œæ¡ä»¶ï¼ˆNeumann or absorbingï¼‰ãŒå¿…è¦ã€‚å¿˜ã‚Œã‚‹ã¨å®šå¸¸è§£ãŒåæŸã—ãªã„ã€‚

æ¸¬åº¦è«–ã‚’ãƒã‚¹ã‚¿ãƒ¼ã™ã‚‹ã“ã¨ã¯ã€Œãƒã‚°ã®äºˆé˜²æ¥ç¨®ã€ã¨è¨€ãˆã‚‹ã€‚
</details>



### 7.9 ã‚ˆãã‚ã‚‹ç½ 

> **âš ï¸ Warning:** **Trap 1**: æ¸¬åº¦ã‚¼ãƒ­ â‰  ç©ºé›†åˆã€‚`$\mathbb{Q}$` ã‚‚ Cantoré›†åˆã‚‚æ¸¬åº¦ã‚¼ãƒ­ã ãŒç¨ å¯†ãƒ»éå¯ç®—ã€‚
>
> **Trap 2**: Riemannå¯ â‡’ Lebesgueå¯ ã ãŒé€†ã¯Ã—ã€‚Dirichleté–¢æ•° `$1_\mathbb{Q}$` ã¯Lebesgueç©åˆ†=0 ã ãŒRiemannä¸å¯ã€‚
>
> **Trap 3**: æ¦‚åæŸ â‡’ ç¢ºç‡åæŸ ã ãŒé€†ã¯Ã—ã€‚Typewriter sequenceãŒåä¾‹ã€‚
>
> **Trap 4**: `$d(W^2) = 2W \, dW + dt$`ã€‚æœ€å¾Œã® `$+dt$` ï¼ˆäºŒæ¬¡å¤‰å‹•ï¼‰ã‚’å¿˜ã‚Œã‚‹ã¨ItÃ´è£œæ­£ã‚’è¦‹é€ƒã™ã€‚
>
> **Trap 5**: é‡ç‚¹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ESS < 10%ãªã‚‰çµæœã¯ä¿¡é ¼ã§ããªã„ã€‚
>
> **Trap 6**: Euler-Maruyamaã§ `$g(X) \cdot \Delta t \cdot Z$` ã¨æ›¸ãã¨é–“é•ã„ã€‚æ­£ã—ãã¯ `$g(X) \cdot \sqrt{\Delta t} \cdot Z$`ã€‚Browné‹å‹•å¢—åˆ† `$\Delta W \sim \mathcal{N}(0, \Delta t)$` ã®æ¨™æº–åå·®ã¯ `$\sqrt{\Delta t}$`ã€‚
>
> **Trap 7**: GBMã§ `$S(T) = S_0 \exp(\mu T + \sigma W_T)$` ã¨æ›¸ãã¨ItÃ´è£œæ­£ã‚’å¿˜ã‚Œã¦ã„ã‚‹ã€‚æ­£ã—ãã¯ `$S(T) = S_0 \exp((\mu - \sigma^2/2)T + \sigma W_T)$`ã€‚`$\mathbb{E}[S(T)]$` ãŒ `$S_0 e^{\mu T}$` ã«ãªã‚‰ãªã„ã“ã¨ã§ç¢ºèªã§ãã‚‹ã€‚
>
> **Trap 8**: `$\sigma$`-åŠ æ³•æ—ã®é–‰åŒ…æ€§ã‚’ç›´æ„Ÿçš„ã«ã€Œå…¨ã¦ã®éƒ¨åˆ†é›†åˆã‚’å«ã‚€ã€ã¨æ€ã†ã¨é–“é•ã„ã€‚`$\sigma(\mathcal{C})$` ã¯ `$\mathcal{C}$` ã‚’å«ã‚€ **æœ€å°ã®** `$\sigma$`-åŠ æ³•æ—ã§ã‚ã‚Šã€ä»»æ„ã®éƒ¨åˆ†é›†åˆã¯å«ã¾ãªã„ã€‚ä¾‹: `$\sigma(\{a\}) = \{\emptyset, \{a\}, \{a\}^c, \Omega\}$` ã¯ `$|\Omega| \geq 3$` ã®ã¨ãå…¨éƒ¨åˆ†é›†åˆã‚ˆã‚Šå°ã•ã„ã€‚
>
> **Trap 9**: é‡ç‚¹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ `$q(x)$` ãŒ `$p(x)f(x)$` ã®ã€Œé‡ã„å°¾ã€ã‚’ã‚«ãƒãƒ¼ã—ã¦ã„ãªã„å ´åˆã€é‡ã¿ `$w_i = p(x_i)/q(x_i)$` ãŒå°‘æ•°ã®ç‚¹ã«é›†ä¸­ã—ã¦ESS â†’ 1 ã«ãªã‚‹ã€‚`$\text{ESS} = (\sum w_i)^2 / \sum w_i^2$` ã‚’å¸¸ã«å ±å‘Šã™ã‚‹ã“ã¨ã€‚ESSãŒæœ‰åŠ¹ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’è¡¨ã™æŒ‡æ¨™ã¨ã—ã¦åºƒãä½¿ã‚ã‚Œã‚‹ã€‚
>
> **Trap 10**: Flow Matchingã§ Conditional OT ãƒ‘ã‚¹ã‚’ä½¿ã‚ãšã«ç›´ç·šãƒ‘ã‚¹ã‚’ä½¿ã†ã¨ã€äº¤å·®ãŒèµ·ãã¦å­¦ç¿’å›°é›£ã«ãªã‚‹ã€‚`$x_t = (1-t)x_0 + tx_1$` ã¯ `$x_0 \sim p_0$`, `$x_1 \sim p_1$` ãŒç‹¬ç«‹ã®ã¨ãè»Œè·¡ãŒäº¤å·®ã™ã‚‹ã€‚Conditional OT [^7] ã¯ `$(x_0, x_1)$` ã‚’æœ€é©è¼¸é€ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ã‹ã‚‰åŒæ™‚ã«ã‚µãƒ³ãƒ—ãƒ«ã™ã‚‹ã“ã¨ã§äº¤å·®ã‚’æœ€å°åŒ–ã™ã‚‹ã€‚





### 7.6 ç¬¬5å›ã¾ã¨ã‚å›³ â€” ç†è«–ã¨å®Ÿè£…ã®æ©‹

```mermaid
graph LR
    subgraph Theory["ç†è«–ï¼ˆPart1ï¼‰"]
        RN["Radon-Nikodym<br/>dP/dQ"]
        LEB["Lebesgueç©åˆ†<br/>âˆ«f dÎ¼"]
        CONV["åæŸå®šç†<br/>MCT/DCT/Fatou"]
        ITO["ä¼Šè—¤ç©åˆ†<br/>âˆ«f dW"]
        FP["Fokker-Planck<br/>âˆ‚p/âˆ‚t = Lâ€ p"]
    end
    subgraph Impl["å®Ÿè£…ï¼ˆPart2ï¼‰"]
        IS["é‡ç‚¹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°<br/>w=p/q"]
        MC["Monte Carlo<br/>1/N Î£f(X_i)"]
        DCT_VERIFY["DCTæ¤œè¨¼<br/>g_nâ†’e^{-x}"]
        EM["Euler-Maruyama<br/>X_{n+1}=X_n+fdt+gâˆšdtZ"]
        LANG["Langevin Dynamics<br/>X+=Îµ/2Â·âˆ‡logp+âˆšÎµÂ·Z"]
    end
    RN --> IS
    LEB --> MC
    CONV --> DCT_VERIFY
    ITO --> EM
    FP --> LANG
    style Theory fill:#e3f2fd
    style Impl fill:#c8e6c9
```

### 7.10 ç†è§£åº¦ã®è‡ªå·±è¨ºæ–­

ä»¥ä¸‹ã®å•ã„ã«ç­”ãˆã‚‰ã‚Œã‚‹ã‹ç¢ºèªã—ã‚ˆã†ã€‚

<details><summary>è¨ºæ–­å•1: Lebesgueç©åˆ†ã®ã‚ˆã•ã‚’Riemannã¨æ¯”è¼ƒã—ã¦èª¬æ˜ã›ã‚ˆ</summary>

**Riemannç©åˆ†ã®å¼±ç‚¹**: ç©åˆ†ã‚’ã€Œxè»¸ã‚’åˆ†å‰²ã—ã¦ç´°é•·ã„é•·æ–¹å½¢ã§è¿‘ä¼¼ã€ã™ã‚‹ã€‚ã“ã‚Œã¯é–¢æ•°ãŒã€Œã»ã¼é€£ç¶šã€ã§ãªã„ã¨æ©Ÿèƒ½ã—ãªã„ã€‚ä¾‹: Dirichleté–¢æ•° `$1_\mathbb{Q}(x)$` ã¯Riemannã§ç©åˆ†ä¸å¯ã€‚

**Lebesgueç©åˆ†**: ã€Œyè»¸ã‚’åˆ†å‰²ã—ã¦å¯¾å¿œã™ã‚‹xã®é›†åˆã®æ¸¬åº¦ã‚’ä½¿ã†ã€ã€‚`$\int f \, d\mu = \int_0^\infty \mu(\{x: f(x) > t\}) \, dt$` (å±¤åˆ¥è¡¨ç¾)ã€‚Dirichleté–¢æ•°: `$\int 1_\mathbb{Q} \, d\mu = \mu(\mathbb{Q}) = 0$`ï¼ˆæœ‰ç†æ•°ã®æ¸¬åº¦ã‚¼ãƒ­ï¼‰ã€‚

**æ ¸å¿ƒçš„å„ªä½æ€§**: ç©åˆ†ã¨æ¥µé™ã®äº¤æ›ãŒä¿è¨¼ã•ã‚Œã‚‹ï¼ˆDCT/MCTï¼‰ã€‚ã“ã‚ŒãŒç¢ºç‡è«–ãƒ»æ¸¬åº¦è«–ãƒ™ãƒ¼ã‚¹ã®MLã®ç†è«–è¨¼æ˜ã§å¿…é ˆã€‚
</details>

<details><summary>è¨ºæ–­å•2: ä¼Šè—¤è£œé¡Œã‚’ä½¿ã£ã¦OUéç¨‹ã®è§£æè§£ã‚’æ±‚ã‚ã‚ˆ</summary>

OUéç¨‹ `$dX = -\theta X dt + \sigma dW$` ã« `$f(t, X) = e^{\theta t} X$` ã‚’é©ç”¨ã€‚

`$df = \frac{\partial f}{\partial t}dt + \frac{\partial f}{\partial X}dX + \frac{1}{2}\frac{\partial^2 f}{\partial X^2}(dX)^2$`

`$= \theta e^{\theta t} X dt + e^{\theta t}(-\theta X dt + \sigma dW) + 0$`

`$= \sigma e^{\theta t} dW$`

ä¸¡è¾ºç©åˆ†: `$e^{\theta t}X_t - X_0 = \sigma \int_0^t e^{\theta s} dW_s$`

`$\therefore X_t = X_0 e^{-\theta t} + \sigma \int_0^t e^{-\theta(t-s)} dW_s$`

ç¢ºç‡ç©åˆ†ã®å¹³å‡ã‚¼ãƒ­æ€§ã‚ˆã‚Š `$\mathbb{E}[X_t] = X_0 e^{-\theta t} \to 0$`ï¼ˆå¹³å‡å›å¸°ï¼‰ã€‚
</details>

<details><summary>è¨ºæ–­å•3: Langevin dynamicsã§ç›®æ¨™åˆ†å¸ƒãŒ `$p^*(x) \propto e^{-U(x)}$` ã®ã¨ãã€å®šå¸¸åˆ†å¸ƒãŒ `$p^*$` ã«åæŸã™ã‚‹ã“ã¨ã‚’ç¤ºã›</summary>

Langevin SDE: `$dX = -\nabla U(X) dt + \sqrt{2} dW$`ï¼ˆ`$\nabla \log p^* = -\nabla U$` ã‚’ä½¿ã£ãŸï¼‰

å¯¾å¿œã™ã‚‹Fokker-Planckæ–¹ç¨‹å¼: `$\partial_t p = \nabla \cdot (p \nabla U) + \Delta p$`

å®šå¸¸è§£ `$p^*$` ã®æ¤œè¨¼: `$\nabla \cdot (p^* \nabla U) + \Delta p^* = ?$`

`$= \nabla p^* \cdot \nabla U + p^* \Delta U + \Delta p^*$`

`$p^* = Z^{-1}e^{-U}$ ã‚ˆã‚Š `$\nabla p^* = -p^* \nabla U$`ã€`$\Delta p^* = p^*(|\nabla U|^2 - \Delta U)$`

ä»£å…¥: `$-p^*|\nabla U|^2 + p^*\Delta U + p^*|\nabla U|^2 - p^*\Delta U = 0$ âœ“
</details>

### 7.11 å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

ç ”ç©¶ãƒ»å®Ÿå‹™ã§æ¸¬åº¦è«–ã®çŸ¥è­˜ãŒå¿…è¦ã«ãªã‚‹å ´é¢ã¨ã€å®Ÿè£…å‰ã«ç¢ºèªã™ã¹ãå•ã„:

**ç¢ºç‡éç¨‹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‰ãƒã‚§ãƒƒã‚¯**:
- [ ] SDEã®ä¿‚æ•° `$f, g$` ã¯å¯æ¸¬ã‹ï¼ˆBorelå¯æ¸¬æ€§ï¼‰
- [ ] å®šå¸¸åˆ†å¸ƒãŒå­˜åœ¨ã™ã‚‹ã‹ï¼ˆFokker-Planckå®šå¸¸è§£ãŒå­˜åœ¨ã™ã‚‹ã‹ï¼‰
- [ ] EMæ³•ã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ— `$\Delta t$` ã¯ååˆ†å°ã•ã„ã‹ï¼ˆå¼±åæŸ `$O(\Delta t)$`ï¼‰
- [ ] `$g(X)$` ãŒ `$X$` ã«ä¾å­˜ã™ã‚‹å ´åˆ: Milsteinè£œæ­£ãŒå¿…è¦ã‹ç¢ºèª

**ç”Ÿæˆãƒ¢ãƒ‡ãƒ«å®Ÿè£…å‰ãƒã‚§ãƒƒã‚¯**:
- [ ] `$p_\theta$` ã¨ `$p_{\text{data}}$` ã¯çµ¶å¯¾é€£ç¶šã‹ï¼ˆKLãŒæœ‰é™ã‹ï¼‰
- [ ] ã‚¹ã‚³ã‚¢é–¢æ•° `$\nabla \log p_t(x)$` ã®è¨ˆç®—ç‚¹ `$x$` ã¯ `$p_t > 0$` ã®é ˜åŸŸã‹
- [ ] Importance Samplingä½¿ç”¨æ™‚: `$\text{ESS} > N/10$` ã‹
- [ ] æ¡ä»¶ä»˜ãæœŸå¾…å€¤ã®ã‚¿ãƒ¯ãƒ¼æ€§è³ªã‚’ä»®å®šã—ã¦ã„ã‚‹ã‹ï¼ˆMarkovæ€§ãŒå´©ã‚Œã¦ã„ãªã„ã‹ï¼‰

**ç†è«–çš„æ ¹æ‹ ã®ç¢ºèª**:
- [ ] ç©åˆ†ã¨å¾®åˆ†ã®äº¤æ›: DCTã®ä»®å®šï¼ˆå„ªé–¢æ•° `$g$` ã§ `$|f_n| \leq g$`ã€`$\mathbb{E}[g] < \infty$`ï¼‰ã‚’ç¢ºèª
- [ ] CLTã‚’ä½¿ã†å‰: `$\text{Var}[f(X)] < \infty$` ã‹ï¼ˆå¯¾æ•°æ­£è¦ãªã©è£¾ãŒé‡ã„å ´åˆã¯å±é™ºï¼‰
- [ ] KLåˆ†è§£ã§ã‚¿ãƒ¯ãƒ¼æ€§è³ªã‚’ä½¿ã†å‰: é©åˆ‡ãªãƒ•ã‚£ãƒ«ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ `$\mathcal{F}_t$` ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹

### 7.14 æ¬¡å›äºˆå‘Š â€” ç¬¬6å›: æƒ…å ±ç†è«–ãƒ»æœ€é©åŒ–ç†è«–

æ¬¡ã®ç¬¬6å›ã§ã¯ **æƒ…å ±ç†è«–ã¨æœ€é©åŒ–ç†è«–** ã«é€²ã‚€ã€‚KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¨SGDã§æ­¦è£…ã™ã‚‹å›ã ã€‚

> **Note:** **ç¬¬6å›ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ**
> - Shannon Entropy: `$H(X) = -\sum p(x) \log p(x)$`
> - KL Divergence: `$D_{\text{KL}}(p \| q) = \int p \log \frac{p}{q} \, d\mu$` â€” Radon-Nikodymå°é–¢æ•°å†ã³!
> - Mutual Information: `$I(X;Y)$` â€” ä¾å­˜ã®æ¸¬åº¦
> - f-Divergence: KLã®çµ±ä¸€çš„ä¸€èˆ¬åŒ–
> - å‹¾é…é™ä¸‹æ³•: SGDãƒ»Adam â€” ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã®æ±ºå®šç‰ˆ
> - æå¤±é–¢æ•°è¨­è¨ˆ: Cross-Entropy = KLæœ€å°åŒ–ã®ç­‰ä¾¡æ€§

> **ç¬¬4å›** ã®ç¢ºç‡åˆ†å¸ƒ â†’ **ç¬¬5å›** ã®æ¸¬åº¦è«–çš„åŸºç¤ â†’ **ç¬¬6å›** ã®æƒ…å ±ç†è«–ãƒ»æœ€é©åŒ–ç†è«–ã€‚3ã¤ã®è¬›ç¾©ã§ç¢ºç‡è«–ã®ã€Œä¸‰è§’å½¢ã€ãŒå®Œæˆã™ã‚‹ã€‚

**ç¬¬6å›ã®æ•°å­¦çš„ä½ç½®ã¥ã‘**: æƒ…å ±ç†è«–ã¯Lebesgueç©åˆ†ã®å¿œç”¨ã ã€‚Shannon Entropy:

```math
H(X) = -\int p(x) \log p(x) \, d\mu(x)
```

ã¯Lebesgueç©åˆ†ãã®ã‚‚ã®ã€‚KL Divergence:

```math
D_{\mathrm{KL}}(P \| Q) = \int \frac{dP}{dQ} \log \frac{dP}{dQ} \, dQ
```

ã¯Radon-Nikodymå°é–¢æ•°ã®ç©åˆ†ã€‚ç¬¬5å›ã§å­¦ã‚“ã ã“ã¨ãŒæƒ…å ±ç†è«–ã®åœŸå°ã«ç›´æ¥ãªã£ã¦ã„ã‚‹ã€‚**Mutual Information** `$I(X; Y) = D_{\mathrm{KL}}(P_{XY} \| P_X \otimes P_Y)$` ã¯çµåˆåˆ†å¸ƒã¨å‘¨è¾ºåˆ†å¸ƒã®ç©ã®KLè·é›¢ â€” ã“ã‚Œã‚‚æ¸¬åº¦è«–ã®è¨€èªã§ã—ã‹å³å¯†ã«ã¯å®šç¾©ã§ããªã„ã€‚

**æœ€é©åŒ–ç†è«–ã¨ã®æ¥ç¶š**: å‹¾é…é™ä¸‹æ³•ã®åæŸè§£æï¼ˆç¬¬6å›å¾ŒåŠï¼‰ã§ã¯ã€æå¤±é–¢æ•°ã®å‡¸æ€§ï¼ˆHessianã®å›ºæœ‰å€¤æ¡ä»¶ï¼‰ã¨åæŸãƒ¬ãƒ¼ãƒˆ `$O(1/\sqrt{T})$`ï¼ˆç¢ºç‡çš„SGDï¼‰ã®è¨¼æ˜ã«ç¢ºç‡è«–çš„æŠ€æ³•ãŒå¿…è¦ã€‚å…·ä½“çš„ã«ã¯ç¢ºç‡å¤‰æ•°ã®å’Œã®é›†ä¸­ä¸ç­‰å¼ï¼ˆHoeffdingã®ä¸ç­‰å¼ã€Azuma-Hoeffdingï¼‰ã‚’ä½¿ã†ã€‚ã“ã‚Œã‚‚æ¸¬åº¦è«–ã®å¿œç”¨ã ã€‚

---


### 7.15 ğŸ’€ ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„

**ã€å•ã„ã€‘ã€Œç¢ºç‡è«–ãªã‚“ã¦æ·±å±¤å­¦ç¿’ã«å¿…è¦ãªã„ã€ã¨ã„ã†ä¸»å¼µã«åè«–ã§ãã‚‹ã‹ï¼Ÿ**

ã“ã®å•ã„ã¯ã€å®Ÿè£…å„ªå…ˆã®å®Ÿå‹™å®¶ã‹ã‚‰ç¹°ã‚Šè¿”ã—èã“ãˆã¦ãã‚‹ã€‚äº‹å®Ÿã€PyTorchã§å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã ã‘ãªã‚‰æ¸¬åº¦è«–ã®çŸ¥è­˜ã¯ã»ã¼ä¸è¦ã ã€‚ã ãŒã€ä»¥ä¸‹ã®çŠ¶æ³ã«ç›´é¢ã—ãŸã¨ãã€ãã®ä¸»å¼µã¯å´©å£Šã™ã‚‹:

- **Score SDE [^2]** ã‚’èª­ã‚“ã§ã€ŒãªãœReverse SDEãŒæˆã‚Šç«‹ã¤ã‹ã€ã‚’ç†è§£ã—ã‚ˆã†ã¨ã—ãŸã¨ã â€” Anderson (1982) ã®Radon-Nikodymå¼•æ•°ãŒãªã‘ã‚Œã°èª­ã‚ãªã„
- **Flow Matching [^7]** ã§Conditional OTã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ãŒã€Œãªãœå¿…è¦ã‹ã€ã‚’èª¬æ˜ã—ã‚ˆã†ã¨ã—ãŸã¨ã â€” æ¸¬åº¦è¼¸é€ã®åŸºç¤ãŒãªã‘ã‚Œã°ç­”ãˆã‚‰ã‚Œãªã„
- **å­¦ç¿’ã®åæŸè¨¼æ˜** ã‚’æ›¸ã“ã†ã¨ã—ãŸã¨ã â€” åæŸå®šç†ï¼ˆMCT/DCTï¼‰ã®äº¤æ›å¯èƒ½æ€§ãŒãªã‘ã‚Œã°è¨¼æ˜ã§ããªã„

<details><summary>æ­´å²çš„èƒŒæ™¯: ç¢ºç‡è«–ã®å·¥å­¦ã¸ã®æµ¸é€</summary>

ç¢ºç‡è«–ã®å³å¯†ãªåŸºç¤ï¼ˆã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã®å…¬ç†åŒ–ï¼‰ãŒç¢ºç«‹ã—ãŸã®ã¯1933å¹´ã€‚ãã‚Œä»¥å‰ã¯ã€Œç¢ºç‡ã¨ã¯ä½•ã‹ã€ã«è¤‡æ•°ã®ä¸æ•´åˆãªå®šç¾©ãŒæ··åœ¨ã—ã¦ã„ãŸã€‚Shannonã®æƒ…å ±ç†è«–ï¼ˆ1948ï¼‰ã€Wienerã®ãƒã‚¤ã‚ºç†è«–ï¼ˆ1948ï¼‰ã€ä¼Šè—¤æ¸…ã®ç¢ºç‡ç©åˆ†ï¼ˆ1944ï¼‰ãŒæ€¥é€Ÿã«å®Ÿç”¨åŒ–ã•ã‚Œã€å·¥å­¦ã«æ¸¬åº¦è«–ãŒæµ¸é€ã—ãŸã€‚

æ·±å±¤å­¦ç¿’ã®çˆ†ç™ºæœŸï¼ˆ2012å¹´ä»¥é™ï¼‰ã¯ã€Œæ¸¬åº¦è«–ãªã—ã§ã‚‚å‹•ãã€ã¨ã„ã†å¹»æƒ³ã‚’ç”Ÿã‚“ã ãŒã€ç†è«–çš„çªç ´ï¼ˆScore SDE: 2020ã€Flow Matching: 2022ï¼‰ãŒã€Œå³å¯†ãªç¢ºç‡è«–ãªã—ã§ã¯ç†è§£ã§ããªã„ã€ã¨ã„ã†ç¾å®Ÿã‚’å¾©æ´»ã•ã›ãŸã€‚æ­´å²ã¯ç¹°ã‚Šè¿”ã™ã€‚
</details>

**åè«–ã®æ ¸å¿ƒ**: ã€Œå‹•ãå®Ÿè£…ã€ã¨ã€Œç†è«–çš„ç†è§£ã€ã¯åˆ¥ç‰©ã ã€‚æ©Ÿæ¢°ãŒå‹•ã‘ã°ååˆ†ã€ã¨ã„ã†ç«‹å ´ã¯ **æ¬¡ä¸–ä»£ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è¨­è¨ˆã™ã‚‹èƒ½åŠ›ã‚’æ”¾æ£„ã™ã‚‹** ã“ã¨ã¨åŒç¾©ã ã€‚ç¢ºç‡è«–ã¯ã€Œã‚¤ãƒ³ãƒ•ãƒ©ã€ã¨ã—ã¦è¡¨ã«å‡ºãªã„ãŒã€æ¶ˆãˆã¦ã¯ã„ãªã„ã€‚

---

> **âš ï¸ Warning:** **PB Question**: Lebesgueç©åˆ†ãªãã—ã¦ç¢ºç‡å¯†åº¦ãªã—ã€‚æ¸¬åº¦ã‚’çŸ¥ã‚‰ãšã«ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’èªã‚Œã‚‹ã‹ï¼Ÿ
>
> Riemannç©åˆ†ã®ä¸–ç•Œã§ã¯ã€`$\mathbb{Q}$` ä¸Šã®ä¸€æ§˜åˆ†å¸ƒã®ã‚ˆã†ãªã€Œç—…çš„ãªã€åˆ†å¸ƒã‚’æ‰±ãˆãªã„ã€‚Lebesgueç©åˆ†ã¯ã“ã®åˆ¶é™ã‚’å–ã‚Šæ‰•ã„ã€Radon-Nikodymå°é–¢æ•°ã¨ã—ã¦ç¢ºç‡å¯†åº¦é–¢æ•°ã‚’å³å¯†ã«å®šç¾©ã™ã‚‹ã€‚
>
> DDPMã®forward processã¯ã€ã‚¬ã‚¦ã‚¹ã®é·ç§»æ ¸ã‚’æŒã¤Markové€£é–ã§ã‚ã‚Šã€ãã®åˆ†å¸ƒã®å¤‰åŒ–ã¯ pushforward measure ã®ç³»åˆ—ã¨ã—ã¦è¨˜è¿°ã•ã‚Œã‚‹ã€‚Score SDE ã¯ã€ã“ã®é›¢æ•£éç¨‹ã‚’é€£ç¶šã®SDEã«æ‹¡å¼µã—ã€Browné‹å‹•ã®ItÃ´ç©åˆ†ã‚’ä½¿ã£ã¦å®šå¼åŒ–ã™ã‚‹ã€‚Flow Matching ã¯ã€æ¸¬åº¦è¼¸é€ã®æœ€é©åŒ–å•é¡Œã¨ã—ã¦ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’å†å®šå¼åŒ–ã™ã‚‹ã€‚
>
> **ã™ã¹ã¦ã®é“ã¯æ¸¬åº¦è«–ã«é€šã˜ã‚‹ã€‚**
>
> æ¸¬åº¦è«–ã‚’å­¦ã¶ã“ã¨ã¯ã€å€‹ã€…ã®æ‰‹æ³•ã®èƒŒå¾Œã«ã‚ã‚‹çµ±ä¸€çš„ãªæ§‹é€ ã‚’è¦‹ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚ãã‚Œã¯å˜ãªã‚‹æ•°å­¦çš„å³å¯†æ€§ã®ãŸã‚ã§ã¯ãªãã€**æ–°ã—ã„ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’è¨­è¨ˆã™ã‚‹ãŸã‚ã®è¨€èª**ã‚’æ‰‹ã«å…¥ã‚Œã‚‹ã“ã¨ã‚’æ„å‘³ã™ã‚‹ã€‚
>
> æ¬¡ã®ç¬¬6å›ã§ã¯ã€ã“ã®æ¸¬åº¦ã®è¨€èªã®ä¸Šã«ã€Œæƒ…å ±ã€ã®æ¦‚å¿µã‚’æ§‹ç¯‰ã™ã‚‹ã€‚KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¯ `$\frac{dP}{dQ}$` ã®å¯¾æ•°ã®æœŸå¾…å€¤ â€” ã¾ã•ã«Radon-Nikodymå°é–¢æ•°ãŒä¸»å½¹ã ã€‚

---
> Progress: 100%

---

## å‚è€ƒæ–‡çŒ®

[^1]: Ho, J., Jain, A., & Abbeel, P. (2020). *Denoising Diffusion Probabilistic Models*. NeurIPS 2020. arXiv:2006.11239 â€” DDPMã®åŸè«–æ–‡ã€‚ã‚¬ã‚¦ã‚¹é·ç§»æ ¸ã‚’æŒã¤Markové€£é–ã¨ã—ã¦æ‹¡æ•£éç¨‹ã‚’å®šç¾©ã€‚

[^2]: Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., & Poole, B. (2020). *Score-Based Generative Modeling through Stochastic Differential Equations*. ICLR 2021. arXiv:2011.13456 â€” Score SDEã®åŸè«–æ–‡ã€‚DDPMã‚’é€£ç¶šSDEã«æ‹¡å¼µã—ã€reverse SDEã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€‚

[^3]: Levin, D. A., & Peres, Y. (2017). *Markov Chains and Mixing Times* (2nd ed.). American Mathematical Society. â€” Markové€£é–ç†è«–ã®æ¨™æº–æ•™ç§‘æ›¸ã€‚ã‚¨ãƒ«ã‚´ãƒ¼ãƒ‰å®šç†ãƒ»æ··åˆæ™‚é–“ã®è©³ç´°ã€‚

[^4]: ItÃ´, K. (1944). *Stochastic Integral*. Proceedings of the Imperial Academy, 20(8), 519-524. â€” ç¢ºç‡ç©åˆ†ã®åŸè«–æ–‡ã€‚Browné‹å‹•ã«å¯¾ã™ã‚‹ç©åˆ†ã‚’å®šç¾©ã€‚

[^5]: Roberts, G. O., Gelman, A., & Gilks, W. R. (1997). *Weak convergence and optimal scaling of random walk Metropolis algorithms*. Annals of Applied Probability, 7(1), 110-120. â€” MHæ³•ã®æœ€é©å—ç†ç‡23.4%ã®ç†è«–ã€‚

[^6]: Liu, X., Gong, C., & Liu, Q. (2022). *Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow*. ICLR 2023. arXiv:2209.03003 â€” Rectified Flowã®åŸè«–æ–‡ã€‚ãƒ‘ã‚¹ã®ç›´ç·šåŒ–ã«ã‚ˆã‚‹é«˜é€Ÿç”Ÿæˆã€‚

[^7]: Lipman, Y., Chen, R. T. Q., Ben-Hamu, H., Nickel, M., & Le, M. (2022). *Flow Matching for Generative Modeling*. ICLR 2023. arXiv:2210.02747 â€” Flow Matchingã®åŸè«–æ–‡ã€‚æ¡ä»¶ä»˜ãé€Ÿåº¦å ´ã®å›å¸°ã§ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã€‚

[^9]: Anderson, B. D. O. (1982). *Reverse-time diffusion equation models*. Stochastic Processes and their Applications, 12(3), 313-326. â€” Reverse SDEã®ç†è«–ã€‚Score SDEã®åŸºç¤ã€‚

[^10]: Tao, M. (2025). VP-SDE Discretization Error Analysis via Gronwall Inequality. arXiv:2506.08337 â€” GrÃ¶nwallä¸ç­‰å¼ã«ã‚ˆã‚‹Euler-Maruyamaé›¢æ•£åŒ–èª¤å·®ã®ä¸Šç•Œã€‚

[^11]: Austin, J., Johnson, D. D., Ho, J., Tarlow, D., & van den Berg, R. (2021). *Structured Denoising Diffusion Models in Discrete State-Spaces*. NeurIPS 2021. arXiv:2107.03006 â€” é›¢æ•£çŠ¶æ…‹ç©ºé–“æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®åŸè«–æ–‡ã€‚

[^12]: Song, J., Meng, C., & Ermon, S. (2021). *Denoising Diffusion Implicit Models*. ICLR 2021. arXiv:2010.02502 â€” DDIMã®åŸè«–æ–‡ã€‚ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤§å¹…å‰Šæ¸›ã—ãªãŒã‚‰å“è³ªç¶­æŒã€‚

[^13]: Albergo, M. S., & Vanden-Eijnden, E. (2022). *Building Normalizing Flows with Stochastic Interpolants*. ICLR 2023. arXiv:2209.15571 â€” Stochastic Interpolantsã®åŸè«–æ–‡ã€‚Flow Matchingã¨Diffusionã®çµ±ä¸€ã€‚

---

## è‘—è€…ãƒªãƒ³ã‚¯

- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

---

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
