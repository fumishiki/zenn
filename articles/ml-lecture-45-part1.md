---
title: "ç¬¬45å›: Videoç”Ÿæˆ: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼"
emoji: "ğŸ¬"
type: "tech"
topics: ["machinelearning","deeplearning","video","julia","rust","elixir"]
published: true
---

# ç¬¬45å›: Videoç”Ÿæˆ â€” æ™‚ç©ºé–“Diffusionã®æœ€å‰ç·š

:::message
**å‰å›ã¾ã§ã®åˆ°é”ç‚¹**: ç¬¬44å›ã§éŸ³å£°ç”Ÿæˆï¼ˆTTS/Music/Flow Matchingï¼‰ã‚’ç¿’å¾—ã€‚é™æ­¢ç”»ãƒ»éŸ³å£°ã‚’å®Œå…¨ãƒã‚¹ã‚¿ãƒ¼ã€‚æ¬¡ã¯æ™‚é–“è»¸+ç©ºé–“=å‹•ç”»ç”Ÿæˆã¸ã€‚

**ä»Šå›ã®ã‚´ãƒ¼ãƒ«**: å‹•ç”»ç”Ÿæˆã®ç†è«–ã¨å®Ÿè£…ã€‚Sora 2è§£æã€CogVideoX/HunyuanVideo/Open-Sora 2.0/Wan-2.1ã®æœ€å‰ç·šã€SmolVLM2å‹•ç”»ç†è§£+LTX-Videoå‹•ç”»ç”Ÿæˆãƒ‡ãƒ¢ã€‚

**é€²æ—**: å…¨ä½“ã®90%å®Œäº†ï¼ˆç¬¬45å›/å…¨50å›ï¼‰
:::

## ğŸš€ 0. ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆ30ç§’ï¼‰â€” 3è¡Œã§å‹•ç”»ç”Ÿæˆä½“é¨“

ãŸã£ãŸ3è¡Œã®ã‚³ãƒ¼ãƒ‰ã§å‹•ç”»diffusionã®æœ¬è³ªã‚’ä½“æ„Ÿã—ã¾ã—ã‚‡ã†ã€‚é™æ­¢ç”»Diffusionã«ã€Œæ™‚é–“è»¸ã€ãŒåŠ ã‚ã‚‹ã¨ä½•ãŒèµ·ãã‚‹ã‹ï¼Ÿ

```julia
using VideoIO, Images, Random

# é™æ­¢ç”»Diffusionã¨åŒã˜ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
Î²â‚œ = LinRange(1e-4, 0.02, 50)  # 50ãƒ•ãƒ¬ãƒ¼ãƒ 
Î±â‚œ = cumprod(1 .- Î²â‚œ)

# Clean video â†’ Noisy video (forward process)
clean_video = [repeat(fill(i/50, 64, 64), 1, 1, 3) for i in 1:50]  # 50ãƒ•ãƒ¬ãƒ¼ãƒ ã€64x64 RGB
noisy_video = [clean_video[t] .+ sqrt(1 - Î±â‚œ[t]) .* randn(size(clean_video[t])) for t in 1:50]

# æ™‚é–“çš„ä¸€è²«æ€§ãŒãªã„ãƒã‚¤ã‚º â†’ ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã§ç‹¬ç«‹ã«ãƒã‚¤ã‚ºãŒå…¥ã‚‹ï¼ˆã¡ã‚‰ã¤ãï¼‰
save_video("noisy_video.mp4", noisy_video, framerate=10)

# ğŸ’¡ ã“ã“ãŒVideo Diffusionã®æœ¬è³ª:
# é™æ­¢ç”»Diffusion: å˜ä¸€ç”»åƒã«ãƒã‚¤ã‚º â†’ å˜ä¸€ç”»åƒã‚’å¾©å…ƒ
# Video Diffusion: 50ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ™‚ç³»åˆ—ã«ãƒã‚¤ã‚º â†’ æ™‚é–“çš„ä¸€è²«æ€§ã‚’ä¿ã£ã¦å¾©å…ƒ
```

**å‡ºåŠ›**: ãƒã‚¤ã‚ºã¾ã¿ã‚Œã ãŒãƒ•ãƒ¬ãƒ¼ãƒ é–“ã§ç›¸é–¢ã®ã‚ã‚‹å‹•ç”»ã€‚æ™‚é–“è»¸ã®è¿½åŠ ã§ã€Œæ™‚é–“çš„ä¸€è²«æ€§ï¼ˆTemporal Coherenceï¼‰ã€ã¨ã„ã†æ–°ãŸãªåˆ¶ç´„ãŒç”Ÿã¾ã‚ŒãŸã€‚

**æ•°å¼ã®æ­£ä½“**:
$$
q(\mathbf{x}_t^{(1:T)} \mid \mathbf{x}_0^{(1:T)}) = \prod_{f=1}^{T} \mathcal{N}(\sqrt{\alpha_t}\mathbf{x}_0^{(f)}, (1-\alpha_t)\mathbf{I})
$$

- $\mathbf{x}_0^{(1:T)}$: Tå€‹ã®ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆclean videoï¼‰
- $t$: Diffusionã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ï¼‰
- $f$: ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·

ã“ã®å¼ã¯ã€Œå„ãƒ•ãƒ¬ãƒ¼ãƒ ã«**ç‹¬ç«‹ã«**ãƒã‚¤ã‚ºã‚’åŠ ãˆã‚‹ã€ã“ã¨ã‚’ç¤ºã™ã€‚ã—ã‹ã—ã€ã“ã‚Œã ã‘ã§ã¯æ™‚é–“çš„ä¸€è²«æ€§ãŒå´©å£Šã™ã‚‹ã€‚**Temporal Attentionã‚„Optical Flowåˆ¶ç´„ãŒæ•‘ä¸–ä¸»ã«ãªã‚‹** â€” æœ¬ç·¨ã§å®Œå…¨å°å‡ºã—ã¾ã™ã€‚

:::message
**ãƒœã‚¹æˆ¦äºˆå‘Š**: Sora 2ã®ã€ŒSpacetime DiTã€ã¯æ™‚ç©ºé–“ã‚’çµ±ä¸€çš„ã«æ‰±ã†ã€‚3D U-Netã¨ã®é•ã„ã¯ï¼ŸãªãœTransformerãŒå‹ã¤ã®ã‹ï¼Ÿâ€” Zone 3ã§æ•°å¼ã®æˆ¦ã„ãŒå§‹ã¾ã‚Šã¾ã™ã€‚
:::

---

## ğŸ® 1. ä½“é¨“ã‚¾ãƒ¼ãƒ³ï¼ˆ10åˆ†ï¼‰â€” å‹•ç”»ç”Ÿæˆã®3ã¤ã®å…¬å¼ã‚’è§¦ã‚‹

å‹•ç”»ç”Ÿæˆã®æ ¸å¿ƒå…¬å¼ã‚’ã€æ•°å¼ã¨ã‚³ãƒ¼ãƒ‰ã®1:1å¯¾å¿œã§ä½“é¨“ã—ã¾ã—ã‚‡ã†ã€‚

### 1.1 å…¬å¼â‘  æ™‚ç©ºé–“Attention â€” ç©ºé–“ã¨æ™‚é–“ã‚’åˆ†é›¢ã™ã‚‹

**æ•°å¼**:
$$
\text{Attention}_{\text{spatial}}(Q, K, V) = \text{softmax}\left(\frac{QK^\top}{\sqrt{d}}\right)V \quad (\text{å„ãƒ•ãƒ¬ãƒ¼ãƒ å†…})
$$
$$
\text{Attention}_{\text{temporal}}(Q, K, V) = \text{softmax}\left(\frac{QK^\top}{\sqrt{d}}\right)V \quad (\text{æ™‚é–“è»¸æ–¹å‘})
$$

**Juliaå®Ÿè£…**:

```julia
using LinearAlgebra, Statistics

function spatial_attention(frames::Array{Float32, 4})  # (H, W, C, T)
    H, W, C, T = size(frames)
    output = similar(frames)

    for t in 1:T
        frame = frames[:, :, :, t]  # å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
        flat = reshape(frame, H*W, C)  # (H*W, C)

        Q = flat  # ç°¡æ˜“ç‰ˆ: è‡ªå·±Attention
        K = flat
        V = flat

        # Scaled Dot-Product Attention
        scores = (Q * K') / sqrt(Float32(C))  # (H*W, H*W)
        attn = softmax(scores, dims=2)  # è¡Œæ–¹å‘ã§softmax
        output_flat = attn * V  # (H*W, C)

        output[:, :, :, t] = reshape(output_flat, H, W, C)
    end

    return output
end

function temporal_attention(frames::Array{Float32, 4})  # (H, W, C, T)
    H, W, C, T = size(frames)
    output = similar(frames)

    for h in 1:H, w in 1:W
        pixel_sequence = frames[h, w, :, :]  # (C, T) â€” æ™‚é–“è»¸æ–¹å‘ã®ç³»åˆ—

        Q = pixel_sequence'  # (T, C)
        K = Q
        V = Q

        scores = (Q * K') / sqrt(Float32(C))  # (T, T)
        attn = softmax(scores, dims=2)
        output_seq = attn * V  # (T, C)

        output[h, w, :, :] = output_seq'
    end

    return output
end

# ãƒ†ã‚¹ãƒˆ: 5ãƒ•ãƒ¬ãƒ¼ãƒ ã€16x16ã€3ãƒãƒ£ãƒãƒ«
frames = randn(Float32, 16, 16, 3, 5)
spatial_out = spatial_attention(frames)  # ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã®ç©ºé–“çš„ä¸€è²«æ€§
temporal_out = temporal_attention(frames)  # ãƒ”ã‚¯ã‚»ãƒ«ä½ç½®ã®æ™‚é–“çš„ä¸€è²«æ€§

println("ç©ºé–“Attention: ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã®ç©ºé–“æ§‹é€ ã‚’ä¿ã¤")
println("æ™‚é–“Attention: ãƒ”ã‚¯ã‚»ãƒ«ã®æ™‚é–“çš„è»Œè·¡ã‚’ä¿ã¤")
```

**æŒ™å‹•ã®é•ã„**:

| Attentionç¨®é¡ | è¨ˆç®—å¯¾è±¡ | ä¿ã¤ä¸€è²«æ€§ | è¨ˆç®—é‡ |
|:--------------|:---------|:----------|:-------|
| Spatial       | å„ãƒ•ãƒ¬ãƒ¼ãƒ å†… | ç©ºé–“æ§‹é€ ï¼ˆç‰©ä½“ã®å½¢ï¼‰ | O(HÂ²WÂ²T) |
| Temporal      | å„ãƒ”ã‚¯ã‚»ãƒ«ä½ç½®ã®æ™‚é–“ç³»åˆ— | æ™‚é–“çš„è»Œè·¡ï¼ˆç‰©ä½“ã®å‹•ãï¼‰ | O(HWTÂ²) |

**æ•°å¼â†”ã‚³ãƒ¼ãƒ‰å¯¾å¿œè¡¨**:

| æ•°å¼ | Julia | æ„å‘³ |
|:-----|:------|:-----|
| $QK^\top/\sqrt{d}$ | `(Q * K') / sqrt(Float32(C))` | ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä»˜ãå†…ç© |
| $\text{softmax}(\cdot)$ | `softmax(scores, dims=2)` | è¡Œæ–¹å‘ã§ç¢ºç‡åŒ– |
| $\text{Attention}(Q,K,V)$ | `attn * V` | é‡ã¿ä»˜ãåŠ é‡å¹³å‡ |

### 1.2 å…¬å¼â‘¡ 3D Convolution â€” æ™‚ç©ºé–“ã®å±€æ‰€æ€§ã‚’æ´»ç”¨

**æ•°å¼**:
$$
y_{t,h,w,c} = \sum_{i,j,k,c'} w_{i,j,k,c',c} \cdot x_{t+i, h+j, w+k, c'}
$$

- $(i,j,k)$: æ™‚é–“ãƒ»é«˜ã•ãƒ»å¹…ã®ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºï¼ˆä¾‹: 3Ã—3Ã—3ï¼‰
- $c'$: å…¥åŠ›ãƒãƒ£ãƒãƒ«ã€$c$: å‡ºåŠ›ãƒãƒ£ãƒãƒ«

**Juliaå®Ÿè£…**:

```julia
using NNlib

function conv3d_demo(video::Array{Float32, 4})  # (T, H, W, C)
    T, H, W, C = size(video)

    # 3D Convã‚«ãƒ¼ãƒãƒ«: (kernel_t, kernel_h, kernel_w, in_channels, out_channels)
    kernel = randn(Float32, 3, 3, 3, C, C)  # 3x3x3ã®æ™‚ç©ºé–“ã‚«ãƒ¼ãƒãƒ«

    # NNlibã®conv3dã¯CUDNNæº–æ‹ : (W, H, T, C, Batch)å½¢å¼ã‚’æœŸå¾…
    video_nchw = permutedims(video, (3, 2, 1, 4))  # (W, H, T, C)
    video_nchw = reshape(video_nchw, size(video_nchw)..., 1)  # ãƒãƒƒãƒæ¬¡å…ƒè¿½åŠ 

    kernel_nchw = permutedims(kernel, (3, 2, 1, 4, 5))  # (W, H, T, C_in, C_out)

    output = conv(video_nchw, kernel_nchw, pad=1)

    return output
end

video = randn(Float32, 10, 32, 32, 3)  # 10ãƒ•ãƒ¬ãƒ¼ãƒ ã€32x32ã€3ãƒãƒ£ãƒãƒ«
output = conv3d_demo(video)

println("3D Conv: æ™‚ç©ºé–“ã®å±€æ‰€æ€§ã‚’ç•³ã¿è¾¼ã¿ã§æ‰ãˆã‚‹")
println("å‡ºåŠ›å½¢çŠ¶: ", size(output))
```

**2D vs 3D Convã®é•ã„**:

| Convç¨®é¡ | ã‚«ãƒ¼ãƒãƒ« | å—å®¹é‡ | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° | ç”¨é€” |
|:---------|:---------|:-------|:-------------|:-----|
| 2D Conv  | (k_h, k_w, C_in, C_out) | ç©ºé–“ã®ã¿ | $k_h \times k_w \times C_{in} \times C_{out}$ | é™æ­¢ç”» |
| 3D Conv  | (k_t, k_h, k_w, C_in, C_out) | æ™‚ç©ºé–“ | $k_t \times k_h \times k_w \times C_{in} \times C_{out}$ | å‹•ç”» |

:::message
**Trojan Horse**: Conv3Dã¯ã€Œæ™‚é–“è»¸ã«ã‚‚ã‚«ãƒ¼ãƒãƒ«ã‚’ã‚¹ãƒ©ã‚¤ãƒ‰ã€ã•ã›ã‚‹ã ã‘ã€‚ç†è«–çš„ã«ã¯å˜ç´”ã ãŒã€**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒ$k_t$å€**ã«è†¨ã‚Œä¸ŠãŒã‚‹ã€‚æ¬¡ä¸–ä»£ãƒ¢ãƒ‡ãƒ«ã¯**DiTï¼ˆDiffusion Transformerï¼‰**ã§ã“ã®å•é¡Œã‚’è§£æ±º â€” Zone 3ã§è©³èª¬ã€‚
:::

### 1.3 å…¬å¼â‘¢ Optical Flow Loss â€” ç‰©ç†çš„ãªå‹•ãã®ä¸€è²«æ€§

**æ•°å¼**:
$$
\mathcal{L}_{\text{flow}} = \sum_{t=1}^{T-1} \left\| \mathbf{x}_{t+1} - \text{Warp}(\mathbf{x}_t, \mathbf{f}_{t \to t+1}) \right\|^2
$$

- $\mathbf{f}_{t \to t+1}$: ãƒ•ãƒ¬ãƒ¼ãƒ $t$ã‹ã‚‰$t+1$ã¸ã®å…‰å­¦ãƒ•ãƒ­ãƒ¼ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ã”ã¨ã®å‹•ããƒ™ã‚¯ãƒˆãƒ«ï¼‰
- $\text{Warp}(\mathbf{x}_t, \mathbf{f})$: ãƒ•ãƒ­ãƒ¼ã«å¾“ã£ã¦$\mathbf{x}_t$ã‚’å¤‰å½¢

**Juliaå®Ÿè£…**:

```julia
using Interpolations

function warp_frame(frame::Matrix{Float32}, flow::Array{Float32, 3})  # flow: (H, W, 2)
    H, W = size(frame)
    warped = similar(frame)

    for h in 1:H, w in 1:W
        dx, dy = flow[h, w, 1], flow[h, w, 2]
        src_h = clamp(h + dy, 1, H)
        src_w = clamp(w + dx, 1, W)

        # ç·šå½¢è£œé–“
        h_low, h_high = floor(Int, src_h), ceil(Int, src_h)
        w_low, w_high = floor(Int, src_w), ceil(Int, src_w)

        h_frac = src_h - h_low
        w_frac = src_w - w_low

        # Bilinearè£œé–“
        if h_high <= H && w_high <= W
            warped[h, w] = (1 - h_frac) * (1 - w_frac) * frame[h_low, w_low] +
                          (1 - h_frac) * w_frac * frame[h_low, w_high] +
                          h_frac * (1 - w_frac) * frame[h_high, w_low] +
                          h_frac * w_frac * frame[h_high, w_high]
        else
            warped[h, w] = frame[h, w]
        end
    end

    return warped
end

function optical_flow_loss(frames::Vector{Matrix{Float32}}, flows::Vector{Array{Float32, 3}})
    T = length(frames)
    total_loss = 0.0f0

    for t in 1:(T-1)
        warped = warp_frame(frames[t], flows[t])
        loss = sum((frames[t+1] .- warped).^2)
        total_loss += loss
    end

    return total_loss / (T - 1)
end

# ãƒ†ã‚¹ãƒˆ: 5ãƒ•ãƒ¬ãƒ¼ãƒ ã€å„32x32
frames = [randn(Float32, 32, 32) for _ in 1:5]
flows = [randn(Float32, 32, 32, 2) for _ in 1:4]  # T-1å€‹ã®ãƒ•ãƒ­ãƒ¼

loss = optical_flow_loss(frames, flows)
println("Optical Flow Loss: ", loss)
println("ã“ã®æå¤±ãŒå°ã•ã„ = ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®å‹•ããŒç‰©ç†çš„ã«ä¸€è²«ã—ã¦ã„ã‚‹")
```

**Optical Flowã®ç›´æ„Ÿ**:

```
ãƒ•ãƒ¬ãƒ¼ãƒ t:    â—------->
              |  dx=+5
              |  dy=+2
              â†“
ãƒ•ãƒ¬ãƒ¼ãƒ t+1:      â—

Warp(x_t, flow) = ã€Œflowã«å¾“ã£ã¦ãƒ”ã‚¯ã‚»ãƒ«ã‚’å‹•ã‹ã™ã€
                 â†’ ãƒ•ãƒ¬ãƒ¼ãƒ t+1ã¨ä¸€è‡´ã™ã‚Œã°flowæ­£ã—ã„
```

:::details Optical Flowæ¨å®šã®3æ‰‹æ³•

| æ‰‹æ³• | åŸç† | ç²¾åº¦ | é€Ÿåº¦ |
|:-----|:-----|:-----|:-----|
| Lucas-Kanade | å±€æ‰€çš„ãªãƒ”ã‚¯ã‚»ãƒ«ç§»å‹•ã‚’ä»®å®š | ä¸­ | é«˜é€Ÿ |
| Horn-Schunck | å¤§åŸŸçš„ãªå¹³æ»‘æ€§åˆ¶ç´„ | é«˜ | é…ã„ |
| FlowNetï¼ˆCNNï¼‰ | End-to-Endã§Flowã‚’äºˆæ¸¬ | éå¸¸ã«é«˜ | GPUå¿…é ˆ |

ç¾ä»£ã®å‹•ç”»ç”Ÿæˆã§ã¯**FlowNetã‚„RAFTï¼ˆRecurrent All-Pairs Field Transformsï¼‰**ãŒä¸»æµã€‚
:::

### 1.4 3å…¬å¼ã®æ¥ç¶š â€” Video Diffusionã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```mermaid
graph LR
    A[Textãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ] --> B[Text Encoder]
    B --> C[Conditional Diffusion Model]
    C --> D[3D U-Net or DiT]
    D -->|Spatial Attention| E[ãƒ•ãƒ¬ãƒ¼ãƒ å†…ä¸€è²«æ€§]
    D -->|Temporal Attention| F[æ™‚é–“çš„ä¸€è²«æ€§]
    D -->|Optical Flow Loss| G[ç‰©ç†çš„å‹•ã]
    E & F & G --> H[Denoised Video Latent]
    H --> I[3D VAE Decoder]
    I --> J[ç”Ÿæˆå‹•ç”»]
```

**3å…¬å¼ã®å½¹å‰²åˆ†æ‹…**:

| å…¬å¼ | å½¹å‰² | ä¿è¨¼ã™ã‚‹æ€§è³ª | æ¬ ã‘ã‚‹ã¨èµ·ãã‚‹å•é¡Œ |
|:-----|:-----|:-------------|:-------------------|
| â‘  Spatial/Temporal Attention | å¤§åŸŸçš„ãªæ™‚ç©ºé–“ä¾å­˜æ€§ | é•·è·é›¢ã®ä¸€è²«æ€§ | ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã§ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒè·³èº |
| â‘¡ 3D Convolution | å±€æ‰€çš„ãªæ™‚ç©ºé–“ãƒ‘ã‚¿ãƒ¼ãƒ³ | ãƒ†ã‚¯ã‚¹ãƒãƒ£ã®æ»‘ã‚‰ã‹ã• | ãƒã‚¤ã‚ºã¾ã¿ã‚Œã®å‹•ç”» |
| â‘¢ Optical Flow Loss | ç‰©ç†çš„ãªå‹•ãã®é€£ç¶šæ€§ | è‡ªç„¶ãªé‹å‹• | ç‰©ä½“ãŒç¬é–“ç§»å‹• |

:::details PyTorchã¨ã®å¯¾å¿œï¼ˆå‚è€ƒï¼‰

```python
import torch
import torch.nn.functional as F

# Spatial Attention
def spatial_attention(frames):  # (B, T, C, H, W)
    B, T, C, H, W = frames.shape
    output = []
    for t in range(T):
        frame = frames[:, t, :, :, :]  # (B, C, H, W)
        flat = frame.view(B, C, H*W).permute(0, 2, 1)  # (B, H*W, C)
        attn = F.softmax(flat @ flat.transpose(-2, -1) / (C ** 0.5), dim=-1)
        out = (attn @ flat).permute(0, 2, 1).view(B, C, H, W)
        output.append(out)
    return torch.stack(output, dim=1)

# 3D Convolution
conv3d = torch.nn.Conv3d(in_channels=3, out_channels=64, kernel_size=(3, 3, 3), padding=1)

# Optical Flow Warp
def warp(x, flow):
    B, C, H, W = x.shape
    grid = torch.meshgrid(torch.arange(H), torch.arange(W), indexing='ij')
    grid = torch.stack(grid, dim=-1).float()  # (H, W, 2)
    grid = grid + flow
    grid = grid / torch.tensor([H-1, W-1]) * 2 - 1  # [-1, 1]æ­£è¦åŒ–
    return F.grid_sample(x, grid.unsqueeze(0).expand(B, -1, -1, -1))
```
:::

---

## ğŸ§© 2. ç›´æ„Ÿã‚¾ãƒ¼ãƒ³ï¼ˆ15åˆ†ï¼‰â€” ãªãœå‹•ç”»ç”Ÿæˆã¯é›£ã—ã„ã®ã‹

### 2.1 Course Vå…¨ä½“ã®åœ°å›³ â€” ãƒ¢ãƒ€ãƒªãƒ†ã‚£æ‹¡å¼µãƒ«ãƒ¼ãƒˆ

```mermaid
graph TD
    A[ç¬¬43å›: DiT & é«˜é€Ÿç”Ÿæˆ] -->|é™æ­¢ç”»ãƒã‚¹ã‚¿ãƒ¼| B[ç¬¬44å›: éŸ³å£°ç”Ÿæˆ]
    B -->|æ™‚ç³»åˆ—1D| C[ç¬¬45å›: å‹•ç”»ç”Ÿæˆ â†ä»Šã‚³ã‚³]
    C -->|æ™‚ç©ºé–“2D+æ™‚é–“| D[ç¬¬46å›: 3Dç”Ÿæˆ]
    D -->|ç©ºé–“3D| E[ç¬¬47å›: ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»4D]
    E -->|å‹•çš„3D| F[ç¬¬48å›: ç§‘å­¦å¿œç”¨]
    F -->|åˆ¶ç´„ä»˜ãç”Ÿæˆ| G[ç¬¬49å›: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«çµ±åˆ]
    G -->|çµ±åˆ| H[ç¬¬50å›: ç·æ‹¬+å’æ¥­åˆ¶ä½œ]
```

**Course IVã¨Course Vã®å½¹å‰²åˆ†æ‹…**:

| Course | è¬›ç¾©ç¯„å›² | ã‚´ãƒ¼ãƒ« | åˆ°é”ãƒ¬ãƒ™ãƒ« |
|:-------|:---------|:-------|:-----------|
| **Course IV** (ç¬¬33-42å›) | Diffusionç†è«–ã®å…¨ã¦ | è«–æ–‡ãŒ**æ›¸ã‘ã‚‹** | Diffusionç†è«–ã®å®Œå…¨ç†è§£ |
| **Course V** (ç¬¬43-50å›) | å…¨ãƒ¢ãƒ€ãƒªãƒ†ã‚£å®Ÿè£… | ã‚·ã‚¹ãƒ†ãƒ ãŒ**ä½œã‚Œã‚‹** | å…¨ãƒ‰ãƒ¡ã‚¤ãƒ³å®Ÿè£…åŠ› |

ä»Šå›ã¯ã€Œæ™‚ç©ºé–“Diffusionã€ã®å®Ÿè£…ç·¨ã€‚ç†è«–çš„åŸºç›¤ã¯ç¬¬37-38å›ï¼ˆSDE/Flow Matchingï¼‰ã§å®Œæˆæ¸ˆã¿ã€‚

### 2.2 å‹•ç”»ç”Ÿæˆã®3ã¤ã®å›°é›£ â€” é™æ­¢ç”»ã¨ã®ã‚®ãƒ£ãƒƒãƒ—

#### å›°é›£â‘  æ™‚é–“çš„ä¸€è²«æ€§ï¼ˆTemporal Coherenceï¼‰

**å•é¡Œ**: ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«ç‹¬ç«‹ã«Diffusionã™ã‚‹ã¨ã€Œãƒãƒ©ã¤ãã€å‹•ç”»ã«ãªã‚‹ã€‚

```
é™æ­¢ç”»Diffusion:  ãƒã‚¤ã‚º â†’ [Denoise] â†’ 1æšã®ç”»åƒ
å‹•ç”»Diffusion:    ãƒã‚¤ã‚º â†’ [Denoise] â†’ 50ãƒ•ãƒ¬ãƒ¼ãƒ 
                  â†‘
                  å„ãƒ•ãƒ¬ãƒ¼ãƒ ãŒç‹¬ç«‹ â†’ ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã§ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä½ç½®ãŒã‚¸ãƒ£ãƒ³ãƒ—
```

**è§£æ±ºç­–**: Temporal Attentionã§ã€Œãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®ä¾å­˜é–¢ä¿‚ã€ã‚’å­¦ç¿’ã€‚

#### å›°é›£â‘¡ è¨ˆç®—é‡ã®çˆ†ç™º

**æ•°å€¤ä¾‹**:

| ãƒ¢ãƒ€ãƒªãƒ†ã‚£ | ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º | Diffusionã‚¹ãƒ†ãƒƒãƒ— | ç·è¨ˆç®—é‡ |
|:----------|:------------|:------------------|:---------|
| é™æ­¢ç”» (512Ã—512) | 786K pixels | 50 steps | 39M operations |
| å‹•ç”» (512Ã—512Ã—24fpsÃ—5ç§’) | 94M pixels | 50 steps | 4.7B operations |

å‹•ç”»ã¯é™æ­¢ç”»ã®**120å€**ã®ãƒ‡ãƒ¼ã‚¿é‡ã€‚å˜ç´”ãªU-Netã§ã¯ç ´ç¶»ã™ã‚‹ã€‚

**è§£æ±ºç­–**: 3D VAEã§æ™‚ç©ºé–“åœ§ç¸®ï¼ˆCogVideoX: 192å€åœ§ç¸®ï¼‰

#### å›°é›£â‘¢ ç‰©ç†æ³•å‰‡ã®éµå®ˆ

**å•é¡Œ**: Diffusionãƒ¢ãƒ‡ãƒ«ã¯ã€Œè¦‹ãŸç›®ãŒãƒªã‚¢ãƒ«ã€ãªç”»åƒã‚’ç”Ÿæˆã™ã‚‹ãŒã€**ç‰©ç†çš„ã«æ­£ã—ã„å‹•ã**ã¯å­¦ç¿’ã—ã«ãã„ã€‚

**å…·ä½“ä¾‹**:
- ãƒœãƒ¼ãƒ«ãŒå£ã‚’è²«é€š
- é‡åŠ›ã‚’ç„¡è¦–ã—ã¦ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒæµ®éŠ
- å½±ã¨å…‰æºã®ä½ç½®ãŒçŸ›ç›¾

**Sora 2ã®æŒ‘æˆ¦**: ç‰©ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã¨ã—ã¦ã®Diffusion â€” ã¾ã å®Œç’§ã§ã¯ãªã„ã€‚

:::message
**æ¾å°¾ãƒ»å²©æ¾¤ç ”ã¨ã®å·®åˆ¥åŒ–**:

| é …ç›® | æ¾å°¾ç ” | æœ¬ã‚·ãƒªãƒ¼ã‚º |
|:-----|:-------|:-----------|
| å‹•ç”»ç”Ÿæˆ | ã‚«ãƒãƒ¼ãªã— | Sora 2/CogVideoX/HunyuanVideoè©³ç´° |
| å®Ÿè£… | ãªã— | 3è¨€èªãƒ•ãƒ«ã‚¹ã‚¿ãƒƒã‚¯ |
| æœ€æ–°æ€§ | ã€œ2023 | 2024-2025æœ€å‰ç·š |
| ãƒ‡ãƒ¢ | ãªã— | SmolVLM2+LTX-Video |
:::

### 2.3 Videoç”Ÿæˆã®3ã¤ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ 

#### ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ â‘  3D U-Netï¼ˆã€œ2023ï¼‰

**ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**:
- 2D U-Netã‚’3Dï¼ˆæ™‚ç©ºé–“ï¼‰ã«æ‹¡å¼µ
- å„å±¤ã§3D Convolution
- ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ»ã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§æ™‚ç©ºé–“è§£åƒåº¦ã‚’åˆ¶å¾¡

**ä»£è¡¨ä¾‹**: Make-A-Videoï¼ˆMeta, 2022ï¼‰, Video LDMï¼ˆICLR 2023ï¼‰

**é™ç•Œ**:
- è¨ˆç®—é‡ãŒè«å¤§ï¼ˆ3D Convã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ï¼‰
- é•·æ™‚é–“å‹•ç”»ã¸ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å›°é›£

#### ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ â‘¡ DiTï¼ˆDiffusion Transformerï¼‰ï¼ˆ2024ã€œï¼‰

**ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**:
- U-Netã®å¸°ç´ãƒã‚¤ã‚¢ã‚¹ã‚’æ¨ã¦ã‚‹
- Transformerãƒ–ãƒ­ãƒƒã‚¯ã§Tokenã®ç³»åˆ—ã‚’å‡¦ç†
- å‹•ç”» = æ™‚ç©ºé–“Tokenã®ç³»åˆ—

**ä»£è¡¨ä¾‹**: Sora (OpenAI, 2024), CogVideoX (2024), Open-Sora 2.0 (2025)

**åˆ©ç‚¹**:
- Scaling LawsãŒé©ç”¨å¯èƒ½ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¢—ã‚„ã›ã°æ€§èƒ½å‘ä¸Šï¼‰
- é•·æ™‚é–“å‹•ç”»ã¸ã®æ‹¡å¼µãŒå®¹æ˜“

#### ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ â‘¢ Latent Flow Matchingï¼ˆ2025ã€œï¼‰

**ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**:
- Diffusionã®ä»£ã‚ã‚Šã«Flow Matchingã‚’ä½¿ç”¨
- Latentç©ºé–“ã§ã®ODEæ±‚è§£ â†’ é«˜é€Ÿã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

**ä»£è¡¨ä¾‹**: LTX-Video (2024), Open-Sora 2.0ï¼ˆéƒ¨åˆ†çš„ï¼‰

**åˆ©ç‚¹**:
- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—æ•°å‰Šæ¸›ï¼ˆ50 â†’ 10ã€œ20ï¼‰
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”Ÿæˆã«è¿‘ã¥ã

| ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ  | ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ | è¨ˆç®—é‡ | å“è³ª | ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ€§ |
|:-----------|:---------------|:-------|:-----|:---------------|
| 3D U-Net   | ç•³ã¿è¾¼ã¿       | é«˜     | ä¸­   | ä½             |
| DiT        | Transformer    | ä¸­     | é«˜   | é«˜             |
| Flow Matching | Transformer + FM | ä½ | é«˜   | é«˜             |

:::message
**ä»Šå›å­¦ã¶ã“ã¨**:
1. **3D U-Net**ã®é™ç•Œã‚’ç†è§£ï¼ˆZone 3ï¼‰
2. **DiT**ãŒãªãœå‹ã¤ã®ã‹ï¼ˆSora 2/CogVideoX, Zone 3-4ï¼‰
3. **Flow Matching**ã®é«˜é€ŸåŒ–æ‰‹æ³•ï¼ˆLTX-Video, Zone 4ï¼‰
4. SmolVLM2ã§å‹•ç”»ã‚’**ç†è§£**ã—ã€LTX-Videoã§**ç”Ÿæˆ**ã™ã‚‹ãƒ‡ãƒ¢ï¼ˆZone 5ï¼‰
:::

### 2.4 3ã¤ã®æ¯”å–©ã§æ‰ãˆã‚‹å‹•ç”»ç”Ÿæˆ

#### æ¯”å–©â‘  å‹•ç”» = ã€Œæ™‚é–“ã‚’å«ã‚€3Dç©ºé–“ã®ã‚¹ãƒ©ã‚¤ã‚¹ã€

é™æ­¢ç”»ãŒ2Dç©ºé–“ãªã‚‰ã€å‹•ç”»ã¯ã€Œ2Dç©ºé–“ + 1Dæ™‚é–“ = 3Dæ™‚ç©ºé–“ã€ã®ãƒ‡ãƒ¼ã‚¿ã€‚

```
æ™‚ç©ºé–“ã®ç«‹æ–¹ä½“:
    æ™‚é–“è»¸â†‘
         |  â–¡â–¡â–¡â–¡â–¡  â† å„ã‚¹ãƒ©ã‚¤ã‚¹ = 1ãƒ•ãƒ¬ãƒ¼ãƒ 
         |  â–¡â–¡â–¡â–¡â–¡
         |  â–¡â–¡â–¡â–¡â–¡
         |--â–¡â–¡â–¡â–¡â–¡--> ç©ºé–“è»¸(x, y)
```

3D U-Netã¯ã€Œç«‹æ–¹ä½“å…¨ä½“ã«ç•³ã¿è¾¼ã¿ã€ã€DiTã¯ã€Œç«‹æ–¹ä½“ã‚’Tokenã«åˆ†è§£ã—ã¦Transformerã€ã€‚

#### æ¯”å–©â‘¡ Temporal Attention = ã€Œãƒ”ã‚¯ã‚»ãƒ«ã®æ™‚é–“æ—…è¡Œã€

å„ãƒ”ã‚¯ã‚»ãƒ«ä½ç½®$(h, w)$ã«ã¤ã„ã¦ã€ã€Œéå»ãƒ»ç¾åœ¨ãƒ»æœªæ¥ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã€ã‚’å‚ç…§ã—ã¦Attentionã‚’è¨ˆç®—ã€‚

```
ãƒ•ãƒ¬ãƒ¼ãƒ 1: â—
ãƒ•ãƒ¬ãƒ¼ãƒ 2:   â—  â† ã“ã®ä½ç½®ã®ãƒ”ã‚¯ã‚»ãƒ«ãŒã€ãƒ•ãƒ¬ãƒ¼ãƒ 1,3ã‚’å‚ç…§
ãƒ•ãƒ¬ãƒ¼ãƒ 3:     â—
```

ã€ŒåŒã˜ä½ç½®ã®ãƒ”ã‚¯ã‚»ãƒ«ãŒæ™‚é–“è»¸ã§ã©ã†å¤‰åŒ–ã™ã‚‹ã‹ã€ã‚’å­¦ç¿’ â†’ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ»‘ã‚‰ã‹ãªå‹•ãã€‚

#### æ¯”å–©â‘¢ Optical Flow = ã€Œãƒ”ã‚¯ã‚»ãƒ«ã®å¼•ã£è¶Šã—ãƒãƒƒãƒ—ã€

å„ãƒ”ã‚¯ã‚»ãƒ«ãŒã€Œæ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã©ã“ã«ç§»å‹•ã™ã‚‹ã‹ã€ã‚’äºˆæ¸¬ã€‚

```
ãƒ•ãƒ¬ãƒ¼ãƒ t:     â—--â†’ flow=(+3, +1)
ãƒ•ãƒ¬ãƒ¼ãƒ t+1:      â—

flow lossãŒå°ã•ã„ = ã€Œå¼•ã£è¶Šã—å…ˆã€ãŒäºˆæ¸¬é€šã‚Š
```

ç‰©ç†çš„ã«ä¸€è²«ã—ãŸå‹•ãã‚’ä¿è¨¼ã™ã‚‹æš—é»™çš„ãªåˆ¶ç´„ã€‚

---

## ğŸ“ 3. æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ï¼ˆ60åˆ†ï¼‰â€” Video Diffusionã®å®Œå…¨ç†è«–

### 3.1 é™æ­¢ç”»ã‹ã‚‰å‹•ç”»ã¸ â€” Diffusionæ‹¡å¼µã®æ•°å­¦

#### 3.1.1 é™æ­¢ç”»Diffusionã®å¾©ç¿’

ç¬¬33-42å›ã§å­¦ã‚“ã DiffusionåŸºç¤ã‚’æŒ¯ã‚Šè¿”ã‚Šã¾ã—ã‚‡ã†ã€‚

**Forward Processï¼ˆãƒã‚¤ã‚ºè¿½åŠ ï¼‰**:
$$
q(\mathbf{x}_t \mid \mathbf{x}_0) = \mathcal{N}(\sqrt{\alpha_t}\mathbf{x}_0, (1-\alpha_t)\mathbf{I})
$$

**Reverse Processï¼ˆãƒã‚¤ã‚ºé™¤å»ï¼‰**:
$$
p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t) = \mathcal{N}(\boldsymbol{\mu}_\theta(\mathbf{x}_t, t), \sigma_t^2 \mathbf{I})
$$

**è¨“ç·´ç›®æ¨™ï¼ˆSimple Objectiveï¼‰**:
$$
\mathcal{L}_{\text{simple}} = \mathbb{E}_{t, \mathbf{x}_0, \boldsymbol{\epsilon}} \left[ \left\| \boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \right\|^2 \right]
$$

ã“ã“ã§ $\mathbf{x}_t = \sqrt{\alpha_t}\mathbf{x}_0 + \sqrt{1-\alpha_t}\boldsymbol{\epsilon}$, $\boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I})$ã€‚

#### 3.1.2 å‹•ç”»ã¸ã®æ‹¡å¼µ â€” ãƒ•ãƒ¬ãƒ¼ãƒ æ¬¡å…ƒã®è¿½åŠ 

å‹•ç”» $\mathbf{X}_0 = (\mathbf{x}_0^{(1)}, \mathbf{x}_0^{(2)}, \ldots, \mathbf{x}_0^{(T)})$ ã¯ $T$ å€‹ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ãªã‚‹ã€‚å„ãƒ•ãƒ¬ãƒ¼ãƒ  $\mathbf{x}_0^{(f)} \in \mathbb{R}^{H \times W \times 3}$ã€‚

**Naiveæ‹¡å¼µï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ ç‹¬ç«‹ï¼‰**:
$$
q(\mathbf{X}_t \mid \mathbf{X}_0) = \prod_{f=1}^{T} q(\mathbf{x}_t^{(f)} \mid \mathbf{x}_0^{(f)}) = \prod_{f=1}^{T} \mathcal{N}(\sqrt{\alpha_t}\mathbf{x}_0^{(f)}, (1-\alpha_t)\mathbf{I})
$$

**å•é¡Œç‚¹**: å„ãƒ•ãƒ¬ãƒ¼ãƒ ã«ç‹¬ç«‹ã«ãƒã‚¤ã‚ºã‚’åŠ ãˆã‚‹ â†’ æ™‚é–“çš„ä¸€è²«æ€§ãŒå´©å£Šã€‚

**è§£æ±ºç­–ï¼ˆCogVideoXç­‰ï¼‰**: Temporal Attentionã§ã€Œãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®ä¾å­˜é–¢ä¿‚ã€ã‚’å­¦ç¿’ã€‚ãƒã‚¤ã‚ºäºˆæ¸¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ $\boldsymbol{\epsilon}_\theta(\mathbf{X}_t, t)$ ãŒå…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚‹ã€‚

**æ‹¡å¼µç‰ˆè¨“ç·´ç›®æ¨™**:
$$
\mathcal{L}_{\text{video}} = \mathbb{E}_{t, \mathbf{X}_0, \mathbf{E}} \left[ \left\| \mathbf{E} - \boldsymbol{\epsilon}_\theta(\mathbf{X}_t, t, c) \right\|^2 \right]
$$

- $\mathbf{X}_t = \sqrt{\alpha_t}\mathbf{X}_0 + \sqrt{1-\alpha_t}\mathbf{E}$
- $\mathbf{E} = (\boldsymbol{\epsilon}^{(1)}, \ldots, \boldsymbol{\epsilon}^{(T)}) \sim \mathcal{N}(0, \mathbf{I})$ ï¼ˆå„ãƒ•ãƒ¬ãƒ¼ãƒ ã«ãƒã‚¤ã‚ºï¼‰
- $c$: ãƒ†ã‚­ã‚¹ãƒˆæ¡ä»¶ï¼ˆT5/CLIPåŸ‹ã‚è¾¼ã¿ï¼‰

:::message alert
**å¼•ã£ã‹ã‹ã‚Šãƒã‚¤ãƒ³ãƒˆ**: ã€Œãƒã‚¤ã‚ºã¯ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«ç‹¬ç«‹ã€ã ãŒã€ã€Œãƒã‚¤ã‚ºäºˆæ¸¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¦‹ã‚‹ã€ã€‚ã“ã®éå¯¾ç§°æ€§ãŒTemporal Coherenceã‚’ç”Ÿã‚€éµã€‚
:::

#### 3.1.3 Temporal Attentionã®å°å‡º

**å•é¡Œè¨­å®š**: ãƒ•ãƒ¬ãƒ¼ãƒ  $f$ ã®ãƒ”ã‚¯ã‚»ãƒ« $(h, w)$ ã«ã¤ã„ã¦ã€ã€Œä»–ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®åŒã˜ä½ç½®ã®ãƒ”ã‚¯ã‚»ãƒ«ã‚’ã©ã‚Œã ã‘å‚ç…§ã™ã¹ãã‹ã€ã‚’å­¦ç¿’ã—ãŸã„ã€‚

**Self-Attentionã®ä¸€èˆ¬å½¢ï¼ˆç¬¬14å›å¾©ç¿’ï¼‰**:
$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^\top}{\sqrt{d_k}}\right)V
$$

**å‹•ç”»ã¸ã®é©ç”¨**:
- å…¥åŠ›: $\mathbf{X} \in \mathbb{R}^{T \times H \times W \times C}$ ï¼ˆ$T$ãƒ•ãƒ¬ãƒ¼ãƒ ã€$H \times W$ç©ºé–“ã€$C$ãƒãƒ£ãƒãƒ«ï¼‰
- ä½ç½®$(h, w)$ã®æ™‚é–“ç³»åˆ—ã‚’æŠ½å‡º: $\mathbf{z}_{h,w} = (\mathbf{x}^{(1)}_{h,w}, \ldots, \mathbf{x}^{(T)}_{h,w}) \in \mathbb{R}^{T \times C}$
- $Q, K, V$ ã‚’ç·šå½¢å¤‰æ›ã§ç”Ÿæˆ:
  $$
  Q = \mathbf{z}_{h,w} W_Q, \quad K = \mathbf{z}_{h,w} W_K, \quad V = \mathbf{z}_{h,w} W_V
  $$

**Temporal Attention**:
$$
\text{Temporal-Attention}(\mathbf{z}_{h,w}) = \text{softmax}\left(\frac{QK^\top}{\sqrt{d_k}}\right)V
$$

**è¨ˆç®—é‡**: ä½ç½®$(h, w)$ã”ã¨ã« $O(T^2 C)$ã€‚å…¨ä½“ã§ $O(HWT^2C)$ã€‚

:::details Spatial vs Temporal Attentionã®è¨ˆç®—é‡æ¯”è¼ƒ

| Attentionç¨®é¡ | è¨ˆç®—å¯¾è±¡ | è¨ˆç®—é‡ | ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ |
|:--------------|:---------|:-------|:-------------|
| Spatial       | å„ãƒ•ãƒ¬ãƒ¼ãƒ å†… | $O(H^2W^2C \cdot T)$ | ç©ºé–“è§£åƒåº¦ |
| Temporal      | å„ãƒ”ã‚¯ã‚»ãƒ«ä½ç½®ã®æ™‚é–“ç³»åˆ— | $O(HWT^2C)$ | ãƒ•ãƒ¬ãƒ¼ãƒ æ•° |

**å®Ÿç”¨ä¸Šã®å¯¾ç­–**:
- Spatial: FlashAttentionï¼ˆç¬¬15å›ï¼‰ã§é«˜é€ŸåŒ–
- Temporal: ãƒ­ãƒ¼ã‚«ãƒ«Attentionï¼ˆè¿‘å‚ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ï¼‰ã‚„Strideï¼ˆæ•°ãƒ•ãƒ¬ãƒ¼ãƒ ãŠãï¼‰
:::

### 3.2 3D U-Net vs DiT â€” ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¯¾æ±º

#### 3.2.1 3D U-Netã®æ§‹é€ 

**åŸºæœ¬æ§‹æˆ**:
```
å…¥åŠ›: (B, T, C, H, W)  # ãƒãƒƒãƒã€ãƒ•ãƒ¬ãƒ¼ãƒ ã€ãƒãƒ£ãƒãƒ«ã€é«˜ã•ã€å¹…
    â†“ 3D Conv (stride=2, æ™‚ç©ºé–“ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°)
(B, T/2, 2C, H/2, W/2)
    â†“ 3D Conv
(B, T/4, 4C, H/4, W/4)  # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯
    â†“ 3D ConvTranspose (ã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°)
(B, T/2, 2C, H/2, W/2)
    â†“ 3D ConvTranspose
(B, T, C, H, W)  # å‡ºåŠ›
```

**3D Convã®å®šå¼åŒ–**:
$$
y_{b,t,c,h,w} = \sum_{t'=-k_t/2}^{k_t/2} \sum_{h'=-k_h/2}^{k_h/2} \sum_{w'=-k_w/2}^{k_w/2} \sum_{c'=1}^{C_{in}} w_{t',h',w',c',c} \cdot x_{b, t+t', c', h+h', w+w'}
$$

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°**:
$$
\text{Params} = k_t \times k_h \times k_w \times C_{in} \times C_{out}
$$

å…¸å‹çš„ãª3Ã—3Ã—3ã‚«ãƒ¼ãƒãƒ«ã€64â†’128ãƒãƒ£ãƒãƒ«: $3 \times 3 \times 3 \times 64 \times 128 = 221K$ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚

**å•é¡Œç‚¹**:
1. **Scalingé™ç•Œ**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒ $k_t$ å€ã«å¢—ãˆã‚‹
2. **å¸°ç´ãƒã‚¤ã‚¢ã‚¹**: Convã®å±€æ‰€æ€§ â†’ é•·è·é›¢ä¾å­˜ã¯è‹¦æ‰‹
3. **å¯å¤‰é•·å¯¾å¿œå›°é›£**: ãƒ•ãƒ¬ãƒ¼ãƒ æ•° $T$ ãŒå¤‰ã‚ã‚‹ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å†è¨­è¨ˆå¿…è¦

#### 3.2.2 DiTï¼ˆDiffusion Transformerï¼‰ã®æ§‹é€ 

**åŸºæœ¬æ§‹æˆ**:
```
å…¥åŠ›: (B, T, H, W, C)
    â†“ Patchify (patch_size=16) â€” 16x16ã®ãƒ‘ãƒƒãƒã«åˆ†å‰²
(B, TÃ—H/16Ã—W/16, CÃ—16Ã—16)  # Tokenç³»åˆ—
    â†“ Linear Projection
(B, N_tokens, D)  # D=åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒï¼ˆä¾‹: 768ï¼‰
    â†“ Transformer Blocks (Lå±¤)
(B, N_tokens, D)
    â†“ Linear â†’ Unpatchify
(B, T, H, W, C)  # å‡ºåŠ›
```

**Transformer Blockã®æ•°å¼**:
$$
\mathbf{h}' = \mathbf{h} + \text{Attention}(\text{LN}(\mathbf{h}))
$$
$$
\mathbf{h}'' = \mathbf{h}' + \text{MLP}(\text{LN}(\mathbf{h}'))
$$

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ï¼ˆå±¤ã‚ãŸã‚Šï¼‰**:
$$
\text{Params}_{\text{Attn}} = 4D^2 + 4D, \quad \text{Params}_{\text{MLP}} = 8D^2 + 5D
$$

$D=768$ã€$L=12$å±¤: ç´„85M ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆU-Netã‚ˆã‚Šå°‘ãªã„ï¼‰ã€‚

**åˆ©ç‚¹**:
1. **Scaling Lawsé©ç”¨å¯èƒ½**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¢—ã‚„ã›ã°æ€§èƒ½å‘ä¸Šï¼ˆç¬¬14å› Scaling Lawsï¼‰
2. **å¯å¤‰é•·å¯¾å¿œ**: Tokenæ•°ãŒå¤‰ã‚ã‚‹ã ã‘ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¸å¤‰
3. **é•·è·é›¢ä¾å­˜**: Attentionã§å…¨Tokenå‚ç…§

:::message
**ãƒœã‚¹æˆ¦äºˆå‘Š**: Sora 2ã®ã€ŒSpacetime DiTã€ã¯æ™‚ç©ºé–“ã‚’çµ±ä¸€Tokenã¨ã—ã¦æ‰±ã†ã€‚3D U-Netã¨ã®æ±ºå®šçš„ãªé•ã„ã‚’å®Œå…¨è¨¼æ˜ â†’ æ¬¡ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã€‚
:::

### 3.3 Sora 2 Spacetime DiT â€” æ™‚ç©ºé–“çµ±ä¸€ã®é©å‘½

#### 3.3.1 Spacetime Patchifyã®æ•°å¼

**å¾“æ¥ã®DiTï¼ˆç”»åƒï¼‰**: 2Dç©ºé–“ã®ã¿ãƒ‘ãƒƒãƒåŒ–
$$
\text{Patch}_{i,j} = \mathbf{x}[i \cdot p : (i+1) \cdot p, \, j \cdot p : (j+1) \cdot p, :]
$$

**Sora 2 Spacetime DiT**: æ™‚é–“è»¸ã‚‚ãƒ‘ãƒƒãƒåŒ–
$$
\text{Patch}_{t,i,j} = \mathbf{X}[t \cdot p_t : (t+1) \cdot p_t, \, i \cdot p : (i+1) \cdot p, \, j \cdot p : (j+1) \cdot p, :]
$$

- $p_t$: æ™‚é–“æ–¹å‘ã®ãƒ‘ãƒƒãƒã‚µã‚¤ã‚ºï¼ˆä¾‹: 4ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
- $p$: ç©ºé–“æ–¹å‘ã®ãƒ‘ãƒƒãƒã‚µã‚¤ã‚ºï¼ˆä¾‹: 16ãƒ”ã‚¯ã‚»ãƒ«ï¼‰

**Tokenæ•°**:
$$
N_{\text{tokens}} = \frac{T}{p_t} \times \frac{H}{p} \times \frac{W}{p}
$$

**å…·ä½“ä¾‹**: $T=120$ãƒ•ãƒ¬ãƒ¼ãƒ ã€$H=W=512$ã€$p_t=4$ã€$p=16$
$$
N_{\text{tokens}} = \frac{120}{4} \times \frac{512}{16} \times \frac{512}{16} = 30 \times 32 \times 32 = 30,720 \text{ tokens}
$$

#### 3.3.2 Spacetime Attentionã®å®Œå…¨å°å‡º

**å•é¡Œè¨­å®š**: æ™‚ç©ºé–“Token $\mathbf{z}_{t,i,j} \in \mathbb{R}^D$ ã«ã¤ã„ã¦ã€ã€Œä»–ã®æ™‚ç©ºé–“Tokenã‚’ã©ã‚Œã ã‘å‚ç…§ã™ã¹ãã‹ã€ã‚’è¨ˆç®—ã€‚

**Self-Attention**:
$$
Q = \mathbf{Z}W_Q, \quad K = \mathbf{Z}W_K, \quad V = \mathbf{Z}W_V
$$

ã“ã“ã§ $\mathbf{Z} \in \mathbb{R}^{N_{\text{tokens}} \times D}$ ã¯å…¨Tokenã‚’ä¸¦ã¹ãŸè¡Œåˆ—ã€‚

**Attentioné‡ã¿**:
$$
A = \text{softmax}\left(\frac{QK^\top}{\sqrt{d_k}}\right) \in \mathbb{R}^{N_{\text{tokens}} \times N_{\text{tokens}}}
$$

**å‡ºåŠ›**:
$$
\mathbf{Z}' = AV
$$

**è¨ˆç®—é‡**: $O(N_{\text{tokens}}^2 \cdot D) = O\left(\left(\frac{THW}{p_t p^2}\right)^2 \cdot D\right)$

:::message alert
**å¼•ã£ã‹ã‹ã‚Šãƒã‚¤ãƒ³ãƒˆ**: Spacetime Attentionã¯Tokenæ•°ãŒ$T/(p_t)$å€ã«ãªã‚‹ãŸã‚ã€è¨ˆç®—é‡ãŒçˆ†ç™ºã™ã‚‹ã€‚

**Sora 2ã®å¯¾ç­–**:
1. **3D VAEã§æ™‚ç©ºé–“åœ§ç¸®**: $T \times H \times W \to T' \times H' \times W'$ ï¼ˆ$T' \ll T$ï¼‰
2. **Sparse Attention**: å…¨Tokenã§ã¯ãªãå±€æ‰€çš„ã«å‚ç…§ï¼ˆç¬¬15å› Sparse Attentionï¼‰
3. **Flash Attention**: SRAMæœ€é©åŒ–ï¼ˆç¬¬15å›ï¼‰
:::

#### 3.3.3 3D U-Net vs Spacetime DiTã®ç†è«–çš„æ¯”è¼ƒ

**å®šç†ï¼ˆSoraè«–æ–‡ã®ä¸»å¼µï¼‰**: Spacetime DiTã¯3D U-Netã‚ˆã‚Šã‚‚**è¡¨ç¾åŠ›ãŒé«˜ã„**ã€‚

**è¨¼æ˜ã‚¹ã‚±ãƒƒãƒ**:

1. **3D U-Netã®å—å®¹é‡**:
   - $L$å±¤ã®U-Netã€å„å±¤ã®ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º $k \times k \times k$
   - æœ‰åŠ¹å—å®¹é‡: $R \approx k \cdot 2^L$ï¼ˆãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§æŒ‡æ•°çš„æ‹¡å¤§ï¼‰
   - ã—ã‹ã—ã€**æœ‰é™**: é ãé›¢ã‚ŒãŸãƒ”ã‚¯ã‚»ãƒ«ã¯ç›´æ¥ä¾å­˜ã—ãªã„

2. **Spacetime DiTã®å—å®¹é‡**:
   - Attentionã¯**å…¨Tokenå‚ç…§**
   - å—å®¹é‡ = **ç„¡é™**ï¼ˆç†è«–ä¸Šï¼‰

3. **Universal Approximation**:
   - Transformerã¯ä»»æ„ã®é–¢æ•°ã‚’è¿‘ä¼¼å¯èƒ½ï¼ˆYun+ 2019 [^1]ï¼‰
   - U-Netã¯å±€æ‰€çš„ãªé–¢æ•°ã®ã¿

**çµŒé¨“å‰‡ï¼ˆSora 2 System Cardï¼‰**: DiTã¯é•·æ™‚é–“å‹•ç”»ï¼ˆ15-25ç§’ï¼‰ã§U-Netã‚’åœ§å€’ã€‚

:::details 3D U-Net vs Spacetime DiTã®æ€§èƒ½æ¯”è¼ƒè¡¨

| æŒ‡æ¨™ | 3D U-Net | Spacetime DiT |
|:-----|:---------|:--------------|
| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡ | ä½ï¼ˆConvé‡è¤‡ï¼‰ | é«˜ï¼ˆå…±æœ‰Attentionï¼‰ |
| è¨ˆç®—é‡ï¼ˆè¨“ç·´æ™‚ï¼‰ | $O(k^3 CHW T)$ | $O(N^2 D)$, $N=THW/(p_t p^2)$ |
| é•·è·é›¢ä¾å­˜ | æœ‰é™å—å®¹é‡ | å…¨Tokenå‚ç…§ |
| å¯å¤‰é•·å¯¾å¿œ | å›°é›£ï¼ˆå†è¨“ç·´å¿…è¦ï¼‰ | å®¹æ˜“ï¼ˆTokenæ•°å¤‰åŒ–ã®ã¿ï¼‰ |
| å®Ÿè£…è¤‡é›‘åº¦ | ä¸­ï¼ˆConvå®Ÿè£…ï¼‰ | é«˜ï¼ˆAttentionæœ€é©åŒ–ï¼‰ |
| å“è³ªï¼ˆVBenchï¼‰ | 70-75ç‚¹ | 80-85ç‚¹ï¼ˆSora 2ï¼‰ |

**VBench**: å‹•ç”»ç”Ÿæˆã®åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆæ™‚é–“çš„ä¸€è²«æ€§ã€ç‰©ç†çš„æ­£ç¢ºæ€§ã€ç¾çš„å“è³ªãªã©16æŒ‡æ¨™ï¼‰
:::

### 3.4 CogVideoX 3D VAE â€” æ™‚ç©ºé–“åœ§ç¸®ã®æ•°å­¦

#### 3.4.1 3D VAEã®æ§‹é€ 

**ç›®çš„**: å‹•ç”» $\mathbf{X} \in \mathbb{R}^{T \times H \times W \times 3}$ ã‚’ä½æ¬¡å…ƒLatent $\mathbf{Z} \in \mathbb{R}^{T' \times H' \times W' \times C}$ ã«åœ§ç¸®ã€‚

**Encoder**:
$$
q_\phi(\mathbf{z} \mid \mathbf{x}) = \mathcal{N}(\boldsymbol{\mu}_\phi(\mathbf{x}), \text{diag}(\boldsymbol{\sigma}_\phi^2(\mathbf{x})))
$$

**Decoder**:
$$
p_\theta(\mathbf{x} \mid \mathbf{z}) = \mathcal{N}(\boldsymbol{\mu}_\theta(\mathbf{z}), \sigma^2 \mathbf{I})
$$

**3D Convå±¤ã®ä¾‹**ï¼ˆEncoderï¼‰:
```
(T, H, W, 3) â†’ 3D Conv(kernel=3x3x3, stride=2x2x2)
    â†’ (T/2, H/2, W/2, 64)
    â†’ 3D Conv(stride=2)
    â†’ (T/4, H/4, W/4, 128)
    â†’ ... (åˆè¨ˆ4-5å±¤)
    â†’ (T', H', W', C)  # C=4 or 8
```

**åœ§ç¸®ç‡**:
$$
r = \frac{T \times H \times W \times 3}{T' \times H' \times W' \times C}
$$

CogVideoXã®ä¾‹: $T=49$, $H=W=768$, $T'=13$, $H'=W'=96$, $C=16$
$$
r = \frac{49 \times 768 \times 768 \times 3}{13 \times 96 \times 96 \times 16} = \frac{86.7M}{1.93M} \approx 45
$$

ãŸã ã—ã€è«–æ–‡ã§ã¯**æ™‚ç©ºé–“åˆã‚ã›ã¦192å€åœ§ç¸®**ã¨è¨˜è¼‰ â†’ Encoderã®è¤‡æ•°æ®µéšã§ã®ç´¯ç©åœ§ç¸®ã€‚

#### 3.4.2 Temporal Compressionã®è©³ç´°

**å•é¡Œ**: æ™‚é–“è»¸ã®åœ§ç¸® $T \to T'$ ã§æƒ…å ±æå¤±ãŒç™ºç”Ÿ â†’ å‹•ãã®æ»‘ã‚‰ã‹ã•ãŒåŠ£åŒ–ã€‚

**è§£æ±ºç­–ï¼ˆCogVideoXï¼‰**: Causal 3D Convã§ã€Œéå»ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ã€ã‚’å‚ç…§ã€‚

**Causal Padding**:
$$
\text{Padding}_{\text{causal}}(x_t) = \text{Concat}([x_{t-k+1}, \ldots, x_{t-1}], x_t)
$$

**é€šå¸¸ã®Convã¨ã®é•ã„**:

| Convç¨®é¡ | Padding | å‚ç…§ç¯„å›² | ç”¨é€” |
|:---------|:--------|:---------|:-----|
| é€šå¸¸3D Conv | å‰å¾Œå¯¾ç§° | éå»+æœªæ¥ | è¨“ç·´æ™‚ã®ã¿ï¼ˆTeacher Forcingï¼‰ |
| Causal 3D Conv | éå»ã®ã¿ | éå»ã®ã¿ | æ¨è«–æ™‚ã«ä½¿ãˆã‚‹ |

**æ•°å¼**ï¼ˆCausal 3D Convï¼‰:
$$
y_t = \sum_{i=0}^{k-1} w_i \cdot x_{t-i}
$$

ã“ã“ã§ $k$ ã¯ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºï¼ˆæ™‚é–“æ–¹å‘ï¼‰ã€‚

:::message
**ãƒœã‚¹æˆ¦ã‚¯ãƒªã‚¢**: 3D VAEã®åœ§ç¸®ç‡ã¯ã€Œç©ºé–“Ã—æ™‚é–“ã€ã®ç©ã§è¨ˆç®—ã•ã‚Œã‚‹ã€‚CogVideoXã¯**192å€**ã¨ã„ã†é©šç•°çš„ãªåœ§ç¸®ã‚’å®Ÿç¾ â†’ Latentç©ºé–“ã§Diffusionã‚’è¡Œã†ã“ã¨ã§ã€è¨ˆç®—é‡ã‚’$1/192$ã«å‰Šæ¸›ã€‚
:::

### 3.5 Optical Flow Lossã¨Warpé–¢æ•°ã®å®Œå…¨å°å‡º

#### 3.5.1 Optical Flowã®å®šå¼åŒ–

**å®šç¾©**: ãƒ•ãƒ¬ãƒ¼ãƒ $t$ã‹ã‚‰$t+1$ã¸ã®å„ãƒ”ã‚¯ã‚»ãƒ«ã®å‹•ããƒ™ã‚¯ãƒˆãƒ«ã€‚
$$
\mathbf{f}_{t \to t+1}(h, w) = (u_{h,w}, v_{h,w}) \in \mathbb{R}^2
$$

- $u_{h,w}$: æ°´å¹³æ–¹å‘ã®ç§»å‹•é‡ï¼ˆãƒ”ã‚¯ã‚»ãƒ«å˜ä½ï¼‰
- $v_{h,w}$: å‚ç›´æ–¹å‘ã®ç§»å‹•é‡

**è¼åº¦ä¸€å®šã®ä»®å®š**ï¼ˆLucas-Kanadeæ³•ã®åŸºç¤ï¼‰:
$$
I(h, w, t) = I(h + u, w + v, t+1)
$$

ã“ã“ã§ $I$ ã¯ç”»åƒã®è¼åº¦å€¤ã€‚

**Taylorå±•é–‹ã«ã‚ˆã‚‹ç·šå½¢åŒ–**:
$$
I(h+u, w+v, t+1) \approx I(h, w, t+1) + \frac{\partial I}{\partial h}u + \frac{\partial I}{\partial w}v
$$

**è¼åº¦ä¸€å®šã®ä»®å®šã‚’ä»£å…¥**:
$$
I(h, w, t) = I(h, w, t+1) + I_h u + I_w v
$$

æ•´ç†ã™ã‚‹ã¨:
$$
I_h u + I_w v + I_t = 0
$$

ã“ã‚ŒãŒ**Optical Flowåˆ¶ç´„æ–¹ç¨‹å¼**ï¼ˆ1ãƒ”ã‚¯ã‚»ãƒ«ã‚ãŸã‚Š1å¼ã€æœªçŸ¥æ•°2ã¤ â†’ ä¸å®šï¼‰ã€‚

#### 3.5.2 Warpé–¢æ•°ã®å°å‡º

**ç›®çš„**: ãƒ•ãƒ¬ãƒ¼ãƒ $t$ã‚’ãƒ•ãƒ­ãƒ¼$\mathbf{f}_{t \to t+1}$ã«å¾“ã£ã¦å¤‰å½¢ã—ã€ãƒ•ãƒ¬ãƒ¼ãƒ $t+1$ã¨æ¯”è¼ƒã€‚

**å®šç¾©**:
$$
\text{Warp}(\mathbf{x}_t, \mathbf{f})_{h,w} = \mathbf{x}_t(h + v_{h,w}, w + u_{h,w})
$$

ã“ã“ã§ $(h + v, w + u)$ ã¯ä¸€èˆ¬ã«æ•´æ•°ã§ãªã„ â†’ **Bilinearè£œé–“**ãŒå¿…è¦ã€‚

**Bilinearè£œé–“ã®æ•°å¼**:
$$
\mathbf{x}_t(h', w') = (1-\alpha)(1-\beta)\mathbf{x}_t(\lfloor h' \rfloor, \lfloor w' \rfloor) + \alpha(1-\beta)\mathbf{x}_t(\lceil h' \rceil, \lfloor w' \rfloor)
$$
$$
+ (1-\alpha)\beta\mathbf{x}_t(\lfloor h' \rfloor, \lceil w' \rceil) + \alpha\beta\mathbf{x}_t(\lceil h' \rceil, \lceil w' \rceil)
$$

ã“ã“ã§:
- $\alpha = h' - \lfloor h' \rfloor$ ï¼ˆå°æ•°éƒ¨åˆ†ï¼‰
- $\beta = w' - \lfloor w' \rfloor$

**Optical Flow Loss**:
$$
\mathcal{L}_{\text{flow}} = \frac{1}{T-1} \sum_{t=1}^{T-1} \left\| \mathbf{x}_{t+1} - \text{Warp}(\mathbf{x}_t, \mathbf{f}_{t \to t+1}) \right\|^2
$$

#### 3.5.3 FlowNetã«ã‚ˆã‚‹End-to-Endæ¨å®š

**å•é¡Œ**: Optical Flowã‚’å¤å…¸çš„æ‰‹æ³•ï¼ˆLucas-Kanadeç­‰ï¼‰ã§æ¨å®š â†’ é…ã„ã€ãƒã‚¤ã‚ºã«å¼±ã„ã€‚

**è§£æ±ºç­–**: CNNã§End-to-Endã«æ¨å®šï¼ˆFlowNet / RAFTï¼‰ã€‚

**FlowNetã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**:
```
å…¥åŠ›: (ãƒ•ãƒ¬ãƒ¼ãƒ t, ãƒ•ãƒ¬ãƒ¼ãƒ t+1) âˆˆ R^(2Ã—HÃ—WÃ—3)
    â†“ Encoder (CNN)
Latent: R^(H/4Ã—W/4Ã—C)
    â†“ Decoder (Transposed Conv)
å‡ºåŠ›: Flow âˆˆ R^(HÃ—WÃ—2)
```

**è¨“ç·´ç›®æ¨™**:
$$
\mathcal{L}_{\text{FlowNet}} = \mathbb{E}_{(\mathbf{x}_t, \mathbf{x}_{t+1}, \mathbf{f}_{\text{gt}})} \left[ \left\| \mathbf{f}_{\text{pred}} - \mathbf{f}_{\text{gt}} \right\|^2 \right]
$$

ã“ã“ã§ $\mathbf{f}_{\text{gt}}$ ã¯Ground Truth Flowï¼ˆåˆæˆãƒ‡ãƒ¼ã‚¿ã§ç”Ÿæˆï¼‰ã€‚

:::details RAFTï¼ˆRecurrent All-Pairs Field Transformsï¼‰ã®æ”¹å–„

**RAFTï¼ˆECCV 2020ï¼‰**ã¯ã€Œåå¾©çš„Flowæ¨å®šã€ã‚’å°å…¥:
1. åˆæœŸFlow $\mathbf{f}^{(0)} = 0$ ã‹ã‚‰é–‹å§‹
2. $K$å›ã®åå¾©ã§æ®µéšçš„ã«ç²¾ç·»åŒ–:
   $$
   \mathbf{f}^{(k+1)} = \mathbf{f}^{(k)} + \Delta\mathbf{f}^{(k)}
   $$
3. $\Delta\mathbf{f}^{(k)}$ ã¯GRUã§è¨ˆç®—ï¼ˆçŠ¶æ…‹ã‚’ä¿æŒï¼‰

**åˆ©ç‚¹**: FlowNetã‚ˆã‚Šç²¾åº¦ãŒé«˜ãã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ãŒå¯èƒ½ï¼ˆ30 FPSï¼‰ã€‚
:::

### 3.6 âš”ï¸ Boss Battle: Sora 2ã®Spacetime DiTã‚’å®Œå…¨èª­è§£

**ç›®æ¨™**: Sora 2ã®è«–æ–‡ï¼ˆOpenAI Technical Report, 2024ï¼‰ã®æ ¸å¿ƒéƒ¨åˆ†ã‚’1è¡Œãšã¤åˆ†è§£ã€‚

#### ãƒœã‚¹æˆ¦ãƒ•ã‚§ãƒ¼ã‚º1: Spacetime Patchifyã®æ•°å¼å±•é–‹

**è«–æ–‡ã®è¨˜è¿°**:
> "We represent videos as sequences of patches in space and time."

**æ•°å¼åŒ–**:

å…¥åŠ›å‹•ç”» $\mathbf{X} \in \mathbb{R}^{T \times H \times W \times 3}$ ã‚’æ™‚ç©ºé–“ãƒ‘ãƒƒãƒã«åˆ†å‰²:
$$
\mathbf{P}_{t,i,j} = \mathbf{X}[t \cdot p_t : (t+1) \cdot p_t, \, i \cdot p_s : (i+1) \cdot p_s, \, j \cdot p_s : (j+1) \cdot p_s, :]
$$

ã“ã“ã§:
- $p_t$: æ™‚é–“æ–¹å‘ã®ãƒ‘ãƒƒãƒã‚µã‚¤ã‚ºï¼ˆä¾‹: 1ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
- $p_s$: ç©ºé–“æ–¹å‘ã®ãƒ‘ãƒƒãƒã‚µã‚¤ã‚ºï¼ˆä¾‹: 16Ã—16ãƒ”ã‚¯ã‚»ãƒ«ï¼‰

**ãƒ‘ãƒƒãƒã‚’ãƒ™ã‚¯ãƒˆãƒ«ã«å±•é–‹**:
$$
\mathbf{z}_{t,i,j} = \text{Flatten}(\mathbf{P}_{t,i,j}) \in \mathbb{R}^{p_t \cdot p_s \cdot p_s \cdot 3}
$$

**ç·šå½¢å°„å½±ã§åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ$D$ã¸**:
$$
\mathbf{h}_{t,i,j} = \mathbf{z}_{t,i,j} W_{\text{embed}} + \mathbf{b}_{\text{embed}}, \quad W_{\text{embed}} \in \mathbb{R}^{(p_t p_s^2 \cdot 3) \times D}
$$

**Tokenæ•°**:
$$
N = \frac{T}{p_t} \times \frac{H}{p_s} \times \frac{W}{p_s}
$$

**æ•°å€¤ä¾‹ï¼ˆSora 2æ¨å®šï¼‰**: $T=120$ãƒ•ãƒ¬ãƒ¼ãƒ ã€$H=W=1024$ã€$p_t=1$ã€$p_s=16$
$$
N = 120 \times 64 \times 64 = 491,520 \text{ tokens}
$$

#### ãƒœã‚¹æˆ¦ãƒ•ã‚§ãƒ¼ã‚º2: DiT Blockã®æ¡ä»¶ä»˜ã‘æ©Ÿæ§‹

**è«–æ–‡ã®è¨˜è¿°**:
> "We condition on text using a cross-attention mechanism."

**æ•°å¼åŒ–**:

ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ï¼ˆT5-XXLï¼‰ã§æ¡ä»¶$c$ã‚’åŸ‹ã‚è¾¼ã¿:
$$
\mathbf{C} = \text{T5}(c) \in \mathbb{R}^{L_{\text{text}} \times D_{\text{text}}}
$$

**DiT Blockå†…ã®Cross-Attention**:
$$
Q = \mathbf{H}W_Q, \quad K = \mathbf{C}W_K, \quad V = \mathbf{C}W_V
$$

ã“ã“ã§ $\mathbf{H} \in \mathbb{R}^{N \times D}$ ã¯å‹•ç”»Tokenã€$\mathbf{C}$ ã¯ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ã€‚

**Attentionå‡ºåŠ›**:
$$
\mathbf{H}' = \mathbf{H} + \text{softmax}\left(\frac{QK^\top}{\sqrt{d_k}}\right)V
$$

**AdaLNï¼ˆAdaptive Layer Normalizationï¼‰ã«ã‚ˆã‚‹æ¡ä»¶ä»˜ã‘**ï¼ˆDiTè«–æ–‡ã®æ‰‹æ³•ï¼‰:
$$
\text{AdaLN}(\mathbf{h}, c) = \gamma(c) \cdot \frac{\mathbf{h} - \mu}{\sigma} + \beta(c)
$$

ã“ã“ã§ $\gamma(c), \beta(c)$ ã¯MLPã§è¨ˆç®—ã•ã‚Œã‚‹ã‚¹ã‚±ãƒ¼ãƒ«ãƒ»ã‚·ãƒ•ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚

#### ãƒœã‚¹æˆ¦ãƒ•ã‚§ãƒ¼ã‚º3: æ™‚é–“çš„ä¸€è²«æ€§ã®ä¿è¨¼ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 

**è«–æ–‡ã®è¨˜è¿°**:
> "Sora is trained to predict clean videos directly from noisy inputs, enabling temporal consistency."

**è¨“ç·´ç›®æ¨™ï¼ˆæ¨å®šï¼‰**:
$$
\mathcal{L} = \mathbb{E}_{t, \mathbf{X}_0, \mathbf{E}, c} \left[ \left\| \mathbf{X}_0 - \mathbf{f}_\theta(\mathbf{X}_t, t, c) \right\|^2 \right]
$$

ã“ã“ã§:
- $\mathbf{X}_t = \sqrt{\alpha_t}\mathbf{X}_0 + \sqrt{1-\alpha_t}\mathbf{E}$
- $\mathbf{f}_\theta$: DiTã®ãƒã‚¤ã‚ºäºˆæ¸¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯

**Temporal Coherenceã®ä¿è¨¼**: DiTãŒå…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åŒæ™‚ã«å‡¦ç† â†’ ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®ä¾å­˜é–¢ä¿‚ã‚’å­¦ç¿’ â†’ æ™‚é–“çš„ä¸€è²«æ€§ãŒå‰µç™ºã€‚

**ç‰©ç†æ³•å‰‡ã®å­¦ç¿’**: å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆæ¨å®š1Bå‹•ç”»ï¼‰ã§è¨“ç·´ â†’ æš—é»™çš„ã«ç‰©ç†æ³•å‰‡ã‚’å­¦ç¿’ï¼ˆé‡åŠ›ã€æ…£æ€§ã€è¡çªï¼‰ã€‚

:::message
**ãƒœã‚¹æ’ƒç ´**: Sora 2ã®Spacetime DiTã¯ã€æ™‚ç©ºé–“ã‚’çµ±ä¸€Tokenã¨ã—ã¦æ‰±ã„ã€Cross-Attentionã¨AdaLNã§ãƒ†ã‚­ã‚¹ãƒˆæ¡ä»¶ä»˜ã‘ã€å…¨ãƒ•ãƒ¬ãƒ¼ãƒ åŒæ™‚å‡¦ç†ã§æ™‚é–“çš„ä¸€è²«æ€§ã‚’å®Ÿç¾ã€‚3D U-Netã®ã€Œå±€æ‰€ç•³ã¿è¾¼ã¿ã€ã‹ã‚‰ã€Œå¤§åŸŸAttentionã€ã¸ã®é©å‘½ã€‚
:::

---

## ğŸ”§ 4. å®Ÿè£…ã‚¾ãƒ¼ãƒ³ï¼ˆ45åˆ†ï¼‰â€” Rustã§3D Conv + Julia DiTè¨“ç·´

**ã‚´ãƒ¼ãƒ«**: 3D Convolution ã‚«ãƒ¼ãƒãƒ«ã‚’Rustã§å®Ÿè£…ã—ã€DiTè¨“ç·´ã‚’Juliaã§é«˜é€ŸåŒ–ã™ã‚‹ã€‚

### 4.1 Rust 3D Convolution: C Pointer Modelã§é«˜é€ŸåŒ–

Zone 1ã§å­¦ã‚“ã 3D Convã®æ•°å¼ã‚’Rustã§å®Ÿè£…ã™ã‚‹ã€‚C Pointer Modelã«å¾“ã„ã€zero-copyè¨­è¨ˆã‚’å¾¹åº•ã™ã‚‹ã€‚

```rust
// src/video_kernels.rs â€” Rust 3D Convolution (C-ABIå¯¾å¿œ)

#![deny(clippy::unwrap_used)]
#![warn(clippy::pedantic, missing_docs)]

/// 3D Convolution: (T, H, W, C_in) * (k_t, k_h, k_w, C_in, C_out) â†’ (T, H, W, C_out)
/// Rust Pointer Model: flat array + offsetè¨ˆç®— = zero-copy
#[no_mangle]
pub unsafe extern "C" fn conv3d_forward(
    input: *const f32,      // (T, H, W, C_in)
    kernel: *const f32,     // (k_t, k_h, k_w, C_in, C_out)
    output: *mut f32,       // (T, H, W, C_out) â€” caller allocates
    T: usize, H: usize, W: usize,
    C_in: usize, C_out: usize,
    k_t: usize, k_h: usize, k_w: usize,
) {
    let pad_t = k_t / 2;
    let pad_h = k_h / 2;
    let pad_w = k_w / 2;

    for t in 0..T {
        for h in 0..H {
            for w in 0..W {
                for c_out in 0..C_out {
                    let mut sum = 0.0f32;

                    // 3D Convolution loop
                    for kt in 0..k_t {
                        for kh in 0..k_h {
                            for kw in 0..k_w {
                                let t_idx = (t + kt).wrapping_sub(pad_t);
                                let h_idx = (h + kh).wrapping_sub(pad_h);
                                let w_idx = (w + kw).wrapping_sub(pad_w);

                                // Bounds check
                                if t_idx >= T || h_idx >= H || w_idx >= W {
                                    continue;
                                }

                                for c_in in 0..C_in {
                                    // Input: (T, H, W, C_in) flat index
                                    let input_idx = ((t_idx * H + h_idx) * W + w_idx) * C_in + c_in;
                                    // Kernel: (k_t, k_h, k_w, C_in, C_out) flat index
                                    let kernel_idx = ((((kt * k_h + kh) * k_w + kw) * C_in + c_in) * C_out + c_out);

                                    sum += *input.add(input_idx) * *kernel.add(kernel_idx);
                                }
                            }
                        }
                    }

                    // Output: (T, H, W, C_out)
                    let output_idx = ((t * H + h) * W + w) * C_out + c_out;
                    *output.add(output_idx) = sum;
                }
            }
        }
    }
}

/// Julia â†’ Rust FFI test
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_conv3d() {
        let T = 4; let H = 8; let W = 8;
        let C_in = 3; let C_out = 16;
        let k_t = 3; let k_h = 3; let k_w = 3;

        let mut input = vec![1.0f32; T * H * W * C_in];
        let kernel = vec![0.01f32; k_t * k_h * k_w * C_in * C_out];
        let mut output = vec![0.0f32; T * H * W * C_out];

        unsafe {
            conv3d_forward(
                input.as_ptr(), kernel.as_ptr(), output.as_mut_ptr(),
                T, H, W, C_in, C_out, k_t, k_h, k_w,
            );
        }

        // æœŸå¾…å€¤: sum â‰ˆ 3*3*3*3*0.01 = 0.81
        assert!((output[0] - 0.81).abs() < 0.01);
    }
}
```

### 4.2 Julia DiTè¨“ç·´: Lux + Reactant GPUåŠ é€Ÿ

Zone 3ã®DiTç†è«–ã‚’Juliaã§å®Ÿè£…ã™ã‚‹ã€‚Lux.jl (Fluxå¾Œç¶™) + Reactant.jl (XLA AOT GPU) ã§GPUè¨“ç·´ã‚’å®Ÿç¾ã€‚

```julia
# julia/dit_video_train.jl â€” DiTè¨“ç·´ (Lux + Reactant)

using Lux, Reactant, Optimisers, Random, Statistics, CUDA

# DiT Block: Multi-Head Self-Attention + MLP + AdaLN
struct DiTBlock{A,M,N1,N2}
    attn::A
    mlp::M
    norm1::N1
    norm2::N2
end

function DiTBlock(dim::Int, n_heads::Int)
    attn = MultiHeadAttention(dim, n_heads=n_heads)
    mlp = Chain(Dense(dim, 4*dim, gelu), Dense(4*dim, dim))
    norm1 = LayerNorm(dim)
    norm2 = LayerNorm(dim)
    DiTBlock(attn, mlp, norm1, norm2)
end

function (m::DiTBlock)(x, ps, st)
    # Residual connection + Layer Norm
    attn_out, st_attn = m.attn(m.norm1(x, ps.norm1, st.norm1)[1], ps.attn, st.attn)
    x = x + attn_out[1]

    mlp_out, st_mlp = m.mlp(m.norm2(x, ps.norm2, st.norm2)[1], ps.mlp, st.mlp)
    x = x + mlp_out[1]

    return x, (attn=st_attn, mlp=st_mlp, norm1=st.norm1, norm2=st.norm2)
end

# DiT: Patchify â†’ Transformer Blocks â†’ Unpatchify
function DiT(; patch_size=16, n_layers=12, dim=768, n_heads=12)
    patchify = Conv((patch_size, patch_size), 3 => dim, stride=patch_size)
    blocks = [DiTBlock(dim, n_heads) for _ in 1:n_layers]
    unpatchify = ConvTranspose((patch_size, patch_size), dim => 3, stride=patch_size)

    Chain(patchify, blocks..., unpatchify)
end

# è¨“ç·´ãƒ«ãƒ¼ãƒ— (Reactant GPU AOT)
function train_dit!(model, data_loader, epochs=10)
    opt_state = Optimisers.setup(Adam(1e-4), model.ps)

    for epoch in 1:epochs
        total_loss = 0.0
        for (x_batch,) in data_loader
            x_batch = x_batch |> gpu  # CUDA.jl GPUè»¢é€

            # Forward + Backward
            loss, grads = Lux.Training.compute_gradients(model, x_batch)
            total_loss += loss

            # Update
            Optimisers.update!(opt_state, model.ps, grads)
        end

        @info "Epoch $epoch: Loss = $(total_loss / length(data_loader))"
    end
end
```

### 4.3 3è¨€èªçµ±åˆ: Juliaè¨“ç·´ â†’ Rustæ¨è«– â†’ Elixiré…ä¿¡

Course IIIç¬¬19å›ã®3è¨€èªFFIãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‹•ç”»ç”Ÿæˆã«é©ç”¨ã™ã‚‹ã€‚

```elixir
# elixir/video_gen_server.ex â€” Elixiråˆ†æ•£é…ä¿¡ã‚µãƒ¼ãƒãƒ¼

defmodule VideoGenServer do
  use GenServer

  # Rust FFI: 3D Convå‘¼ã³å‡ºã—
  @on_load :load_nif
  def load_nif do
    :erlang.load_nif('./target/release/libvideo_kernels', 0)
  end

  def conv3d_forward(_input, _kernel, _output, _dims), do: :erlang.nif_error(:not_loaded)

  # Juliaè¨“ç·´ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
  def load_julia_model(model_path) do
    # jlrsçµŒç”±ã§Juliaãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ (ç¬¬19å›å‚ç…§)
    Jlrs.call(:load_model, [model_path])
  end

  # å‹•ç”»ç”ŸæˆAPI
  def handle_call({:generate_video, prompt, num_frames}, _from, state) do
    # 1. Rust: 3D Convé«˜é€Ÿæ¨è«–
    # 2. Julia: DiT forward pass
    # 3. Elixir: åˆ†æ•£é…ä¿¡
    video = generate_with_dit(prompt, num_frames, state.model)
    {:reply, {:ok, video}, state}
  end
end
```

---

## ğŸ§ª 5. å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” SmolVLM2å‹•ç”»ç†è§£ + LTX-Videoç”Ÿæˆãƒ‡ãƒ¢

**ã‚´ãƒ¼ãƒ«**: å®Ÿéš›ã®å‹•ç”»ã‚’å…¥åŠ›ã—ã€SmolVLM2ã§ç†è§£ â†’ LTX-Videoã§æ–°è¦å‹•ç”»ç”Ÿæˆã™ã‚‹çµ±åˆãƒ‡ãƒ¢ã‚’å®Ÿè¡Œã™ã‚‹ã€‚

### 5.1 SmolVLM2 (256M): å‹•ç”»ç†è§£

SmolVLM2ã¯256Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å°å‹VLMã ãŒã€å‹•ç”»ç†è§£ãŒå¯èƒ½ã€‚ãƒ­ãƒ¼ã‚«ãƒ«GPU (RTX 4090ç­‰) ã§å®Ÿè¡Œå¯èƒ½ã€‚

```julia
# julia/smolvlm2_video.jl â€” SmolVLM2å‹•ç”»ç†è§£

using Transformers, VideoIO

# SmolVLM2ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ (256M params)
smol_vlm = load_model("HuggingFaceTB/SmolVLM2-256M")

# å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º (24fps â†’ 1fps ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°)
function extract_frames(video_path::String; fps=1)
    reader = VideoIO.openvideo(video_path)
    frames = []

    frame_interval = Int(reader.fps / fps)
    for (i, frame) in enumerate(reader)
        if i % frame_interval == 0
            push!(frames, frame)
        end
    end

    return frames
end

# å‹•ç”»ç†è§£
video_path = "demo.mp4"
frames = extract_frames(video_path)  # 10ç§’å‹•ç”» â†’ 10ãƒ•ãƒ¬ãƒ¼ãƒ 

# SmolVLM2æ¨è«–
caption = smol_vlm(frames, prompt="ã“ã®å‹•ç”»ã§ä½•ãŒèµ·ã“ã£ã¦ã„ã‚‹ã‹è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„")

println("SmolVLM2ç†è§£: ", caption)
# å‡ºåŠ›ä¾‹: "ã‚«ãƒ•ã‚§ã§2äººã®å¥³æ€§ãŒä¼šè©±ã—ã¦ã„ã‚‹ã€‚çª“ã®å¤–ã«ã¯æ¡œã®æœ¨ãŒè¦‹ãˆã‚‹ã€‚æ˜¥ã®æ˜¼é–“ã®ã‚·ãƒ¼ãƒ³ã€‚"
```

### 5.2 LTX-Video: ãƒ†ã‚­ã‚¹ãƒˆâ†’å‹•ç”»ç”Ÿæˆ

LTX-Videoã¯DiT-basedå‹•ç”»ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã€‚Pyramidal Flow Matching (arXiv:2410.05954) ã®å®Ÿè£…ä¾‹ã€‚

```julia
# julia/ltx_video_gen.jl â€” LTX-Videoå‹•ç”»ç”Ÿæˆ

using Diffusers, VideoIO

# LTX-Videoãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
ltx_model = load_model("Lightricks/LTX-Video")

# ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ â†’ å‹•ç”»ç”Ÿæˆ
prompt = "æ¡œã®æœ¨ã®ä¸‹ã®ã‚«ãƒ•ã‚§ã§2äººã®å¥³æ€§ãŒä¼šè©±ã—ã¦ã„ã‚‹ã€æ˜¥ã®æ˜¼é–“ã€ã‚¢ãƒ‹ãƒ¡èª¿"
generated_video = ltx_model(
    prompt,
    num_frames=48,        # 2ç§’ (24fps)
    resolution=(768, 768),
    num_steps=28,         # Rectified Flow: 28ã‚¹ãƒ†ãƒƒãƒ—
    guidance_scale=7.5
)

# ä¿å­˜
save_video(generated_video, "generated_cafe.mp4", framerate=24)
println("âœ… LTX-Videoç”Ÿæˆå®Œäº†: generated_cafe.mp4")
```

### 5.3 çµ±åˆãƒ‡ãƒ¢: SmolVLM2ç†è§£ â†’ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ â†’ LTX-Videoç”Ÿæˆ

å‹•ç”»ã‚’å…¥åŠ› â†’ SmolVLM2ã§ç†è§£ â†’ ç†è§£çµæœã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ› â†’ LTX-Videoã§æ–°è¦å‹•ç”»ç”Ÿæˆã€‚

```julia
# julia/integrated_demo.jl â€” çµ±åˆãƒ‡ãƒ¢

using Transformers, Diffusers, VideoIO

# 1ï¸âƒ£ å…¥åŠ›å‹•ç”»ã‚’ SmolVLM2 ã§ç†è§£
input_video = "input_cafe.mp4"
frames = extract_frames(input_video)
smol_vlm = load_model("HuggingFaceTB/SmolVLM2-256M")

understanding = smol_vlm(frames, prompt="ã“ã®å‹•ç”»ã®ã‚¹ã‚¿ã‚¤ãƒ«ã€ã‚·ãƒ¼ãƒ³ã€é›°å›²æ°—ã‚’è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„")
println("SmolVLM2ç†è§£:\n", understanding)
# å‡ºåŠ›: "ã‚¢ãƒ‹ãƒ¡èª¿ã®ã‚«ãƒ•ã‚§ã‚·ãƒ¼ãƒ³ã€‚æ˜¥ã®æ¡œãŒçª“ã®å¤–ã«è¦‹ãˆã‚‹ã€‚æ˜ã‚‹ã„æ˜¼é–“ã€‚2äººã®å¥³æ€§ãŒç¬‘é¡”ã§ä¼šè©±ã€‚"

# 2ï¸âƒ£ ç†è§£çµæœã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
enhanced_prompt = """
$(understanding)
ã•ã‚‰ã«ã€ã‚«ãƒ¡ãƒ©ãŒæ¡œã®æœ¨ã«ã‚ºãƒ¼ãƒ ã‚¤ãƒ³ã™ã‚‹å‹•ãã‚’è¿½åŠ ã€‚
é«˜å“è³ªã€è©³ç´°ãªã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚·ãƒãƒãƒ†ã‚£ãƒƒã‚¯ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ã€‚
"""

# 3ï¸âƒ£ LTX-Videoã§æ–°è¦å‹•ç”»ç”Ÿæˆ
ltx_model = load_model("Lightricks/LTX-Video")
new_video = ltx_model(
    enhanced_prompt,
    num_frames=96,  # 4ç§’ (24fps)
    resolution=(1024, 1024),
    num_steps=28
)

save_video(new_video, "enhanced_cafe.mp4", framerate=24)
println("âœ… çµ±åˆãƒ‡ãƒ¢å®Œäº†: enhanced_cafe.mp4")
```

---

## ğŸŒŸ 6. ç™ºå±•ã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” 2025æœ€æ–°æ‰‹æ³• + ç ”ç©¶ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢

**ã‚´ãƒ¼ãƒ«**: 2025å¹´ã®æœ€æ–°Video Diffusionç ”ç©¶ã‚’ç†è§£ã—ã€æ¬¡ã®ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¹ãƒ«ãƒ¼ã‚’äºˆæ¸¬ã™ã‚‹è¦–ç‚¹ã‚’ç²å¾—ã™ã‚‹ã€‚

### 6.1 TurboDiffusion: 100-200å€é«˜é€ŸåŒ– (arXiv:2512.16093)

**å•é¡Œ**: Sora 2ç­‰ã®Video Diffusionã¯ã€1å‹•ç”»ç”Ÿæˆã«æ•°åˆ†ã‹ã‹ã‚‹ã€‚

**TurboDiffusionã®è§£æ±ºç­–** [^1]:
- **End-to-Endé«˜é€ŸåŒ–**: ç”Ÿæˆã‚’100-200å€åŠ é€Ÿ
- **å“è³ªä¿æŒ**: é«˜é€ŸåŒ–ã—ã¤ã¤å“è³ªã‚’ç¶­æŒ
- **æ‰‹æ³•**: Knowledge distillation + Adaptive sampling + Early stopping

```julia
# TurboDiffusioné¢¨ã®é«˜é€ŸåŒ–æ‰‹æ³• (ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰)
function turbo_diffusion(model, prompt, num_steps_base=50)
    # Adaptive sampling: é‡è¦åº¦ãŒä½ã„ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—
    important_steps = adaptive_step_selection(num_steps_base)  # 50 â†’ 5-10 steps

    # Early stopping: å“è³ªãŒé–¾å€¤ã‚’è¶…ãˆãŸã‚‰çµ‚äº†
    for step in important_steps
        latent = model.denoise_step(latent, step)

        if quality_score(latent) > threshold
            break  # Early stopping
        end
    end

    return decode_latent(latent)
end
```

**çµæœ**: å¾“æ¥50ã‚¹ãƒ†ãƒƒãƒ— â†’ TurboD 5ã‚¹ãƒ†ãƒƒãƒ— ã§åŒç­‰å“è³ª â†’ 10å€é«˜é€ŸåŒ–ã€‚ã•ã‚‰ã«KDè’¸ç•™ã§100å€é”æˆã€‚

### 6.2 Pyramidal Flow Matching (arXiv:2410.05954)

**å•é¡Œ**: é«˜è§£åƒåº¦å‹•ç”»ç”Ÿæˆ (1024p, 2K) ã¯è¨ˆç®—é‡ãŒçˆ†ç™ºã€‚

**Pyramidal Flow Matchingã®è§£æ±ºç­–** [^2]:
- **Pyramidæ§‹é€ **: ä½è§£åƒåº¦ â†’ ä¸­è§£åƒåº¦ â†’ é«˜è§£åƒåº¦ ã®æ®µéšçš„ç”Ÿæˆ
- **å˜ä¸€DiT**: å…¨è§£åƒåº¦ã‚’1ã¤ã®DiTã§å‡¦ç† (Multi-scale patchify)
- **End-to-Endè¨“ç·´**: Pyramidã‚’çµ±åˆçš„ã«æœ€é©åŒ–

**ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**:

```
å…¥åŠ›: Text prompt
  â†“
Level 1: 256Ã—256 (ç²—ã„æ§‹é€ ç”Ÿæˆ)
  â†“ Upsample
Level 2: 512Ã—512 (è©³ç´°è¿½åŠ )
  â†“ Upsample
Level 3: 768Ã—768 (æœ€çµ‚å“è³ª)
```

**æ•°å¼** (Multi-scale Flow Matching):

$$
\mathcal{L}_{\text{pyramid}} = \sum_{l=1}^{L} \lambda_l \mathbb{E}_{t, x_0^{(l)}, x_1^{(l)}} \left[ \|v_\theta(x_t^{(l)}, t, l) - u_t(x_t^{(l)} | x_1^{(l)})\|^2 \right]
$$

ã“ã“ã§ $l$ ã¯ãƒ¬ãƒ™ãƒ«ã€$\lambda_l$ ã¯é‡ã¿ã€‚

**çµæœ**: 768p, 24fps, 5ç§’å‹•ç”»ã‚’å˜ä¸€DiTã§ç”Ÿæˆå¯èƒ½ã€‚

### 6.3 Survey: Video Diffusionå…¨ä½“åƒ (arXiv:2504.16081)

2025å¹´ã®Video Diffusion Survey [^3] ã«ã‚ˆã‚‹ã¨ã€ä»¥ä¸‹ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚·ãƒ•ãƒˆãŒé€²è¡Œä¸­:

| è¦³ç‚¹ | å¾“æ¥ (2022-2023) | æœ€æ–° (2024-2025) |
|:-----|:----------------|:----------------|
| **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£** | 3D U-Net | DiT (Diffusion Transformer) |
| **Sampling** | 1000 steps (DDPM) | 10-50 steps (Flow Matching) |
| **é«˜é€ŸåŒ–** | DPM-Solver (50 steps) | TurboDiffusion (5 steps) |
| **è§£åƒåº¦** | 512Ã—512 | 768Ã—768 â†’ 1024Ã—1024 (Pyramidal) |
| **é•·ã•** | 2-5ç§’ | 15-25ç§’ (Sora 2) |
| **åˆ¶å¾¡æ€§** | Text only | Text + Image + Audio (Multimodal control) |

**æœªè§£æ±ºå•é¡Œ**:
1. **é•·æ™‚é–“ä¸€è²«æ€§**: æ•°åˆ†ã®å‹•ç”»ã§ä¸€è²«æ€§ãŒå´©ã‚Œã‚‹
2. **ç‰©ç†æ³•å‰‡**: é‡åŠ›ãƒ»è¡çªã‚’å®Œå…¨ã«ã¯å­¦ç¿’ã§ãã¦ã„ãªã„
3. **è¨ˆç®—ã‚³ã‚¹ãƒˆ**: 1å‹•ç”»ç”Ÿæˆã«æ•°åƒGPUæ™‚é–“ (Sora 2æ¨å®š)

### 6.4 ç ”ç©¶ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢: æ¬¡ã®ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¹ãƒ«ãƒ¼äºˆæ¸¬

**äºˆæ¸¬1: SSM (State Space Models) ã®å‹•ç”»ç”Ÿæˆé©ç”¨** (2026-2027)

- **å‹•æ©Ÿ**: Transformer ã¯ $O(T^2)$ ã®Attentionã§é•·æ™‚é–“å‹•ç”»ãŒè‹¦æ‰‹ã€‚SSM (Mamba) ã¯ $O(T)$ã€‚
- **æ‰‹æ³•**: Mamba-DiT Hybrid â€” æ™‚é–“è»¸ã¯Mambaã€ç©ºé–“è»¸ã¯Attention
- **æœŸå¾…**: æ•°åˆ†ã€œæ•°ååˆ†ã®é•·æ™‚é–“å‹•ç”»ä¸€è²«æ€§

**äºˆæ¸¬2: Test-Time Training for Video** (2026)

- **å‹•æ©Ÿ**: Inference-Time Scalingã®å‹•ç”»ç‰ˆ
- **æ‰‹æ³•**: ç”Ÿæˆä¸­ã«å‹•ç”»ã®ã€Œç‰©ç†æ³•å‰‡ã€ã‚’æ¨è«–æ™‚ã«å­¦ç¿’ãƒ»å¾®èª¿æ•´
- **æœŸå¾…**: Soraã®ç‰©ç†æ³•å‰‡ã‚¨ãƒ©ãƒ¼ (ç ´ç‰‡æ¶ˆå¤±ç­‰) ã‚’æ¨è«–æ™‚ã«ä¿®æ­£

**äºˆæ¸¬3: Neural PDEçµ±åˆWorld Models** (2027-2028)

- **å‹•æ©Ÿ**: æš—é»™çš„ç‰©ç†æ³•å‰‡å­¦ç¿’ã®é™ç•Œ
- **æ‰‹æ³•**: Diffusion + Differentiable Physics Simulator çµ±åˆ
- **æœŸå¾…**: ç‰©ç†æ³•å‰‡ã‚’æ˜ç¤ºçš„ã«ä¿è¨¼ã—ãŸå‹•ç”»ç”Ÿæˆ

---

## ğŸ“ 7. æŒ¯ã‚Šè¿”ã‚Šã‚¾ãƒ¼ãƒ³ (30åˆ†) â€” å…¨çŸ¥è­˜ã®æ¥ç¶š

**ã‚´ãƒ¼ãƒ«**: ç¬¬45å›ã§å­¦ã‚“ã Videoç”Ÿæˆã®ç†è«–ãƒ»å®Ÿè£…ãƒ»æœ€æ–°ç ”ç©¶ã‚’æŒ¯ã‚Šè¿”ã‚Šã€å…¨50å›ã®åˆ°é”ç‚¹ã‚’ç¢ºèªã™ã‚‹ã€‚

### 7.1 ç¬¬45å›ã®åˆ°é”ç‚¹ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

å…¨7ã‚¾ãƒ¼ãƒ³ã‚’æŒ¯ã‚Šè¿”ã‚Šã€ç†è§£åº¦ã‚’è‡ªå·±è©•ä¾¡ã—ã¾ã—ã‚‡ã†ã€‚

| Zone | å†…å®¹ | ç†è§£åº¦ (è‡ªå·±è©•ä¾¡) |
|:-----|:-----|:-----------------|
| **Zone 0** | 30ç§’ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ â€” Temporal Attentionä½“æ„Ÿ | âœ… / âš ï¸ / âŒ |
| **Zone 1** | ä½“é¨“ã‚¾ãƒ¼ãƒ³ â€” Spatial/Temporal/3D Conv/Optical Flowå®Ÿè£… | âœ… / âš ï¸ / âŒ |
| **Zone 2** | ç›´æ„Ÿã‚¾ãƒ¼ãƒ³ â€” 3ã¤ã®å›°é›£ãƒ»3ã¤ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ  | âœ… / âš ï¸ / âŒ |
| **Zone 3** | æ•°å¼ä¿®è¡Œ â€” Video Diffusion/DiT/3D VAE/Optical Flowå°å‡º | âœ… / âš ï¸ / âŒ |
| **Zone 4** | å®Ÿè£…ã‚¾ãƒ¼ãƒ³ â€” Rust 3D Conv + Julia DiTè¨“ç·´ | âœ… / âš ï¸ / âŒ |
| **Zone 5** | å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ â€” SmolVLM2 + LTX-Videoçµ±åˆãƒ‡ãƒ¢ | âœ… / âš ï¸ / âŒ |
| **Zone 6** | ç™ºå±•ã‚¾ãƒ¼ãƒ³ â€” TurboDiffusion/Pyramidal/Survey/Frontier | âœ… / âš ï¸ / âŒ |

**âœ… = å®Œå…¨ç†è§£** / **âš ï¸ = éƒ¨åˆ†çš„ç†è§£** / **âŒ = è¦å¾©ç¿’**

### 7.2 Course I-Vã¨ã®æ¥ç¶š: ç¬¬45å›ã®ä½ç½®ã¥ã‘

ç¬¬45å›ã¯ã€Course I-Vã®å…¨çŸ¥è­˜ãŒæ¥ç¶šã•ã‚Œã‚‹åœ°ç‚¹ã ã€‚

```mermaid
graph TD
    A["Course I<br/>ç¬¬2å›: ç·šå½¢ä»£æ•°"] -.->|"QKáµ€ / softmax"| B["Zone 1: Temporal Attention"]
    C["Course I<br/>ç¬¬4å›: å¾®ç©åˆ†"] -.->|"âˆ‚/âˆ‚Î¸ backprop"| D["Zone 4: Juliaè¨“ç·´"]
    E["Course II<br/>ç¬¬16å›: Transformer"] -.->|"Self-Attention"| B
    F["Course IV<br/>ç¬¬36å›: DDPM"] -.->|"ãƒã‚¤ã‚ºäºˆæ¸¬"| G["Zone 3: Video Diffusion"]
    H["Course IV<br/>ç¬¬38å›: Flow Matching"] -.->|"Rectified Flow"| I["Zone 6: Pyramidal FM"]
    J["Course III<br/>ç¬¬19å›: FFI"] -.->|"Juliaâ†’Rust"| D
    K["Course V<br/>ç¬¬43å›: DiT"] -.->|"Spacetime DiT"| G

    style B fill:#ffe6f0
    style G fill:#e6f3ff
    style D fill:#fff4e6
    style I fill:#e6fff0
```

**å…¨50å›ã®çµ±åˆä¾‹**:

- **ç¬¬2å› ç·šå½¢ä»£æ•°** â†’ Zone 1 Temporal Attention ã® $QK^\top$ è¨ˆç®—
- **ç¬¬4å› å¾®ç©åˆ†** â†’ Zone 4 Juliaè¨“ç·´ã®å‹¾é…é™ä¸‹
- **ç¬¬16å› Transformer** â†’ Zone 1 Spatial/Temporal Attention ã®åŸºç¤
- **ç¬¬36å› DDPM** â†’ Zone 3 Video Diffusion ã®ãƒã‚¤ã‚ºäºˆæ¸¬
- **ç¬¬38å› Flow Matching** â†’ Zone 6 Pyramidal Flow Matching
- **ç¬¬19å› FFI** â†’ Zone 4 Juliaâ†’Rust 3D Convå‘¼ã³å‡ºã—
- **ç¬¬43å› DiT** â†’ Zone 3 Spacetime DiT

### 7.3 æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: ç¬¬46å›ã€Œ3Dç”Ÿæˆã€ã¸

ç¬¬45å›ã§**æ™‚ç©ºé–“2D+æ™‚é–“**ã‚’å¾æœã—ãŸã€‚æ¬¡ã¯**ç©ºé–“3D**ã ã€‚

```mermaid
graph LR
    A["ç¬¬44å›<br/>éŸ³å£°ç”Ÿæˆ<br/>æ™‚ç³»åˆ—1D"] --> B["ç¬¬45å›<br/>Videoç”Ÿæˆ<br/>æ™‚ç©ºé–“2D+æ™‚é–“"]
    B --> C["ç¬¬46å›<br/>3Dç”Ÿæˆ<br/>ç©ºé–“3D"]
    C --> D["ç¬¬47å›<br/>4Dç”Ÿæˆ<br/>ç©ºé–“3D+æ™‚é–“"]

    style B fill:#ffd700,stroke:#ff6347,stroke-width:4px
    style C fill:#98fb98
```

**ç¬¬46å›ã§å­¦ã¶ã“ã¨**:
- **NeRF**: Neural Radiance Fields â€” Volume Renderingæ–¹ç¨‹å¼
- **3DGS**: 3D Gaussian Splatting â€” 1000å€é«˜é€ŸåŒ–ã®å¾®åˆ†å¯èƒ½ãƒ©ã‚¹ã‚¿ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³
- **DreamFusion**: Score Distillation Sampling (SDS) ã§Text-to-3D
- **SLAMå¿œç”¨**: GARAD-SLAM, Dy3DGS-SLAM (2025å¹´ã®æœ€æ–°SLAM)

### 7.4 å…¨50å›ã§ã®ç¬¬45å›ã®å½¹å‰²

ç¬¬45å›ã¯ã€Course Vã®ä¸­æ ¸ã‚’æ‹…ã†ã€‚

| è¬›ç¾© | ãƒ¢ãƒ€ãƒªãƒ†ã‚£ | æ¬¡å…ƒ | å½¹å‰² |
|:-----|:----------|:-----|:-----|
| ç¬¬43å› | ç”»åƒ | 2Dç©ºé–“ | DiT/ControlNet â€” åŸºç›¤ |
| ç¬¬44å› | éŸ³å£° | 1Dæ™‚é–“ | æ™‚ç³»åˆ—ãƒ¢ãƒ‡ãƒªãƒ³ã‚° |
| **ç¬¬45å›** | **å‹•ç”»** | **2Dç©ºé–“+æ™‚é–“** | **æ™‚ç©ºé–“çµ±åˆ** â€” 3D/4Dã¸ã®æ©‹æ¸¡ã— |
| ç¬¬46å› | 3D | 3Dç©ºé–“ | ç©ºé–“ãƒ¢ãƒ‡ãƒªãƒ³ã‚° |
| ç¬¬47å› | 4D | 3Dç©ºé–“+æ™‚é–“ | ç©¶æ¥µã®çµ±åˆ |

ç¬¬45å›ã®**æ™‚ç©ºé–“DiT**ã¯ã€ç¬¬46å›ã®**3D NeRF/3DGS**ã€ç¬¬47å›ã®**4D-GS**ã¸ã®æ¶ã‘æ©‹ã ã€‚

### 7.5 å®Ÿè·µèª²é¡Œ: è‡ªåˆ†ã§å‹•ç”»ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã‚‹

ç¬¬45å›ã®å…¨çŸ¥è­˜ã‚’ä½¿ã£ã¦ã€ä»¥ä¸‹ã®ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã«æŒ‘æˆ¦ã—ã‚ˆã†ã€‚

**èª²é¡Œ1: SmolVLM2 + LTX-Videoçµ±åˆã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰** (é›£æ˜“åº¦: â˜…â˜…â˜…â˜†â˜†)

- Zone 5ã®ãƒ‡ãƒ¢ã‚’æ‹¡å¼µã—ã€Web UIã‚’è¿½åŠ  (Genie.jlç­‰)
- å…¥åŠ›: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
- å‡¦ç†: SmolVLM2ã§ç†è§£ â†’ LLM (GPT-4ç­‰) ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ â†’ LTX-Videoç”Ÿæˆ
- å‡ºåŠ›: ç”Ÿæˆå‹•ç”»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

**èª²é¡Œ2: Rust 3D Conv + Julia DiTè¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³** (é›£æ˜“åº¦: â˜…â˜…â˜…â˜…â˜†)

- Zone 4ã®Rust 3D Convã‚’CUDAå¯¾å¿œã«æ‹¡å¼µ (cuDNN C APIå‘¼ã³å‡ºã—)
- Juliaå´ã§Lux + Reactant GPUãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰
- å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (UCF-101ç­‰) ã§è¨“ç·´ â†’ æ¨è«–é€Ÿåº¦è¨ˆæ¸¬

**èª²é¡Œ3: TurboDiffusionå®Ÿè£…** (é›£æ˜“åº¦: â˜…â˜…â˜…â˜…â˜…)

- arXiv:2512.16093 ã‚’èª­ã¿ã€Adaptive samplingéƒ¨åˆ†ã‚’å®Ÿè£…
- Knowledge distillationã§LTX-Videoã‚’è’¸ç•™ (50 steps â†’ 5 steps)
- å“è³ªè©•ä¾¡ (FVD, IS) ã§æ¤œè¨¼

### 7.6 24æ™‚é–“ä»¥å†…ã«å§‹ã‚ã‚‹3ã¤ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

ç¬¬45å›ã‚’èª­äº†ã—ãŸã€Œä»Šã€ã€ä»¥ä¸‹ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’24æ™‚é–“ä»¥å†…ã«å®Ÿè¡Œã—ã‚ˆã†ã€‚

1. **SmolVLM2ãƒ‡ãƒ¢å®Ÿè¡Œ**: Zone 5ã®ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒšã—ã¦å‹•ç”»ç†è§£ã‚’è©¦ã™ (30åˆ†)
2. **Sora 2 Technical Reportã‚’èª­ã‚€**: OpenAIã®å…¬å¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç²¾èª­ (1æ™‚é–“)
3. **arXivæœ€æ–°è«–æ–‡1æœ¬**: TurboDiffusion or Pyramidal Flow Matching ã‚’èª­ã‚€ (1æ™‚é–“)

---

**ç¬¬45å›å®Œèµ°ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼** æ™‚ç©ºé–“Diffusionã®ç†è«–ãƒ»å®Ÿè£…ãƒ»æœ€æ–°ç ”ç©¶ã‚’å®Œå…¨ç¿’å¾—ã—ã¾ã—ãŸã€‚æ¬¡ã¯ç¬¬46å›ã€Œ3Dç”Ÿæˆã€ã§ç©ºé–“3Dã‚’å¾æœã—ã¾ã—ã‚‡ã†ã€‚

### 7.7 è£œè¶³è³‡æ–™: Juliaãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ 

å‹•ç”»ç”Ÿæˆã«å½¹ç«‹ã¤Juliaãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã¾ã¨ã‚ã¾ã™ã€‚

| ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ | ç”¨é€” | ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« |
|:----------|:-----|:-----------|
| **Lux.jl** | Neural network framework (Fluxå¾Œç¶™) | `using Pkg; Pkg.add("Lux")` |
| **Reactant.jl** | XLA AOT GPU compilation | `Pkg.add("Reactant")` |
| **VideoIO.jl** | å‹•ç”»èª­ã¿è¾¼ã¿ãƒ»æ›¸ãè¾¼ã¿ | `Pkg.add("VideoIO")` |
| **Transformers.jl** | HuggingFaceäº’æ›æ¨è«– | `Pkg.add("Transformers")` |
| **CUDA.jl** | NVIDIA GPU programming | `Pkg.add("CUDA")` |
| **Optimisers.jl** | Adam, AdamW, etc. | `Pkg.add("Optimisers")` |

å®Ÿè£…æ™‚ã®ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:

```julia
# Issue 1: VideoIO.jl installation error
# Solution: ffmpegã‚’ã‚·ã‚¹ãƒ†ãƒ ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# macOS: brew install ffmpeg
# Linux: apt install ffmpeg

# Issue 2: CUDA out of memory
# Solution: Batch sizeã‚’å‰Šæ¸› or Gradient checkpointing
using Lux.Experimental: gradient_checkpointing

# Issue 3: Reactant.jl not found
# Solution: Julia 1.11+ required
versioninfo()  # Julia 1.11.0 ä»¥ä¸Šã‚’ç¢ºèª
```

## å‚è€ƒæ–‡çŒ®

[^1]: [TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times](https://arxiv.org/abs/2512.16093) â€” arXiv:2512.16093, Dec 2025
[^2]: [Pyramidal Flow Matching for Efficient Video Generative Modeling](https://arxiv.org/abs/2410.05954) â€” arXiv:2410.05954, Oct 2024
[^3]: [Survey of Video Diffusion Models: Foundations, Implementations, and Applications](https://arxiv.org/abs/2504.16081) â€” arXiv:2504.16081, Apr 2025

---


---

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
