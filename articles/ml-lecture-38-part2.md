---
title: "ç¬¬38å›: Flow Matching & ç”Ÿæˆãƒ¢ãƒ‡ãƒ«çµ±ä¸€ç†è«–: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
emoji: "ğŸŒ€"
type: "tech"
topics: ["machinelearning", "deeplearning", "flowmatching", "rust", "diffusion"]
published: true
slug: "ml-lecture-38-part2"
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Rust"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---

**â†’ å‰ç·¨ï¼ˆç†è«–ç·¨ï¼‰**: [ml-lecture-38-part1](./ml-lecture-38-part1)

## ğŸ’» Z5. è©¦ç·´ï¼ˆå®Ÿè£…ï¼‰ â€” Rust Flow Matchingå®Ÿè£…

ç†è«–ã‚’æ‰‹ã‚’å‹•ã‹ã—ã¦ç¢ºã‹ã‚ã‚ˆã†ã€‚ã“ã“ã§ã¯ã€**Conditional Flow Matching (CFM)**ã®å®Œå…¨ãªå®Ÿè£…ã‚’é€šã˜ã¦ã€ç†è«–ã®å„è¦ç´ ãŒå®Ÿã‚³ãƒ¼ãƒ‰ã«ã©ã†å¯¾å¿œã™ã‚‹ã‹ã‚’å­¦ã¶ã€‚

---

### 4.1 å®Ÿè£…ã®å…¨ä½“åƒ

å®Ÿè£…ã™ã‚‹å†…å®¹ï¼š

1. **Gaussian Probability Paths**ï¼ˆOT Path / VP Pathï¼‰
2. **Conditional Vector Field** $\mathbf{u}_t(\mathbf{x}|\mathbf{x}_1)$
3. **CFM Loss**ã®è¨“ç·´ãƒ«ãƒ¼ãƒ—
4. **ODE Sampling**ï¼ˆEuleræ³• / RK4æ³•ï¼‰
5. **2æ¬¡å…ƒç©å…·ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**ã§ã®å¯è¦–åŒ–

å®Ÿè£…è¨€èªï¼š**Rust 1.11**ï¼ˆCandle + burn::optim + ode_solversï¼‰

---

### 4.2 ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸

```rust:setup.rs
use candle_core::{Tensor, Device, DType, Result};
use candle_nn::{Module, VarBuilder, Linear, linear};
use ndarray::{Array1, Array2, ArrayView2, s};
use rand::{Rng, SeedableRng};

let mut rng = rand::rngs::StdRng::seed_from_u64(42); // seed=42: reproducible
```

---

### 4.3 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ

2æ¬¡å…ƒã®**2å³°ã‚¬ã‚¦ã‚¹æ··åˆ**ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒã¨ã™ã‚‹ï¼š

```rust:dataset.rs
use ndarray::Array2;
use rand::Rng;
use rand_distr::StandardNormal;

/// Target distribution: mixture of 2 Gaussians
///     p_data(x) = 0.5*N([-2, 0], I) + 0.5*N([2, 0], I)
fn sample_target(n: usize, rng: &mut impl Rng) -> Array2<f32> {
    let d = 2;
    let centers: [[f32; 2]; 2] = [[-2.0, 0.0], [2.0, 0.0]];
    Array2::from_shape_fn((d, n), |(j, i)| {
        let mode = (i * 6364136223846793005u64.wrapping_add(i as u64) % 2) as usize;
        rng.sample::<f32, _>(StandardNormal) + centers[mode][j] // xâ‚ ~ p_data: N(centers[mode], I)
    })
}

/// Source distribution: standard Gaussian N(0, I)
fn sample_source(n: usize, d: usize, rng: &mut impl Rng) -> Array2<f32> { Array2::from_shape_fn((d, n), |_| rng.sample::<f32, _>(StandardNormal)) } // xâ‚€ ~ N(0,I)
```

---

### 4.4 Probability Pathå®šç¾©

å‰è¿°ã®ç†è«–ã«åŸºã¥ãã€**Optimal Transport Path**ã¨**VP Path**ã‚’å®Ÿè£…ã™ã‚‹ã€‚

```rust:paths.rs
use ndarray::Array2;
use rand::Rng;
use rand_distr::StandardNormal;

/// Gaussian Probability Path: Î¼_t(xâ‚|xâ‚€) ã¨ Î£_t
///
/// Parameters:
///   - path_type: PathType::OT (Optimal Transport) or PathType::VP (Variance Preserving)
#[derive(Clone, Copy)]
enum PathType { OT, VP }

struct GaussianPath {
    path_type: PathType,
    sigma_min: f32,
}

impl GaussianPath {
    /// Default: OT path with minimal noise
    fn new() -> Self { GaussianPath { path_type: PathType::OT, sigma_min: 1e-5 } }

    /// Compute Î¼_t(xâ‚, xâ‚€) and Ïƒ_t at time t
    fn path_params(&self, t: f32, x1: &Array2<f32>, x0: &Array2<f32>)
        -> (Array2<f32>, f32)
    {
        match self.path_type {
            PathType::OT => {
                let mu_t = x1.mapv(|v| t * v) + x0.mapv(|v| (1.0 - t) * v); // Î¼_t(xâ‚,xâ‚€) = tÂ·xâ‚ + (1-t)Â·xâ‚€  (OT straight path)
                (mu_t, self.sigma_min) // Ïƒ_t = Ïƒ_min  (OT path, constant noise)
            }
            PathType::VP => {
                let mu_t = x1.mapv(|v| t * v);           // Î¼_t = tÂ·xâ‚  (VP path mean)
                let sigma_t = (1.0 - t * t).sqrt();      // Ïƒ_t = âˆš(1-tÂ²)  (VP path std)
                (mu_t, sigma_t)
            }
        }
    }

    /// Sample from conditional distribution q_t(x|xâ‚, xâ‚€)
    ///     x_t ~ N(Î¼_t, Ïƒ_tÂ²I)
    fn sample_conditional(&self, t: f32, x1: &Array2<f32>, x0: &Array2<f32>,
                           rng: &mut impl Rng) -> Array2<f32>
    {
        let (mu_t, sigma_t) = self.path_params(t, x1, x0);
        let eps = Array2::from_shape_fn(mu_t.raw_dim(),
            |_| rng.sample::<f32, _>(StandardNormal));
        mu_t + eps.mapv(|v| sigma_t * v) // xâ‚œ ~ N(Î¼_t, Ïƒ_tÂ²I)  (conditional path)
    }

    /// Compute conditional vector field u_t(x|xâ‚, xâ‚€)
    ///     u_t = âˆ‚Î¼_t/âˆ‚t + (Ïƒ_t Ïƒ'_t / Ïƒ_tÂ²)(x - Î¼_t)
    fn conditional_vector_field(&self, t: f32, x_t: &Array2<f32>,
                                 x1: &Array2<f32>, x0: &Array2<f32>) -> Array2<f32>
    {
        match self.path_type {
            PathType::OT => {
                // uâ‚œ(x|xâ‚,xâ‚€) = xâ‚ - xâ‚€  (constant! OT path)
                x1 - x0
            }
            PathType::VP => {
                // uâ‚œ(x|xâ‚,xâ‚€) = xâ‚ + Ïƒ'_t/Ïƒ_tÂ·(x - Î¼_t)  (VP conditional field)
                let (mu_t, sigma_t) = self.path_params(t, x1, x0);
                let dsigma_dt = -t / (1.0 - t * t + 1e-8).sqrt(); // Ïƒ'_t = -t/âˆš(1-tÂ²)
                x1 + (x_t - &mu_t).mapv(|v| dsigma_dt / (sigma_t + 1e-8) * v)
            }
        }
    }
}
```

**é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ**ï¼š
- OT Pathã§ã¯$\mathbf{u}_t = \mathbf{x}_1 - \mathbf{x}_0$ï¼ˆå®šæ•°ï¼ï¼‰
- VP Pathã§ã¯$\mathbf{u}_t$ãŒ$\mathbf{x}_t$ã«ä¾å­˜ã™ã‚‹

---

### 4.5 Vector Field Network

æ™‚åˆ»$t$ã¨ä½ç½®$\mathbf{x}_t$ã‹ã‚‰é€Ÿåº¦$\mathbf{v}_\theta(\mathbf{x}_t, t)$ã‚’äºˆæ¸¬ã™ã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€‚

```rust:network.rs
use candle_core::{Tensor, Device, Result};
use candle_nn::{Module, VarBuilder, Linear, linear, Activation};

// Vector field network: v_Î¸(xâ‚œ, t) â‰ˆ uâ‚œ  (CFM target)
// Implements: trait FlowModel { fn forward(&self, x: &Tensor, t: &Tensor) -> Result<Tensor> }
/// Time-conditional MLP for vector field prediction
///     v_Î¸(x_t, t): (d+1) â†’ 128 â†’ 128 â†’ d
struct VectorFieldNet {
    fc1: Linear,
    fc2: Linear,
    fc3: Linear,
}

impl VectorFieldNet {
    fn new(d: usize, vb: VarBuilder) -> Result<Self> {
        Ok(Self {
            fc1: linear(d + 1, 128, vb.pp("fc1"))?,
            fc2: linear(128, 128, vb.pp("fc2"))?,
            fc3: linear(128, d, vb.pp("fc3"))?,
        })
    }

    /// Forward pass with time conditioning
    ///     v_Î¸(xâ‚œ, t): R^{d+1} â†’ R^d  (network forward)
    fn forward(&self, x_t: &Tensor, t: &Tensor) -> Result<Tensor> {
        let t_col = t.unsqueeze(1)?;
        let input = Tensor::cat(&[x_t, &t_col], 1)?; // [xâ‚œ || t]: R^{d+1}  (time conditioning)
        let h = self.fc1.forward(&input)?.gelu()?;
        let h = self.fc2.forward(&h)?.gelu()?;
        self.fc3.forward(&h) // v_Î¸(xâ‚œ, t): R^{d+1} â†’ R^d
    }
}
```

---

### 4.6 CFM Losså®Ÿè£…

ç†è«–å¼ï¼ˆZone 3.1ï¼‰ã®Lossã‚’å®Ÿè£…ã™ã‚‹ï¼š

$$
\mathcal{L}_{\text{CFM}}(\theta) = \mathbb{E}_{t, \mathbf{x}_0, \mathbf{x}_1}\left[\left\|\mathbf{v}_\theta(t, \mathbf{x}_t) - \mathbf{u}_t(\mathbf{x}_t | \mathbf{x}_1, \mathbf{x}_0)\right\|^2\right]
$$

```rust:loss.rs
use ndarray::Array2;
use rand::Rng;

/// Conditional Flow Matching Loss
fn cfm_loss(
    model: &VectorFieldNet,
    path: &GaussianPath,
    batch_size: usize,
    rng: &mut impl Rng,
) -> f32 {
    let t: f32 = rng.gen(); // t ~ U(0,1)  (uniform time sampling)
    let x0 = sample_source(batch_size, 2, rng); // xâ‚€ ~ N(0,I)
    let x1 = sample_target(batch_size, rng);    // xâ‚ ~ p_data
    let x_t = path.sample_conditional(t, &x1, &x0, rng); // xâ‚œ ~ N(Î¼_t, Ïƒ_tÂ²I)  (conditional path)
    let u_t = path.conditional_vector_field(t, &x_t, &x1, &x0); // uâ‚œ: conditional target field
    let v_hat = model_predict(model, &x_t, t); // v_Î¸(xâ‚œ, t): R^{d+1} â†’ R^d
    // L_CFM = E_{t,xâ‚€,xâ‚}[||v_Î¸(xâ‚œ,t) - uâ‚œ(xâ‚œ|xâ‚,xâ‚€)||Â²]
    let diff = &v_hat - &u_t;
    diff.iter().map(|v| v * v).sum::<f32>() / diff.len() as f32
}
```

---

### 4.7 è¨“ç·´ãƒ«ãƒ¼ãƒ—

```rust:train.rs
use candle_nn::optim::{Adam, AdamConfig, Optimizer};
use std::time::Instant;

/// Train Flow Matching model
fn train_flow_matching(
    n_epochs: usize,
    batch_size: usize,
    lr: f64,
    path_type: PathType,
    rng: &mut impl Rng,
) -> Result<(VectorFieldNet, Vec<f32>)> {
    let d = 2;
    let dev = Device::Cpu;
    let vb = VarBuilder::zeros(DType::F32, &dev);
    let model = VectorFieldNet::new(d, vb.clone())?;
    let mut opt = Adam::new(vb.all_vars(), AdamConfig { lr, ..Default::default() })?;

    let path = GaussianPath { path_type, sigma_min: 1e-5 };
    let mut losses = Vec::with_capacity(n_epochs);

    for epoch in 0..n_epochs {
        let loss = cfm_loss(&model, &path, batch_size, rng); // L_CFM = E_{t,xâ‚€,xâ‚}[||v_Î¸ - uâ‚œ||Â²]
        // Autograd backward + optimizer step handled via candle_core
        opt.backward_step(&Tensor::new(loss, &dev)?)?; // Î¸ â† Î¸ - Î±âˆ‡L_CFM  (Adam step)

        losses.push(loss);

        if (epoch + 1) % 100 == 0 {
            println!("Epoch {}: Loss = {}", epoch + 1, loss);
        }
    }

    Ok((model, losses))
}
```

---

### 4.8 ODE Sampling

è¨“ç·´å¾Œã€ODEã‚’è§£ã„ã¦ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆï¼š

$$
\frac{\mathrm{d}\mathbf{x}_t}{\mathrm{d}t} = \mathbf{v}_\theta(\mathbf{x}_t, t), \quad \mathbf{x}_0 \sim \mathcal{N}(0, I)
$$

```rust:sampling.rs
use ndarray::Array2;

/// Euler ODE integrator: dx/dt = v_fn(x, t)
fn euler_integrate(
    v_fn: impl Fn(&Array2<f32>, f32) -> Array2<f32>,
    x0: &Array2<f32>,
    n_steps: usize,
) -> Array2<f32> {
    let dt = 1.0_f32 / n_steps as f32; // Euler step size Î”t = 1/N
    let mut x = x0.clone();
    for step in 0..n_steps {
        let t = step as f32 * dt; // t = step Ã— Î”t
        let v = v_fn(&x, t);
        x = x + v * dt; // xâ‚œâ‚Šdt = xâ‚œ + v_Î¸(xâ‚œ,t)Â·dt  (ODE integrator)
    }
    x
}

/// Sample from learned flow via Euler ODE solving
fn sample_flow(
    model: &VectorFieldNet,
    n_samples: usize,
    n_steps: usize,
    rng: &mut impl Rng,
) -> Array2<f32> {
    let x0 = sample_source(n_samples, 2, rng);

    euler_integrate(
        |x, t| model_predict(model, x, t),
        &x0,
        n_steps,
    )
}
```

**æ³¨**ï¼š
- `Euler()`: 1æ¬¡ç²¾åº¦ï¼ˆé€Ÿã„ï¼‰
- `RK4()`: 4æ¬¡ç²¾åº¦ï¼ˆé«˜ç²¾åº¦ï¼‰
- Rectified Flowã§ã¯1-stepã§ååˆ†ï¼ˆ$\Delta t = 1$ï¼‰

---

### 4.9 å¯è¦–åŒ–

```rust:visualize.rs
/// Visualize training progress and generated samples
fn visualize_results(model: &VectorFieldNet, losses: &[f32], n_samples: usize,
                     rng: &mut impl Rng)
{
    // Plot 1: Training loss curve
    println!("Training Loss (last 10): {:?}", &losses[losses.len().saturating_sub(10)..]);

    // Plot 2: Generated samples vs real data
    let x_real = sample_target(n_samples, rng);
    let x_gen = sample_flow(model, n_samples, 100, rng);

    println!("Real samples shape: {:?}", x_real.shape());
    println!("Generated samples shape: {:?}", x_gen.shape());

    // Plot 3: Trajectory visualization (single sample)
    let x0_single = sample_source(1, 2, rng);
    let n_steps = 20;
    let dt = 1.0_f32 / n_steps as f32;
    let mut traj = vec![x0_single.clone()];
    let mut x = x0_single.clone();
    for step in 0..n_steps {
        let t = step as f32 * dt;
        let v = model_predict(model, &x, t); // v_Î¸(xâ‚œ, t): R^{d+1} â†’ R^d
        x = x + v * dt; // xâ‚œâ‚Šdt = xâ‚œ + v_Î¸(xâ‚œ,t)Â·dt  (Euler step)
        traj.push(x.clone());
    }
    println!("Trajectory length: {}", traj.len());
}
```

---

### 4.10 å®Ÿè¡Œä¾‹

```rust:main.rs
fn main() -> Result<()> {
    let mut rng = rand::rngs::StdRng::seed_from_u64(42);

    // Train OT-based CFM: Î¼_t(xâ‚,xâ‚€) = tÂ·xâ‚ + (1-t)Â·xâ‚€  (straight path)
    let (model_ot, losses_ot) = train_flow_matching(
        1000, 256, 1e-3, PathType::OT, &mut rng
    )?;

    // Visualize
    visualize_results(&model_ot, &losses_ot, 1000, &mut rng);

    // Train VP-based CFM: Î¼_t = tÂ·xâ‚,  Ïƒ_t = âˆš(1-tÂ²)  (VP path)
    let (model_vp, losses_vp) = train_flow_matching(
        1000, 256, 1e-3, PathType::VP, &mut rng
    )?;

    Ok(())
}
```

**æœŸå¾…ã•ã‚Œã‚‹çµæœ**ï¼š
- OT Pathã®æ–¹ãŒåæŸãŒé€Ÿã„ï¼ˆç›´ç·šçµŒè·¯ï¼‰
- VP Pathã¯è‹¥å¹²è¿‚å›ã™ã‚‹ãŒã€å®‰å®šæ€§ãŒé«˜ã„
- ã©ã¡ã‚‰ã‚‚çœŸã®åˆ†å¸ƒã‚’æ­£ç¢ºã«å†ç¾

---

### 4.11 å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆæ•´ç†

| ç†è«–è¦ç´  | å®Ÿè£…ä¸Šã®å¯¾å¿œ |
|----------|--------------|
| $\mathbf{u}_t(\mathbf{x}\|\mathbf{x}_1, \mathbf{x}_0)$ | `conditional_vector_field()` |
| $\mu_t(\mathbf{x}_1, \mathbf{x}_0)$ | `path_params()` ã® `Î¼_t` |
| $q_t(\mathbf{x}\|\mathbf{x}_1, \mathbf{x}_0)$ | `sample_conditional()` |
| $\mathcal{L}_{\text{CFM}}$ | `cfm_loss()` ã®MSE |
| ODE Sampling | `sample_flow()` ã® `solve(ODEProblem)` |

> **Note:** **å®Ÿè£…ã®æ ¸å¿ƒ**
> CFMã®å®Ÿè£…ã¯é©šãã»ã©ã‚·ãƒ³ãƒ—ãƒ«ã€‚Diffusion Modelã®ã‚ˆã†ãªè¤‡é›‘ãªãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã€å¤šæ®µéšé€†éç¨‹ã€score networkã®å·¥å¤«ã¯ä¸€åˆ‡ä¸è¦ã€‚**ç›´ç·šçµŒè·¯ï¼ˆOT Pathï¼‰+ MSE Loss + ODE Solver**ã ã‘ã§ååˆ†ã ã€‚

---

### ğŸ”¬ å®Ÿé¨“ãƒ»æ¤œè¨¼ å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ â€” æ¼”ç¿’ã¨æ¤œè¨¼

ç†è«–ã¨å®Ÿè£…ã‚’è¸ã¾ãˆã€ä»¥ä¸‹ã®æ¼”ç¿’ã‚’é€šã˜ã¦ç†è§£ã‚’æ·±ã‚ã‚ˆã†ã€‚

---

### æ¼”ç¿’1: OT Path vs VP Pathã®æ¯”è¼ƒ

**å•é¡Œ**ï¼š
Zone 4ã®å®Ÿè£…ã§ã€`:ot`ã¨`:vp`ã®ä¸¡æ–¹ã‚’è¨“ç·´ã—ã€ä»¥ä¸‹ã‚’æ¯”è¼ƒã›ã‚ˆï¼š

1. **è¨“ç·´é€Ÿåº¦**ï¼ˆåŒã˜lossã«åˆ°é”ã™ã‚‹epochæ•°ï¼‰
2. **ç”Ÿæˆå“è³ª**ï¼ˆ2-Wassersteinè·é›¢ã§å®šé‡è©•ä¾¡ï¼‰
3. **è»Œé“ã®ç›´ç·šæ€§**ï¼ˆå§‹ç‚¹â†’çµ‚ç‚¹ã®ç›´ç·šã‹ã‚‰ã®å¹³å‡åå·®ï¼‰

**ãƒ’ãƒ³ãƒˆ**ï¼š
- Wassersteinè·é›¢ï¼š`using OptimalTransport; w2 = wasserstein(x_real, x_gen, 2)`
- ç›´ç·šæ€§ï¼šå„æ™‚åˆ»$t$ã§ã®ä½ç½®ã¨ç›´ç·š$(1-t)\mathbf{x}_0 + t\mathbf{x}_1$ã®è·é›¢

**æœŸå¾…ã•ã‚Œã‚‹è¦³å¯Ÿ**ï¼š
- OT Pathã®æ–¹ãŒè¨“ç·´ãŒé€Ÿãã€è»Œé“ã‚‚ç›´ç·šã«è¿‘ã„
- VP Pathã¯åˆæœŸæ®µéšã§å¤§ããè¿‚å›ã™ã‚‹

---

### æ¼”ç¿’2: Rectified Flowã®1-stepç”Ÿæˆ

**å•é¡Œ**ï¼š
Rectified Flowï¼ˆarXiv:2209.03003ï¼‰ã¯ã€OT Pathã‚’**å†å­¦ç¿’**ã™ã‚‹ã“ã¨ã§1-stepã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚æ¬¡ã®æ‰‹é †ã§å®Ÿè£…ã›ã‚ˆï¼š

**Step 1: åˆæœŸCFMã®è¨“ç·´**

```rust
// Step 1: train initial CFM  (OT path: Î¼_t = tÂ·xâ‚ + (1-t)Â·xâ‚€)
let (model_1, losses_1) = train_flow_matching(1000, 256, 1e-3, PathType::OT, &mut rng)?;
```

**Step 2: è»Œé“ã®å†ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°**

è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§$\mathbf{x}_0 \to \mathbf{x}_1$ã®è»Œé“ã‚’ç”Ÿæˆã—ã€æ–°ã—ã„ãƒšã‚¢$(\mathbf{x}_0', \mathbf{x}_1')$ã‚’ä½œã‚‹ï¼š

```rust
fn resample_trajectories(model: &VectorFieldNet, n_samples: usize,
                          rng: &mut impl Rng) -> (Array2<f32>, Array2<f32>)
{
    let x0 = sample_source(n_samples, 2, rng); // xâ‚€ ~ N(0,I)
    let x1 = sample_flow(model, n_samples, 100, rng); // xâ‚' = ODESolve(v_Î¸; xâ‚€, t:0â†’1)  (Reflow)
    (x0, x1)
}
```

**Step 3: ç›´ç·šçµŒè·¯ã§ã®å†è¨“ç·´**

æ–°ã—ã„ãƒšã‚¢$(\mathbf{x}_0', \mathbf{x}_1')$ã«å¯¾ã—ã€**å®Œå…¨ãªç›´ç·š**ã‚’ç›®æ¨™ã¨ã™ã‚‹ï¼š

```rust
fn rectified_loss(model: &VectorFieldNet, x0: &Array2<f32>, x1: &Array2<f32>,
                   batch_size: usize, rng: &mut impl Rng) -> f32
{
    let n = x0.ncols();
    let idx: Vec<usize> = (0..batch_size).map(|_| rng.gen_range(0..n)).collect();
    let t: f32 = rng.gen();

    let x0_b = Array2::from_shape_fn((2, batch_size), |(r, c)| x0[[r, idx[c]]]);
    let x1_b = Array2::from_shape_fn((2, batch_size), |(r, c)| x1[[r, idx[c]]]);

    // x_t = t * xâ‚ + (1-t) * xâ‚€
    let x_t = x1_b.mapv(|v| t * v) + x0_b.mapv(|v| (1.0 - t) * v); // Î¼_t(xâ‚,xâ‚€) = tÂ·xâ‚ + (1-t)Â·xâ‚€  (OT straight path)
    let u_t = &x1_b - &x0_b; // u_t = xâ‚ - xâ‚€  (straight-line target)

    let v_hat = model_predict(model, &x_t, t);
    let diff = v_hat - u_t;
    diff.iter().map(|v| v * v).sum::<f32>() / diff.len() as f32 // L_CFM = E[||v_Î¸(xâ‚œ,t) - u_t||Â²]
}

```

**Step 4: 1-stepç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ**

```rust
// Resample
let (x0_new, x1_new) = resample_trajectories(&model_1, 10000, &mut rng);

// Re-train
let (model_2, _) = train_with_rectified_loss(&x0_new, &x1_new, &mut rng)?;

// 1-step sampling (Euler with Î”t=1)
let x0_test = sample_source(1000, 2, &mut rng);
let t_ones: Vec<f32> = vec![1.0_f32; 1000];
let v_hat = model_predict_batch(&model_2, &x0_test, &t_ones);
let x1_gen = &x0_test + &v_hat; // xâ‚ â‰ˆ xâ‚€ + v_Î¸(xâ‚€,0)Â·1  (1-step Euler, Î”t=1)
```

**æ¤œè¨¼**ï¼š
- 1-stepç”Ÿæˆã®å“è³ªãŒã€åˆæœŸãƒ¢ãƒ‡ãƒ«ã®50-step ODEã«åŒ¹æ•µã™ã‚‹ã“ã¨ã‚’ç¢ºèªã›ã‚ˆ

---

### æ¼”ç¿’3: Score â†” Flowç­‰ä¾¡æ€§ã®æ•°å€¤æ¤œè¨¼

**å•é¡Œ**ï¼š
Zone 3.5ã®ç†è«–çš„ç­‰ä¾¡æ€§ã‚’æ•°å€¤çš„ã«æ¤œè¨¼ã›ã‚ˆã€‚

**Step 1: Diffusion Modelã®è¨“ç·´**

æ¨™æº–çš„ãªDDPMã‚’è¨“ç·´ã—ã€score function $\nabla_{\mathbf{x}}\log p_t(\mathbf{x})$ã‚’å­¦ç¿’ï¼š

```rust
// Score network: Îµ_Î¸(x_t, t) â‰ˆ -âˆš(Î²_t) âˆ‡log p_t(x_t)
fn train_score_model(_rng: &mut impl Rng) -> ScoreNet {
    // DDPM training (Zone 3.5ã®å¼ã‚’ä½¿ç”¨)
    todo!()
}
```

**Step 2: Score â†’ Flowã®å¤‰æ›**

Probability Flow ODE (3.5.3ã®å¼) ã‚’ä½¿ã£ã¦ã€scoreã‹ã‚‰é€Ÿåº¦å ´ã‚’è¨ˆç®—ï¼š

```rust
// v_t(x) = -Â½Î²_tÂ·[x + Îµ_Î¸(xâ‚œ,t)]  (Scoreâ†”Flow equiv.)
fn score_to_flow(eps_theta: &Array2<f32>, x_t: &Array2<f32>, beta_t: f32) -> Array2<f32> { (x_t + eps_theta).mapv(|v| -0.5 * beta_t * v) }
```

**Step 3: ç›´æ¥Flow Matchingã¨ã®æ¯”è¼ƒ**

CFMã§è¨“ç·´ã—ãŸé€Ÿåº¦å ´$\mathbf{v}_\theta$ã¨ã€scoreã‹ã‚‰è¨ˆç®—ã—ãŸé€Ÿåº¦å ´ã‚’æ¯”è¼ƒï¼š

```rust
// Sample test points
let x_test = sample_target(100, &mut rng);
let t_test: Vec<f32> = (0..100).map(|_| rng.gen::<f32>() * 0.9 + 0.05).collect(); // t âˆˆ [0.05, 0.95]

// CFM prediction
let v_cfm = model_predict_batch(&model_cfm, &x_test, &t_test);

// Score-based prediction
let eps_pred = model_predict_batch(&model_score, &x_test, &t_test);
let beta_t = 0.1_f32; // Î²_t = 0.1  (example diffusion coefficient)
let v_score = score_to_flow(&eps_pred, &x_test, beta_t); // v_t(x) = -Â½Î²_tÂ·[x + Îµ_Î¸(xâ‚œ,t)]  (Scoreâ†”Flow equiv.)

// Compute correlation
let v_cfm_flat: Vec<f32> = v_cfm.iter().cloned().collect();
let v_score_flat: Vec<f32> = v_score.iter().cloned().collect();
let n = v_cfm_flat.len() as f32;
let mean_c = v_cfm_flat.iter().sum::<f32>() / n;
let mean_s = v_score_flat.iter().sum::<f32>() / n;
let cov: f32 = v_cfm_flat.iter().zip(&v_score_flat).map(|(a, b)| (a - mean_c) * (b - mean_s)).sum::<f32>() / n;
let std_c = (v_cfm_flat.iter().map(|a| (a - mean_c).powi(2)).sum::<f32>() / n).sqrt();
let std_s = (v_score_flat.iter().map(|b| (b - mean_s).powi(2)).sum::<f32>() / n).sqrt();
let correlation = cov / (std_c * std_s + 1e-8);
println!("Score â†” Flow correlation: {}", correlation);
```

**æœŸå¾…ã•ã‚Œã‚‹çµæœ**ï¼š
- ç›¸é–¢ä¿‚æ•°ãŒ0.95ä»¥ä¸Šï¼ˆã»ã¼ä¸€è‡´ï¼‰
- ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«ã®å“è³ªã‚‚åŒç­‰

---

### æ¼”ç¿’4: DiffFlowã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è¨“ç·´

**å•é¡Œ**ï¼š
Zone 3.6ã®DiffFlowã‚’ç°¡æ˜“å®Ÿè£…ã—ã€$\lambda$ã®åŠ¹æœã‚’èª¿ã¹ã‚ˆã€‚

**Discriminatorè¿½åŠ **ï¼š

```rust
// D(x,t): R^{d+1} â†’ [0,1]  (discriminator for DiffFlow GAN term)
fn build_discriminator(d: usize, vb: VarBuilder) -> Result<Discriminator> {
    Ok(Discriminator {
        fc1: linear(d + 1, 64, vb.pp("fc1"))?,
        fc2: linear(64, 64, vb.pp("fc2"))?,
        fc3: linear(64, 1, vb.pp("fc3"))?,
    })
}
```

**DiffFlow Loss**ï¼š

```rust
fn diffflow_loss(model: &VectorFieldNet, disc: &Discriminator,
                 path: &GaussianPath, lambda: f32,
                 batch_size: usize, rng: &mut impl Rng) -> (f32, f32)
{
    // CFM term
    let loss_cfm = cfm_loss(model, path, batch_size, rng);

    // GAN term
    let x_real = sample_target(batch_size, rng);
    let x_fake = sample_flow(model, batch_size, 100, rng);

    let zeros = Array2::zeros((1, batch_size));
    let ones_arr = Array2::ones((1, batch_size));
    let d_real = disc_forward(disc, &ndarray::concatenate![ndarray::Axis(0), x_real, zeros]);
    let d_fake = disc_forward(disc, &ndarray::concatenate![ndarray::Axis(0), x_fake, ones_arr]);

    let loss_d = -(d_real.iter().map(|v| (v + 1e-8).ln()).sum::<f32>()
                 + d_fake.iter().map(|v| (1.0 - v + 1e-8).ln()).sum::<f32>())
                 / batch_size as f32;
    let loss_g = -d_fake.iter().map(|v| (v + 1e-8).ln()).sum::<f32>()
                 / batch_size as f32;

    let total_loss = loss_cfm + lambda * loss_g; // L_DiffFlow = L_CFM + Î»Â·L_G  (hybrid CFM+GAN)
    (total_loss, loss_d)
}
```

**å®Ÿé¨“**ï¼š
- $\lambda \in \{0, 0.01, 0.1, 1.0\}$ã§è¨“ç·´
- å„è¨­å®šã§FIDï¼ˆã¾ãŸã¯2-Wassersteinè·é›¢ï¼‰ã‚’è¨ˆç®—
- è¨“ç·´å®‰å®šæ€§ï¼ˆlossã®åˆ†æ•£ï¼‰ã‚’æ¯”è¼ƒ

**ä»®èª¬**ï¼š
- $\lambda=0$ï¼šæœ€ã‚‚å®‰å®šã ãŒã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒé…ã„
- $\lambda=0.1$ï¼šå“è³ªã¨é€Ÿåº¦ã®ãƒãƒ©ãƒ³ã‚¹ãŒæœ€è‰¯
- $\lambda=1.0$ï¼šä¸å®‰å®šåŒ–ï¼ˆmode collapseç™ºç”Ÿã®å¯èƒ½æ€§ï¼‰

---

### æ¼”ç¿’5: Wassersteinå‹¾é…æµã®å¯è¦–åŒ–

**å•é¡Œ**ï¼š
JKOã‚¹ã‚­ãƒ¼ãƒ ï¼ˆZone 3.7.5ï¼‰ã‚’ç”¨ã„ã¦ã€2æ¬¡å…ƒåˆ†å¸ƒã®å‹¾é…æµã‚’å¯è¦–åŒ–ã›ã‚ˆã€‚

**è¨­å®š**ï¼š
- åˆæœŸåˆ†å¸ƒ$p_0 = \mathcal{N}([3, 3], I)$
- ç›®æ¨™åˆ†å¸ƒ$p_{\text{data}} = 0.5\mathcal{N}([-2, 0], I) + 0.5\mathcal{N}([2, 0], I)$
- ç›®çš„é–¢æ•°$\mathcal{F}[p] = \mathrm{KL}(p \| p_{\text{data}})$

**å®Ÿè£…**ï¼š

```rust
fn jko_step(p_current: &Array2<f32>, p_target: &Array2<f32>, tau: f32,
             rng: &mut impl Rng) -> Array2<f32>
{
    // JKO step: min_p [KL(p||p_target) + Wâ‚‚Â²(p, p_current)/(2Ï„)]
    let m = pairwise_sq_dist(p_current, p_target); // C_ij = ||xáµ¢ - yâ±¼||Â²  (cost matrix)
    let gamma = sinkhorn_ot(&m.mapv(|v| v as f64), tau as f64, 100); // Entropic OT: min_Ï€ Î£Ï€áµ¢â±¼cáµ¢â±¼ + ÎµÂ·H(Ï€)

    // Update via transport plan: move particles toward target
    apply_transport(p_current, p_target, &gamma.mapv(|v| v as f32))
}

fn main_jko() {
    let mut rng = rand::rngs::StdRng::seed_from_u64(0);
    let mut p = sample_source(1000, 2, &mut rng);
    for k in 0..50 {
        let p_target = sample_target(1000, &mut rng);
        p = jko_step(&p, &p_target, 0.1, &mut rng);
        if k % 10 == 0 {
            println!("JKO step {}: p shape {:?}", k, p.shape());
        }
    }
}
```

**å¯è¦–åŒ–**ï¼š
- å„ã‚¹ãƒ†ãƒƒãƒ—ã§åˆ†å¸ƒã®scatter plotã‚’ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³åŒ–
- è»Œé“ãŒã€Œæ»‘ã‚‰ã‹ã«ã€2å³°ã‚¬ã‚¦ã‚¹ã«åæŸã™ã‚‹ã“ã¨ã‚’ç¢ºèª

---

### å®Ÿé¨“ã®ã¾ã¨ã‚

| æ¼”ç¿’ | ç¢ºèªã™ã‚‹ç†è«– | é‡è¦ãªè¦³å¯Ÿ |
|------|--------------|------------|
| æ¼”ç¿’1 | OT vs VP Path | OT = ç›´ç·š â†’ é«˜åŠ¹ç‡ |
| æ¼”ç¿’2 | Rectified Flow | å†è¨“ç·´ã§1-stepåŒ–å¯èƒ½ |
| æ¼”ç¿’3 | Score â†” Flowç­‰ä¾¡æ€§ | æ•°å€¤çš„ã«ã»ã¼ä¸€è‡´ |
| æ¼”ç¿’4 | DiffFlowçµ±ä¸€ | $\lambda$ã§Diffusionâ†”GANé€£ç¶šå¤‰åŒ– |
| æ¼”ç¿’5 | Wassersteinå‹¾é…æµ | JKO = é›¢æ•£å‹¾é…é™ä¸‹ |

> **Note:** **å®Ÿé¨“ã®æœ¬è³ª**
> ç†è«–ã¯ç¾ã—ã„ãŒã€æ‰‹ã‚’å‹•ã‹ã—ã¦åˆã‚ã¦ã€Œãªãœã“ã‚ŒãŒé©å‘½çš„ã‹ã€ãŒè…¹è½ã¡ã™ã‚‹ã€‚ç‰¹ã«æ¼”ç¿’2ã®Rectified Flowã§ã¯ã€**1-stepã§é«˜å“è³ªãªç”»åƒãŒç”Ÿæˆã•ã‚Œã‚‹ç¬é–“**ã«ç«‹ã¡ä¼šãˆã‚‹ã€‚ã“ã‚Œã¯ã€ç†è«–ãŒå®Ÿç”¨ã«ç›´çµã™ã‚‹ç¨€æœ‰ãªä¾‹ã ã€‚

> **Progress: 85%**
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. OT-CFM å®Ÿè£…ã§ `x_t = (1-t)*x0 + t*x1` ã‚’ä½¿ã£ãŸå ´åˆã®æ¡ä»¶ä»˜ããƒ™ã‚¯ãƒˆãƒ«å ´ `u_t = x1 - x0` ãŒå®šæ•°ã«ãªã‚‹ç†ç”±ã‚’ã€çµŒè·¯ã®å¾®åˆ†ã‹ã‚‰å°ã‘ã€‚
> 2. Rectified Flow ã® ReFlow ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ãŠã„ã¦ã€è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç”Ÿæˆã—ãŸè»Œé“ $(x_0, x_1^\prime)$ ã‚’ãƒšã‚¢ã¨ã—ã¦å†è¨“ç·´ã™ã‚‹ç†ç”±ï¼ˆç›´ç·šæ€§æ”¹å–„ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ï¼‰ã‚’èª¬æ˜ã›ã‚ˆã€‚

---

## ğŸ”¬ Z6. æ–°ãŸãªå†’é™ºã¸ï¼ˆç ”ç©¶å‹•å‘ï¼‰

Flow Matchingã¯æ€¥é€Ÿã«é€²åŒ–ã—ã¦ã„ã‚‹ã€‚ã“ã“ã§ã¯ã€2024-2025å¹´ã®æœ€æ–°ç ”ç©¶ã¨ã€æœªè§£æ±ºã®èª²é¡Œã‚’ç´¹ä»‹ã™ã‚‹ã€‚

---

### 6.1 Flow Map Matching (Boffi+ NeurIPS 2025)

**å•é¡Œæ„è­˜**ï¼š
å¾“æ¥ã®CFMã¯ã€å„ã‚µãƒ³ãƒ—ãƒ«$(\mathbf{x}_0, \mathbf{x}_1)$ã”ã¨ã«**ç‹¬ç«‹ã«**æ¡ä»¶ä»˜ãé€Ÿåº¦å ´$\mathbf{u}_t(\mathbf{x}|\mathbf{x}_1)$ã‚’è¨ˆç®—ã™ã‚‹ã€‚ã—ã‹ã—ã€ã“ã‚Œã¯æ¬¡ã®éåŠ¹ç‡ã‚’ç”Ÿã‚€ï¼š

- ã‚µãƒ³ãƒ—ãƒ«é–“ã®**å…±é€šæ§‹é€ **ï¼ˆä¾‹ï¼šé¡”ç”»åƒã®ç›®ã®ä½ç½®ï¼‰ã‚’æ´»ç”¨ã§ããªã„
- é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã§è¨ˆç®—ã‚³ã‚¹ãƒˆãŒå¢—å¤§

**Flow Map Matchingã®ææ¡ˆ**ï¼š

ã€Œæ¡ä»¶ä»˜ãé€Ÿåº¦å ´ã€ã§ã¯ãªãã€**è¼¸é€å†™åƒ**ï¼ˆtransport mapï¼‰$\mathbf{T}_t: \mathbb{R}^d \to \mathbb{R}^d$ã‚’ç›´æ¥å­¦ç¿’ã™ã‚‹ã€‚

$$
\mathbf{x}_t = \mathbf{T}_t(\mathbf{x}_0), \quad \mathbf{v}_t(\mathbf{x}_t) = \frac{\partial \mathbf{T}_t}{\partial t}(\mathbf{T}_t^{-1}(\mathbf{x}_t))
$$

**åˆ©ç‚¹**ï¼š
1. **Amortization**ï¼šä¸€åº¦$\mathbf{T}_t$ã‚’å­¦ç¿’ã™ã‚Œã°ã€ä»»æ„ã®$\mathbf{x}_0$ã«é©ç”¨å¯èƒ½
2. **å¹¾ä½•å­¦çš„åˆ¶ç´„**ã®çµ±åˆï¼ˆä¾‹ï¼šä½“ç©ä¿å­˜ã€æ›²ç‡åˆ¶ç´„ï¼‰
3. **é€†å†™åƒ**$\mathbf{T}_t^{-1}$ã‚‚å­¦ç¿’å¯èƒ½ï¼ˆåŒæ–¹å‘ç”Ÿæˆï¼‰

**å®Ÿé¨“çµæœ**ï¼ˆImageNet 64Ã—64ï¼‰ï¼š

| æ‰‹æ³• | FID â†“ | Sampling Steps | è¨“ç·´æ™‚é–“ |
|------|-------|----------------|----------|
| CFM | 2.31 | 50 | 100% |
| **Flow Map Matching** | **2.18** | **50** | **75%** |

---

### 6.2 Variational Rectified Flow (Guo+ 2025)

**å•é¡Œ**ï¼š
Rectified Flowã®å†è¨“ç·´ï¼ˆreflowï¼‰ã¯ã€è»Œé“ã‚’ç›´ç·šã«è¿‘ã¥ã‘ã‚‹ãŒã€**ç†è«–çš„ä¿è¨¼**ãŒãªã„ã€‚ã©ã®ç¨‹åº¦ã®å†è¨“ç·´ã§æœ€é©ã«ãªã‚‹ã‹ï¼Ÿ

**å¤‰åˆ†å®šå¼åŒ–**ï¼š

æœ€é©è¼¸é€å†™åƒã‚’**å¤‰åˆ†å•é¡Œ**ã¨ã—ã¦å®šå¼åŒ–ï¼š

$$
\min_{\mathbf{T}} \mathbb{E}\left[\|\mathbf{T}(\mathbf{x}_0) - \mathbf{x}_1\|^2\right] + \lambda\,\mathrm{KL}(q_{\mathbf{T}} \| p_{\text{data}})
$$

ã“ã“ã§ï¼š
- ç¬¬1é …ï¼šè¼¸é€ã‚³ã‚¹ãƒˆï¼ˆç›´ç·šæ€§ï¼‰
- ç¬¬2é …ï¼šåˆ†å¸ƒä¸€è‡´æ€§
- $\lambda$ï¼šæ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

**ç†è«–çš„æˆæœ**ï¼š
- å†è¨“ç·´ã®**åæŸãƒ¬ãƒ¼ãƒˆ**ã‚’å°å‡ºï¼š$O(1/\sqrt{K})$ï¼ˆ$K$=å†è¨“ç·´å›æ•°ï¼‰
- æœ€é©$\lambda$ã®é¸æŠåŸºæº–ã‚’æä¾›

**å®Ÿç”¨çš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ**ï¼š
- å†è¨“ç·´ã‚’2-3å›ã§æ‰“ã¡åˆ‡ã‚‹ç†è«–çš„æ ¹æ‹ 
- è¨ˆç®—ã‚³ã‚¹ãƒˆå‰Šæ¸›

---

### 6.3 Multitask Stochastic Interpolants (Negrel+ 2025)

**å‹•æ©Ÿ**ï¼š
ç”»åƒç”Ÿæˆã§ã¯ã€è¤‡æ•°ã®æ¡ä»¶ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã€ã‚¹ã‚¿ã‚¤ãƒ«ã€è§£åƒåº¦ï¼‰ã‚’åŒæ™‚ã«æ‰±ã„ãŸã„ã€‚

**ææ¡ˆ**ï¼š
Stochastic Interpolantsï¼ˆZone 3.4ï¼‰ã‚’**ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’**ã«æ‹¡å¼µï¼š

$$
\mathcal{L}_{\text{multi}} = \sum_{k=1}^K w_k\,\mathbb{E}_{t, \mathbf{x}_0, \mathbf{x}_1^{(k)}}\left[\left\|\mathbf{v}_\theta^{(k)}(t, \mathbf{x}_t) - \mathbf{u}_t^{(k)}\right\|^2\right]
$$

ã“ã“ã§ï¼š
- $k$ï¼šã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆä¾‹ï¼š$k=1$ã¯ãƒ†ã‚­ã‚¹ãƒˆæ¡ä»¶ã€$k=2$ã¯ã‚¹ã‚¿ã‚¤ãƒ«æ¡ä»¶ï¼‰
- $w_k$ï¼šã‚¿ã‚¹ã‚¯é‡ã¿
- $\mathbf{v}_\theta^{(k)}$ï¼šã‚¿ã‚¹ã‚¯å›ºæœ‰ã®é€Ÿåº¦å ´

**æŠ€è¡“çš„å·¥å¤«**ï¼š
- **Adapter Modules**ï¼šå…±é€šãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ + ã‚¿ã‚¹ã‚¯å›ºæœ‰å±¤
- **Task Balancing**ï¼šå„ã‚¿ã‚¹ã‚¯ã®lossã‚’å‹•çš„ã«èª¿æ•´ï¼ˆGradNormã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰

**å®Ÿé¨“**ï¼š
- Text-to-Imageã¨Style Transferã‚’åŒæ™‚è¨“ç·´
- å˜ä¸€ã‚¿ã‚¹ã‚¯è¨“ç·´ã‚ˆã‚Š**30%ã®è¨ˆç®—å‰Šæ¸›**ã€å“è³ªã¯åŒç­‰

---

### 6.4 Flow Matching for Discrete Domains

**èª²é¡Œ**ï¼š
ã“ã‚Œã¾ã§ã®Flow Matchingã¯**é€£ç¶šç©ºé–“**$\mathbb{R}^d$ã‚’ä»®å®šã€‚ã—ã‹ã—ã€ãƒ†ã‚­ã‚¹ãƒˆã€ã‚°ãƒ©ãƒ•ã€åˆ†å­ãªã©ã¯**é›¢æ•£æ§‹é€ **ã‚’æŒã¤ã€‚

**ç¾åœ¨ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**ï¼š

1. **Embedding Space Flow**ï¼ˆCampbell+ 2024ï¼‰
   - é›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é€£ç¶šembeddingã«å†™åƒ
   - Embeddingç©ºé–“ã§Flow Matching
   - ãƒ‡ã‚³ãƒ¼ãƒ‰æ™‚ã«æœ€è¿‘å‚ãƒˆãƒ¼ã‚¯ãƒ³ã«ä¸¸ã‚ã‚‹

   **å•é¡Œ**ï¼šä¸¸ã‚èª¤å·®ã€embeddingç©ºé–“ã®éè‡ªç„¶æ€§

2. **Continuous-Time Markov Chain Flow**ï¼ˆSun+ 2024ï¼‰
   - é›¢æ•£çŠ¶æ…‹é–“ã®é·ç§»ç¢ºç‡ã‚’Flowã¨ã—ã¦å®šå¼åŒ–
   - Rate matrix $\mathbf{Q}_t$ã‚’å­¦ç¿’

   $$
   \frac{\partial p_t}{\partial t} = p_t \mathbf{Q}_t
   $$

   **å•é¡Œ**ï¼šçŠ¶æ…‹ç©ºé–“ãŒå¤§ãã„ã¨$\mathbf{Q}_t$ã®æ¬¡å…ƒçˆ†ç™º

**æœªè§£æ±ºå•é¡Œ**ï¼š
- é›¢æ•£Flowã®**æœ€é©è¼¸é€ç†è«–**ã®ç¢ºç«‹
- åŠ¹ç‡çš„ãªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

---

### 6.5 High-Resolution Image Generationã¸ã®Scale

**ç¾çŠ¶**ï¼š
- CIFAR-10 (32Ã—32)ï¼šFID ~2
- ImageNet 64Ã—64ï¼šFID ~2.5
- **ImageNet 256Ã—256**ï¼šFID ~5-7ï¼ˆDiffusionã«åŠ£ã‚‹ï¼‰

**ãƒœãƒˆãƒ«ãƒãƒƒã‚¯**ï¼š

1. **Memory**ï¼šé«˜è§£åƒåº¦ã§ã¯é€Ÿåº¦å ´ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒå·¨å¤§åŒ–
2. **ODE Stiffness**ï¼šè¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿ã§ODEãŒã€Œç¡¬ã„ã€ï¼ˆstiffï¼‰ã«ãªã‚Šã€æ•°å€¤èª¤å·®ãŒè“„ç©

**ç ”ç©¶æ–¹å‘**ï¼š

**a) Latent Flow Matching**ï¼ˆDao+ 2024ï¼‰
- VAEã®æ½œåœ¨ç©ºé–“ã§Flow Matching
- Stable Diffusionã¨åŒæ§˜ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
- ImageNet 256Ã—256ã§FID **3.2**é”æˆ

**b) Multi-Scale Flow**ï¼ˆKim+ 2024ï¼‰
- ä½è§£åƒåº¦â†’é«˜è§£åƒåº¦ã®æ®µéšçš„ç”Ÿæˆ
- å„ã‚¹ã‚±ãƒ¼ãƒ«ã§ç‹¬ç«‹ãªFlow
- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒå¤§å¹…å‘ä¸Š

**c) Adaptive Step Size ODE Solver**
- DiffEq.jlã®`Tsit5()`ãªã©ã€é©å¿œçš„ã‚½ãƒ«ãƒãƒ¼ã‚’æ´»ç”¨
- Stiffnessã‚’è‡ªå‹•æ¤œå‡ºã—ã¦ã‚¹ãƒ†ãƒƒãƒ—ã‚µã‚¤ã‚ºèª¿æ•´

---

### 6.6 æœªè§£æ±ºã®ç†è«–çš„å•é¡Œ

**Problem 1: éå‡¸æœ€é©åŒ–ã®ä¿è¨¼**

CFM Lossã¯éå‡¸ã ãŒã€å®Ÿéš›ã«ã¯å±€æ‰€æœ€é©ã«é™¥ã‚‰ãªã„ã€‚ãªãœã‹ï¼Ÿ

**äºˆæƒ³**ï¼š
- Over-parameterizationï¼ˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãŒéå‰°ã«å¤§ãã„ï¼‰
- Loss landscapeãŒã€Œãƒ•ãƒ©ãƒƒãƒˆã€ï¼ˆimplicit regularizationï¼‰

**å¿…è¦ãªç†è«–**ï¼šNeural Tangent Kernel (NTK)è§£æã€Mean Fieldç†è«–

---

**Problem 2: æœ€é©ãªProbability Pathã®é¸æŠ**

OT Pathã€VP Pathã€General Pathã®ã†ã¡ã€**ãƒ‡ãƒ¼ã‚¿ä¾å­˜ã§æœ€é©ãªçµŒè·¯**ã‚’è‡ªå‹•é¸æŠã§ãã‚‹ã‹ï¼Ÿ

**ã‚¢ã‚¤ãƒ‡ã‚¢**ï¼š
- Meta-learningï¼šè¤‡æ•°ã®pathã§è¨“ç·´ã—ã€validation lossã§é¸æŠ
- Adaptive Pathï¼šãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã®å¹¾ä½•å­¦çš„ç‰¹æ€§ï¼ˆæ›²ç‡ã€ä½ç›¸ï¼‰ã‹ã‚‰çµŒè·¯ã‚’æ§‹ç¯‰

---

**Problem 3: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°è¤‡é›‘åº¦ã®ä¸‹ç•Œ**

Rectified Flowã¯1-stepã‚’ä¸»å¼µã™ã‚‹ãŒã€**ç†è«–çš„ã«å¿…è¦ãªæœ€å°ã‚¹ãƒ†ãƒƒãƒ—æ•°**ã¯ï¼Ÿ

**æ—¢çŸ¥ã®çµæœ**ï¼š
- Lipschitzé€£ç¶šãªé€Ÿåº¦å ´ã§ã¯ã€$O(\epsilon^{-1})$ã‚¹ãƒ†ãƒƒãƒ—ã§$\epsilon$-è¿‘ä¼¼ï¼ˆæ¨™æº–çš„ODEç†è«–ï¼‰

**Open Question**ï¼š
- ãƒ‡ãƒ¼ã‚¿ã®ã€Œè¤‡é›‘ã•ã€ï¼ˆä¾‹ï¼šãƒ¢ãƒ¼ãƒ‰æ•°ã€æ¬¡å…ƒï¼‰ã¨å¿…è¦ã‚¹ãƒ†ãƒƒãƒ—æ•°ã®é–¢ä¿‚
- 1-stepãŒå¯èƒ½ãªæ¡ä»¶ã®ç‰¹å¾´ã¥ã‘

---

### 6.7 å¿œç”¨é ˜åŸŸã®æ‹¡å¤§

Flow Matchingã¯ç”»åƒç”Ÿæˆã‚’è¶…ãˆã¦åºƒãŒã£ã¦ã„ã‚‹ï¼š

**a) åˆ†å­è¨­è¨ˆ**ï¼ˆDrug Discoveryï¼‰
- ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã®3Dæ§‹é€ ç”Ÿæˆï¼ˆAlphaFoldçš„å¿œç”¨ï¼‰
- åŒ–å­¦çš„åˆ¶ç´„ï¼ˆçµåˆé•·ã€è§’åº¦ï¼‰ã‚’Flowã«çµ„ã¿è¾¼ã‚€

**b) éŸ³å£°åˆæˆ**
- WaveNetã®ä»£æ›¿ã¨ã—ã¦ã®Flow-based TTS
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”Ÿæˆï¼ˆä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼‰

**c) å¼·åŒ–å­¦ç¿’**
- è¡Œå‹•ãƒãƒªã‚·ãƒ¼ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«åŒ–
- Flow Matching + Actor-Critic

**d) æ°—è±¡äºˆæ¸¬**
- æ™‚ç©ºé–“ãƒ‡ãƒ¼ã‚¿ã®ç¢ºç‡çš„äºˆæ¸¬
- Ensembleç”Ÿæˆï¼ˆè¤‡æ•°ã®æœªæ¥è»Œé“ï¼‰

---

### 6.8 æœ€æ–°è«–æ–‡ãƒªã‚¹ãƒˆï¼ˆ2024-2025ï¼‰

è¨“ç·´åŠ¹ç‡ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹æœ€æ–°ç ”ç©¶ï¼š

1. **Flow Map Matching**ï¼ˆBoffi+ 2024, arXiv:2406.07507ï¼‰
   - è¼¸é€å†™åƒã®ç›´æ¥å­¦ç¿’

2. **Variational Rectified Flow**ï¼ˆGuo+ 2025, arXiv:2502.09616ï¼‰
   - å¤‰åˆ†å®šå¼åŒ–ã¨åæŸä¿è¨¼

3. **Multitask Stochastic Interpolants**ï¼ˆNegrel+ 2025, arXiv:2508.04605ï¼‰
   - ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã¸ã®æ‹¡å¼µ

4. **Meta AI Flow Matching Guide**ï¼ˆ2024, arXiv:2412.06264ï¼‰
   - å®Ÿè£…ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹é›†

5. **Discrete Flow Matching**ï¼ˆCampbell+ 2024ï¼‰
   - ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã¸ã®å¿œç”¨

<details><summary>æ·±æ˜ã‚Š: Flow Matchingå®Ÿè£…ãƒªã‚½ãƒ¼ã‚¹</summary>

Flow Matchingã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¯æ´»ç™ºã§ã€æ¯æœˆæ–°ã—ã„è«–æ–‡ãŒç™»å ´ã™ã‚‹ã€‚ä»¥ä¸‹ã®ãƒªã‚½ãƒ¼ã‚¹ãŒæœ‰ç”¨ï¼š

- **GitHub**: `atong01/conditional-flow-matching`ï¼ˆå…¬å¼å®Ÿè£…ï¼‰
- **Papers with Code**: "Flow Matching"ã‚¿ã‚°ã§ãƒ•ã‚£ãƒ«ã‚¿
- **Twitter**: #FlowMatching ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ï¼ˆç ”ç©¶è€…ã®è­°è«–ï¼‰

ç‰¹ã«ã€**ICLR 2025 Workshop on Flow-Based Models**ã§ã¯ã€æœªå…¬é–‹ã®æœ€æ–°ç ”ç©¶ãŒè­°è«–ã•ã‚Œã‚‹ã€‚

</details>

> **Progress: 95%**
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. Flow Map Matchingï¼ˆarXiv:2406.07507ï¼‰ãŒãªãœåå¾©ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ä¸è¦ã«ã§ãã‚‹ã®ã‹ã€Flow Consistency æ¡ä»¶ã®è¦³ç‚¹ã‹ã‚‰èª¬æ˜ã›ã‚ˆã€‚
> 2. Wasserstein å‹¾é…æµã®é›¢æ•£è¿‘ä¼¼ã§ã‚ã‚‹ JKO scheme $\rho^{k+1} = \arg\min_\rho \frac{1}{2\tau}W_2^2(\rho,\rho^k) + \mathcal{F}(\rho)$ ã«ãŠã„ã¦ã€$\tau\to0$ ã®æ¥µé™ã§é€£ç¶šæ™‚é–“ã® Fokker-Planck æ–¹ç¨‹å¼ãŒå¾©å…ƒã•ã‚Œã‚‹ã“ã¨ã‚’ç›´æ„Ÿçš„ã«èª¬æ˜ã›ã‚ˆã€‚

---

## ğŸ­ Z7. ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ï¼ˆã¾ã¨ã‚ãƒ»FAQãƒ»æ¬¡å›äºˆå‘Šï¼‰

ã“ã“ã¾ã§ã®é•·ã„æ—…ã‚’æŒ¯ã‚Šè¿”ã‚Šã€é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’æ•´ç†ã—ã‚ˆã†ã€‚

---

### 7.1 ã“ã®è¬›ç¾©ã§å­¦ã‚“ã ã“ã¨

**æ ¸å¿ƒçš„æ´å¯Ÿ**ï¼š

1. **ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®çµ±ä¸€ç†è«–**
   - Score Matchingã€Diffusion Modelsã€Flow Matchingã€GANsã¯ã€ã™ã¹ã¦**æœ€é©è¼¸é€ç†è«–ã®Wassersteinå‹¾é…æµ**ã¨ã—ã¦ç†è§£ã§ãã‚‹
   - é•ã„ã¯ã€Œç›®çš„é–¢æ•°$\mathcal{F}$ã€ã¨ã€Œé›¢æ•£åŒ–æ‰‹æ³•ã€ã ã‘

2. **Conditional Flow Matching (CFM)ã®é©æ–°æ€§**
   - **å‘¨è¾ºåŒ–ãƒˆãƒªãƒƒã‚¯**ã«ã‚ˆã‚Šã€å‘¨è¾ºé€Ÿåº¦å ´$\mathbf{v}_t$ã‚’å­¦ç¿’ã›ãšã«ã€æ¡ä»¶ä»˜ãé€Ÿåº¦å ´$\mathbf{u}_t(\mathbf{x}|\mathbf{x}_1)$ã ã‘ã§è¨“ç·´å¯èƒ½
   - Simulation-freeï¼ˆSDEã‚’è§£ã‹ãšã«è¨“ç·´ã§ãã‚‹ï¼‰

3. **Optimal Transport (OT) Pathã®å„ªä½æ€§**
   - ç›´ç·šçµŒè·¯ â†’ æœ€çŸ­è·é›¢ â†’ å°‘ãªã„ã‚¹ãƒ†ãƒƒãƒ—ã§é«˜å“è³ªç”Ÿæˆ
   - Rectified Flowã§1-stepç”Ÿæˆã‚‚å¯èƒ½

4. **Stochastic Interpolantsã®ä¸€èˆ¬æ€§**
   - Flowã¨Diffusionã‚’çµ±ä¸€ã™ã‚‹æ çµ„ã¿
   - ç¢ºç‡çš„æºã‚‰ã$\sigma_t$ã®é¸æŠã§é€£ç¶šçš„ã«ç§»è¡Œ

5. **DiffFlowã®çµ±ä¸€è¦–ç‚¹**
   - SDMã¨GANãŒ**åŒä¸€SDE**ã‹ã‚‰å°å‡ºã•ã‚Œã‚‹
   - $g(t)$ï¼ˆæ‹¡æ•£ä¿‚æ•°ï¼‰ã¨$\lambda$ï¼ˆGANé …ã®é‡ã¿ï¼‰ã§é€£ç¶šçš„ã«åˆ¶å¾¡

---

### 7.2 é‡è¦ãªæ•°å¼ã®ç·ã¾ã¨ã‚

**CFM Loss**ï¼š
$$
\mathcal{L}_{\text{CFM}}(\theta) = \mathbb{E}_{t, \mathbf{x}_0, \mathbf{x}_1}\left[\left\|\mathbf{v}_\theta(t, \mathbf{x}_t) - \mathbf{u}_t(\mathbf{x}_t | \mathbf{x}_1, \mathbf{x}_0)\right\|^2\right]
$$

**Gaussian Probability Path**ï¼ˆOTï¼‰ï¼š
$$
\mu_t(\mathbf{x}_1, \mathbf{x}_0) = t\mathbf{x}_1 + (1-t)\mathbf{x}_0, \quad \sigma_t = \sigma_{\min}
$$

**æ¡ä»¶ä»˜ãé€Ÿåº¦å ´**ï¼ˆOT Pathï¼‰ï¼š
$$
\mathbf{u}_t(\mathbf{x} | \mathbf{x}_1, \mathbf{x}_0) = \mathbf{x}_1 - \mathbf{x}_0
$$

**Score â†” Flowç­‰ä¾¡æ€§**ï¼š
$$
\mathbf{v}_t(\mathbf{x}) = \mathbf{f}(\mathbf{x}, t) - \frac{1}{2}g(t)^2\nabla_{\mathbf{x}}\log p_t(\mathbf{x})
$$

**Wassersteinå‹¾é…æµ**ï¼š
$$
\mathbf{v}_t = -\nabla \frac{\delta \mathcal{F}}{\delta p}\bigg|_{p=p_t}
$$

---

### 7.3 å®Ÿè£…ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

Flow Matchingã‚’å®Ÿè£…ã™ã‚‹éš›ã®å¿…é ˆè¦ç´ ï¼š

- [ ] **Probability Path**ã®å®šç¾©ï¼ˆ`path_params()`ï¼‰
- [ ] **æ¡ä»¶ä»˜ãé€Ÿåº¦å ´**ã®è¨ˆç®—ï¼ˆ`conditional_vector_field()`ï¼‰
- [ ] **CFM Loss**ã®å®Ÿè£…ï¼ˆMSE between $\mathbf{v}_\theta$ and $\mathbf{u}_t$ï¼‰
- [ ] **æ™‚åˆ»æ¡ä»¶ä»˜ããƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**ï¼ˆå…¥åŠ›ã«$t$ã‚’çµåˆï¼‰
- [ ] **ODE Solver**ï¼ˆDifferentialEquations.jlãªã©ï¼‰
- [ ] **å¯è¦–åŒ–**ï¼ˆè»Œé“ã€ã‚µãƒ³ãƒ—ãƒ«ã€loss curveï¼‰

---

### 7.4 ã‚ˆãã‚ã‚‹è³ªå•ï¼ˆFAQï¼‰

**Q1: Flow Matchingã¨Diffusion Modelsã€ã©ã¡ã‚‰ã‚’ä½¿ã†ã¹ãï¼Ÿ**

**A**ï¼š
- **Flow Matching**ï¼šã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é€Ÿåº¦ãŒé‡è¦ãªå ´åˆï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”Ÿæˆã€1-stepåŒ–ï¼‰
- **Diffusion Models**ï¼šæ—¢å­˜ã®å¤§è¦æ¨¡å®Ÿè£…ï¼ˆStable Diffusionï¼‰ã‚’æ´»ç”¨ã—ãŸã„å ´åˆ
- **ä¸¡è€…ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰**ï¼ˆDiffFlowï¼‰ï¼šæœ€é«˜å“è³ªã‚’è¿½æ±‚ã™ã‚‹å ´åˆ

**ç¾æ™‚ç‚¹ã®æ¨å¥¨**ï¼šæ–°è¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãªã‚‰**Flow Matching**ã€‚ç†ç”±ï¼š
- ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…
- é«˜é€Ÿã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
- ç†è«–çš„ã«æ´—ç·´ã•ã‚Œã¦ã„ã‚‹

---

**Q2: ãªãœOT PathãŒæœ€é©ãªã®ã‹ï¼Ÿ**

**A**ï¼š
æœ€é©è¼¸é€ç†è«–ã«ã‚ˆã‚Šã€$p_0$ã‹ã‚‰$p_1$ã¸ã®ã€Œæœ€çŸ­çµŒè·¯ã€ãŒOT Pathã§ã‚ã‚‹ã“ã¨ãŒä¿è¨¼ã•ã‚Œã‚‹ã€‚æ•°å­¦çš„ã«ã¯ï¼š

$$
W_2(p_0, p_1)^2 = \inf_{\pi} \mathbb{E}_{(\mathbf{x}_0, \mathbf{x}_1) \sim \pi}\left[\|\mathbf{x}_1 - \mathbf{x}_0\|^2\right]
$$

ã“ã®æœ€é©è§£ãŒç›´ç·šçµŒè·¯$\mu_t = t\mathbf{x}_1 + (1-t)\mathbf{x}_0$ã‚’ä¸ãˆã‚‹ï¼ˆGaussianã®å ´åˆï¼‰ã€‚

---

**Q3: Rectified Flowã®å†è¨“ç·´ã¯æœ¬å½“ã«å¿…è¦ï¼Ÿ**

**A**ï¼š
**ãƒ‡ãƒ¼ã‚¿ä¾å­˜**ã€‚ç°¡å˜ãªåˆ†å¸ƒï¼ˆMNISTã€2D toy dataï¼‰ã§ã¯åˆå›è¨“ç·´ã§ã»ã¼ç›´ç·šã€‚è¤‡é›‘ãªåˆ†å¸ƒï¼ˆImageNetï¼‰ã§ã¯1-2å›ã®å†è¨“ç·´ã§å¤§å¹…æ”¹å–„ã€‚

**åˆ¤æ–­åŸºæº–**ï¼š
- è»Œé“ã®ç›´ç·šæ€§ã‚’æ¸¬å®šï¼ˆå¹³å‡åå·®ï¼‰
- 1-stepç”Ÿæˆã®å“è³ªã‚’ãƒã‚§ãƒƒã‚¯
- æ”¹å–„ãŒè¦‹ã‚‰ã‚Œãªããªã£ãŸã‚‰çµ‚äº†

---

**Q4: é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ï¼ˆä¾‹ï¼š1024Ã—1024ç”»åƒï¼‰ã§ã‚‚Flow Matchingã¯æœ‰åŠ¹ï¼Ÿ**

**A**ï¼š
**Latent Space Flow Matching**ãŒæœ‰åŠ¹ã€‚æ‰‹é †ï¼š

1. VAEã§ç”»åƒã‚’ä½æ¬¡å…ƒæ½œåœ¨ç©ºé–“ã«åœ§ç¸®ï¼ˆä¾‹ï¼š1024Ã—1024 â†’ 64Ã—64Ã—4ï¼‰
2. æ½œåœ¨ç©ºé–“ã§Flow Matchingè¨“ç·´
3. ãƒ‡ã‚³ãƒ¼ãƒ€ã§ç”»åƒã«æˆ»ã™

Stable Diffusionã¨åŒã˜ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€‚Meta AIã®Flow Matching Guideï¼ˆarXiv:2412.06264ï¼‰ã«è©³ç´°ã‚ã‚Šã€‚

---

**Q5: å®Ÿè£…ã§æœ€ã‚‚ãƒãƒã‚Šã‚„ã™ã„ãƒã‚°ã¯ï¼Ÿ**

**A**ï¼š
**Top 3**ï¼š

1. **æ™‚åˆ»$t$ã®ç¯„å›²ãƒŸã‚¹**
   - è¨“ç·´ã§ã¯$t \in (0, 1)$ã ãŒã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ã¯$t=0$ã¨$t=1$ã®å¢ƒç•Œã‚‚å¿…è¦
   - è§£æ±ºï¼š`t = rand() * 0.98 + 0.01`ã§è¨“ç·´ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¯`t âˆˆ [0, 1]`

2. **ãƒ™ã‚¯ãƒˆãƒ«å ´ã®ç¬¦å·ãƒŸã‚¹**
   - $\mathbf{u}_t = \mathbf{x}_1 - \mathbf{x}_0$ã‚’$\mathbf{x}_0 - \mathbf{x}_1$ã¨æ›¸ã„ã¦ã—ã¾ã†
   - è§£æ±ºï¼šZone 1ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ä¾‹ã§å¯è¦–åŒ–ã—ã¦ç¢ºèª

3. **ODEã®æ•°å€¤èª¤å·®**
   - Euleræ³•ã§ã‚¹ãƒ†ãƒƒãƒ—ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã‚‹
   - è§£æ±ºï¼šRK4æ³•ã‚’ä½¿ã†ã€ã¾ãŸã¯ã‚¹ãƒ†ãƒƒãƒ—ã‚µã‚¤ã‚ºã‚’åŠåˆ†ã«

---

**Q6: Wassersteinå‹¾é…æµã®ç†è§£ã¯å¿…é ˆï¼Ÿ**

**A**ï¼š
**å®Ÿè£…ã«ã¯ä¸è¦ã€ç†è«–ã®æ·±ã„ç†è§£ã«ã¯å¿…é ˆ**ã€‚

- å®Ÿè£…è€…ï¼šZone 4ã®ã‚³ãƒ¼ãƒ‰ã ã‘èª­ã‚ã°OK
- ç ”ç©¶è€…ï¼šZone 3.7ã‚’ç†Ÿèª­ã—ã€Jordan+ (1998) ã®åŸè«–æ–‡ã¸
- æ•°å­¦çš„èƒŒæ™¯ï¼šæ¸¬åº¦è«–ã€å¤‰åˆ†æ³•ã€PDE

---

### 7.5 æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

**Level 1ï¼ˆåˆå­¦è€…ï¼‰**ï¼š
- [ ] Zone 4ã®å®Ÿè£…ã‚’å®Œå…¨ã«å†ç¾
- [ ] æ¼”ç¿’1-3ã‚’è§£ã
- [ ] 2D toy datasetã§å¯è¦–åŒ–

**Level 2ï¼ˆä¸­ç´šè€…ï¼‰**ï¼š
- [ ] MNIST/CIFAR-10ã§Flow Matchingè¨“ç·´
- [ ] Rectified Flowå®Ÿè£…
- [ ] æ¼”ç¿’4-5ã«æŒ‘æˆ¦

**Level 3ï¼ˆä¸Šç´šè€…ï¼‰**ï¼š
- [ ] Latent Flow Matchingå®Ÿè£…ï¼ˆVAEçµ±åˆï¼‰
- [ ] æœ€æ–°è«–æ–‡ï¼ˆZone 6.8ï¼‰ã‚’å®Ÿè£…
- [ ] ç‹¬è‡ªã®å¿œç”¨é ˜åŸŸã§å®Ÿé¨“ï¼ˆéŸ³å£°ã€åˆ†å­ãªã©ï¼‰

**Level 4ï¼ˆç ”ç©¶è€…ï¼‰**ï¼š
- [ ] æœªè§£æ±ºå•é¡Œï¼ˆZone 6.6ï¼‰ã«å–ã‚Šçµ„ã‚€
- [ ] æ–°ã—ã„Probability Pathã‚’ææ¡ˆ
- [ ] ICLR/NeurIPSã«æŠ•ç¨¿

---

### 7.6 ãƒªã‚½ãƒ¼ã‚¹é›†

**å…¬å¼å®Ÿè£…**ï¼š
- `atong01/conditional-flow-matching`ï¼ˆPyTorchã€referenceå®Ÿè£…ï¼‰
- `Candle/Burn`ï¼ˆRustã€æœ¬è¬›ç¾©ã®ãƒ™ãƒ¼ã‚¹ï¼‰

**è«–æ–‡**ï¼š
- Flow MatchingåŸè«–æ–‡ï¼ˆLipman+ ICLR 2023, arXiv:2210.02747ï¼‰
- Stochastic Interpolantsï¼ˆAlbergo+ 2023, arXiv:2303.08797ï¼‰
- DiffFlowï¼ˆZhang+ 2023, arXiv:2307.02159ï¼‰

**ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«**ï¼š
- Meta AI Flow Matching Guideï¼ˆarXiv:2412.06264ï¼‰
- Hugging Face Diffusersï¼ˆFlow Matchingå®Ÿè£…ä¾‹ï¼‰

**æ•°å­¦çš„èƒŒæ™¯**ï¼š
- Optimal Transportï¼ˆVillani, "Topics in Optimal Transportation"ï¼‰
- Wasserstein Gradient Flowï¼ˆJordan+ "The Variational Formulation of the Fokker-Planck Equation", 1998ï¼‰

---

## Paradigm-Breaking Question: ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®ã€Œæ¬¡ã€ã¯ä½•ã‹ï¼Ÿ

ã“ã“ã¾ã§ã®è¬›ç¾©ã§ã€æˆ‘ã€…ã¯ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®çµ±ä¸€ç†è«–ã«åˆ°é”ã—ãŸã€‚Score Matchingã€Diffusionã€Flowã€GANã¯ã€ã™ã¹ã¦**Wassersteinå‹¾é…æµ**ã¨ã„ã†åŒã˜å±±ã®ç•°ãªã‚‹ç™»å±±ãƒ«ãƒ¼ãƒˆã ã€‚

ã—ã‹ã—ã€å•ã„ã¯æ®‹ã‚‹ï¼š

> **ã€Œã“ã®çµ±ä¸€ç†è«–ã®å…ˆã«ã€ã•ã‚‰ãªã‚‹ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚·ãƒ•ãƒˆã¯ã‚ã‚‹ã®ã‹ï¼Ÿã€**

---

### ç¾åœ¨ã®é™ç•Œ

ã©ã‚Œã»ã©æ´—ç·´ã•ã‚Œã¦ã‚‚ã€ç¾åœ¨ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯æœ¬è³ªçš„ã«**ãƒ‡ãƒ¼ã‚¿ã®æ¨¡å€£**ã ï¼š

- è¨“ç·´ãƒ‡ãƒ¼ã‚¿$p_{\text{data}}$ã‚’è¿‘ä¼¼ã™ã‚‹åˆ†å¸ƒ$p_\theta$ã‚’å­¦ç¿’
- æ–°ã—ã„ã€Œå‰µé€ ã€ã§ã¯ãªãã€ã€Œæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®è£œé–“ã€

**å…·ä½“ä¾‹**ï¼š
- Stable Diffusionã¯ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«ãªã„å®Œå…¨ã«æ–°ã—ã„æ¦‚å¿µï¼ˆä¾‹ï¼šã€Œé‡å­ã‚‚ã¤ã‚Œã‚’å¯è¦–åŒ–ã—ãŸæŠ½è±¡ç”»ã€ï¼‰ã‚’ç”Ÿæˆã§ããªã„
- Flow Matchingã‚‚ã€$p_0$ã‹ã‚‰$p_{\text{data}}$ã¸ã®æœ€é©çµŒè·¯ã‚’å­¦ã¶ã ã‘

---

### æ¬¡ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã¸ã®ç¤ºå”†

**æ–¹å‘1: å› æœç”Ÿæˆãƒ¢ãƒ‡ãƒ«**

ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯**ç›¸é–¢**ã‚’å­¦ã¶ãŒã€**å› æœé–¢ä¿‚**ã¯å­¦ã°ãªã„ã€‚

**å¿…è¦ãªè¦ç´ **ï¼š
- æ§‹é€ å› æœãƒ¢ãƒ‡ãƒ«ï¼ˆSCMï¼‰ã¨Flowã®çµ±åˆ
- ä»‹å…¥ï¼ˆinterventionï¼‰ã¨åäº‹å®Ÿï¼ˆcounterfactualï¼‰ã®ç”Ÿæˆ

**æƒ³åƒã•ã‚Œã‚‹å¿œç”¨**ï¼š
- ã€Œã“ã®è–¬ã‚’æŠ•ä¸ã—ãªã‹ã£ãŸã‚‰ã€ã©ã†ãªã£ã¦ã„ãŸã‹ï¼Ÿã€ã®ç”»åƒç”Ÿæˆ
- å› æœçš„ã«æ•´åˆã—ãŸæœªæ¥äºˆæ¸¬

---

**æ–¹å‘2: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ç”Ÿæˆï¼ˆActive Generationï¼‰**

ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯**å—å‹•çš„**ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åå¿œã™ã‚‹ã ã‘ï¼‰ã€‚

**æ¬¡ä¸–ä»£**ï¼š
- ç”Ÿæˆãƒ¢ãƒ‡ãƒ«è‡ªèº«ãŒã€Œæ¬¡ã«ä½•ã‚’ç”Ÿæˆã™ã¹ãã‹ã€ã‚’èƒ½å‹•çš„ã«æ±ºå®š
- å¼·åŒ–å­¦ç¿’ã¨ã®æ·±ã„çµ±åˆï¼ˆreward-conditioned flowï¼‰

**ä¾‹**ï¼š
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã‚’äºˆæ¸¬ã—ã¦ã€å…ˆå›ã‚Šã§ç”»åƒã‚’ææ¡ˆ
- å¯¾è©±çš„ãªå‰µé€ ï¼ˆAI: ã€Œã“ã®è‰²ã‚’ã‚‚ã£ã¨é®®ã‚„ã‹ã«ã—ã¾ã™ã‹ï¼Ÿã€ï¼‰

---

**æ–¹å‘3: ç‰©ç†æ³•å‰‡åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ**

ç”»åƒç”Ÿæˆã¯è‡ªç”±ã™ãã‚‹ï¼ˆç‰©ç†çš„ã«ã‚ã‚Šå¾—ãªã„ç”»åƒã‚‚ç”Ÿæˆï¼‰ã€‚

**åˆ¶ç´„ä»˜ãç”Ÿæˆ**ï¼š
- Navier-Stokesæ–¹ç¨‹å¼ã‚’æº€ãŸã™æµä½“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”»åƒ
- ç†±åŠ›å­¦ç¬¬äºŒæ³•å‰‡ã‚’æº€ãŸã™ãƒ—ãƒ­ã‚»ã‚¹å‹•ç”»
- Flow Matchingã®Pathã«**å¾®åˆ†æ–¹ç¨‹å¼åˆ¶ç´„**ã‚’åŸ‹ã‚è¾¼ã‚€

**æŠ€è¡“**ï¼š
- Physics-Informed Neural Networks (PINN) + Flow Matching
- Symplectic Flowï¼ˆãƒãƒŸãƒ«ãƒˆãƒ³åŠ›å­¦ä¿å­˜ï¼‰

---

**æ–¹å‘4: æ„å‘³çš„é€£ç¶šæ€§ã®æ¢æ±‚**

OT Pathã¯ã€Œåº§æ¨™ç©ºé–“ã€ã§ç›´ç·šã ãŒã€ã€Œæ„å‘³ç©ºé–“ã€ã§ã¯ï¼Ÿ

**å•ã„**ï¼š
- ã€ŒçŒ«ã€ã‹ã‚‰ã€ŒçŠ¬ã€ã¸ã®æœ€é©ãªå¤‰å½¢çµŒè·¯ã¯ã€åº§æ¨™ã®ç·šå½¢è£œé–“ã‹ï¼Ÿ
- ã‚€ã—ã‚ã€ŒçŒ« â†’ ãƒã‚³ç§‘ â†’ å‹•ç‰© â†’ ã‚¤ãƒŒç§‘ â†’ çŠ¬ã€ã®ã‚ˆã†ãª**æ¦‚å¿µéšå±¤**ã‚’è¾¿ã‚‹ã¹ãã§ã¯ï¼Ÿ

**ç ”ç©¶**ï¼š
- æ„å‘³çš„è·é›¢ï¼ˆsemantic distanceï¼‰ã®å®šç¾©
- æ¦‚å¿µã‚°ãƒ©ãƒ•ä¸Šã®Flow

---

### ã‚ãªãŸã¸ã®å•ã„

ã“ã®ã‚³ãƒ¼ã‚¹ã‚’ä¿®äº†ã—ãŸã‚ãªãŸã«ã€æœ€å¾Œã®å•ã„ã‚’æŠ•ã’ã‹ã‘ãŸã„ï¼š

**ã€ŒFlow Matchingã®æ¬¡ã«æ¥ã‚‹ã€ã‚ãªãŸè‡ªèº«ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯ä½•ã‹ï¼Ÿã€**

- ãã‚Œã¯ã€å› æœã‚’æ‰±ã†ã‹ï¼Ÿ
- ç‰©ç†æ³•å‰‡ã‚’å°Šé‡ã™ã‚‹ã‹ï¼Ÿ
- æ„å‘³çš„ãªæ§‹é€ ã‚’æŒã¤ã‹ï¼Ÿ
- ãã‚Œã¨ã‚‚ã€ã¾ã£ãŸãåˆ¥ã®åŸç†ã«åŸºã¥ãã‹ï¼Ÿ

ç†è«–ã¯é“å…·ã ã€‚**çœŸã®å‰µé€ ã¯ã€é“å…·ã‚’è¶…ãˆãŸã¨ã“ã‚ã«ã‚ã‚‹**ã€‚

---

**Congratulations!** ğŸ‰

ã‚ãªãŸã¯ã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®æœ€å‰ç·šã«åˆ°é”ã—ãŸã€‚ã“ã“ã‹ã‚‰å…ˆã¯ã€ã‚ãªãŸè‡ªèº«ãŒé“ã‚’åˆ‡ã‚Šæ‹“ãç•ªã ã€‚

---

## 7. æœ€æ–°ç ”ç©¶å‹•å‘ï¼ˆ2024-2025ï¼‰

### 7.1 Conditional Variable Flow Matching (CVFM)

**å•é¡Œè¨­å®š**: å¾“æ¥ã® Conditional Flow Matching (CFM) ã¯å›ºå®šæ¡ä»¶ $c$ ã«å¯¾ã™ã‚‹ç”Ÿæˆ $p(x|c)$ ã‚’å­¦ç¿’ã™ã‚‹ãŒã€**é€£ç¶šçš„ãªæ¡ä»¶å¤‰æ•°** $c \in \mathbb{R}^d$ ã«å¯¾ã™ã‚‹ amortizationï¼ˆå„Ÿå´å­¦ç¿’ï¼‰ã¯å›°é›£ã ã£ãŸã€‚

ä¾‹: æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ $T \in [0.1, 2.0]$ ã§ç”Ÿæˆã‚¹ã‚¿ã‚¤ãƒ«ã‚’åˆ¶å¾¡ã—ãŸã„ãŒã€å„ $T$ å€¤ã”ã¨ã«åˆ¥ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã®ã¯éåŠ¹ç‡ã€‚

**CVFM ã®è§£æ±ºç­–** (Brennan et al., 2024) [^cvfm]:

Conditional OT (CÂ²OT) ã‚’å°å…¥ â€” **æ¡ä»¶ä¾å­˜ã‚³ã‚¹ãƒˆ**ã§ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ã‚’å­¦ç¿’:

$$
\pi^* = \arg\min_{\pi \in \Pi(p_0, p_1)} \mathbb{E}_{(x_0, x_1, c) \sim \pi} \left[ \| x_1 - x_0 \|^2 + \lambda \| g(c) - f(x_0, x_1) \|^2 \right]
$$

ã“ã“ã§:
- $g(c)$: æ¡ä»¶ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ï¼ˆä¾‹: MLPï¼‰
- $f(x_0, x_1)$: ãƒšã‚¢ç‰¹å¾´æŠ½å‡ºå™¨
- $\lambda$: ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆå¼·åº¦

**ç›´æ„Ÿ**: å˜ãªã‚‹ OT ã¯ $c$ ã‚’ç„¡è¦–ã—ã¦ $p_0 \to p_1$ ã®æœ€çŸ­çµŒè·¯ã‚’æ±‚ã‚ã‚‹ã€‚CÂ²OT ã¯ $c$ ã¨ $(x_0, x_1)$ ã®ä¸€è²«æ€§ã‚’ç½°å‰‡åŒ– â†’ æ¡ä»¶ã«å¿œã˜ãŸç•°ãªã‚‹çµŒè·¯ã‚’å­¦ç¿’ã€‚

**Velocity Field**:

$$
v_\theta(x_t, t, c) = \text{VelocityNet}(x_t, t, g(c))
$$

è¨“ç·´:

$$
\mathcal{L}_\text{CVFM} = \mathbb{E}_{t, c, (x_0, x_1) \sim \pi^*(c)} \left[ \| v_\theta(x_t, t, c) - (x_1 - x_0) \|^2 \right]
$$

**å®Ÿé¨“çµæœ** (Conditional Image Generation):

| Method | FID â†“ | Condition Fidelity (CLIP â†‘) |
|:-------|:------|:----------------------------|
| CFM (per-condition) | 12.3 | 0.82 |
| Conditional Diffusion | 14.7 | 0.79 |
| **CVFM** | **11.1** | **0.85** |

**å¿œç”¨**: Text-to-Image ã§ guidance scale $w \in [1, 20]$ ã‚’é€£ç¶šåˆ¶å¾¡ã€åˆ†å­ç”Ÿæˆã§çµåˆè¦ªå’Œæ€§ã‚’é€£ç¶šæ¡ä»¶ã¨ã—ã¦å­¦ç¿’ã€‚

### 7.2 Minibatch Optimal Transport Flow Matching

Tong et al. (2023) [^minibatch_ot] ã¯ã€**ãƒŸãƒ‹ãƒãƒƒãƒå†…ã§ OT ã‚’è§£ã**ã“ã¨ã§è¨ˆç®—é‡ã‚’ $O(n^3)$ ã‹ã‚‰ $O(B^3)$ ã«å‰Šæ¸›ï¼ˆ$B$ = ãƒãƒƒãƒã‚µã‚¤ã‚º $\ll n$ = ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ï¼‰ã€‚

**èª²é¡Œ**: å¾“æ¥ã® OT-CFM ã¯å…¨ãƒ‡ãƒ¼ã‚¿ãƒšã‚¢ $(x_0^{(i)}, x_1^{(j)})$ ã®è·é›¢è¡Œåˆ— $C_{ij} = \| x_1^{(j)} - x_0^{(i)} \|^2$ ($n \times n$) ã‚’è§£ãå¿…è¦ â†’ ãƒ¡ãƒ¢ãƒª $O(n^2)$ã€è¨ˆç®— $O(n^3)$ã€‚

**Minibatch OT ã®ã‚¢ã‚¤ãƒ‡ã‚¢**:

å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ãƒãƒƒãƒ $\{x_0^{(i)}\}_{i=1}^B$ ã¨ $\{x_1^{(j)}\}_{j=1}^B$ ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€**ãƒãƒƒãƒå†… OT** ã‚’è§£ã:

$$
\pi_B^* = \arg\min_{\pi \in \Pi(p_{B,0}, p_{B,1})} \sum_{i,j} \pi_{ij} \| x_1^{(j)} - x_0^{(i)} \|^2
$$

ã“ã“ã§ $p_{B,0}, p_{B,1}$ ã¯ãƒãƒƒãƒã®çµŒé¨“åˆ†å¸ƒã€‚

**ç†è«–çš„ä¿è¨¼**: ãƒãƒƒãƒã‚µã‚¤ã‚º $B$ ãŒååˆ†å¤§ãã‘ã‚Œã°ï¼ˆ$B \gtrsim \sqrt{n}$ï¼‰ã€$\pi_B^*$ ã¯çœŸã® OT $\pi^*$ ã«åæŸï¼ˆWasserstein è·é›¢ã§ï¼‰ã€‚

**å®Ÿè£…** (Sinkhorn ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ):

```rust
use ndarray::{Array1, Array2};

fn sinkhorn_ot(c: &Array2<f64>, eps: f64, max_iter: usize) -> Array2<f64> {
    let b = c.nrows();
    let k = c.mapv(|v| (-v / eps).exp()); // K = exp(-C/Îµ)  (Gibbs kernel)
    let mut u = Array1::<f64>::ones(b);
    let mut v = Array1::<f64>::ones(b);

    for _ in 0..max_iter {
        u = k.dot(&v).mapv(|x| 1.0 / (x + 1e-8));     // u = 1/(Kv)   (Sinkhorn iteration)
        v = k.t().dot(&u).mapv(|x| 1.0 / (x + 1e-8)); // v = 1/(Káµ€u)
    }

    // Ï€ = diag(u)Â·KÂ·diag(v)  (OT coupling)
    let pi = Array2::from_shape_fn((b, b), |(i, j)| u[i] * k[[i, j]] * v[j]);
    let s = pi.sum();
    pi / s // Normalize
}

fn minibatch_ot_loss(x0_batch: &Array2<f32>, x1_batch: &Array2<f32>,
                      model: &VectorFieldNet, t: f32) -> f32
{
    // L_OT-CFM = Î£áµ¢â±¼ Ï€áµ¢â±¼Â·||v_Î¸(xâ‚œ,t) - (xâ‚â±¼-xâ‚€áµ¢)||Â²
    let b = x0_batch.ncols();
    let c = pairwise_sq_dist_f64(x1_batch, x0_batch); // C_ij = ||xâ‚â±¼ - xâ‚€áµ¢||Â²
    let pi = sinkhorn_ot(&c, 0.1, 100); // Ï€ = OT coupling  (Îµ=0.1)

    (0..b).flat_map(|i| (0..b).map(move |j| (i, j)))
        .filter(|&(i, j)| pi[[i, j]] > 1e-6)
        .map(|(i, j)| {
            let x_t = Array2::from_shape_fn((2, 1), |(r, _)|
                (1.0 - t) * x0_batch[[r, i]] + t * x1_batch[[r, j]]); // xâ‚œ = (1-t)xâ‚€áµ¢ + tÂ·xâ‚â±¼
            let u_t = Array2::from_shape_fn((2, 1), |(r, _)|
                x1_batch[[r, j]] - x0_batch[[r, i]]); // uâ‚œ = xâ‚â±¼ - xâ‚€áµ¢  (OT straight-line)
            let v_hat = model_predict(model, &x_t, t);
            let diff = v_hat - u_t;
            pi[[i, j]] as f32 * diff.iter().map(|v| v * v).sum::<f32>()
        })
        .sum::<f32>() / b as f32
}
```

**è¨ˆç®—é‡æ¯”è¼ƒ**:

| Method | OT Solve | Memory | Time/Iter |
|:-------|:---------|:-------|:----------|
| Full OT-CFM | $O(n^3)$ | $O(n^2)$ | 10-100s (n=50K) |
| **Minibatch OT-CFM** | $O(B^3)$ | $O(B^2)$ | **0.5s** (B=256) |

**å“è³ª**: CIFAR-10 ã§ FID å·®ã¯ 0.3 æœªæº€ï¼ˆã»ã¼åŒç­‰ï¼‰ã€‚

### 7.3 Weighted Conditional Flow Matching

Liu et al. (2025) [^weighted_cfm] ã¯ã€**ã‚µãƒ³ãƒ—ãƒ«é‡ã¿ä»˜ã CFM** ã‚’ææ¡ˆ â€” ãƒ‡ãƒ¼ã‚¿ã®é‡è¦åº¦ã«å¿œã˜ã¦å­¦ç¿’ã‚’èª¿æ•´ã€‚

**å‹•æ©Ÿ**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ä¸å‡è¡¡ï¼ˆä¾‹: åŒ»ç™‚ç”»åƒã§ç¨€ãªç–¾æ‚£ã€ãƒ†ã‚­ã‚¹ãƒˆã§ä½é »åº¦èªå½™ï¼‰ã€‚å‡ä¸€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¯å¤šæ•°æ´¾ãƒã‚¤ã‚¢ã‚¹ã‚’ç”Ÿã‚€ã€‚

**Weighted CFM Loss**:

$$
\mathcal{L}_\text{WCFM} = \mathbb{E}_{t, x_0, x_1} \left[ w(x_0, x_1) \cdot \| v_\theta(x_t, t) - (x_1 - x_0) \|^2 \right]
$$

é‡ã¿é–¢æ•°ã®ä¾‹:

1. **Inverse Frequency**:
   $$
   w(x_1) = \frac{1}{\sqrt{\text{count}(c(x_1))}}
   $$
   $c(x_1)$ ã¯ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã€‚

2. **Importance Sampling**:
   $$
   w(x_0, x_1) = \frac{\| x_1 - x_0 \|^2}{\mathbb{E}[\| x_1 - x_0 \|^2]}
   $$
   é›£ã—ã„ãƒšã‚¢ï¼ˆè·é›¢ãŒå¤§ãã„ï¼‰ã«æ³¨ç›®ã€‚

3. **Curriculum Learning**:
   $$
   w(x_0, x_1; \text{epoch}) = \min\left(1, \frac{\text{epoch}}{T_\text{warmup}} \right) \cdot \mathbb{1}[\text{difficult}(x_0, x_1)]
   $$
   åˆæœŸã¯ç°¡å˜ãªã‚µãƒ³ãƒ—ãƒ«ã€å¾ã€…ã«é›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã¸ã€‚

**å®Ÿé¨“** (Imbalanced CIFAR-10, ã‚¯ãƒ©ã‚¹æ¯” 1:100):

| Method | Minority Class FID â†“ | Majority Class FID â†“ |
|:-------|:---------------------|:---------------------|
| CFM (uniform) | 28.4 | 5.2 |
| Weighted Diffusion | 15.7 | 5.8 |
| **Weighted CFM** | **12.3** | **5.4** |

**Minority Class ã®å“è³ªãŒ 2.3å€æ”¹å–„**ï¼ˆMajority ã¸ã®å½±éŸ¿ã¯æœ€å°ï¼‰ã€‚

### 7.4 å®Ÿè£…ä¾‹: Minibatch OT-CFM (Rust)

ä»¥ä¸‹ã¯ã€å‰è¿°ã®ç†è«–ã‚’çµ±åˆã—ãŸå®Ÿè£…ä¾‹ã€‚

```rust
use candle_core::{Tensor, Device, DType, Result};
use candle_nn::optim::{Adam, AdamConfig, Optimizer};
use ndarray::{Array1, Array2};
use rand::Rng;

// --- Minibatch OT Solver ---
fn sinkhorn_coupling(c: &Array2<f32>, eps: f32, max_iter: usize) -> Array2<f32> {
    let b = c.nrows();
    let k = c.mapv(|v| (-v / eps).exp()); // K = exp(-C/Îµ)  (Gibbs kernel)
    let mut u = Array1::<f32>::ones(b);
    let mut v = Array1::<f32>::ones(b);

    for _ in 0..max_iter {
        u = k.dot(&v).mapv(|x| 1.0 / (x + 1e-8));     // u = 1/(Kv)   (Sinkhorn iteration)
        v = k.t().dot(&u).mapv(|x| 1.0 / (x + 1e-8)); // v = 1/(Káµ€u)
    }

    let pi = Array2::from_shape_fn((b, b), |(i, j)| u[i] * k[[i, j]] * v[j]); // Ï€ = diag(u)Â·KÂ·diag(v)  (OT coupling)
    let s = pi.sum();
    pi / s
}

// --- Velocity Network ---
fn velocity_net(d_in: usize, d_hidden: usize, vb: VarBuilder) -> Result<VectorFieldNet> { VectorFieldNet::new_with_hidden(d_in, d_hidden, vb) }

// --- Minibatch OT-CFM Training ---
fn train_minibatch_ot_cfm(
    data_source: impl Fn(&mut rand::rngs::StdRng) -> Array2<f32>,
    data_target: impl Fn(&mut rand::rngs::StdRng) -> Array2<f32>,
    n_epochs: usize,
    batch_size: usize,
    eps_sinkhorn: f32,
    rng: &mut rand::rngs::StdRng,
) -> Result<VectorFieldNet> {
    let d = 2;
    let dev = Device::Cpu;
    let vb = VarBuilder::zeros(DType::F32, &dev);
    let model = velocity_net(d, 128, vb.clone())?;
    let mut opt = Adam::new(vb.all_vars(), AdamConfig { lr: 1e-3, ..Default::default() })?;

    for epoch in 0..n_epochs {
        // Sample batches
        let x0 = data_source(rng); // (d, B)
        let x1 = data_target(rng); // (d, B)

        let c = pairwise_sq_dist(&x1, &x0); // C_ij = ||xâ‚â±¼ - xâ‚€áµ¢||Â²  (cost matrix)
        let pi = sinkhorn_coupling(&c, eps_sinkhorn, 50); // Ï€ = OT coupling via Sinkhorn
        let t: f32 = rng.gen(); // t ~ U(0,1)
        // L_OT-CFM = Î£áµ¢â±¼ Ï€áµ¢â±¼Â·||v_Î¸(xâ‚œ,t) - (xâ‚â±¼-xâ‚€áµ¢)||Â²
        let loss = (0..batch_size).flat_map(|i| (0..batch_size).map(move |j| (i, j)))
            .filter(|&(i, j)| pi[[i, j]] > 1e-6)
            .map(|(i, j)| {
                let x_t = Array2::from_shape_fn((d, 1), |(r, _)|
                    (1.0 - t) * x0[[r, i]] + t * x1[[r, j]]); // xâ‚œ = (1-t)xâ‚€áµ¢ + tÂ·xâ‚â±¼
                let u_t_vec: Vec<f32> = (0..d).map(|r| x1[[r, j]] - x0[[r, i]]).collect(); // uâ‚œ = xâ‚â±¼ - xâ‚€áµ¢
                let v_hat = model_predict(&model, &x_t, t); // v_Î¸(xâ‚œ, t): R^{d+1} â†’ R^d
                let diff: f32 = v_hat.iter().zip(&u_t_vec).map(|(a, b)| (a - b).powi(2)).sum();
                pi[[i, j]] * diff
            })
            .sum::<f32>() / batch_size as f32;

        opt.backward_step(&Tensor::new(loss, &dev)?)?;

        if (epoch + 1) % 10 == 0 {
            println!("Epoch {}, Loss: {}", epoch + 1, loss);
        }
    }

    Ok(model)
}

// --- ODE Sampling ---
fn sample_ot_cfm(model: &VectorFieldNet, x0: &Array2<f32>, n_steps: usize) -> Array2<f32> { euler_integrate(|x, t| model_predict(model, x, t), x0, n_steps) } // xâ‚œâ‚Šdt = xâ‚œ + v_Î¸(xâ‚œ,t)Â·dt  (ODE integrator)
```

**ä½¿ç”¨ä¾‹**:

```rust
// xâ‚€ ~ N(0,I), xâ‚ ~ N([3,0],I): Two Gaussians
let source = |rng: &mut rand::rngs::StdRng| -> Array2<f32> {
    sample_source(256, 2, rng) // xâ‚€ ~ N(0,I)
};
let target = |rng: &mut rand::rngs::StdRng| -> Array2<f32> {
    sample_source(256, 2, rng).mapv(|v| v) + 3.0_f32 // xâ‚ ~ N([3,0],I)
};

// Train minibatch OT-CFM: L_OT-CFM = Î£áµ¢â±¼ Ï€áµ¢â±¼Â·||v_Î¸(xâ‚œ,t) - (xâ‚â±¼-xâ‚€áµ¢)||Â²
let model = train_minibatch_ot_cfm(source, target, 200, 256, 0.1, &mut rng)?;

// Sample
let x0_test = sample_source(500, 2, &mut rng); // xâ‚€ ~ N(0,I)
let x1_samples = sample_ot_cfm(&model, &x0_test, 100); // ODE solve: xâ‚ = ODESolve(v_Î¸; xâ‚€)

// Print summary
println!("Source: {:?}", x0_test.shape());
println!("Generated: {:?}", x1_samples.shape());
```

---

## å‚è€ƒæ–‡çŒ®

[^cvfm]: Brennan, M., et al. (2024). "Conditional Variable Flow Matching: Transforming Conditional Densities with Amortized Conditional Optimal Transport". *arXiv:2411.08314*.

[^minibatch_ot]: Tong, A., et al. (2023). "Improving and Generalizing Flow-Based Generative Models with Minibatch Optimal Transport". *arXiv:2302.00482*.

[^weighted_cfm]: Calvo-Ordonez, S., et al. (2025). "Weighted Conditional Flow Matching". *arXiv:2507.22270*.

---

### 7.5 Rectified Flow: Flow Matching ã®ç†è«–çš„æ´—ç·´

Liu et al. (2023) ã¯ã€**Rectified Flow** ã‚’ææ¡ˆ â€” Flow Matching ã®çµŒè·¯ã‚’ã‚ˆã‚Šç›´ç·šçš„ã«ã™ã‚‹æ‰‹æ³•ã€‚

**å•é¡Œ**: æ¨™æº– OT-CFM ã§ã‚‚ã€çµŒè·¯ $\mathbf{x}_t$ ã¯å®Œå…¨ãªç›´ç·šã§ã¯ãªã„ï¼ˆãƒ‡ãƒ¼ã‚¿å¤šæ§˜ä½“ã®æ›²ç‡ã®å½±éŸ¿ï¼‰ã€‚æ›²ãŒã£ãŸçµŒè·¯ â†’ ã‚ˆã‚Šå¤šãã® NFE ãŒå¿…è¦ã€‚

**Rectification ã®ã‚¢ã‚¤ãƒ‡ã‚¢**:

1. **åˆæœŸ Flow** ã‚’è¨“ç·´ï¼ˆOT-CFMï¼‰
2. **Reflow**: è¨“ç·´æ¸ˆã¿ Flow ã§ã‚µãƒ³ãƒ—ãƒ«ãƒšã‚¢ $(x_0', x_1')$ ã‚’ç”Ÿæˆ
3. ã“ã‚Œã‚‰ã®ãƒšã‚¢ã§**å†è¨“ç·´** â†’ ã‚ˆã‚Šç›´ç·šçš„ãª Flow

æ•°å­¦çš„ã«ã¯:

$$
(x_0^{(k+1)}, x_1^{(k+1)}) = \text{Sample from } p_\theta^{(k)}
$$

$k$ å›ç›®ã® Flow ã§ç”Ÿæˆã—ãŸãƒšã‚¢ã‚’ä½¿ã„ã€$k+1$ å›ç›®ã‚’è¨“ç·´ã€‚

**ç†è«–çš„ä¿è¨¼**: $k \to \infty$ ã§ã€çµŒè·¯ã¯**ã»ã¼ç›´ç·š**ã«åæŸ â†’ 1-step sampling ãŒå¯èƒ½ã€‚

**å®Ÿé¨“** (CIFAR-10):

| Iteration | Steps for FID<5 | Training Time |
|:----------|:----------------|:--------------|
| k=0 (OT-CFM) | 20 | 1Ã— |
| k=1 (Reflow) | 10 | 2Ã— (ç´¯ç©) |
| k=2 (ReflowÂ²) | **5** | 3Ã— (ç´¯ç©) |

**2å›ã® Reflow ã§ 5-step ç”Ÿæˆ** ã‚’é”æˆã€‚

**Rust å®Ÿè£…**:

```rust
fn reflow_iteration(
    model_k: &VectorFieldNet,
    data_source: impl Fn(&mut rand::rngs::StdRng) -> Array2<f32>,
    n_samples: usize,
    rng: &mut rand::rngs::StdRng,
) -> Result<VectorFieldNet> {
    let x0_new: Vec<Array2<f32>> = (0..n_samples)
        .map(|_| data_source(rng)) // xâ‚€ ~ p_source
        .collect();
    let x1_new: Vec<Array2<f32>> = x0_new.iter()
        .map(|x0| euler_integrate(|x, t| model_predict(model_k, x, t), x0, 100)) // xâ‚' = ODESolve(v_Î¸; xâ‚€, t:0â†’1)  (Reflow)
        .collect();

    // Re-train with rectified pairs
    train_cfm_from_pairs(&x0_new, &x1_new, rng)
}
```

**å¿œç”¨**: Text-to-Image (Stable Diffusion) ã§ ReflowÂ² â†’ 4-step ç”Ÿæˆã§å“è³ªç¶­æŒã€‚

---

## è‘—è€…ãƒªãƒ³ã‚¯

- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
