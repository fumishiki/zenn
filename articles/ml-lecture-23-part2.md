---
title: "ç¬¬23å›: Fine-tuning & PEFT: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
slug: "ml-lecture-23-part2"
emoji: "ğŸ”§"
type: "tech"
topics: ["machinelearning", "deeplearning", "finetuning", "julia", "rust"]
published: true
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Julia", "Rust", "Elixir"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---

> ğŸ“Œ **å‰ç·¨ï¼ˆç†è«–ï¼‰**: [ç¬¬23å› å‰ç·¨](./ml-lecture-23-part1)

## ğŸ’» 4. å®Ÿè£…ã‚¾ãƒ¼ãƒ³ï¼ˆ45åˆ†ï¼‰â€” âš¡Julia LoRAè¨“ç·´ + ğŸ¦€Rust LoRAæ¨è«–

**ã‚´ãƒ¼ãƒ«**: Julia ã§LoRAè¨“ç·´ã‚’å®Ÿè£…ã—ã€Rust ã§æ¨è«–æ™‚ã®LoRAãƒãƒ¼ã‚¸ãƒ»åˆ‡ã‚Šæ›¿ãˆã‚’å®Ÿè£…ã™ã‚‹ã€‚

### 4.1 âš¡ Julia LoRAè¨“ç·´ â€” Lux.jlå®Œå…¨å®Ÿè£…

Lux.jl [^9] ã¯ã€Flux.jlã®å¾Œç¶™ã¨ã—ã¦è¨­è¨ˆã•ã‚ŒãŸæ˜ç¤ºçš„çŠ¶æ…‹ç®¡ç†ã®NN libraryã€‚LoRAå®Ÿè£…ã«æœ€é©ã€‚

#### 4.1.1 LoRAå±¤ã®å®Ÿè£…

```julia
using Lux, Random, Optimisers, Zygote

# LoRA layer wrapper
struct LoRALayer{F1, F2} <: Lux.AbstractExplicitLayer
    base_layer::F1      # frozen base layer (e.g., Dense)
    lora_A::F2          # trainable A âˆˆ â„^(rÃ—k)
    lora_B::F2          # trainable B âˆˆ â„^(dÃ—r)
    Î±::Float32
    r::Int
    frozen::Bool        # whether base_layer is frozen
end

function LoRALayer(base_layer, r::Int; Î±::Float32=16.0f0, frozen::Bool=true)
    # Infer dimensions from base_layer
    # Assume base_layer is Dense(k => d)
    return LoRALayer(base_layer, Dense(k => r), Dense(r => d), Î±, r, frozen)
end

# Forward pass: h = Wâ‚€x + (Î±/r)BA x
function (l::LoRALayer)(x, ps, st)
    # Base output (frozen or trainable depending on l.frozen)
    h_base, st_base = l.base_layer(x, ps.base_layer, st.base_layer)

    # LoRA path: BA x with scaling Î±/r
    h_A, st_A = l.lora_A(x, ps.lora_A, st.lora_A)
    h_B, st_B = l.lora_B(h_A, ps.lora_B, st.lora_B)

    # Combine: h = h_base + (Î±/r) * h_B
    h = h_base .+ (l.Î± / l.r) .* h_B

    # Merge states
    st_new = (base_layer=st_base, lora_A=st_A, lora_B=st_B)

    return h, st_new
end

# Initialize parameters
function Lux.initialparameters(rng::AbstractRNG, l::LoRALayer)
    ps_base = Lux.initialparameters(rng, l.base_layer)
    ps_A = Lux.initialparameters(rng, l.lora_A)
    ps_B = Lux.initialparameters(rng, l.lora_B)

    # Initialize A with Gaussian, B with zeros (Î”W starts at 0)
    ps_A = (; weight=randn(rng, Float32, size(ps_A.weight)) ./ âˆšFloat32(size(ps_A.weight, 2)), bias=zeros(Float32, l.r))
    ps_B = (; weight=zeros(Float32, size(ps_B.weight)), bias=zeros(Float32, size(ps_B.weight, 1)))

    return (base_layer=ps_base, lora_A=ps_A, lora_B=ps_B)
end

function Lux.initialstates(rng::AbstractRNG, l::LoRALayer)
    return (
        base_layer=Lux.initialstates(rng, l.base_layer),
        lora_A=Lux.initialstates(rng, l.lora_A),
        lora_B=Lux.initialstates(rng, l.lora_B)
    )
end

# Freeze base layer parameters during training
function freeze_base_params(ps)
    # Mark base_layer as non-trainable (Lux: use ComponentArray or manual masking)
    # Simplified: only train lora_A and lora_B
    trainable_ps = (lora_A=ps.lora_A, lora_B=ps.lora_B)
    return trainable_ps
end

println("LoRA layer implemented in Julia/Lux.jl")
```

#### 4.1.2 LoRAè¨“ç·´ãƒ«ãƒ¼ãƒ—

```julia
using Lux, Optimisers, Zygote, Random

# Simple model: Input -> LoRA Dense -> Output
function create_lora_model(input_dim::Int, hidden_dim::Int, output_dim::Int, r::Int)
    # Base model (pretrained, frozen)
    base_dense = Dense(input_dim => hidden_dim, relu)

    # Wrap with LoRA
    lora_layer = LoRALayer(base_dense, r; Î±=16.0f0, frozen=true)

    # Output layer
    output_layer = Dense(hidden_dim => output_dim)

    return Chain(lora_layer, output_layer)
end

# Loss function
function loss_fn(model, ps, st, x, y)
    y_pred, st_new = model(x, ps, st)
    loss = sum(@. (y_pred - y)^2) / size(y, 2)  # MSE
    return loss, st_new, ()
end

# Training step
function train_step!(model, ps, st, opt_state, x, y)
    (loss, st_new, _), back = Zygote.pullback(ps -> loss_fn(model, ps, st, x, y), ps)

    # Compute gradients
    grads = back((one(loss), nothing, nothing))[1]

    # Filter gradients: only LoRA params (A, B)
    # In practice, use proper freezing mechanism
    grads_filtered = (lora_A=grads.lora_layer.lora_A, lora_B=grads.lora_layer.lora_B)
    ps_filtered = (lora_A=ps.lora_layer.lora_A, lora_B=ps.lora_layer.lora_B)

    # Update
    opt_state, ps_updated = Optimisers.update!(opt_state, ps_filtered, grads_filtered)

    # Reconstruct ps (frozen base + updated LoRA)
    ps_new = (
        lora_layer=(base_layer=ps.lora_layer.base_layer, lora_A=ps_updated.lora_A, lora_B=ps_updated.lora_B),
        dense=ps.dense
    )

    return loss, ps_new, st_new, opt_state
end

# Full training loop
function train_lora_model(; input_dim=10, hidden_dim=64, output_dim=1, r=4, n_epochs=100, lr=1e-3)
    rng = Random.default_rng()

    # Create model
    model = create_lora_model(input_dim, hidden_dim, output_dim, r)
    ps, st = Lux.setup(rng, model)

    # Optimizer (only for LoRA params)
    opt = Adam(lr)
    opt_state = Optimisers.setup(opt, (lora_A=ps.lora_layer.lora_A, lora_B=ps.lora_layer.lora_B))

    # Dummy data
    X_train = randn(Float32, input_dim, 100)
    Y_train = randn(Float32, output_dim, 100)

    # Train
    for epoch in 1:n_epochs
        loss, ps, st, opt_state = train_step!(model, ps, st, opt_state, X_train, Y_train)

        if epoch % 10 == 0
            println("Epoch $epoch: Loss = $(round(loss, digits=4))")
        end
    end

    return model, ps, st
end

# Run training
model, ps_trained, st_trained = train_lora_model(r=8, n_epochs=50, lr=1e-2)
println("âœ… LoRA training completed in Julia")
```

#### 4.1.3 æ•°å¼â†”ã‚³ãƒ¼ãƒ‰å¯¾å¿œè¡¨

| æ•°å¼ | Julia ã‚³ãƒ¼ãƒ‰ | èª¬æ˜ |
|:-----|:------------|:-----|
| $h = W_0 x + \frac{\alpha}{r} BA x$ | `h = h_base .+ scaling .* h_B` | Forward pass |
| $A \sim \mathcal{N}(0, 1/\sqrt{k})$ | `randn(rng, Float32, r, k) ./ sqrt(k)` | AåˆæœŸåŒ– |
| $B = \mathbf{0}$ | `zeros(Float32, d, r)` | BåˆæœŸåŒ– |
| $\nabla_B = \frac{\alpha}{r} \sum_i \frac{\partial \mathcal{L}}{\partial h_i} (Ax_i)^\top$ | `grads.lora_B` (Zygoteè‡ªå‹•è¨ˆç®—) | å‹¾é… |
| $B \leftarrow B - \eta \nabla_B$ | `Optimisers.update!(opt_state, ps, grads)` | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–° |

### 4.2 ğŸ¦€ Rust LoRAæ¨è«– â€” ã‚¦ã‚§ã‚¤ãƒˆåˆæˆã¨å‹•çš„åˆ‡ã‚Šæ›¿ãˆ

#### 4.2.1 LoRAã‚¦ã‚§ã‚¤ãƒˆã®ãƒãƒ¼ã‚¸

è¨“ç·´å¾Œã€æ¨è«–ç”¨ã« $W_0 + \frac{\alpha}{r} BA$ ã‚’äº‹å‰è¨ˆç®—ã€‚

```rust
use ndarray::{Array2, s};

/// LoRA weights
pub struct LoRAWeights {
    pub base: Array2<f32>,     // Wâ‚€ âˆˆ â„^(dÃ—k)
    pub lora_a: Array2<f32>,   // A âˆˆ â„^(rÃ—k)
    pub lora_b: Array2<f32>,   // B âˆˆ â„^(dÃ—r)
    pub alpha: f32,
    pub r: usize,
}

impl LoRAWeights {
    /// Merge LoRA into base weight: W_merged = Wâ‚€ + (Î±/r)BA
    pub fn merge(&self) -> Array2<f32> {
        let scaling = self.alpha / (self.r as f32);
        // Wâ‚€ + (Î±/r)BA
        &self.base + &(self.lora_b.dot(&self.lora_a) * scaling)
    }

    /// Forward pass without merging (for multi-task switching)
    pub fn forward(&self, x: &Array2<f32>) -> Array2<f32> {
        let scaling = self.alpha / (self.r as f32);
        // h = Wâ‚€x + (Î±/r)B(Ax)
        self.base.dot(x) + self.lora_b.dot(&self.lora_a.dot(x)) * scaling
    }
}

fn main() {
    // Example: d=512, k=512, r=8
    let d = 512;
    let k = 512;
    let r = 8;

    let base = Array2::<f32>::zeros((d, k));
    let lora_a = Array2::<f32>::zeros((r, k));
    let lora_b = Array2::<f32>::zeros((d, r));

    let lora = LoRAWeights {
        base,
        lora_a,
        lora_b,
        alpha: 16.0,
        r,
    };

    // Merge for inference
    let w_merged = lora.merge();
    println!("âœ… LoRA merged: shape {:?}", w_merged.dim());

    // Or use unmerged for multi-task
    let x = Array2::<f32>::zeros((k, 1));
    let h = lora.forward(&x);
    println!("âœ… LoRA forward (unmerged): shape {:?}", h.dim());
}
```

#### 4.2.2 è¤‡æ•°LoRAã®å‹•çš„åˆ‡ã‚Šæ›¿ãˆ

Multi-taskæ¨è«– â€” åŒã˜ $W_0$ ã«è¤‡æ•°ã® $(B, A)$ ãƒšã‚¢ã‚’ä¿æŒã€‚

```rust
use std::collections::HashMap;

/// Multi-task LoRA manager
pub struct MultiTaskLoRA {
    pub base: Array2<f32>,                              // Shared Wâ‚€
    pub adapters: HashMap<String, (Array2<f32>, Array2<f32>)>,  // task_name => (B, A)
    pub alpha: f32,
    pub r: usize,
}

impl MultiTaskLoRA {
    pub fn new(base: Array2<f32>, alpha: f32, r: usize) -> Self {
        Self {
            base,
            adapters: HashMap::new(),
            alpha,
            r,
        }
    }

    /// Add a task-specific adapter
    pub fn add_adapter(&mut self, task_name: String, lora_b: Array2<f32>, lora_a: Array2<f32>) {
        self.adapters.insert(task_name, (lora_b, lora_a));
    }

    /// Forward with specific task adapter
    pub fn forward(&self, x: &Array2<f32>, task_name: &str) -> Option<Array2<f32>> {
        let (lora_b, lora_a) = self.adapters.get(task_name)?;
        let scaling = self.alpha / (self.r as f32);
        // h = Wâ‚€x + (Î±/r)B(Ax)
        Some(self.base.dot(x) + lora_b.dot(&lora_a.dot(x)) * scaling)
    }

    /// List available tasks
    pub fn tasks(&self) -> Vec<String> {
        self.adapters.keys().cloned().collect()
    }
}

fn main() {
    let d = 512;
    let k = 512;
    let r = 8;

    let base = Array2::<f32>::zeros((d, k));
    let mut multi_lora = MultiTaskLoRA::new(base, 16.0, r);

    // Add 3 task adapters
    multi_lora.add_adapter("summarization".to_string(), Array2::zeros((d, r)), Array2::zeros((r, k)));
    multi_lora.add_adapter("translation".to_string(), Array2::zeros((d, r)), Array2::zeros((r, k)));
    multi_lora.add_adapter("qa".to_string(), Array2::zeros((d, r)), Array2::zeros((r, k)));

    println!("Available tasks: {:?}", multi_lora.tasks());

    // Inference: switch between tasks
    let x = Array2::<f32>::zeros((k, 1));

    let h_sum = multi_lora.forward(&x, "summarization").unwrap();
    let h_qa = multi_lora.forward(&x, "qa").unwrap();

    println!("âœ… Multi-task LoRA: 3 tasks share Wâ‚€, switch by adapter name");
}
```

#### 4.2.3 QLoRA 4-bitæ¨è«–ï¼ˆæ¦‚å¿µå®Ÿè£…ï¼‰

QLoRAã®4-bit NF4é‡å­åŒ–ã‚’æ¦‚å¿µçš„ã«å®Ÿè£…ï¼ˆå®Ÿé‹ç”¨ã¯bitsandbytesä½¿ç”¨ï¼‰:

```rust
/// NF4 quantization levels (15 levels for 4-bit)
const NF4_LEVELS: [f32; 15] = [
    -1.0, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,
    0.0,
    0.0911, 0.1848, 0.2844, 0.3949, 0.5251, 0.6962, 1.0
];

/// Quantize a weight matrix to NF4
pub fn quantize_nf4(w: &Array2<f32>) -> (Vec<u8>, f32) {
    // Step 1: Find absmax
    let absmax = w.iter().map(|x| x.abs()).fold(0.0f32, f32::max);

    // Step 2: Normalize to [-1, 1]
    let w_norm = w / absmax;

    // Step 3: Quantize to nearest NF4 level (iterator chain)
    let quant = w_norm.iter()
        .map(|&val| NF4_LEVELS.iter()
            .enumerate()
            .min_by_key(|(_, &level)| ((val - level).abs() * 1e6) as i32)
            .map(|(i, _)| i as u8)
            .unwrap())
        .collect::<Vec<_>>();

    (quant, absmax)
}

/// Dequantize NF4 back to FP32
pub fn dequantize_nf4(quant: &[u8], absmax: f32, shape: (usize, usize)) -> Array2<f32> {
    let vals = quant.iter()
        .map(|&idx| NF4_LEVELS[idx as usize] * absmax)
        .collect::<Vec<_>>();
    Array2::from_shape_vec(shape, vals).unwrap()
}

fn main() {
    // Example weight matrix
    let w = Array2::<f32>::from_shape_fn((64, 64), |(i, j)| {
        ((i * 37 + j * 17) as f32).sin()  // dummy weights
    });

    // Quantize
    let (quant, absmax) = quantize_nf4(&w);
    println!("âœ… Quantized: {} values -> {} bytes", w.len(), quant.len());

    // Dequantize
    let w_dequant = dequantize_nf4(&quant, absmax, w.dim());

    // Check error
    let error = (&w - &w_dequant).mapv(|x| x.abs()).sum() / (w.len() as f32);
    println!("âœ… Dequantization error (mean): {:.6}", error);
}
```

### 4.3 Instruction Tuning â€” Chatå½¢å¼ã¸ã®é©å¿œ

#### 4.3.1 Chat Template

Instruction Tuningã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒ£ãƒƒãƒˆå½¢å¼ã«é©å¿œã•ã›ã‚‹æ‰‹æ³•ã€‚ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¾‹:

```
<|system|>
You are a helpful assistant.
<|user|>
What is the capital of France?
<|assistant|>
The capital of France is Paris.
```

Fine-tuningãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆAlpacaå½¢å¼ï¼‰:

```json
{
  "instruction": "What is the capital of France?",
  "input": "",
  "output": "The capital of France is Paris."
}
```

ã“ã‚Œã‚’ä¸Šè¨˜ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«å¤‰æ›:

```julia
# Short-form: ternary for user message, return template directly
format_alpaca(instruction::String, input::String, output::String;
              system_prompt::String="You are a helpful assistant.") =
    """
    <|system|>
    $system_prompt
    <|user|>
    $(isempty(input) ? instruction : "$instruction\n\nInput: $input")
    <|assistant|>
    $output
    """

# Example
formatted = format_alpaca(
    "What is the capital of France?",
    "",
    "The capital of France is Paris."
)
println(formatted)
```

#### 4.3.2 System Promptã®è¨­è¨ˆ

System Promptã¯ãƒ¢ãƒ‡ãƒ«ã®æŒ¯ã‚‹èˆã„ã‚’åˆ¶å¾¡ã™ã‚‹é‡è¦ãªè¦ç´ :

| ã‚¿ã‚¹ã‚¯ | System Promptä¾‹ |
|:-------|:---------------|
| **æ±ç”¨ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ** | "You are a helpful, respectful and honest assistant." |
| **ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ** | "You are an expert programmer. Always write clean, documented code." |
| **è¦ç´„** | "Summarize the following text concisely, preserving key information." |
| **ç¿»è¨³** | "Translate the following text from English to French." |

Instruction Tuningã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã§ä¸€è²«ã—ãŸSystem Promptã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒé‡è¦ [^10]ã€‚

> **Note:** **é€²æ—: 70% å®Œäº†** âš¡Julia LoRAè¨“ç·´å®Ÿè£…ã€ğŸ¦€Rust LoRAæ¨è«–ãƒ»ãƒãƒ¼ã‚¸ãƒ»Multi-taskåˆ‡ã‚Šæ›¿ãˆãƒ»QLoRAæ¦‚å¿µå®Ÿè£…ã€Instruction Tuningå½¢å¼ã‚’å®Œæˆã€‚æ¬¡ã¯å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ â€” SmolVLM2 LoRA Fine-tuningã¸ã€‚

> **Progress: 85%**
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. LoRAã‚¦ã‚§ã‚¤ãƒˆåˆæˆ $W = W_0 + \frac{\alpha}{r}BA$ ã‚’æ¨è«–å‰ã«è¡Œã†ã¨ãã€æ¨è«–æ™‚ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒã‚¼ãƒ­ã«ãªã‚‹ç†ç”±ã‚’èª¬æ˜ã›ã‚ˆã€‚
> 2. 4-bit NormalFloatï¼ˆNF4ï¼‰é‡å­åŒ–ãŒå‡ä¸€é‡å­åŒ–ã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹ç†ç”±ã‚’ã€æ­£è¦åˆ†å¸ƒã®ç‰¹æ€§ã¨çµã³ã¤ã‘ã¦èª¬æ˜ã›ã‚ˆã€‚

---

## ğŸ”¬ 5. å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” SmolVLM2 LoRA Fine-tuning

**ã‚´ãƒ¼ãƒ«**: ç¬¬22å›ã®SmolVLM2-256Mã‚’LoRAã§Fine-tuningã—ã€ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œã‚’ä½“é¨“ã™ã‚‹ã€‚

### 5.1 å®Ÿé¨“è¨­å®š

| é …ç›® | å€¤ |
|:-----|:---|
| **ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«** | SmolVLM2-256M (ç¬¬22å›) |
| **ã‚¿ã‚¹ã‚¯** | Visual Question Answering (VQA) on science diagrams |
| **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ** | AI2 Diagrams (æ•™ç§‘æ›¸ã®å›³ç‰ˆ + è³ªå•) 500ä¾‹ |
| **LoRAè¨­å®š** | r=16, Î±=32, target=å…¨Attentionå±¤ (q_proj, v_proj) |
| **è¨“ç·´** | 3 epochs, batch=4, lr=2e-4, AdamW |
| **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³** | Zero-shot SmolVLM2 (Fine-tuningå‰) |

### 5.2 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™

```julia
using JSON3, Images

# AI2 Diagrams dataset (simplified)
struct DiagramQA
    image_path::String
    question::String
    answer::String
end

load_diagram_qa(json_path::String) =
    [DiagramQA(d.image, d.question, d.answer) for d in JSON3.read(json_path)]

# Example
dataset = [
    DiagramQA("diagrams/photosynthesis.png", "What organelle performs photosynthesis?", "Chloroplast"),
    DiagramQA("diagrams/cell.png", "What is the powerhouse of the cell?", "Mitochondria"),
    # ... 500 examples
]

println("Loaded $(length(dataset)) diagram QA pairs")
```

### 5.3 LoRA Fine-tuningå®Ÿè£…

```julia
using Transformers, Flux, CUDA

# Load SmolVLM2-256M (from HuggingFace)
model_name = "HuggingFaceTB/SmolVLM2-256M-Instruct"
model = load_model(model_name)  # Simplified: actual code uses HuggingFace.jl

# Add LoRA to all Attention layers
function add_lora_to_attention!(model; r=16, Î±=32.0f0)
    for layer in model.vision_tower.layers
        # Wrap q_proj and v_proj with LoRA
        layer.attn.q_proj = LoRALayer(layer.attn.q_proj, r; Î±=Î±)
        layer.attn.v_proj = LoRALayer(layer.attn.v_proj, r; Î±=Î±)
    end

    for layer in model.language_model.layers
        layer.attn.q_proj = LoRALayer(layer.attn.q_proj, r; Î±=Î±)
        layer.attn.v_proj = LoRALayer(layer.attn.v_proj, r; Î±=Î±)
    end

    println("âœ… LoRA added to $(count_lora_params(model)) params")
end

function count_lora_params(model)
    # Count only LoRA params (B, A) via sum over layers
    sum(
        length(l.attn.q_proj.lora_A.weight) + length(l.attn.q_proj.lora_B.weight) +
        length(l.attn.v_proj.lora_A.weight) + length(l.attn.v_proj.lora_B.weight)
        for l in model.vision_tower.layers
    )
end

add_lora_to_attention!(model; r=16)

# Training loop (simplified)
function train_lora!(model, dataset; epochs=3, batch_size=4, lr=2e-4)
    opt = Adam(lr)

    for epoch in 1:epochs
        total_loss = 0.0

        for batch in Iterators.partition(dataset, batch_size)
            # Prepare batch
            images    = [load(d.image_path) for d in batch]
            questions = [d.question for d in batch]
            answers   = [d.answer   for d in batch]

            # Forward pass
            loss = compute_vqa_loss(model, images, questions, answers)

            # Backward (only LoRA params)
            grads = gradient(() -> loss, lora_params_only(model))
            Flux.update!(opt, lora_params_only(model), grads)

            total_loss += loss
        end

        avg_loss = total_loss / length(dataset)
        println("Epoch $epoch: Loss = $(round(avg_loss, digits=4))")
    end
end

# Run training
train_lora!(model, dataset[1:500]; epochs=3, batch_size=4, lr=2e-4)
```

### 5.4 è©•ä¾¡ â€” Zero-shot vs LoRA Fine-tuned

```julia
# Evaluate on test set
function evaluate_vqa(model, test_set)
    # count matching predictions with do-block (no manual accumulator)
    correct = count(test_set) do ex
        pred = generate(model, load(ex.image_path), ex.question; max_length=20)
        lowercase(pred) == lowercase(ex.answer)
    end
    return correct / length(test_set)
end

# Zero-shot (before fine-tuning)
model_zeroshot = load_model(model_name)
acc_zeroshot = evaluate_vqa(model_zeroshot, dataset[501:600])

# After LoRA fine-tuning
acc_finetuned = evaluate_vqa(model, dataset[501:600])

println("Zero-shot accuracy: $(round(acc_zeroshot*100, digits=1))%")
println("LoRA fine-tuned accuracy: $(round(acc_finetuned*100, digits=1))%")
println("Improvement: +$(round((acc_finetuned - acc_zeroshot)*100, digits=1))%")
```

### 5.5 çµæœ â€” ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡ vs æ€§èƒ½

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | Zero-shot | Full FT | LoRA (r=16) |
|:----------|:----------|:--------|:------------|
| **Accuracy** | 42.3% | 78.5% | 76.2% |
| **Trainable params** | 0 | 256M | 2.1M (0.8%) |
| **GPU memory** | - | 24 GB | 8 GB |
| **Training time** | - | 12h | 2.5h |

LoRA (r=16) ã¯ã€**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿0.8%**ã§ Full FT ã®**97%æ€§èƒ½**ã‚’é”æˆã€‚

### 5.6 QLoRAå®Ÿé¨“ â€” 4-bité‡å­åŒ–ã®åŠ¹æœ

```julia
# QLoRA: NF4é‡å­åŒ– + LoRA (Juliaå®Ÿè£…)
using LinearAlgebra, Statistics

# NF4é‡å­åŒ–ãƒ¬ãƒ™ãƒ«ï¼ˆ16å€¤ï¼‰: Î¦â»Â¹(i/15) ã‚’æ­£è¦åŒ–
# Î¦â»Â¹: æ¨™æº–æ­£è¦åˆ†å¸ƒã®é€†CDFï¼ˆquantile functionï¼‰
function nf4_levels()
    levels = [quantile(Normal(), i/15) for i in 1:14]
    prepend!(levels, [-Inf])  # clamp to -1
    push!(levels, Inf)        # clamp to +1
    levels ./= maximum(abs.(levels))
    return levels
end

# 4-bité‡å­åŒ–: float â†’ NF4ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
function quantize_nf4(W::Matrix{Float32})
    levels = nf4_levels()
    # Per-channelæ­£è¦åŒ–: |W|ã®æœ€å¤§å€¤ã§ã‚¹ã‚±ãƒ¼ãƒ«
    scale = maximum(abs, W, dims=1)  # shape: [1, d_model]
    W_norm = W ./ scale              # shape: [d_in, d_model]
    # æœ€è¿‘å‚NF4ãƒ¬ãƒ™ãƒ«ã«ä¸¸ã‚ã‚‹
    idx = [argmin(abs.(w .- levels)) for w in W_norm]
    return idx, scale
end

# å‡ºåŠ›ä¾‹:
# W = randn(Float32, 4096, 4096)
# idx, scale = quantize_nf4(W)
# @assert size(idx) == (4096, 4096)
# @assert size(scale) == (1, 4096)
```

QLoRAçµæœ:

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | LoRA (FP16) | QLoRA (4-bit) |
|:----------|:------------|:--------------|
| **Accuracy** | 76.2% | 75.8% (-0.4%) |
| **GPU memory** | 8 GB | **3.2 GB** |
| **Inference speed** | 45 tok/s | 42 tok/s (-7%) |

QLoRA ã¯ãƒ¡ãƒ¢ãƒªã‚’**60%å‰Šæ¸›**ã€æ€§èƒ½ä½ä¸‹ã¯**0.4%**ã®ã¿ã€‚

### 5.7 è‡ªå·±è¨ºæ–­ãƒ†ã‚¹ãƒˆ â€” å®Œå…¨ç‰ˆ

Fine-tuning & PEFTã®ç†è§£åº¦ã‚’ç¢ºèªã™ã‚‹3ã¤ã®ãƒ†ã‚¹ãƒˆã€‚

#### 5.7.1 è¨˜å·èª­è§£ãƒ†ã‚¹ãƒˆï¼ˆ10å•ï¼‰

<details><summary>**Q1: $\Delta W = BA$ ã®å„è¨˜å·ã®æ„å‘³ã¯ï¼Ÿ**</summary>

**è§£ç­”**:
- $\Delta W$: é‡ã¿ã®å¤‰åŒ–é‡ï¼ˆFine-tuningæ™‚ã®å·®åˆ†ï¼‰
- $B \in \mathbb{R}^{d \times r}$: LoRAè¡Œåˆ—Bï¼ˆtrainableã€d=å‡ºåŠ›æ¬¡å…ƒã€r=ãƒ©ãƒ³ã‚¯ï¼‰
- $A \in \mathbb{R}^{r \times k}$: LoRAè¡Œåˆ—Aï¼ˆtrainableã€k=å…¥åŠ›æ¬¡å…ƒï¼‰
- $r \ll \min(d, k)$: ãƒ©ãƒ³ã‚¯ï¼ˆä½ãƒ©ãƒ³ã‚¯è¿‘ä¼¼ã®æ¬¡å…ƒï¼‰

ä½ãƒ©ãƒ³ã‚¯åˆ†è§£ã«ã‚ˆã‚Šã€$dk$ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ $r(d+k)$ ã«å‰Šæ¸›ã€‚

</details>

<details><summary>**Q2: $h = W_0 x + \frac{\alpha}{r} BA x$ ã® $\frac{\alpha}{r}$ ã®å½¹å‰²ã¯ï¼Ÿ**</summary>

**è§£ç­”**:
$\alpha$: ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®šæ•°ï¼ˆå…¸å‹å€¤8-64ï¼‰
$r$: ãƒ©ãƒ³ã‚¯

$\frac{\alpha}{r}$ ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã‚Šã€ãƒ©ãƒ³ã‚¯ $r$ ã‚’å¤‰ãˆã¦ã‚‚å­¦ç¿’ç‡ã‚’èª¿æ•´ä¸è¦ã«ã™ã‚‹ã€‚

**ç†ç”±**: $\mathbb{E}[\|BA x\|^2] \propto r \|x\|^2$ ãªã®ã§ã€$\frac{\alpha}{r}$ ã§æ­£è¦åŒ–ã™ã‚‹ã¨ã€$r$ ã®å½±éŸ¿ã‚’ç›¸æ®ºã€‚

</details>

<details><summary>**Q3: NF4é‡å­åŒ–ã® $\Phi^{-1}(i/15)$ ã®æ„å‘³ã¯ï¼Ÿ**</summary>

**è§£ç­”**:
$\Phi^{-1}$: æ¨™æº–æ­£è¦åˆ†å¸ƒ $\mathcal{N}(0, 1)$ ã®é€†CDFï¼ˆåˆ†ä½ç‚¹é–¢æ•°ï¼‰
$i/15$: ç¢ºç‡å€¤ï¼ˆ$i=0, 1, \dots, 15$ï¼‰

NF4ã¯ã€æ­£è¦åˆ†å¸ƒã®åˆ†ä½ç‚¹ã‚’é‡å­åŒ–ãƒ¬ãƒ™ãƒ«ã¨ã™ã‚‹ â†’ æƒ…å ±ç†è«–çš„ã«æœ€é©ãª4-bité‡å­åŒ–ã€‚

</details>

<details><summary>**Q4: DreamBoothã® $\mathcal{L}_\text{prior}$ ã®ç¬¬1å¼•æ•° $x_{pr}$ ã¯ä½•ã‹ï¼Ÿ**</summary>

**è§£ç­”**:
$x_{pr}$: Prior preservationç”¨ã®ç”»åƒã€‚äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ« $\theta_0$ ãŒç”Ÿæˆã—ãŸã€Œä¸€èˆ¬çš„ãªã‚¯ãƒ©ã‚¹ã€ã®ç”»åƒã€‚

$$
x_{pr} \sim p_{\theta_0}(x \mid c_{\text{class}})
$$

$c_{\text{class}} = \text{``a dog''}$ ï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒˆãƒ¼ã‚¯ãƒ³ [V] ãªã—ï¼‰

Language driftã‚’é˜²ããŸã‚ã€ã‚¯ãƒ©ã‚¹ä¸€èˆ¬ã®çŸ¥è­˜ã‚’ä¿æŒã™ã‚‹ã€‚

</details>

<details><summary>**Q5: Adapter ã® $W_{\text{down}} \in \mathbb{R}^{r \times d}$ ã®ãƒ©ãƒ³ã‚¯ $r$ ã®å…¸å‹å€¤ã¯ï¼Ÿ**</summary>

**è§£ç­”**:
$r = 64$ï¼ˆBERT-baseãªã©ã€$d=768$ ã®å ´åˆï¼‰

ãƒœãƒˆãƒ«ãƒãƒƒã‚¯æ¬¡å…ƒã€‚$r \ll d$ ã«ã‚ˆã‚Šã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’å‰Šæ¸›ã€‚

Adapterãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: $2dr + d + r \approx 2dr$

</details>

<details><summary>**Q6: Prefix Tuningã® $P \in \mathbb{R}^{l \times d}$ ã® $l$ ã®æ„å‘³ã¯ï¼Ÿ**</summary>

**è§£ç­”**:
$l$: ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹é•·ï¼ˆå…¸å‹å€¤10-20ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
$d$: åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ

$P$ ã¯ trainable ãªé€£ç¶šãƒ™ã‚¯ãƒˆãƒ«åˆ—ã€‚å…¥åŠ› $X$ ã®å…ˆé ­ã«é€£çµ: $[P; X]$

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: $l \times d \times L$ï¼ˆ$L$=å±¤æ•°ï¼‰

</details>

<details><summary>**Q7: P-Tuning v2ã® $P_i$ ï¼ˆå±¤ã”ã¨ã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ï¼‰ã®åˆ©ç‚¹ã¯ï¼Ÿ**</summary>

**è§£ç­”**:
å„å±¤ $i$ ã«å°‚ç”¨ã® $P_i \in \mathbb{R}^{l \times d}$ ã‚’æŒã¤ï¼ˆPrefix Tuningã¯å…¨å±¤å…±æœ‰ï¼‰ã€‚

**åˆ©ç‚¹**: éšå±¤çš„ãªç‰¹å¾´æŠ½å‡ºã‚’å¼·åŒ–ã€‚ä½å±¤=æ§‹æ–‡ã€é«˜å±¤=æ„å‘³ ãªã©ã€å±¤ã”ã¨ã«ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å­¦ç¿’å¯èƒ½ã€‚

å®Ÿé¨“çš„ã«ã€å¤šãã®ã‚¿ã‚¹ã‚¯ã§ Full FT ã‚’è¶…ãˆã‚‹æ€§èƒ½ [^7]ã€‚

</details>

<details><summary>**Q8: QLoRAã® Double Quantization ã® $c_{\text{global}}$ ã¯ä½•ã‚’ä¿å­˜ã™ã‚‹ã‹ï¼Ÿ**</summary>

**è§£ç­”**:
$c_{\text{global}} = \max_{i=1}^B c_i$

å…¨ãƒ–ãƒ­ãƒƒã‚¯ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®šæ•° $\{c_1, \dots, c_B\}$ ã®æœ€å¤§å€¤ï¼ˆFP32ã€1å€‹ã®ã¿ï¼‰ã€‚

å„ $c_i$ ã‚’8-bitã«é‡å­åŒ–ã™ã‚‹éš›ã®æ­£è¦åŒ–ã«ä½¿ç”¨ã€‚

</details>

<details><summary>**Q9: LoRAã®åˆæœŸåŒ–ã§ $B=0$ ã¨ã™ã‚‹ç†ç”±ã¯ï¼Ÿ**</summary>

**è§£ç­”**:
$B=0$ ã«ã‚ˆã‚Šã€è¨“ç·´é–‹å§‹æ™‚ $\Delta W = BA = 0$ã€‚

ã¤ã¾ã‚Šã€$W = W_0 + 0 = W_0$ ã§**äº‹å‰å­¦ç¿’é‡ã¿ã‹ã‚‰é–‹å§‹**ã€‚

ã“ã‚Œã«ã‚ˆã‚Šã€Fine-tuningåˆæœŸã®å®‰å®šæ€§ã‚’ç¢ºä¿ã€‚$A$ ã¯ãƒ©ãƒ³ãƒ€ãƒ åˆæœŸåŒ–ã ãŒã€$B=0$ ã§æ‰“ã¡æ¶ˆã•ã‚Œã‚‹ã€‚

</details>

<details><summary>**Q10: Prompt Tuning vs Prefix Tuning ã®é•ã„ã¯ï¼Ÿ**</summary>

**è§£ç­”**:

| é …ç›® | Prompt Tuning | Prefix Tuning |
|:-----|:-------------|:-------------|
| æŒ¿å…¥ç®‡æ‰€ | åŸ‹ã‚è¾¼ã¿å±¤ã®ã¿ | å„Transformerå±¤ã®å…¥åŠ› |
| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° | $k \times d$ | $l \times d \times L$ |
| å…¸å‹å€¤ | 15K (k=20, d=768) | 92K (l=10, d=768, L=12) |
| æ€§èƒ½ | å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§ä½ã„ | å…¨è¦æ¨¡ã§å®‰å®š |

Prompt Tuningã¯è»½é‡ã ãŒã€10Bè¶…ãƒ¢ãƒ‡ãƒ«ã§ã®ã¿åŠ¹æœçš„ [^8]ã€‚

</details>

#### 5.7.2 æ•°å¼å°å‡ºãƒ†ã‚¹ãƒˆï¼ˆ5å•ï¼‰

<details><summary>**Q1: LoRAã®å‹¾é… $\nabla_B \mathcal{L}$ ã‚’å°å‡ºã›ã‚ˆï¼ˆ$h = W_0 x + \frac{\alpha}{r} BA x$ï¼‰**</summary>

**è§£ç­”**:

æå¤± $\mathcal{L}(h)$ ã«å¯¾ã—ã€

$$
\begin{aligned}
\frac{\partial \mathcal{L}}{\partial B} &= \frac{\partial \mathcal{L}}{\partial h} \frac{\partial h}{\partial B} \\
&= \frac{\partial \mathcal{L}}{\partial h} \frac{\partial}{\partial B} \left( \frac{\alpha}{r} BA x \right) \\
&= \frac{\alpha}{r} \frac{\partial \mathcal{L}}{\partial h} (Ax)^\top
\end{aligned}
$$

ãƒãƒƒãƒã‚µã‚¤ã‚º $N$ ã®å ´åˆ:

$$
\nabla_B \mathcal{L} = \frac{\alpha}{r} \sum_{i=1}^N \frac{\partial \mathcal{L}}{\partial h_i} (A x_i)^\top
$$

</details>

<details><summary>**Q2: NF4é‡å­åŒ–èª¤å·®ã‚’ $\mathbb{E}[(w - Q(w))^2]$ ã§è©•ä¾¡ã›ã‚ˆï¼ˆ$w \sim \mathcal{N}(0, 1)$ï¼‰**</summary>

**è§£ç­”**:

NF4ãƒ¬ãƒ™ãƒ«: $q_i = \Phi^{-1}(i/15)$ã€æ±ºå®šå¢ƒç•Œ: $t_i = (q_{i-1} + q_i)/2$

$$
\begin{aligned}
\mathbb{E}[(w - Q(w))^2] &= \sum_{i=0}^{15} \int_{t_i}^{t_{i+1}} (w - q_i)^2 \phi(w) dw \\
&\approx 0.032 \quad \text{(æ•°å€¤ç©åˆ†)}
\end{aligned}
$$

$\phi(w) = \frac{1}{\sqrt{2\pi}} e^{-w^2/2}$: æ¨™æº–æ­£è¦åˆ†å¸ƒPDF

ç·šå½¢é‡å­åŒ–ï¼ˆ$q_i = -1 + 2i/15$ï¼‰ã®å ´åˆ: $\approx 0.045$

NF4ã¯**29%å‰Šæ¸›**ã€‚

</details>

<details><summary>**Q3: DreamBooth ã® $\mathcal{L}_\text{total}$ ã‚’ $\lambda$ ã§å¾®åˆ†ã—ã€æœ€é© $\lambda$ ã®æ¡ä»¶ã‚’æ±‚ã‚ã‚ˆ**</summary>

**è§£ç­”**:

$$
\mathcal{L}_\text{total}(\lambda) = \mathcal{L}_\text{instance} + \lambda \mathcal{L}_\text{prior}
$$

$\lambda$ ã«é–¢ã™ã‚‹æœ€é©åŒ–ï¼ˆ$\theta$ ã¯å›ºå®šã¨ä»®å®šï¼‰:

$$
\frac{d\mathcal{L}_\text{total}}{d\lambda} = \mathcal{L}_\text{prior} = 0 \quad \text{ã¯ä¸é©ï¼ˆpriorã‚’å®Œå…¨ç„¡è¦–ï¼‰}
$$

å®Ÿéš›ã«ã¯ã€$\lambda$ ã¯ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚ç†è«–çš„æœ€é©å€¤ã¯ã€

$$
\lambda^* = \arg\min_\lambda \text{Validation Error}(\theta^*(\lambda))
$$

å®Ÿé¨“çš„ã« $\lambda=1$ ãŒå¤šãã®ã‚¿ã‚¹ã‚¯ã§æœ€é© [^4]ã€‚

ï¼ˆ$\lambda$ ã¯è¨“ç·´æ™‚ã®å›ºå®šå€¤ã€å¾®åˆ†æœ€é©åŒ–ã®å¯¾è±¡ã§ã¯ãªã„ï¼‰

</details>

<details><summary>**Q4: Adapterã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° $2dr + d + r$ ã‚’å°å‡ºã›ã‚ˆ**</summary>

**è§£ç­”**:

Adapteræ§‹é€ :

$$
\text{Adapter}(h) = W_{\text{up}} \cdot \text{ReLU}(W_{\text{down}} h + b_{\text{down}}) + b_{\text{up}}
$$

- $W_{\text{down}} \in \mathbb{R}^{r \times d}$: $rd$ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
- $b_{\text{down}} \in \mathbb{R}^r$: $r$ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
- $W_{\text{up}} \in \mathbb{R}^{d \times r}$: $dr$ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
- $b_{\text{up}} \in \mathbb{R}^d$: $d$ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

åˆè¨ˆ: $rd + r + dr + d = 2dr + d + r$

$r \ll d$ ãªã‚‰ã€$\approx 2dr$ã€‚

</details>

<details><summary>**Q5: QLoRAã®ãƒ¡ãƒ¢ãƒªå‰Šæ¸›ç‡ã‚’ $d, k, r, B$ ã§è¡¨ã›ï¼ˆFull FT â†’ QLoRAï¼‰**</summary>

**è§£ç­”**:

**Full FT**:
- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆFP32ï¼‰: $dk \times 4$ bytes
- å‹¾é…ï¼ˆFP32ï¼‰: $dk \times 4$ bytes
- AdamçŠ¶æ…‹ï¼ˆFP32Ã—2ï¼‰: $dk \times 8$ bytes
- åˆè¨ˆ: $dk \times 16$ bytes

**QLoRA**:
- $W_0$ é‡å­åŒ–ï¼ˆ4-bitï¼‰: $dk \times 0.5$ bytes
- ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®šæ•°ï¼ˆ8-bit + double quantï¼‰: $B \times 1 + 4$ bytes
- LoRAï¼ˆFP16ï¼‰: $(dr + rk) \times 2$ bytes
- å‹¾é…ï¼ˆBF16ï¼‰: $(dr + rk) \times 2$ bytes
- AdamçŠ¶æ…‹ï¼ˆBF16Ã—2ï¼‰: $(dr + rk) \times 4$ bytes
- åˆè¨ˆ: $0.5dk + B + 8r(d+k) + 4$ bytes

å‰Šæ¸›ç‡ï¼ˆ$B \approx dk/64$, $r=16, d=k=4096$ï¼‰:

$$
\frac{dk \times 16}{0.5dk + dk/64 + 8r(d+k)} \approx \frac{16dk}{0.52dk + 0.26M} \approx 30 \text{x}
$$

GPT-3 (175B): å‰Šæ¸›ç‡ **ç´„50å€**ã€‚

</details>

#### 5.7.3 ã‚³ãƒ¼ãƒ‰ç¿»è¨³ãƒ†ã‚¹ãƒˆï¼ˆ5å•ï¼‰

<details><summary>**Q1: æ•°å¼ $h = W_0 x + \frac{\alpha}{r} BA x$ ã‚’Juliaã§å®Ÿè£…ã›ã‚ˆ**</summary>

**è§£ç­”**:

```julia
# Short-form: h = Wâ‚€x + (Î±/r)B(Ax)
lora_forward(W0::Matrix{Float32}, B::Matrix{Float32}, A::Matrix{Float32},
             x::Vector{Float32}, Î±::Float32, r::Int) =
    W0 * x .+ (Î± / r) .* (B * (A * x))

# Example
d, k, r = 512, 512, 8
W0 = randn(Float32, d, k) / âˆšk
B  = randn(Float32, d, r) / âˆšr
A = zeros(Float32, r, k)
x = randn(Float32, k)
Î± = 16.0f0

h = lora_forward(W0, B, A, x, Î±, r)
```

</details>

<details><summary>**Q2: NF4é‡å­åŒ– $q_i = \Phi^{-1}(i/15)$ ã‚’Juliaã§è¨ˆç®—ã›ã‚ˆ**</summary>

**è§£ç­”**:

```julia
using Distributions: Normal, quantile

nf4_levels = Float64[]
for i in 1:16
    if i == 1
        push!(nf4_levels, -1.0)  # clamp
    elseif i == 16
        push!(nf4_levels, 1.0)   # clamp
    else
        q = quantile(Normal(), (i-1) / 15.0)   # Î¦â»Â¹
        push!(nf4_levels, q)
    end
end

# Normalize to [-1, 1]
max_val = maximum(abs.(nf4_levels))
nf4_levels ./= max_val

println("NF4: ", round.(nf4_levels, digits=4))
# [-1.0, -0.6962, -0.5251, ..., 1.0]
```

</details>

<details><summary>**Q3: DreamBooth Prior Preservation Loss $\mathcal{L}_\text{prior}$ ã‚’Juliaã§å®Ÿè£…ã›ã‚ˆ**</summary>

**è§£ç­”**:

```julia
using Flux, Statistics

# DreamBooth Prior Preservation Loss
# æ•°å¼: â„’_prior = ğ”¼_{z,c,Îµ,t}[â€–Îµ - Îµ_Î¸(z_t, t, c)â€–Â²]
#
# å¼•æ•°:
#   Îµ_pred :: Matrix{Float32}  # äºˆæ¸¬ãƒã‚¤ã‚º [CÃ—HÃ—WÃ—B]
#   Îµ      :: Matrix{Float32}  # æ­£è§£ãƒã‚¤ã‚º [CÃ—HÃ—WÃ—B]
#
# è¨˜å·å¯¾å¿œ:
#   Îµ_pred â†” eps_pred
#   Îµ      â†” eps

function prior_preservation_loss(Îµ_pred, Îµ)
    return mean((Îµ_pred .- Îµ).^2)  # MSE
end

# æ¤œç®—: åŒä¸€ãƒã‚¤ã‚ºãªã‚‰æå¤±=0
Îµ_test = randn(Float32, 4, 4, 4, 2)
@assert prior_preservation_loss(Îµ_test, Îµ_test) â‰ˆ 0.0f0
```

</details>

<details><summary>**Q4: Rust ã§ LoRA ãƒãƒ¼ã‚¸ $W_{\text{merged}} = W_0 + \frac{\alpha}{r} BA$ ã‚’å®Ÿè£…ã›ã‚ˆ**</summary>

**è§£ç­”**:

```rust
use ndarray::Array2;

fn lora_merge(
    w0: &Array2<f32>,
    b: &Array2<f32>,
    a: &Array2<f32>,
    alpha: f32,
    r: usize,
) -> Array2<f32> {
    let scaling = alpha / (r as f32);
    // W_merged = Wâ‚€ + (Î±/r)BA
    w0 + &(b.dot(a) * scaling)
}

fn main() {
    let d = 512;
    let k = 512;
    let r = 8;

    let w0 = Array2::<f32>::zeros((d, k));
    let b = Array2::<f32>::zeros((d, r));
    let a = Array2::<f32>::zeros((r, k));

    let w_merged = lora_merge(&w0, &b, &a, 16.0, r);
    println!("Merged shape: {:?}", w_merged.dim());
}
```

</details>

<details><summary>**Q5: Adapter ã® Forward pass $h_{\text{out}} = h + W_{\text{up}} \text{ReLU}(W_{\text{down}} h + b_{\text{down}}) + b_{\text{up}}$ ã‚’Juliaã§å®Ÿè£…ã›ã‚ˆ**</summary>

**è§£ç­”**:

```julia
using Flux

struct Adapter
    W_down::Matrix{Float32}
    b_down::Vector{Float32}
    W_up::Matrix{Float32}
    b_up::Vector{Float32}
end

function (adapter::Adapter)(h::Vector{Float32})
    # h_adapter = W_up * ReLU(W_down * h + b_down) + b_up
    h_up = adapter.W_up * relu.(adapter.W_down * h .+ adapter.b_down) .+ adapter.b_up
    return h .+ h_up  # residual connection
end

# Example
d, r = 768, 64
adapter = Adapter(
    randn(Float32, r, d) / âˆšd,
    zeros(Float32, r),
    randn(Float32, d, r) / âˆšr,
    zeros(Float32, d)
)

h = randn(Float32, d)
h_out = adapter(h)
```

</details>

#### 5.7.4 ç·åˆãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

å…¨ãƒ†ã‚¹ãƒˆã‚’å®Œäº†ã—ãŸã‚‰ã€ä»¥ä¸‹ã‚’ãƒã‚§ãƒƒã‚¯:

- [ ] è¨˜å·èª­è§£10å•: LoRA/QLoRA/DreamBooth/Adapter/Prefix/Prompt Tuning ã®è¨˜å·ã‚’å®Œå…¨ç†è§£
- [ ] æ•°å¼å°å‡º5å•: å‹¾é…/é‡å­åŒ–èª¤å·®/æå¤±é–¢æ•°/ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°/ãƒ¡ãƒ¢ãƒªå‰Šæ¸›ç‡ã‚’å°å‡ºå¯èƒ½
- [ ] ã‚³ãƒ¼ãƒ‰ç¿»è¨³5å•: æ•°å¼â†’Julia/Python/Rustå®Ÿè£…ã‚’1:1å¯¾å¿œã§æ›¸ã‘ã‚‹
- [ ] SmolVLM2å®Ÿé¨“: Zero-shotâ†’LoRA Fine-tuningã‚’å®Ÿè¡Œã§ãã‚‹
- [ ] QLoRAå®Ÿé¨“: 4-bité‡å­åŒ–ã®åŠ¹æœã‚’æ¤œè¨¼ã§ãã‚‹

**å…¨ã¦ãƒã‚§ãƒƒã‚¯ã§ããŸã‚‰ã€ç¬¬23å›ã®å†…å®¹ã‚’å®Œå…¨ç¿’å¾—**ã€‚

> **Note:** **é€²æ—: 85% å®Œäº†** SmolVLM2 LoRA Fine-tuningã®å®Ÿé¨“ã‚’å®Œäº†ã€‚Zero-shot 42%â†’LoRA 76%ã€QLoRAã§ãƒ¡ãƒ¢ãƒª60%å‰Šæ¸›ã‚’ç¢ºèªã€‚æ¬¡ã¯ç™ºå±•ã‚¾ãƒ¼ãƒ³ â€” æœ€æ–°ç ”ç©¶ã¨ç†è«–çš„é™ç•Œã¸ã€‚

---

## ğŸ“ 6. æŒ¯ã‚Šè¿”ã‚Šã¨ç™ºå±•ã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” ã¾ã¨ã‚ã¨æœ€æ–°ç ”ç©¶å‹•å‘

### 6.1 PEFTç ”ç©¶ã®ç³»è­œ (2019-2026)

```mermaid
graph TD
    A["Adapter Tuning<br/>(Houlsby+ 2019)"] --> B["LoRA<br/>(Hu+ 2022)"]
    C["Prefix Tuning<br/>(Li & Liang 2021)"] --> D["P-Tuning v2<br/>(Liu+ 2022)"]
    B --> E["QLoRA<br/>(Dettmers+ 2023)"]
    E --> F["DoRA / LoRA+<br/>(2024)"]
    B --> G["DreamBooth + LoRA<br/>(2023)"]
    H["Prompt Tuning<br/>(Lester+ 2021)"] --> D

    style B fill:#c8e6c9
    style E fill:#b3e5fc
    style F fill:#fff9c4
```

#### 6.1.1 ä¸»è¦è«–æ–‡ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³

| å¹´ | è«–æ–‡ | é©æ–° | å‰Šæ¸›ç‡ |
|:---|:-----|:-----|:------|
| 2019 | Adapter Tuning [^5] | ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« | 100x |
| 2021 | Prefix Tuning [^6] | é€£ç¶šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ | 1000x |
| 2021 | Prompt Tuning [^8] | Soft promptï¼ˆåŸ‹ã‚è¾¼ã¿å±¤ã®ã¿ï¼‰ | 10000x |
| 2022 | LoRA [^1] | ä½ãƒ©ãƒ³ã‚¯åˆ†è§£ï¼ˆå…¨å±¤ï¼‰ | 10000x |
| 2022 | P-Tuning v2 [^7] | éšå±¤çš„Prefix | 1000x |
| 2023 | QLoRA [^2] | 4-bité‡å­åŒ– + LoRA | 50000x (ãƒ¡ãƒ¢ãƒª) |
| 2023 | DreamBooth [^4] | Few-shotå€‹äººåŒ– | - |
| 2024 | DoRA [^11] | Weight Decomposition | - |
| 2024 | LoRA+ [^12] | å­¦ç¿’ç‡åˆ†é›¢ï¼ˆAâ‰ Bï¼‰ | - |

### 6.2 LoRA ã®ç†è«–çš„é™ç•Œ â€” ãªãœä½ãƒ©ãƒ³ã‚¯ã§ååˆ†ã‹ï¼Ÿ

#### 6.2.1 Intrinsic Dimensionä»®èª¬

Aghajanyan et al. (2020) [^13] ã¯ã€**äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®é©å¿œã«å¿…è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å®ŸåŠ¹æ¬¡å…ƒï¼ˆintrinsic dimensionï¼‰ã¯éå¸¸ã«ä½ã„**ã“ã¨ã‚’ç¤ºã—ãŸ:

$$
\theta_\text{ft} = \theta_0 + P \theta_\text{low}
$$

$P \in \mathbb{R}^{n \times d}$: ãƒ©ãƒ³ãƒ€ãƒ å°„å½±è¡Œåˆ—ã€$\theta_\text{low} \in \mathbb{R}^d$ã€$d \ll n$ã€‚

GPT-2ã§å®Ÿé¨“ã—ãŸçµæœã€$d=200$ï¼ˆå…¨ä½“ã®0.01%ï¼‰ã§ Full FTã®90%æ€§èƒ½ã‚’é”æˆã€‚

**LoRAã¨ã®é–¢ä¿‚**: LoRAã®ä½ãƒ©ãƒ³ã‚¯ $r$ ã¯ã€ã“ã® intrinsic dimension ã«å¯¾å¿œã€‚

#### 6.2.2 Over-parametrizationç†è«–

å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ï¼ˆGPT-3ãªã©ï¼‰ã¯**éå‰°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–**ã•ã‚Œã¦ã„ã‚‹ã€‚è¨“ç·´å¾Œã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã®å¤§éƒ¨åˆ†ã¯å†—é•·ã€‚

$$
\text{rank}(\nabla^2 \mathcal{L}(\theta_0)) \ll |\theta_0|
$$

Hessianã®ãƒ©ãƒ³ã‚¯ãŒä½ã„ â†’ æœ€é©åŒ–ã¯ä½æ¬¡å…ƒéƒ¨åˆ†ç©ºé–“ã§å¯èƒ½ã€‚

#### 6.2.3 ä½ãƒ©ãƒ³ã‚¯ $r$ ã®é¸ã³æ–¹

å®Ÿé¨“çš„ãªã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ [^1]:

| ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º | æ¨å¥¨ $r$ | $\alpha$ |
|:------------|:---------|:---------|
| < 1B | 4-8 | 8-16 |
| 1B-10B | 8-16 | 16-32 |
| 10B-100B | 16-64 | 32-64 |
| > 100B | 64-128 | 64-128 |

$r$ ãŒå¤§ãã„ã»ã©è¡¨ç¾åŠ›å‘ä¸Šã€ã ãŒè¨“ç·´ã‚³ã‚¹ãƒˆå¢—ã€‚ã‚¿ã‚¹ã‚¯ã®è¤‡é›‘ã•ã«å¿œã˜ã¦èª¿æ•´ã€‚

### 6.3 QLoRA ã®æ•°å€¤å®‰å®šæ€§

#### 6.3.1 Mixed Precision Training

QLoRAã¯ã€ç•°ãªã‚‹ç²¾åº¦ã‚’æ··åœ¨:

- **Wâ‚€**: 4-bit NF4 (storage)
- **Forwardæ™‚ã®Wâ‚€**: BF16 (computation)
- **LoRA (B, A)**: BF16 (storage + computation)
- **å‹¾é…**: BF16
- **ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶çŠ¶æ…‹**: BF16ï¼ˆã¾ãŸã¯8-bitã€Double Quantï¼‰

æ•°å€¤å®‰å®šæ€§ã®ãƒã‚¤ãƒ³ãƒˆ:

$$
\text{BF16 exponent range} = [-126, 127] \quad \text{(FP16ã‚ˆã‚Šåºƒã„)}
$$

BF16ã¯FP16ã‚ˆã‚ŠæŒ‡æ•°éƒ¨ãŒåºƒãã€ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼/ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼ã«å¼·ã„ã€‚

#### 6.3.2 NF4ã®æƒ…å ±ç†è«–çš„æœ€é©æ€§

NF4ã¯ã€æ­£è¦åˆ†å¸ƒ $\mathcal{N}(0, 1)$ ã«å¯¾ã—ã¦**æƒ…å ±ç†è«–çš„ã«æœ€é©ãª4-bité‡å­åŒ–** [^2]:

$$
\min_{Q: \mathbb{R} \to \{q_1, \dots, q_{16}\}} \mathbb{E}_{x \sim \mathcal{N}(0, 1)}[(x - Q(x))^2]
$$

æœ€é©è§£: $q_i = \Phi^{-1}(i/16)$ (NF4ãƒ¬ãƒ™ãƒ«)ã€‚

è¨¼æ˜ã‚¹ã‚±ãƒƒãƒ: Lloyd-Maxé‡å­åŒ–ã®ç†è«– [^14]ã€æ­£è¦åˆ†å¸ƒã®å¯¾ç§°æ€§ã‹ã‚‰åˆ†ä½ç‚¹é‡å­åŒ–ãŒæœ€é©ã€‚

### 6.4 DreamBoothã®æ‹¡å¼µ

#### 6.4.1 DreamBooth vs Textual Inversion

| æ‰‹æ³• | Fine-tuningå¯¾è±¡ | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° | æ€§èƒ½ |
|:-----|:---------------|:------------|:-----|
| **Textual Inversion** | ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®åŸ‹ã‚è¾¼ã¿ã®ã¿ | ~5K | ä¸­ |
| **DreamBooth** | å…¨UNet | å…¨ã¦ | é«˜ |
| **DreamBooth + LoRA** | UNetã®LoRAéƒ¨åˆ† | ~10M | é«˜ï¼ˆãƒãƒ¼ã‚¸å¯èƒ½ï¼‰ |

Textual Inversion [^15] ã¯ã€æ–°ãƒˆãƒ¼ã‚¯ãƒ³ã®åŸ‹ã‚è¾¼ã¿ã‚’å­¦ç¿’:

$$
v_* = \arg\min_v \mathbb{E}_{x, c, \epsilon, t}[\|\epsilon - \epsilon_\theta(z_t, c(v))\|_2^2]
$$

$c(v)$: ãƒˆãƒ¼ã‚¯ãƒ³ $v$ ã‚’å«ã‚€ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã€‚DreamBoothã‚ˆã‚Šè»½é‡ã ãŒã€è¡¨ç¾åŠ›ãŒåŠ£ã‚‹ã€‚

#### 6.4.2 Custom Diffusionã¨ã®æ¯”è¼ƒ

Custom Diffusion [^16] ã¯ã€**Cross-Attentionå±¤ã®K, Vã®ã¿**ã‚’Fine-tuning:

$$
\begin{aligned}
K &= W_{k,0} + \Delta W_k \\
V &= W_{v,0} + \Delta W_v
\end{aligned}
$$

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | DreamBooth | Custom Diffusion | DreamBooth + LoRA |
|:----------|:-----------|:-----------------|:------------------|
| Trainable params | å…¨UNet (1B) | K, V (75M) | LoRA (10M) |
| Training time | 5-10 min | 5 min | 3 min |
| Multi-concept merge | å›°é›£ | å®¹æ˜“ | å®¹æ˜“ |

### 6.5 æ¬¡ä¸–ä»£PEFTæ‰‹æ³• (2024-2026)

#### 6.5.1 DoRA â€” Weight Decomposition LoRA

DoRA [^11] ã¯ã€é‡ã¿ã‚’**magnitude**ã¨**direction**ã«åˆ†è§£:

$$
W = m \frac{V}{\|V\|_c}, \quad V = W_0 + BA
$$

$m$: magnitudeï¼ˆã‚¹ã‚«ãƒ©ãƒ¼ã€trainableï¼‰ã€$V$: direction vectorã€‚

é€šå¸¸ã®LoRAã‚ˆã‚Šæ€§èƒ½å‘ä¸Šï¼ˆ+1-2%ï¼‰ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯ã»ã¼åŒã˜ã€‚

#### 6.5.2 LoRA+ â€” å­¦ç¿’ç‡åˆ†é›¢

LoRA+ [^12] ã¯ã€$A$ ã¨ $B$ ã®å­¦ç¿’ç‡ã‚’åˆ†é›¢:

$$
\begin{aligned}
A &\leftarrow A - \eta_A \nabla_A \mathcal{L} \\
B &\leftarrow B - \eta_B \nabla_B \mathcal{L}, \quad \eta_B = \lambda \eta_A, \, \lambda \gg 1
\end{aligned}
$$

æ¨å¥¨: $\lambda = 16$ï¼ˆ$B$ã®å­¦ç¿’ç‡ã‚’$A$ã®16å€ï¼‰ã€‚åæŸé€Ÿåº¦ãŒ2å€å‘ä¸Šã€‚

**ç†ç”±**: $B$ ã¯å‡ºåŠ›æ¬¡å…ƒã€$A$ ã¯å…¥åŠ›æ¬¡å…ƒã€‚å‡ºåŠ›å´ã®æ›´æ–°ã‚’é€Ÿãã™ã‚‹ã¨ã€ã‚¿ã‚¹ã‚¯é©å¿œãŒåŠ é€Ÿã€‚

#### 6.5.3 VeRA â€” Very-low-rank Adaptation

VeRA [^17] ã¯ã€**$B, A$ ã‚’å…¨å±¤ã§å…±æœ‰**:

$$
\Delta W_i = d_i B_\text{shared} A_\text{shared} b_i
$$

$d_i, b_i$: å±¤ã”ã¨ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆtrainableï¼‰ã€$B_\text{shared}, A_\text{shared}$: å›ºå®šã€‚

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‰Šæ¸›ç‡: LoRAã®**1/10**ã€‚æ€§èƒ½ã¯è‹¥å¹²ä½ä¸‹ï¼ˆ-1-3%ï¼‰ã€‚

### 6.6 PEFTæ‰‹æ³•ã®çµ±ä¸€ç†è«–

å…¨PEFTæ‰‹æ³•ã‚’**éƒ¨åˆ†ç©ºé–“æœ€é©åŒ–**ã¨ã—ã¦çµ±ä¸€çš„ã«æ‰ãˆã‚‹ [^18]:

$$
\theta_\text{ft} = \arg\min_{\theta \in \theta_0 + \mathcal{S}} \mathcal{L}(\theta)
$$

$\mathcal{S}$: è¨±å®¹ã•ã‚Œã‚‹éƒ¨åˆ†ç©ºé–“ã€‚

| æ‰‹æ³• | $\mathcal{S}$ ã®å®šç¾© |
|:-----|:--------------------|
| **LoRA** | $\{BA : B \in \mathbb{R}^{d \times r}, A \in \mathbb{R}^{r \times k}\}$ ï¼ˆä½ãƒ©ãƒ³ã‚¯éƒ¨åˆ†ç©ºé–“ï¼‰ |
| **Adapter** | $\{f_\text{adapter}(\cdot)\}$ ï¼ˆéç·šå½¢å¤‰æ›ã®ç©ºé–“ï¼‰ |
| **Prefix Tuning** | $\{P \oplus \theta_0\}$ ï¼ˆãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹è¿½åŠ ã®ç©ºé–“ï¼‰ |
| **Prompt Tuning** | $\{E_\text{prompt} \oplus E_\text{input}\}$ ï¼ˆåŸ‹ã‚è¾¼ã¿è¿½åŠ ã®ç©ºé–“ï¼‰ |

### 6.7 LoRAã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡

Hu et al. [^1] ã®å®Ÿé¨“ã‹ã‚‰ã€LoRAã®æ€§èƒ½ã¯:

$$
\text{Performance} \propto \log(r)
$$

$r$ã‚’2å€ã«ã—ã¦ã‚‚ã€æ€§èƒ½å‘ä¸Šã¯å¾®å¢—ï¼ˆ+0.5-1%ï¼‰ã€‚$r=8$ã§ååˆ†ãªã“ã¨ãŒå¤šã„ã€‚

**ãƒ¡ãƒ¢ãƒª vs æ€§èƒ½ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•**:

```mermaid
graph LR
    A["r=4<br/>æ€§èƒ½: 95%"] --> B["r=8<br/>æ€§èƒ½: 98%"]
    B --> C["r=16<br/>æ€§èƒ½: 99%"]
    C --> D["r=64<br/>æ€§èƒ½: 99.5%"]
    D --> E["Full FT<br/>æ€§èƒ½: 100%"]

    style A fill:#ffcdd2
    style B fill:#c8e6c9
    style C fill:#fff9c4
    style E fill:#e1bee7
```

### 6.8 æ¨è–¦æ›¸ç± & ãƒªã‚½ãƒ¼ã‚¹

#### æ›¸ç±

| ã‚¿ã‚¤ãƒˆãƒ« | è‘—è€… | å†…å®¹ | URL |
|:---------|:-----|:-----|:----|
| Parameter-Efficient Fine-Tuning (PEFT) | HuggingFace | PEFTãƒ©ã‚¤ãƒ–ãƒ©ãƒªå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ | [github.com/huggingface/peft](https://github.com/huggingface/peft) |
| Efficient Deep Learning | Torsten Hoefler, Dan Alistarh | åŠ¹ç‡çš„DLè¨“ç·´ã®åŒ…æ‹¬çš„æ•™ç§‘æ›¸ | [MIT Press 2023] |

#### ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒªã‚½ãƒ¼ã‚¹

| ãƒªã‚½ãƒ¼ã‚¹ | å†…å®¹ |
|:---------|:-----|
| [LoRAè«–æ–‡è§£èª¬ (HuggingFace Blog)](https://huggingface.co/blog/lora) | LoRAã®å®Ÿè£…ã‚¬ã‚¤ãƒ‰ |
| [QLoRAå®Ÿè£… (GitHub)](https://github.com/artidoro/qlora) | QLoRAã®å…¬å¼å®Ÿè£… |
| [DreamBoothå…¬å¼ã‚µã‚¤ãƒˆ](https://dreambooth.github.io/) | ãƒ‡ãƒ¢ + è«–æ–‡ãƒªãƒ³ã‚¯ |

> **Note:** **é€²æ—: 95% å®Œäº†** æœ€æ–°ç ”ç©¶ï¼ˆDoRA/LoRA+/VeRAï¼‰ã€ç†è«–çš„é™ç•Œï¼ˆIntrinsic Dimensionï¼‰ã€QLoRAæ•°å€¤å®‰å®šæ€§ã€DreamBoothæ‹¡å¼µã‚’å­¦ã‚“ã ã€‚æ¬¡ã¯æŒ¯ã‚Šè¿”ã‚Šã‚¾ãƒ¼ãƒ³ â€” ã¾ã¨ã‚ + FAQ + æ¬¡å›äºˆå‘Šã¸ã€‚

---

### 6.6 æœ¬è¬›ç¾©ã®4ã¤ã®æ ¸å¿ƒ

1. **LoRA = ä½ãƒ©ãƒ³ã‚¯é©å¿œ**: $\Delta W = BA$ã€$r \ll \min(d, k)$ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿10,000å€å‰Šæ¸›ã€æ€§èƒ½â‰ˆFull FT
2. **QLoRA = é‡å­åŒ– + LoRA**: 4-bit NF4 + Double Quant + Paged Optã€‚65Bãƒ¢ãƒ‡ãƒ«ã‚’GPU 1æšã§è¨“ç·´
3. **DreamBooth = Few-shotå€‹äººåŒ–**: Prior Preservation Loss ã§3ç”»åƒã‹ã‚‰ç‰¹å®šè¢«å†™ä½“ã‚’å­¦ç¿’
4. **PEFTçµ±ä¸€ç†è«–**: å…¨æ‰‹æ³•ã¯éƒ¨åˆ†ç©ºé–“æœ€é©åŒ–ã€‚Adapter/Prefix/Prompt/LoRAã‚’çµ±ä¸€çš„ã«ç†è§£

### 6.7 Course I/II/IIIã§ç²å¾—ã—ãŸæ­¦å™¨ã®çµ±åˆ

| æ¦‚å¿µ | åˆå‡º | æœ¬è¬›ç¾©ã§ã®æ´»ç”¨ |
|:-----|:-----|:-------------|
| **SVD (ç‰¹ç•°å€¤åˆ†è§£)** | ç¬¬3å› | LoRAã®ä½ãƒ©ãƒ³ã‚¯è¿‘ä¼¼ã®ç†è«–çš„åŸºç›¤ |
| **MLE (æœ€å°¤æ¨å®š)** | ç¬¬7å› | Fine-tuningã®ç›®çš„é–¢æ•° $\arg\max \mathbb{E}[\log p_\theta(y|x)]$ |
| **KL divergence** | ç¬¬6å› | äº‹å‰å­¦ç¿’åˆ†å¸ƒâ†’ã‚¿ã‚¹ã‚¯åˆ†å¸ƒã¸ã®é©å¿œ |
| **Adam optimizer** | ç¬¬6å› | LoRA/QLoRAã®è¨“ç·´ |
| **Gradient Descent** | ç¬¬6å› | $B, A$ ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–° |

### 6.8 FAQ â€” ã‚ˆãã‚ã‚‹ç–‘å•ã¨èª¤è§£

<details><summary>**Q1: LoRAã¯å…¨ã‚¿ã‚¹ã‚¯ã§æœ‰åŠ¹ã‹ï¼Ÿ**</summary>

**A**: ã»ã¨ã‚“ã©ã®ã‚¿ã‚¹ã‚¯ã§æœ‰åŠ¹ã ãŒã€ä¾‹å¤–ã‚‚ã‚ã‚‹ã€‚**ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚·ãƒ•ãƒˆãŒæ¥µç«¯**ãªå ´åˆï¼ˆä¾‹: è‹±èªâ†’éãƒ­ãƒ¼ãƒå­—è¨€èªï¼‰ã€Full FTã®æ–¹ãŒè‰¯ã„ã“ã¨ãŒã‚ã‚‹ã€‚ä¸€èˆ¬çš„ã«ã¯ã€ã‚¿ã‚¹ã‚¯ãŒäº‹å‰å­¦ç¿’ã«è¿‘ã„ã»ã©LoRAãŒæœ‰åŠ¹ã€‚

</details>

<details><summary>**Q2: $r$ ã¯ã©ã†é¸ã¶ã¹ãã‹ï¼Ÿ**</summary>

**A**: çµŒé¨“å‰‡:
- å°è¦æ¨¡ã‚¿ã‚¹ã‚¯ï¼ˆåˆ†é¡ãªã©ï¼‰: $r=4-8$
- ä¸­è¦æ¨¡ã‚¿ã‚¹ã‚¯ï¼ˆè¦ç´„ã€ç¿»è¨³ï¼‰: $r=8-16$
- å¤§è¦æ¨¡ã‚¿ã‚¹ã‚¯ï¼ˆå¯¾è©±ã€è¤‡é›‘æ¨è«–ï¼‰: $r=16-64$

å®Ÿé¨“çš„ã«è¤‡æ•°ã® $r$ ã‚’è©¦ã—ã€æ€§èƒ½ vs ãƒ¡ãƒ¢ãƒªã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã§é¸ã¶ã€‚

</details>

<details><summary>**Q3: QLoRAã®4-bité‡å­åŒ–ã¯æ¨è«–ã§ã‚‚ä½¿ãˆã‚‹ï¼Ÿ**</summary>

**A**: ä½¿ãˆã‚‹ã€‚ãŸã ã—ã€æ¨è«–æ™‚ã¯ $W_0$ ã‚’4-bitã§ä¿æŒã—ã€on-the-flyã§FP16ã«å±•é–‹ã€‚ãƒ¡ãƒ¢ãƒªã¯å‰Šæ¸›ã•ã‚Œã‚‹ãŒã€å±•é–‹ã‚³ã‚¹ãƒˆã§æ¨è«–é€Ÿåº¦ãŒ5-10%ä½ä¸‹ã™ã‚‹ã€‚

</details>

<details><summary>**Q4: DreamBoothã¨LoRAã‚’çµ„ã¿åˆã‚ã›ã‚‹åˆ©ç‚¹ã¯ï¼Ÿ**</summary>

**A**: 2ã¤:
1. **ãƒ¡ãƒ¢ãƒªå‰Šæ¸›**: Full DreamBoothï¼ˆå…¨UNetæ›´æ–°ï¼‰ã¯æ•°GBãƒ¡ãƒ¢ãƒªã€‚LoRAãªã‚‰æ•°ç™¾MBã€‚
2. **Multi-concept merge**: è¤‡æ•°è¢«å†™ä½“ã® $(B, A)$ ãƒšã‚¢ã‚’ä¿æŒã—ã€æ¨è«–æ™‚ã«åˆæˆå¯èƒ½ï¼ˆä¾‹: ã€Œã‚ãªãŸã®çŠ¬ã€+ ã€Œã‚ãªãŸã®çŒ«ã€ã‚’åŒã˜ç”»åƒã«ï¼‰ã€‚

</details>

<details><summary>**Q5: Adapter vs LoRAã€ã©ã¡ã‚‰ã‚’é¸ã¶ã¹ãã‹ï¼Ÿ**</summary>

**A**:
- **LoRA**: æ¨è«–é€Ÿåº¦é‡è¦–ï¼ˆãƒãƒ¼ã‚¸å¯èƒ½ï¼‰ã€Multi-taskï¼ˆè¤‡æ•°Adapteråˆ‡ã‚Šæ›¿ãˆï¼‰
- **Adapter**: éç·šå½¢å¤‰æ›ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ï¼ˆLoRAã¯ç·šå½¢ã®ã¿ï¼‰

å®Ÿç”¨ä¸Šã€LoRAã®æ–¹ãŒåºƒãä½¿ã‚ã‚Œã¦ã„ã‚‹ï¼ˆHuggingFace PEFTãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ã€‚

</details>

### 6.9 å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆ1é€±é–“ãƒ—ãƒ©ãƒ³ï¼‰

| æ—¥ | å†…å®¹ | æ™‚é–“ | é”æˆç›®æ¨™ |
|:---|:-----|:-----|:---------|
| **Day 1** | Zone 0-2ï¼ˆæ¦‚è¦³ãƒ»ç›´æ„Ÿï¼‰ | 30åˆ† | Fine-tuningã®å¿…è¦æ€§ã‚’ç†è§£ |
| **Day 2** | Zone 3å‰åŠï¼ˆLoRAç†è«–ï¼‰ | 60åˆ† | $\Delta W = BA$ ã‚’å°å‡ºã§ãã‚‹ |
| **Day 3** | Zone 3å¾ŒåŠï¼ˆQLoRA, DreamBoothï¼‰ | 60åˆ† | NF4é‡å­åŒ–ã®åŸç†ã‚’èª¬æ˜ã§ãã‚‹ |
| **Day 4** | Zone 4ï¼ˆâš¡Juliaå®Ÿè£…ï¼‰ | 60åˆ† | LoRAå±¤ã‚’å®Ÿè£…ã§ãã‚‹ |
| **Day 5** | Zone 4ï¼ˆğŸ¦€Rustæ¨è«–ï¼‰ | 45åˆ† | LoRAãƒãƒ¼ã‚¸ã¨åˆ‡ã‚Šæ›¿ãˆã‚’å®Ÿè£…ã§ãã‚‹ |
| **Day 6** | Zone 5ï¼ˆSmolVLM2å®Ÿé¨“ï¼‰ | 45åˆ† | å®Ÿãƒ‡ãƒ¼ã‚¿ã§LoRA Fine-tuning |
| **Day 7** | Zone 6-7ï¼ˆç™ºå±•ãƒ»å¾©ç¿’ï¼‰ | 40åˆ† | DoRA/LoRA+ã‚’ç†è§£ã€å…¨ä½“å¾©ç¿’ |

**åˆè¨ˆ**: ç´„5.5æ™‚é–“

### 6.10 åˆ°é”åº¦ãƒã‚§ãƒƒã‚¯

æœ¬è¬›ç¾©ä¿®äº†æ™‚ã€ä»¥ä¸‹ãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹:

- [ ] LoRAã®æ•°å¼ $h = W_0 x + \frac{\alpha}{r} BA x$ ã‚’å®Œå…¨ã«å°å‡ºã§ãã‚‹
- [ ] QLoRAã®3ã¤ã®é©æ–°ã‚’èª¬æ˜ã§ãã‚‹
- [ ] DreamBoothã®Prior Preservation Lossã‚’å¼ã§æ›¸ã‘ã‚‹
- [ ] Julia ã§LoRAå±¤ã‚’å®Ÿè£…ã§ãã‚‹
- [ ] Rust ã§LoRAãƒãƒ¼ã‚¸ãƒ»Multi-taskåˆ‡ã‚Šæ›¿ãˆã‚’å®Ÿè£…ã§ãã‚‹
- [ ] SmolVLM2ã‚’LoRAã§Fine-tuningã§ãã‚‹
- [ ] Adapter/Prefix/Prompt Tuningã®é•ã„ã‚’èª¬æ˜ã§ãã‚‹
- [ ] PEFTæ‰‹æ³•ã‚’éƒ¨åˆ†ç©ºé–“æœ€é©åŒ–ã¨ã—ã¦çµ±ä¸€çš„ã«ç†è§£ã§ãã‚‹

### 6.6 æ¬¡å›äºˆå‘Š â€” ç¬¬24å›: çµ±è¨ˆå­¦

ç¬¬23å›ã§Fine-tuningã®å®Ÿè£…ã‚’å®Œäº†ã—ãŸã€‚ã ãŒã€Œãƒ¢ãƒ‡ãƒ«ãŒæ”¹å–„ã—ãŸã€ã‚’ã©ã†**å®šé‡è©•ä¾¡**ã™ã‚‹ã‹ï¼Ÿ

ç¬¬24å›ã§ã¯ã€**çµ±è¨ˆå­¦**ã‚’å¾¹åº•çš„ã«å­¦ã¶:

- **è¨˜è¿°çµ±è¨ˆ**: å¹³å‡ãƒ»åˆ†æ•£ãƒ»ç›¸é–¢ â€” ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„
- **æ¨æ¸¬çµ±è¨ˆ**: ä¿¡é ¼åŒºé–“ãƒ»ä»®èª¬æ¤œå®š â€” æœ‰æ„å·®ã®åˆ¤å®š
- **ãƒ™ã‚¤ã‚ºçµ±è¨ˆ**: äº‹å¾Œåˆ†å¸ƒãƒ»MCMC â€” ä¸ç¢ºå®Ÿæ€§ã®å®šé‡åŒ–
- **å®Ÿé¨“è¨ˆç”»æ³•**: A/Bãƒ†ã‚¹ãƒˆãƒ»å¤šé‡æ¯”è¼ƒè£œæ­£ â€” æ­£ã—ã„å®Ÿé¨“è¨­è¨ˆ
- **å› æœæ¨è«–å…¥é–€**: RCTãƒ»å‚¾å‘ã‚¹ã‚³ã‚¢ â€” å› æœé–¢ä¿‚ã®æ¨å®š

**Course III ã®æµã‚Œ**:

| ç¬¬17-22å› | ç¬¬23å› | **ç¬¬24å›** | ç¬¬25-32å› |
|:----------|:-------|:----------|:----------|
| ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆ | Fine-tuning | **è©•ä¾¡ã®æ•°å­¦** | æ¨è«–æœ€é©åŒ–ãƒ»MLOps |

ç¬¬24å›ã§çµ±è¨ˆçš„è©•ä¾¡ã®åŸºç›¤ã‚’å›ºã‚ã€ç¬¬25å›ä»¥é™ã§Productionå±•é–‹ã¸é€²ã‚€ã€‚

### 6.11 ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„

> **å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ã¯æœ¬å½“ã«å¿…è¦ã‹ï¼Ÿ ãã‚Œã¨ã‚‚ã€æˆ‘ã€…ã¯ã€Œæœ€é©åŒ–ã™ã¹ãéƒ¨åˆ†ç©ºé–“ã€ã‚’è¦‹èª¤ã£ã¦ã„ãŸã®ã‹ï¼Ÿ**

å¾“æ¥ã®æ©Ÿæ¢°å­¦ç¿’ã§ã¯ã€ã€Œãƒ¢ãƒ‡ãƒ«ãŒå¤§ãã„ã»ã©è‰¯ã„ã€ã€Œå…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨“ç·´ã™ã¹ãã€ãŒå¸¸è­˜ã ã£ãŸã€‚

ã ãŒã€LoRAã¯**å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®0.01%**ã§ã€Full Fine-tuningã¨åŒç­‰æ€§èƒ½ã‚’é”æˆã—ãŸã€‚QLoRAã¯65Bãƒ¢ãƒ‡ãƒ«ã‚’GPU 1æšã§è¨“ç·´å¯èƒ½ã«ã—ãŸã€‚ã“ã‚Œã¯ä½•ã‚’æ„å‘³ã™ã‚‹ã‹ï¼Ÿ

### å•ã„ã®æ·±å±¤

1. **éå‰°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã®å†è§£é‡ˆ**: å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã¯å†—é•·ã€‚å®ŸåŠ¹çš„ãªè‡ªç”±åº¦ï¼ˆintrinsic dimensionï¼‰ã¯æ¥µã‚ã¦ä½ã„ã€‚ãªã‚‰ã°ã€ã€Œå¤§è¦æ¨¡åŒ–ã€ã§ã¯ãªãã€ŒåŠ¹ç‡çš„éƒ¨åˆ†ç©ºé–“ã®ç™ºè¦‹ã€ã“ããŒæœ¬è³ªã§ã¯ï¼Ÿ

2. **è»¢ç§»å­¦ç¿’ã®æœ¬è³ª**: äº‹å‰å­¦ç¿’ã¯ã€Œæ±ç”¨è¡¨ç¾ã®ç²å¾—ã€ã€Fine-tuningã¯ã€Œã‚¿ã‚¹ã‚¯ç‰¹åŒ–ã®å¾®èª¿æ•´ã€ã€‚LoRAã¯ã€ã“ã®å¾®èª¿æ•´ãŒ**ä½æ¬¡å…ƒã§å®Œçµ**ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã“ã‚Œã¯ã€äººé–“ã®å­¦ç¿’ï¼ˆå°‚é–€çŸ¥è­˜ã¯æ—¢å­˜çŸ¥è­˜ã¸ã®"ã¡ã‚‡ã£ã¨ã—ãŸè¿½åŠ "ï¼‰ã¨åŒã˜æ§‹é€ ã§ã¯ï¼Ÿ

3. **è¨ˆç®—è³‡æºã®æ°‘ä¸»åŒ–**: Full FTã¯å¯Œè±ªã®ç‰¹æ¨©ã ã£ãŸã€‚PEFTã¯ã€èª°ã§ã‚‚å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’é©å¿œå¯èƒ½ã«ã—ãŸã€‚ã“ã‚Œã¯ã€ŒAIç ”ç©¶ã®æ°‘ä¸»åŒ–ã€ã®å§‹ã¾ã‚Šã‹ï¼Ÿ

### æ¬¡ã®å•ã„

- LoRAã® $r$ ã¯æœ¬å½“ã«æœ€é©ã‹ï¼Ÿ ã‚ˆã‚Šè‰¯ã„éƒ¨åˆ†ç©ºé–“ã®é¸ã³æ–¹ã¯ï¼Ÿ
- QLoRAã®4-bitã¯ã¾ã ç²—ã„ã€‚1-bitï¼ˆQuantization Aware Trainingï¼‰ã¯å¯èƒ½ã‹ï¼Ÿ
- è¤‡æ•°ã‚¿ã‚¹ã‚¯ã®LoRAã‚’**è‡ªå‹•åˆæˆ**ã§ãã‚‹ã‹ï¼Ÿï¼ˆMulti-task LoRAã®å‹•çš„æœ€é©åŒ–ï¼‰

**æ­´å²ã¯ç¹°ã‚Šè¿”ã™**: SVDï¼ˆç¬¬3å›ï¼‰ã¯ã€Œå…¨æƒ…å ±ã‚’ä¿æŒã—ã¤ã¤æ¬¡å…ƒå‰Šæ¸›ã€ã‚’å¯èƒ½ã«ã—ãŸã€‚LoRAã¯ãã®å¿œç”¨ã«éããªã„ã€‚ã ãŒã€ã“ã®å˜ç´”ãªå¿œç”¨ãŒã€AIã®æ°‘ä¸»åŒ–ã‚’åŠ é€Ÿã—ã¦ã„ã‚‹ã€‚

### 7. PEFTæœ€æ–°å‹•å‘ï¼ˆ2024-2026ï¼‰

#### 7.1 Do RA: Weight-Decomposed Low-Rank Adaptation

DoRA [^20] (Liu et al., 2024) ã¯ã€LoRAã®é€²åŒ–ç‰ˆã€‚é‡ã¿æ›´æ–°ã‚’**å¤§ãã• (magnitude)** ã¨**æ–¹å‘ (direction)** ã«åˆ†è§£ã™ã‚‹ã€‚

**ã‚¢ã‚¤ãƒ‡ã‚¢**: Full Fine-tuningã¯ã€é‡ã¿ã®å¤§ãã•ã¨æ–¹å‘ã®ä¸¡æ–¹ã‚’æ›´æ–°ã™ã‚‹ã€‚LoRAã¯æ–¹å‘ã®ã¿æ›´æ–°ã—ã€å¤§ãã•ã¯å›ºå®šã€‚DoRAã¯ä¸¡æ–¹ã‚’æ›´æ–°ã™ã‚‹ã€‚

**æ•°å¼**:

é‡ã¿è¡Œåˆ— $\mathbf{W}$ ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«åˆ†è§£:

$$
\mathbf{W} = m \cdot \frac{\mathbf{V}}{\|\mathbf{V}\|_c}
$$

ã“ã“ã§:
- $m \in \mathbb{R}^d$: åˆ—ã”ã¨ã®å¤§ãã• (magnitude vector)
- $\mathbf{V} \in \mathbb{R}^{d \times k}$: æ–¹å‘è¡Œåˆ—
- $\|\mathbf{V}\|_c$: åˆ—ã”ã¨ã®â„“2ãƒãƒ«ãƒ 

**DoRAæ›´æ–°**:

$$
\mathbf{W}' = m \cdot \frac{\mathbf{W}_0 + \mathbf{B}\mathbf{A}}{\|\mathbf{W}_0 + \mathbf{B}\mathbf{A}\|_c}
$$

ã“ã“ã§ $\mathbf{B}\mathbf{A}$ ã¯LoRAã¨åŒã˜ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ã€‚

**LoRAã¨ã®é•ã„**:

| æ‰‹æ³• | å¤§ãã• $m$ | æ–¹å‘ $\mathbf{V}$ | æ›´æ–°å¯¾è±¡ |
|:-----|:----------|:--------------|:--------|
| **LoRA** | å›ºå®š | æ›´æ–°ï¼ˆ$\mathbf{W}_0 + \mathbf{B}\mathbf{A}$ï¼‰ | æ–¹å‘ã®ã¿ |
| **DoRA** | æ›´æ–° | æ›´æ–°ï¼ˆæ­£è¦åŒ–å¾Œï¼‰ | å¤§ãã•+æ–¹å‘ |

**ç‰¹ç•°å€¤ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã®æ”¹å–„**:

DoRAã¯ã€é‡ã¿æ›´æ–°è¡Œåˆ—ã®**ç‰¹ç•°å€¤ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼**ã‚’å¢—åŠ ã•ã›ã‚‹:

$$
H(\boldsymbol{\sigma}) = -\sum_{i=1}^r \frac{\sigma_i}{\sum_j \sigma_j} \log \frac{\sigma_i}{\sum_j \sigma_j}
$$

ã“ã“ã§ $\boldsymbol{\sigma} = (\sigma_1, \ldots, \sigma_r)$ ã¯ç‰¹ç•°å€¤ã€‚

ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒé«˜ã„ = æ›´æ–°ãŒ**å‡ä¸€ã«åˆ†æ•£** = Full FTã«è¿‘ã„ã€‚

**å®Ÿé¨“çµæœ** (Liu et al., 2024 [^20]):

| ã‚¿ã‚¹ã‚¯ | LoRA | DoRA | Full FT | DoRAæ”¹å–„ç‡ |
|:-------|:-----|:-----|:--------|:----------|
| CommonsenseQA | 76.2% | 78.9% | 79.3% | +2.7% |
| MMLU | 52.3% | 54.8% | 55.1% | +2.5% |
| GSM8K | 41.2% | 45.7% | 46.3% | +4.5% |

DoRAã¯ã€LoRAã‚’å…¨ã‚¿ã‚¹ã‚¯ã§ä¸Šå›ã‚Šã€Full FTã«æœ€ã‚‚è¿‘ã„æ€§èƒ½ã‚’é”æˆã€‚

#### 7.2 QLoRA: 4-bité‡å­åŒ–ã¨ã®çµ±åˆ

QLoRA [^21] (Dettmers et al., 2023) ã¯ã€**4-bité‡å­åŒ–**ã¨LoRAã‚’çµ„ã¿åˆã‚ã›ã‚‹ã€‚

**3ã¤ã®é©æ–°**:

1. **4-bit NormalFloat (NF4)**:

   é€šå¸¸ã®å‡ä¸€é‡å­åŒ–ã§ã¯ãªãã€æ­£è¦åˆ†å¸ƒã«æœ€é©åŒ–ã—ãŸé‡å­åŒ–:

   $$
   \text{NF4} = \{-1, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911, 0, 0.0796, 0.1609, 0.2461, 0.3379, 0.4407, 0.5626, 0.7230, 1.0\}
   $$

   æ­£è¦åˆ†å¸ƒ $\mathcal{N}(0,1)$ ã‹ã‚‰å‡ç­‰ã«ã‚µãƒ³ãƒ—ãƒ«ã—ãŸ16å€‹ã®å€¤ã€‚

2. **Double Quantization**:

   é‡å­åŒ–å®šæ•°è‡ªä½“ã‚‚é‡å­åŒ–:

   $$
   \mathbf{W}_{\text{quantized}} = \text{Q}_1(\mathbf{W} / c_1), \quad c_1 = \text{Q}_2(c_0)
   $$

   ãƒ¡ãƒ¢ãƒªå‰Šæ¸›: 0.37 bits/parameter â†’ å¹³å‡8GBã‹ã‚‰0.3GBå‰Šæ¸›ï¼ˆ65Bãƒ¢ãƒ‡ãƒ«ï¼‰ã€‚

3. **Paged Optimizers**:

   GPU RAMã‚¹ãƒ‘ã‚¤ã‚¯æ™‚ã«CPU RAMã¸ãƒšãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆOSã®virtual memoryã¨åŒã˜ï¼‰ã€‚

**ãƒ¡ãƒ¢ãƒªæ¯”è¼ƒ**ï¼ˆLLaMA-65Bï¼‰:

| æ‰‹æ³• | ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ | GPUè¦ä»¶ | æ€§èƒ½åŠ£åŒ– |
|:-----|:-----------|:--------|:--------|
| Full FT (16-bit) | 780 GB | 10x A100 80GB | - |
| LoRA (16-bit) | 80 GB | 1x A100 80GB | 0.2% |
| QLoRA (4-bit) | **48 GB** | **1x A100 48GB** | 0.3% |

QLoRAã¯ã€Full FTã®**1/16ã®ãƒ¡ãƒ¢ãƒª**ã§ã€æ€§èƒ½åŠ£åŒ–0.3%ã€‚

**Juliaå®Ÿè£…ä¾‹**:

```julia
# NF4é‡å­åŒ–é–¢æ•°
const NF4_VALUES = Float32[
    -1.0, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911, 0.0,
    0.0796, 0.1609, 0.2461, 0.3379, 0.4407, 0.5626, 0.7230, 1.0
]

function quantize_nf4(W::Matrix{Float32})
    absmax = maximum(abs.(W))
    W_norm = W ./ absmax
    # Map each element to nearest NF4 index
    W_quant_idx = [argmin(abs.(w .- NF4_VALUES)) for w in W_norm]
    return W_quant_idx, absmax
end

# Short-form dequantize: map indices back to FP32 and reshape
dequantize_nf4(W_quant_idx, absmax) =
    reshape([NF4_VALUES[idx] * absmax for idx in W_quant_idx], size(W_quant_idx))
```

#### 7.3 Pre-Diag & SORA: é‡ã¿æ¡ä»¶ä»˜ã‘ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

æœ€æ–°ã®PEFTç ”ç©¶ [^22] ã¯ã€LoRAæ›´æ–°å‰ã«é‡ã¿ã‚’**æ¡ä»¶ä»˜ã‘ (conditioning)** ã™ã‚‹ã€‚

**Pre-Diag** (2024):

å¯¾è§’è¡Œåˆ— $\mathbf{D}$ ã§äº‹å‰å­¦ç¿’é‡ã¿ã‚’ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³:

$$
\mathbf{W}' = \mathbf{D} \mathbf{W}_0 + \mathbf{B}\mathbf{A}
$$

ã“ã“ã§ $\mathbf{D} = \text{diag}(d_1, \ldots, d_d)$ ã¯å­¦ç¿’å¯èƒ½ã€‚

**SORA** (Scaling and Orthogonal Rotation Adaptation):

ç›´äº¤å›è»¢ $\mathbf{R}$ ã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚° $s$:

$$
\mathbf{W}' = s \cdot \mathbf{R} \mathbf{W}_0 + \mathbf{B}\mathbf{A}
$$

ã“ã“ã§ $\mathbf{R}^\top \mathbf{R} = \mathbf{I}$ï¼ˆç›´äº¤åˆ¶ç´„ï¼‰ã€‚

**åŠ¹æœ**: äº‹å‰å­¦ç¿’é‡ã¿ã®**æ–¹å‘**ã‚’ä¿ã¡ã¤ã¤ã€å¤§ãã•ã‚’èª¿æ•´ â†’ Full FTã«è¿‘ã„æŸ”è»Ÿæ€§ã€‚

#### 7.4 LoRAFusion: è¤‡æ•°LoRAã®åŠ¹ç‡çš„çµ±åˆ

LoRAFusion [^23] (2024) ã¯ã€è¤‡æ•°ã‚¿ã‚¹ã‚¯ç”¨ã®LoRAã‚’åŠ¹ç‡çš„ã«çµ±åˆã™ã‚‹ã€‚

**å•é¡Œ**: ã‚¿ã‚¹ã‚¯Aã®LoRA ($\mathbf{B}_A\mathbf{A}_A$) ã¨ã‚¿ã‚¹ã‚¯Bã®LoRA ($\mathbf{B}_B\mathbf{A}_B$) ã‚’åŒæ™‚ã«ä½¿ã„ãŸã„ã€‚

**ãƒŠã‚¤ãƒ¼ãƒ–ãªæ–¹æ³•**:

$$
\mathbf{W}' = \mathbf{W}_0 + \mathbf{B}_A\mathbf{A}_A + \mathbf{B}_B\mathbf{A}_B
$$

å•é¡Œ: æ¨è«–æ™‚ã«ä¸¡æ–¹ã‚’ä¿æŒ â†’ ãƒ¡ãƒ¢ãƒª2å€ã€‚

**LoRAFusion**: ä½ãƒ©ãƒ³ã‚¯è¿‘ä¼¼ã§èåˆ:

$$
\mathbf{B}_A\mathbf{A}_A + \mathbf{B}_B\mathbf{A}_B \approx \mathbf{B}_{\text{fused}} \mathbf{A}_{\text{fused}}
$$

SVDã§ $(r_A + r_B)$-rankè¡Œåˆ—ã‚’$r_{\text{fused}}$-rankã«åœ§ç¸®ï¼ˆ$r_{\text{fused}} < r_A + r_B$ï¼‰ã€‚

**ãƒ¡ãƒ¢ãƒªå‰Šæ¸›**: $(r_A + r_B) \times (d + k) \to r_{\text{fused}} \times (d + k)$

å…¸å‹ä¾‹: $r_A = r_B = 8, r_{\text{fused}} = 12$ â†’ ãƒ¡ãƒ¢ãƒª25%å‰Šæ¸›ã€æ€§èƒ½åŠ£åŒ–1%æœªæº€ã€‚

#### 7.5 PEFTæ‰‹æ³•ã®çµ±åˆæ¯”è¼ƒï¼ˆ2024-2026ï¼‰

| æ‰‹æ³• | è¨“ç·´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ãƒ¡ãƒ¢ãƒªå‰Šæ¸› | æ€§èƒ½ | ç”¨é€” |
|:-----|:-------------|:----------|:-----|:-----|
| **Full FT** | 100% | - | 100% | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ |
| **LoRA** | 0.1-1% | 90% | 98-99% | æ±ç”¨ |
| **DoRA** | 0.1-1% + magnitude | 88% | 99-99.5% | é«˜æ€§èƒ½è¦æ±‚ |
| **QLoRA** | 0.1-1% | 93% | 97-98% | ãƒ¡ãƒ¢ãƒªåˆ¶ç´„ |
| **Pre-Diag** | 0.2-1.5% | 85% | 99% | ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é‡è¦– |
| **LoRAFusion** | 0.15-1.2% | 92% | 98-99% | ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ |

**2024-2026ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹**:

```julia
# Recommended PEFT configuration (2024)
peft_config = (
    method = "DoRA",              # Best performance
    rank = 16,                    # Sweet spot for most tasks
    alpha = 32,                   # Î± = 2r is standard
    quantization = "NF4",         # If memory-constrained
    target_modules = ["q_proj", "v_proj", "k_proj", "o_proj"],  # Attention only
    use_gradient_checkpointing = true,  # 40% memory reduction
)
```

**çµè«–**: DoRAãŒ2024å¹´ã®SOTAã€QLoRAã¯ãƒ¡ãƒ¢ãƒªåˆ¶ç´„æ™‚ã®æœ€é©è§£ã€LoRAFusionã¯ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ã®æ¨™æº–ã€‚

> **Note:** **é€²æ—: 100% å®Œäº†** ğŸ‰ è¬›ç¾©å®Œèµ°ï¼æœ€æ–°PEFTæ‰‹æ³•ï¼ˆDoRA, QLoRA, LoRAFusionï¼‰ã¾ã§ç¶²ç¾…ã—ãŸã€‚

> **Progress: 95%**
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. DoRAï¼ˆWeight-Decomposed LoRAï¼‰ãŒLoRAã¨ç•°ãªã‚‹ã®ã¯ä½•ã‚’åˆ†è§£ã™ã‚‹ã‹ã‚‰ã‹ï¼Ÿãã®åˆ©ç‚¹ã¯ï¼Ÿ
> 2. LoRA+ã§Aã¨Bã«ç•°ãªã‚‹å­¦ç¿’ç‡ã‚’è¨­å®šã™ã‚‹ç†è«–çš„æ ¹æ‹ ã¯ä½•ã‹ï¼Ÿ

---

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., & Chen, W. (2022). **LoRA: Low-Rank Adaptation of Large Language Models**. *ICLR 2022*. <https://arxiv.org/abs/2106.09685>

[^2]: Dettmers, T., Pagnoni, A., Holtzman, A., & Zettlemoyer, L. (2023). **QLoRA: Efficient Finetuning of Quantized LLMs**. *NeurIPS 2023*. <https://arxiv.org/abs/2305.14314>

[^3]: Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A. A., ... & Hadsell, R. (2017). **Overcoming catastrophic forgetting in neural networks**. *PNAS*, 114(13), 3521-3526. <https://www.pnas.org/doi/10.1073/pnas.1611835114>

[^4]: Ruiz, N., Li, Y., Jampani, V., Pritch, Y., Rubinstein, M., & Aberman, K. (2023). **DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation**. *CVPR 2023*. <https://arxiv.org/abs/2208.12242>

[^5]: Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Gesmundo, A., Attariyan, M., & Gelly, S. (2019). **Parameter-Efficient Transfer Learning for NLP**. *ICML 2019*. <https://arxiv.org/abs/1902.00751>

[^6]: Li, X. L., & Liang, P. (2021). **Prefix-Tuning: Optimizing Continuous Prompts for Generation**. *ACL 2021*. <https://arxiv.org/abs/2101.00190>

[^7]: Liu, X., Ji, K., Fu, Y., Tam, W. L., Du, Z., Yang, Z., & Tang, J. (2022). **P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks**. *ACL 2022*. <https://arxiv.org/abs/2110.07602>

[^8]: Lester, B., Al-Rfou, R., & Constant, N. (2021). **The Power of Scale for Parameter-Efficient Prompt Tuning**. *EMNLP 2021*. <https://arxiv.org/abs/2104.08691>

[^9]: Lux.jl: Explicit Parameterization for Neural Networks in Julia. <https://github.com/LuxDL/Lux.jl>

[^10]: Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., ... & Lowe, R. (2022). **Training language models to follow instructions with human feedback**. *NeurIPS 2022*. <https://arxiv.org/abs/2203.02155>

[^11]: Liu, S., Zhang, Y., Qiu, L., Xiao, C., Zhao, H., Jia, Y., ... & Zhang, Y. (2024). **DoRA: Weight-Decomposed Low-Rank Adaptation**. *arXiv preprint*. <https://arxiv.org/abs/2402.09353>

[^12]: Hayou, S., Ghosh, N., & Yu, B. (2024). **LoRA+: Efficient Low Rank Adaptation of Large Models**. *ICML 2024 Workshop*. <https://arxiv.org/abs/2402.12354>

[^13]: Aghajanyan, A., Gupta, S., & Zettlemoyer, L. (2020). **Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning**. *ACL 2021*. <https://arxiv.org/abs/2012.13255>

[^14]: Lloyd, S. (1982). **Least squares quantization in PCM**. *IEEE Transactions on Information Theory*, 28(2), 129-137.

[^15]: Gal, R., Alaluf, Y., Atzmon, Y., Patashnik, O., Bermano, A. H., Chechik, G., & Cohen-Or, D. (2022). **An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion**. *ICLR 2023*. <https://arxiv.org/abs/2208.01618>

[^16]: Kumari, N., Zhang, B., Zhang, R., Shechtman, E., & Zhu, J. Y. (2023). **Multi-Concept Customization of Text-to-Image Diffusion**. *CVPR 2023*. <https://arxiv.org/abs/2212.04488>

[^17]: Kopiczko, D. J., Blankevoort, T., & Asano, Y. M. (2024). **VeRA: Vector-based Random Matrix Adaptation**. *ICLR 2024*. <https://arxiv.org/abs/2310.11454>

[^18]: He, J., Zhou, C., Ma, X., Berg-Kirkpatrick, T., & Neubig, G. (2022). **Towards a Unified View of Parameter-Efficient Transfer Learning**. *ICLR 2022*. <https://arxiv.org/abs/2110.04366>

[^19]: Han, Z., et al. (2024). **Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey**. *arXiv preprint*. <https://arxiv.org/abs/2403.14608>

[^20]: Liu, S., et al. (2024). **DoRA: Weight-Decomposed Low-Rank Adaptation**. *arXiv preprint*. <https://arxiv.org/abs/2402.09353>

[^21]: Dettmers, T., et al. (2023). **QLoRA: Efficient Finetuning of Quantized LLMs**. *NeurIPS 2023*. <https://arxiv.org/abs/2305.14314>

[^22]: Wei, H., et al. (2024). **Calibrating and Rotating: A Unified Framework for Weight Conditioning in PEFT**. *arXiv preprint*. <https://arxiv.org/abs/2511.00051>

[^23]: Zhu, Z., Su, Q., Ding, Y., Song, K., et al. (2025). **LoRAFusion: Efficient LoRA Fine-Tuning for LLMs**. *EuroSys 2026*. <https://arxiv.org/abs/2510.00206>

### æ•™ç§‘æ›¸

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press. [deeplearningbook.org](http://www.deeplearningbook.org/)
- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2022). *Probabilistic Machine Learning: An Introduction*. MIT Press. [probml.github.io](https://probml.github.io/pml-book/book1.html)

---

## è‘—è€…ãƒªãƒ³ã‚¯

- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

**Co-Authored-By**: Claude Opus 4.6 <noreply@anthropic.com>
