---
title: "ç¬¬31å›: MLOpså®Œå…¨ç‰ˆã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨: Julia/Rust/Elixirå®Ÿè£…â†’ãƒã‚¹ã‚¿ãƒ¼""
emoji: "ğŸ”„"
type: "tech"
topics: ["machinelearning", "mlops", "rust", "julia", "elixir"]
published: true
slug: "ml-lecture-31-part2"
---
## ğŸ’» 4. å®Ÿè£…ã‚¾ãƒ¼ãƒ³ï¼ˆ60åˆ†ï¼‰â€” âš¡Juliaå®Ÿé¨“ç®¡ç† + ğŸ¦€Rust MLOpsãƒ„ãƒ¼ãƒ« + ğŸ”®Elixirç›£è¦–

### Part F: å®Ÿè£…ç·¨

#### 4.1 âš¡ Juliaå®Ÿé¨“ç®¡ç† â€” MLflowçµ±åˆ

Juliaã§å®Ÿé¨“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’å®Ÿè£…ã™ã‚‹ã€‚`MLFlowClient.jl`ã‚’ä½¿ã£ã¦MLflow APIã¨é€šä¿¡ã€‚

```julia
using HTTP, JSON3, Dates

# MLflow tracking server URL
const MLFLOW_URI = "http://localhost:5000"

"""
Log parameters to MLflow
"""
function log_params(run_id::String, params::Dict{String, Any})
    url = "$MLFLOW_URI/api/2.0/mlflow/runs/log-parameter"

    for (key, value) in params
        body = JSON3.write(Dict(
            "run_id" => run_id,
            "key" => key,
            "value" => string(value)
        ))

        HTTP.post(url, ["Content-Type" => "application/json"], body)
    end
end

"""
Log metrics to MLflow with step
"""
function log_metrics(run_id::String, metrics::Dict{String, Float64}, step::Int)
    url = "$MLFLOW_URI/api/2.0/mlflow/runs/log-metric"

    for (key, value) in metrics
        body = JSON3.write(Dict(
            "run_id" => run_id,
            "key" => key,
            "value" => value,
            "timestamp" => round(Int, datetime2unix(now()) * 1000),
            "step" => step
        ))

        HTTP.post(url, ["Content-Type" => "application/json"], body)
    end
end

"""
Create MLflow run
"""
function create_run(experiment_id::String, run_name::String)
    url = "$MLFLOW_URI/api/2.0/mlflow/runs/create"

    body = JSON3.write(Dict(
        "experiment_id" => experiment_id,
        "run_name" => run_name,
        "start_time" => round(Int, datetime2unix(now()) * 1000)
    ))

    response = HTTP.post(url, ["Content-Type" => "application/json"], body)
    result = JSON3.read(String(response.body))

    return result["run"]["info"]["run_id"]
end

"""
Complete MLflow run
"""
function end_run(run_id::String, status::String="FINISHED")
    url = "$MLFLOW_URI/api/2.0/mlflow/runs/update"

    body = JSON3.write(Dict(
        "run_id" => run_id,
        "status" => status,
        "end_time" => round(Int, datetime2unix(now()) * 1000)
    ))

    HTTP.post(url, ["Content-Type" => "application/json"], body)
end

# Example: Track a training run
function train_and_log()
    # Create run
    experiment_id = "0"  # Default experiment
    run_id = create_run(experiment_id, "julia-training-run")

    # Log hyperparameters
    params = Dict(
        "learning_rate" => 0.001,
        "batch_size" => 32,
        "epochs" => 10,
        "optimizer" => "Adam"
    )
    log_params(run_id, params)

    # Simulate training loop
    for epoch in 1:10
        train_loss = 1.0 / (1 + epoch * 0.1)  # Decreasing loss
        val_acc = 0.8 + epoch * 0.02  # Increasing accuracy

        # Log metrics with step
        metrics = Dict(
            "train_loss" => train_loss,
            "val_acc" => val_acc
        )
        log_metrics(run_id, metrics, epoch)

        println("Epoch $epoch: loss=$train_loss, acc=$val_acc")
    end

    # End run
    end_run(run_id)
    println("âœ… Run completed: $run_id")

    return run_id
end

# Run experiment
run_id = train_and_log()
```

å‡ºåŠ›:
```
Epoch 1: loss=0.9090909090909091, acc=0.82
Epoch 2: loss=0.8333333333333334, acc=0.84
...
Epoch 10: loss=0.5, acc=1.0
âœ… Run completed: a3f9c2e1b4d87f3a9c2e1b4d87f3a9c2
```

**MLflow UI** (`mlflow ui`) ã§å¯è¦–åŒ–:

- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒ
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•
- Runé–“ã®æ¯”è¼ƒ

**Juliaã®åˆ©ç‚¹**:

- è¨“ç·´ãƒ«ãƒ¼ãƒ—ãŒé«˜é€Ÿ (C/Fortranãƒ¬ãƒ™ãƒ«)
- MLflow APIã¯å˜ãªã‚‹HTTP POST (è¨€èªéä¾å­˜)
- å¤šé‡ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒã§å‹ã«å¿œã˜ãŸæœ€é©åŒ–

#### 4.2 ğŸ¦€ Rust MLOpsãƒ„ãƒ¼ãƒ« â€” ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚° & ãƒ¡ãƒˆãƒªã‚¯ã‚¹

Rustã§é«˜é€ŸãªMLOpsãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’æ§‹ç¯‰ã€‚

##### 4.2.1 ãƒ¢ãƒ‡ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®— (SHA-256)

```rust
use sha2::{Sha256, Digest};
use std::fs::File;
use std::io::Read;

/// Calculate SHA-256 hash of model file
pub fn hash_model_file(path: &str) -> Result<String, std::io::Error> {
    let mut file = File::open(path)?;
    let mut hasher = Sha256::new();
    let mut buffer = [0u8; 8192];

    loop {
        let n = file.read(&mut buffer)?;
        if n == 0 { break; }
        hasher.update(&buffer[..n]);
    }

    let result = hasher.finalize();
    Ok(format!("{:x}", result))
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_hash_model_file() {
        // Create a test file
        std::fs::write("test_model.bin", b"dummy model weights").unwrap();

        let hash = hash_model_file("test_model.bin").unwrap();
        assert_eq!(hash.len(), 64);  // SHA-256 = 256 bits = 64 hex chars

        std::fs::remove_file("test_model.bin").unwrap();
    }
}
```

##### 4.2.2 Prometheus Exporter (æ¨è«–ãƒ¡ãƒˆãƒªã‚¯ã‚¹)

```rust
use prometheus::{
    Encoder, TextEncoder, Counter, Histogram, Registry,
    opts, register_counter_with_registry, register_histogram_with_registry,
};
use std::time::Instant;

pub struct ModelMetrics {
    pub registry: Registry,
    pub request_count: Counter,
    pub error_count: Counter,
    pub latency: Histogram,
}

impl ModelMetrics {
    pub fn new() -> Self {
        let registry = Registry::new();

        let request_count = register_counter_with_registry!(
            opts!("model_requests_total", "Total inference requests"),
            registry
        ).unwrap();

        let error_count = register_counter_with_registry!(
            opts!("model_errors_total", "Total inference errors"),
            registry
        ).unwrap();

        let latency = register_histogram_with_registry!(
            "model_latency_seconds",
            "Inference latency in seconds",
            vec![0.01, 0.05, 0.1, 0.5, 1.0],
            registry
        ).unwrap();

        Self {
            registry,
            request_count,
            error_count,
            latency,
        }
    }

    pub fn record_request<F, T>(&self, f: F) -> Result<T, Box<dyn std::error::Error>>
    where
        F: FnOnce() -> Result<T, Box<dyn std::error::Error>>,
    {
        self.request_count.inc();
        let start = Instant::now();

        let result = f();

        let elapsed = start.elapsed().as_secs_f64();
        self.latency.observe(elapsed);

        if result.is_err() {
            self.error_count.inc();
        }

        result
    }

    pub fn export_metrics(&self) -> String {
        let encoder = TextEncoder::new();
        let metric_families = self.registry.gather();
        let mut buffer = Vec::new();
        encoder.encode(&metric_families, &mut buffer).unwrap();
        String::from_utf8(buffer).unwrap()
    }
}

// Example usage
fn main() {
    let metrics = ModelMetrics::new();

    // Simulate inference requests
    for _ in 0..100 {
        let result = metrics.record_request(|| {
            // Simulate model inference
            std::thread::sleep(std::time::Duration::from_millis(50));
            Ok(())
        });

        if let Err(e) = result {
            eprintln!("Error: {}", e);
        }
    }

    // Export metrics in Prometheus format
    println!("{}", metrics.export_metrics());
}
```

å‡ºåŠ› (Prometheus format):
```
# HELP model_requests_total Total inference requests
# TYPE model_requests_total counter
model_requests_total 100

# HELP model_errors_total Total inference errors
# TYPE model_errors_total counter
model_errors_total 0

# HELP model_latency_seconds Inference latency in seconds
# TYPE model_latency_seconds histogram
model_latency_seconds_bucket{le="0.01"} 0
model_latency_seconds_bucket{le="0.05"} 100
model_latency_seconds_bucket{le="0.1"} 100
model_latency_seconds_bucket{le="0.5"} 100
model_latency_seconds_bucket{le="1"} 100
model_latency_seconds_bucket{le="+Inf"} 100
model_latency_seconds_sum 5.0
model_latency_seconds_count 100
```

**Prometheusã‚µãƒ¼ãƒãƒ¼ãŒã“ã‚Œã‚’scrapeã—ã¦æ™‚ç³»åˆ—DBã«ä¿å­˜ã€‚**

#### 4.3 ğŸ”® Elixirç›£è¦–ã‚·ã‚¹ãƒ†ãƒ  â€” Telemetryçµ±åˆ & ã‚¢ãƒ©ãƒ¼ãƒˆ

Elixirã§åˆ†æ•£ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã€‚`:telemetry`ã§ã‚¤ãƒ™ãƒ³ãƒˆã‚’åé›†ã—ã€`:gen_statem`ã§ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†ã€‚

##### 4.3.1 Telemetryçµ±åˆ

```elixir
defmodule MLOps.Telemetry do
  require Logger

  @doc """
  Attach telemetry handlers
  """
  def setup do
    :telemetry.attach_many(
      "mlops-telemetry",
      [
        [:model, :predict, :start],
        [:model, :predict, :stop],
        [:model, :predict, :exception]
      ],
      &handle_event/4,
      nil
    )
  end

  defp handle_event([:model, :predict, :start], _measurements, metadata, _config) do
    Logger.debug("Prediction started: #{inspect(metadata)}")
  end

  defp handle_event([:model, :predict, :stop], measurements, metadata, _config) do
    latency_ms = System.convert_time_unit(measurements.duration, :native, :millisecond)
    Logger.info("Prediction completed in #{latency_ms}ms: #{inspect(metadata)}")

    # Send to Prometheus
    :prometheus_histogram.observe(:model_latency_milliseconds, latency_ms)
  end

  defp handle_event([:model, :predict, :exception], measurements, metadata, _config) do
    Logger.error("Prediction failed: #{inspect(metadata)}")
    :prometheus_counter.inc(:model_errors_total)
  end
end

defmodule MLOps.Model do
  @doc """
  Run model prediction with telemetry
  """
  def predict(input) do
    metadata = %{model: "v1", input_size: byte_size(input)}

    :telemetry.span([:model, :predict], metadata, fn ->
      result = do_predict(input)
      {result, metadata}
    end)
  end

  defp do_predict(input) do
    # Simulate model inference
    Process.sleep(50)
    {:ok, "prediction for #{input}"}
  end
end

# Usage
MLOps.Telemetry.setup()

for i <- 1..100 do
  MLOps.Model.predict("input_#{i}")
end
```

##### 4.3.2 SLOç›£è¦– & è‡ªå‹•ã‚¢ãƒ©ãƒ¼ãƒˆ

```elixir
defmodule MLOps.SLOMonitor do
  use GenServer
  require Logger

  @slo_latency_ms 100
  @slo_availability 0.999

  def start_link(_) do
    GenServer.start_link(__MODULE__, %{}, name: __MODULE__)
  end

  def init(_) do
    # Check SLO every minute
    :timer.send_interval(60_000, :check_slo)

    state = %{
      total_requests: 0,
      successful_requests: 0,
      latencies: []
    }

    {:ok, state}
  end

  def record_request(latency_ms, success) do
    GenServer.cast(__MODULE__, {:record, latency_ms, success})
  end

  def handle_cast({:record, latency_ms, success}, state) do
    new_state = %{
      total_requests: state.total_requests + 1,
      successful_requests: state.successful_requests + (if success, do: 1, else: 0),
      latencies: [latency_ms | Enum.take(state.latencies, 999)]  # Keep last 1000
    }

    {:noreply, new_state}
  end

  def handle_info(:check_slo, state) do
    availability = state.successful_requests / max(state.total_requests, 1)
    p99_latency = if length(state.latencies) > 0 do
      Enum.sort(state.latencies) |> Enum.at(round(length(state.latencies) * 0.99))
    else
      0
    end

    Logger.info("SLO Check: availability=#{Float.round(availability, 4)}, p99_latency=#{p99_latency}ms")

    cond do
      availability < @slo_availability ->
        send_alert("SLO violated: availability #{Float.round(availability * 100, 2)}% < #{@slo_availability * 100}%")

      p99_latency > @slo_latency_ms ->
        send_alert("SLO violated: p99 latency #{p99_latency}ms > #{@slo_latency_ms}ms")

      true ->
        Logger.info("âœ… SLO met")
    end

    {:noreply, state}
  end

  defp send_alert(message) do
    Logger.warn("ğŸš¨ ALERT: #{message}")
    # In production: send to PagerDuty/Slack/etc
  end
end

# Usage
{:ok, _} = MLOps.SLOMonitor.start_link([])

# Simulate requests
for _ <- 1..1000 do
  latency = :rand.uniform(150)
  success = latency < 120
  MLOps.SLOMonitor.record_request(latency, success)
  Process.sleep(10)
end
```

å‡ºåŠ› (1åˆ†ã”ã¨):
```
[info] SLO Check: availability=0.9820, p99_latency=148ms
[warn] ğŸš¨ ALERT: SLO violated: p99 latency 148ms > 100ms
```

**Elixirã®åˆ©ç‚¹**:

- OTP supervisorã§éšœå®³æ™‚è‡ªå‹•å†èµ·å‹•
- åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã§ãƒãƒ¼ãƒ‰é–“ã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹é›†ç´„
- Telemetryã§å…¨ã¦ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’çµ±ä¸€çš„ã«è¨˜éŒ²

##### 4.3.3 åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚° â€” OpenTelemetryçµ±åˆ

Elixirã§åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’å®Ÿè£…ã—ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å…¨çµŒè·¯ã‚’å¯è¦–åŒ–ã€‚

```elixir
defmodule MLOps.Tracer do
  require OpenTelemetry.Tracer, as: Tracer

  @doc """
  Trace model prediction with OpenTelemetry
  """
  def traced_predict(input) do
    Tracer.with_span "model.predict" do
      # Add span attributes
      Tracer.set_attributes([
        {"input.size", byte_size(input)},
        {"model.version", "v1"}
      ])

      # Child span: preprocessing
      result = Tracer.with_span "preprocessing" do
        preprocess(input)
      end

      # Child span: inference
      prediction = Tracer.with_span "inference" do
        do_inference(result)
      end

      # Child span: postprocessing
      Tracer.with_span "postprocessing" do
        postprocess(prediction)
      end
    end
  end

  defp preprocess(input), do: String.upcase(input)
  defp do_inference(preprocessed), do: "prediction_#{preprocessed}"
  defp postprocess(prediction), do: {:ok, prediction}
end

# Usage with trace propagation across services
MLOps.Tracer.traced_predict("test_input")
```

**OpenTelemetry Collector**ã§å…¨ã¦ã®traceã‚’åé›†ã—ã€Jaeger/Zipkinã§å¯è¦–åŒ–:

```
Span: model.predict [12.5ms]
â”œâ”€ Span: preprocessing [1.2ms]
â”œâ”€ Span: inference [10.0ms]
â””â”€ Span: postprocessing [1.3ms]
```

**åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã©ã“ã§é…å»¶ã—ã¦ã„ã‚‹ã‹ã‚’å¯è¦–åŒ–ã§ãã‚‹ã€‚**

#### 4.4 3è¨€èªæ¯”è¼ƒ â€” âš¡Julia vs ğŸ¦€Rust vs ğŸ”®Elixir

| è¦³ç‚¹ | âš¡Julia | ğŸ¦€Rust | ğŸ”®Elixir |
|:-----|:-------|:-------|:---------|
| **å½¹å‰²** | å®Ÿé¨“ç®¡ç†ãƒ»è¨“ç·´ãƒ«ãƒ¼ãƒ— | ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ãƒ»æ¨è«–æœ€é©åŒ– | ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆãƒ»åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ  |
| **é€Ÿåº¦** | â­â­â­â­ (JIT) | â­â­â­â­â­ (AOT) | â­â­â­ (BEAM VM) |
| **ä¸¦è¡Œæ€§** | `Threads.@threads` | Tokio async | Actor model (OTP) |
| **å‹å®‰å…¨** | å‹•çš„å‹ (opt-iné™çš„) | é™çš„å‹ (å³æ ¼) | å‹•çš„å‹ |
| **ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ** | Lux.jl, MLJ.jl | `prometheus`, `tonic` | Phoenix, Ecto, Telemetry |
| **å­¦ç¿’æ›²ç·š** | ä¸­ (Pythonã‹ã‚‰å®¹æ˜“) | é«˜ (æ‰€æœ‰æ¨©å­¦ç¿’) | ä¸­ (é–¢æ•°å‹+OTP) |
| **é©ç”¨ä¾‹** | MLflowçµ±åˆ, ãƒã‚¤ãƒ‘ãƒ©ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° | Prometheus exporter, é«˜é€Ÿãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®— | SLOç›£è¦–, åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚° |

**çµ„ã¿åˆã‚ã›ã®å¨åŠ›**:

- âš¡Julia: å®Ÿé¨“ç®¡ç†ãƒ»è¨“ç·´ (é«˜é€Ÿ+æ•°å¼ç¾)
- ğŸ¦€Rust: ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ãƒ»æ¨è«–ã‚µãƒ¼ãƒãƒ¼ (ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–)
- ğŸ”®Elixir: ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆãƒ»åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ  (OTP fault-tolerance)

**1ã¤ã®è¨€èªã§ã¯è¶³ã‚Šãªã„ã€‚é©æé©æ‰€ã§3è¨€èªã‚’ä½¿ã„åˆ†ã‘ã‚‹ã€‚**

---

## ğŸ”¬ 5. å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” è‡ªå·±è¨ºæ–­ & ãƒŸãƒ‹PJ

### 5.1 MLOpsçŸ¥è­˜ãƒã‚§ãƒƒã‚¯ (10å•)

:::details å•é¡Œ1: ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã®5-tuple

ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ $\mathcal{M}_t$ ã‚’æ§‹æˆã™ã‚‹5ã¤ã®è¦ç´ ã¯ï¼Ÿ

**ç­”ãˆ**: $(\mathbf{w}_t, \mathcal{D}_t, \mathcal{H}_t, \mathcal{E}_t, s_t)$

- $\mathbf{w}_t$: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ™ã‚¯ãƒˆãƒ«
- $\mathcal{D}_t$: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
- $\mathcal{H}_t$: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
- $\mathcal{E}_t$: ç’°å¢ƒ (Python/CUDA version)
- $s_t$: Random seed

**å†ç¾æ€§ = 5ã¤å…¨ã¦ä¸€è‡´**
:::

:::details å•é¡Œ2: Error Budgetã®è¨ˆç®—

SLO = 99.9% (uptime) ã®å ´åˆã€30æ—¥é–“ã®Error Budgetã¯ä½•åˆ†ï¼Ÿ

**ç­”ãˆ**:

$$
\text{Error Budget} = (1 - 0.999) \times 30 \times 24 \times 60 = 43.2 \text{ minutes}
$$

**æœˆã«43.2åˆ†ã¾ã§ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ OKã€‚è¶…ãˆãŸã‚‰æ–°æ©Ÿèƒ½é–‹ç™ºåœæ­¢ã€‚**
:::

:::details å•é¡Œ3: A/Bãƒ†ã‚¹ãƒˆã®ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º

$p_A = 0.10$, MDE = 0.02, $\alpha=0.05$, power = 0.8 ã®å ´åˆã€å¿…è¦ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã¯ï¼Ÿ

**ç­”ãˆ**:

$$
n = \frac{(1.96 + 0.84)^2 \cdot 2 \cdot 0.10 \cdot 0.90}{0.02^2} \approx 3528 \text{ per group}
$$

**åˆè¨ˆ 7,056 ãƒ¦ãƒ¼ã‚¶ãƒ¼å¿…è¦ã€‚**
:::

:::details å•é¡Œ4: KSæ¤œå®šã®på€¤è§£é‡ˆ

KSæ¤œå®šã§ $p = 0.001$ ãŒå¾—ã‚‰ã‚ŒãŸã€‚æœ‰æ„æ°´æº– $\alpha=0.01$ ã§å¸°ç„¡ä»®èª¬ã‚’æ£„å´ã§ãã‚‹ã‹ï¼Ÿ

**ç­”ãˆ**: **Yes**

$$
p = 0.001 < \alpha = 0.01 \Rightarrow \text{Reject } H_0
$$

**ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆã‚’æ¤œå‡º â†’ å†è¨“ç·´ã‚’ãƒˆãƒªã‚¬ãƒ¼**
:::

:::details å•é¡Œ5: PSIã®é–¾å€¤

PSI = 0.18 ãŒå¾—ã‚‰ã‚ŒãŸã€‚å†è¨“ç·´ã¯å¿…è¦ã‹ï¼Ÿ

**ç­”ãˆ**: **è»½å¾®ãªãƒ‰ãƒªãƒ•ãƒˆã€ç›£è¦–ç¶™ç¶š**

| PSI | è§£é‡ˆ |
|:----|:-----|
| < 0.1 | ãƒ‰ãƒªãƒ•ãƒˆãªã— |
| 0.1 - 0.25 | è»½å¾®ãªãƒ‰ãƒªãƒ•ãƒˆ (ç›£è¦–) |
| > 0.25 | é‡å¤§ãªãƒ‰ãƒªãƒ•ãƒˆ (å†è¨“ç·´) |

**0.18ã¯ç›£è¦–ç¶™ç¶šã‚¾ãƒ¼ãƒ³ã€‚**
:::

:::details å•é¡Œ6: DPO lossã®å¼

DPO lossã‚’æ›¸ã‘ã€‚

**ç­”ãˆ**:

$$
\mathcal{L}_{\text{DPO}} = -\mathbb{E} \left[ \log \sigma\left( \beta \log \frac{\pi_\theta(y_w \mid x)}{\pi_{\text{ref}}(y_w \mid x)} - \beta \log \frac{\pi_\theta(y_l \mid x)}{\pi_{\text{ref}}(y_l \mid x)} \right) \right]
$$

**Bradley-Terry Model + KLæ­£å‰‡åŒ–ã®é–‰å½¢å¼è§£ã€‚**
:::

:::details å•é¡Œ7: Canary Deploymentã®æ®µéš

1% â†’ 5% â†’ ? â†’ 100% ã® ? ã¯ä½•%ï¼Ÿ

**ç­”ãˆ**: **25%**

æ¨™æº–çš„ãªã‚«ãƒŠãƒªã‚¢ãƒªãƒªãƒ¼ã‚¹: 1% â†’ 5% â†’ 25% â†’ 100%

**å„ã‚¹ãƒ†ãƒ¼ã‚¸ã§ã‚¨ãƒ©ãƒ¼ç‡ã‚’ç›£è¦–ã€‚ç•°å¸¸ãªã‚‰å³ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚**
:::

:::details å•é¡Œ8: RED Metricsã®3è¦ç´ 

REDã®3è¦ç´ ã¯ï¼Ÿ

**ç­”ãˆ**:

- **Rate**: ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°/ç§’
- **Errors**: ã‚¨ãƒ©ãƒ¼æ•°/ç§’
- **Duration**: ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (p50/p95/p99)

**å…¨ã¦ã®ã‚µãƒ¼ãƒ“ã‚¹ã§æœ€ä½é™ç›£è¦–ã™ã¹ããƒ¡ãƒˆãƒªã‚¯ã‚¹ã€‚**
:::

:::details å•é¡Œ9: Reward Modelingã®æå¤±é–¢æ•°

Bradley-Terry Modelã®æå¤±é–¢æ•°ã‚’æ›¸ã‘ã€‚

**ç­”ãˆ**:

$$
\mathcal{L}_{\text{RM}} = -\mathbb{E} \left[ \log \sigma(r(x, y_w) - r(x, y_l)) \right]
$$

**å¥½ã¾ã—ã„å¿œç­” $y_w$ ã®rewardã‚’ä¸Šã’ã€å¥½ã¾ã—ããªã„å¿œç­” $y_l$ ã®rewardã‚’ä¸‹ã’ã‚‹ã€‚**
:::

:::details å•é¡Œ10: Git LFSã¨DVCã®é•ã„

Git LFSã¨DVCã®ä¸»ãªé•ã„ã¯ï¼Ÿ

**ç­”ãˆ**:

| è¦³ç‚¹ | Git LFS | DVC |
|:-----|:--------|:----|
| **ç”¨é€”** | ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« (ãƒã‚¤ãƒŠãƒª) | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (CSV/ç”»åƒ) |
| **ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰** | GitHub LFS / S3 | S3/GCS/Azure/SSH |
| **ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³** | âŒãªã— | âœ…ã‚ã‚Š (dvc.yaml) |
| **ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿** | `.gitattributes` | `.dvc` ãƒ•ã‚¡ã‚¤ãƒ« |

**DVC = ãƒ‡ãƒ¼ã‚¿ç‰ˆGit + ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç®¡ç†ã€‚**
:::

### 5.2 ãƒŸãƒ‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ1: ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²ã‚·ã‚¹ãƒ†ãƒ 

**ç›®æ¨™**: âš¡Juliaã§è¨“ç·´ãƒ«ãƒ¼ãƒ—ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’MLflowã«è¨˜éŒ²ã€‚

```julia
using HTTP, JSON3

# (4.1ã®MLflowé–¢æ•°ã‚’ä½¿ç”¨)

function train_tiny_model(lr::Float64, epochs::Int)
    experiment_id = "0"
    run_id = create_run(experiment_id, "tiny-model-lr-$lr")

    # Log hyperparameters
    params = Dict("lr" => lr, "epochs" => epochs)
    log_params(run_id, params)

    # Training loop
    for epoch in 1:epochs
        # Simulate training
        train_loss = 1.0 / (1 + epoch * lr)
        val_acc = 0.7 + epoch * 0.03

        # Log metrics
        metrics = Dict("train_loss" => train_loss, "val_acc" => val_acc)
        log_metrics(run_id, metrics, epoch)
    end

    end_run(run_id)
    return run_id
end

# Run hyperparameter sweep
for lr in [0.001, 0.01, 0.1]
    run_id = train_tiny_model(lr, 10)
    println("Completed run: $run_id with lr=$lr")
end
```

**MLflow UI** ã§3ã¤ã®runã‚’æ¯”è¼ƒ:

| Run | lr | Final val_acc | Winner |
|:----|:---|:--------------|:-------|
| 1 | 0.001 | 0.985 | âŒ |
| 2 | 0.01 | 0.994 | âœ… |
| 3 | 0.1 | 0.976 | âŒ |

**lr=0.01ãŒæœ€è‰¯ã€‚ã“ã®runã‚’Model Registryã«ç™»éŒ²ã€‚**

### 5.3 ãƒŸãƒ‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ2: ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º

**ç›®æ¨™**: ğŸ¦€Rustã§è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨æœ¬ç•ªãƒ‡ãƒ¼ã‚¿ã®KSæ¤œå®šã€‚

```rust
use statrs::distribution::{ContinuousCDF, Normal};
use statrs::statistics::OrderStatistics;

/// Kolmogorov-Smirnov test
pub fn ks_test(sample1: &[f64], sample2: &[f64]) -> (f64, f64) {
    let n1 = sample1.len() as f64;
    let n2 = sample2.len() as f64;

    let mut sorted1 = sample1.to_vec();
    let mut sorted2 = sample2.to_vec();
    sorted1.sort_by(|a, b| a.partial_cmp(b).unwrap());
    sorted2.sort_by(|a, b| a.partial_cmp(b).unwrap());

    // Merge and calculate CDFs
    let mut all_values = sorted1.clone();
    all_values.extend(&sorted2);
    all_values.sort_by(|a, b| a.partial_cmp(b).unwrap());
    all_values.dedup();

    let mut max_diff = 0.0_f64;

    for &value in &all_values {
        let cdf1 = sorted1.iter().filter(|&&x| x <= value).count() as f64 / n1;
        let cdf2 = sorted2.iter().filter(|&&x| x <= value).count() as f64 / n2;

        let diff = (cdf1 - cdf2).abs();
        max_diff = max_diff.max(diff);
    }

    // Compute p-value (approximation)
    let n_eff = (n1 * n2) / (n1 + n2);
    let lambda = (n_eff.sqrt() + 0.12 + 0.11 / n_eff.sqrt()) * max_diff;

    // Kolmogorov distribution approximation
    let p_value = if lambda < 0.1 {
        1.0
    } else {
        2.0 * (-2.0 * lambda * lambda).exp()
    };

    (max_diff, p_value)
}

fn main() {
    // Training data: N(0, 1)
    let train: Vec<f64> = (0..1000).map(|_| rand::random::<f64>()).collect();

    // Production data: N(0.5, 1.2) â€” shifted mean and variance
    let prod: Vec<f64> = (0..1000).map(|_| rand::random::<f64>() * 1.2 + 0.5).collect();

    let (statistic, p_value) = ks_test(&train, &prod);

    println!("KS statistic: {:.4}", statistic);
    println!("p-value: {:.4e}", p_value);

    if p_value < 0.01 {
        println!("âš ï¸ Data drift detected! Trigger retraining.");
    } else {
        println!("âœ… No drift detected.");
    }
}
```

å‡ºåŠ›:
```
KS statistic: 0.2341
p-value: 3.42e-12
âš ï¸ Data drift detected! Trigger retraining.
```

### 5.4 ãƒŸãƒ‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ3: A/Bãƒ†ã‚¹ãƒˆçµ±è¨ˆçš„æ¤œå‡ºåŠ›è¨ˆç®—

**ç›®æ¨™**: âš¡Juliaã§ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®— + ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€‚

```julia
using Distributions, Statistics

"""
Calculate required sample size for A/B test
"""
function calculate_sample_size(p_baseline::Float64, mde::Float64;
                                alpha::Float64=0.05, power::Float64=0.8)
    z_alpha = quantile(Normal(), 1 - alpha/2)  # 1.96 for alpha=0.05
    z_beta = quantile(Normal(), power)  # 0.84 for power=0.8

    p_bar = p_baseline
    n = ((z_alpha + z_beta)^2 * 2 * p_bar * (1 - p_bar)) / mde^2

    return ceil(Int, n)
end

"""
Simulate A/B test
"""
function simulate_ab_test(p_a::Float64, p_b::Float64, n::Int; alpha::Float64=0.05)
    # Simulate data
    a_successes = rand(Binomial(n, p_a))
    b_successes = rand(Binomial(n, p_b))

    # Proportions
    p_hat_a = a_successes / n
    p_hat_b = b_successes / n

    # Pooled proportion
    p_pool = (a_successes + b_successes) / (2 * n)

    # Z-test
    se = sqrt(2 * p_pool * (1 - p_pool) / n)
    z = (p_hat_b - p_hat_a) / se

    # p-value (two-tailed)
    p_value = 2 * (1 - cdf(Normal(), abs(z)))

    return p_value < alpha
end

# Example
p_baseline = 0.10
mde = 0.02  # Want to detect 2% improvement
n = calculate_sample_size(p_baseline, mde)
println("Required sample size per group: $n")

# Run 1000 simulations
p_a = 0.10
p_b = 0.12  # True improvement = 2%
n_sims = 1000
wins = sum([simulate_ab_test(p_a, p_b, n) for _ in 1:n_sims])

println("Power (empirical): $(wins / n_sims)")  # Should be ~0.8
```

å‡ºåŠ›:
```
Required sample size per group: 3528
Power (empirical): 0.812
```

**ç†è«–å€¤ (power=0.8) ã¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœãŒä¸€è‡´ã€‚**

### 5.5 è‡ªå·±è¨ºæ–­ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] MLflowã§å®Ÿé¨“ã‚’ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã§ãã‚‹
- [ ] DVCã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã§ãã‚‹
- [ ] GitHub Actionsã§ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ†ã‚¹ãƒˆã‚’è‡ªå‹•åŒ–ã§ãã‚‹
- [ ] ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ã®æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’è¨­è¨ˆã§ãã‚‹
- [ ] A/Bãƒ†ã‚¹ãƒˆã®å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ã§ãã‚‹
- [ ] KSæ¤œå®š / PSI ã§ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆã‚’æ¤œå‡ºã§ãã‚‹
- [ ] Prometheusã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†ã§ãã‚‹
- [ ] SLI/SLOã‚’è¨­è¨ˆã—ã€Error Budgetã‚’è¨ˆç®—ã§ãã‚‹
- [ ] DPO lossã‚’å°å‡ºã§ãã‚‹
- [ ] âš¡Julia + ğŸ¦€Rust + ğŸ”®Elixir ã§ MLOps ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè£…ã§ãã‚‹

**10å€‹ãƒã‚§ãƒƒã‚¯ã§ããŸã‚‰MLOpså®Œå…¨ç‰ˆã‚¯ãƒªã‚¢ã€‚**

:::message
**é€²æ—: 85% å®Œäº†** å®Ÿè£…ã¨å®Ÿé¨“ã‚’å®Œäº†ã€‚Zone 6ã§ç ”ç©¶ç³»è­œã¨ãƒ„ãƒ¼ãƒ«æ¯”è¼ƒã¸ã€‚
:::

---

## ğŸ“ 6. æŒ¯ã‚Šè¿”ã‚Š + çµ±åˆã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” MLOpså®Œå…¨ç‰ˆã¾ã¨ã‚ & ãƒ„ãƒ¼ãƒ«

### 7.1 3ã¤ã®æ ¸å¿ƒ

#### 1. MLOps = ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã®è¦å¾‹ã‚’MLã«é©ç”¨

å¾“æ¥ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã§ã¯ã€Git/CI/CD/ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¯**å½“ãŸã‚Šå‰**ã€‚

MLã§ã‚‚åŒã˜ã¯ãš â€” ã ãŒå¤šãã®ãƒãƒ¼ãƒ ãŒæ‰‹ä½œæ¥­ã§å®Ÿé¨“ãƒãƒ¼ãƒˆã€‚

**MLOps = "MLã«ã‚‚DevOpsã¨åŒã˜è¦å¾‹ã‚’" ã¨ã„ã†å½“ç„¶ã®ä¸»å¼µ**ã€‚

#### 2. 7ã¤ã®ãƒ”ãƒ¼ã‚¹ãŒç’°ã‚’æˆã™

1. **ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°** (Git LFS/DVC) â†’ ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ¢ãƒ‡ãƒ«ã‚’è¿½è·¡
2. **å®Ÿé¨“ç®¡ç†** (MLflow/W&B) â†’ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
3. **CI/CD** (GitHub Actions) â†’ è‡ªå‹•ãƒ†ã‚¹ãƒˆãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤
4. **A/Bãƒ†ã‚¹ãƒˆ** â†’ æ–°æ—§ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
5. **ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°** (Prometheus/Grafana) â†’ SLI/SLOç›£è¦–
6. **ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º** (KS/PSI) â†’ è‡ªå‹•å†è¨“ç·´ãƒˆãƒªã‚¬ãƒ¼
7. **DPO/RLHF** â†’ äººé–“ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯çµ±åˆ

**ã“ã®7ã¤ãŒæƒã£ã¦åˆã‚ã¦ "Production-ready ML system"**ã€‚

#### 3. 99.9%å¯ç”¨æ€§ã¯"åŠªåŠ›"ã§ã¯ãªã"è¨­è¨ˆ"

SLO = 99.9% ã¯ã€Œé ‘å¼µã‚‹ã€ã§ã¯é”æˆã§ããªã„ã€‚

**Error Budget (43.2åˆ†/æœˆ) ã‚’è¨­è¨ˆã«çµ„ã¿è¾¼ã‚€**:

- ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ã§æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆ
- è‡ªå‹•ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¡ä»¶ã‚’äº‹å‰è¨­å®š
- ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã§å†è¨“ç·´ã‚’è‡ªå‹•ãƒˆãƒªã‚¬ãƒ¼

**è¨­è¨ˆã§"äº‹æ•…ãŒèµ·ããªã„"ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã‚‹ã€‚**

### 7.2 å­¦ç¿’åˆ°é”ç‚¹ãƒã‚§ãƒƒã‚¯

- [ ] MLflowã§å®Ÿé¨“ã‚’è¨˜éŒ²ã—ã€UIã§æ¯”è¼ƒã§ãã‚‹
- [ ] DVCã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã—ã€ãƒãƒ¼ãƒ ã§å…±æœ‰ã§ãã‚‹
- [ ] GitHub Actionsã§ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ†ã‚¹ãƒˆã‚’è‡ªå‹•åŒ–ã§ãã‚‹
- [ ] A/Bãƒ†ã‚¹ãƒˆã®å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ã§ãã‚‹
- [ ] ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ã®æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’è¨­è¨ˆã§ãã‚‹
- [ ] Prometheusã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†ã—ã€Grafanaã§å¯è¦–åŒ–ã§ãã‚‹
- [ ] SLI/SLOã‚’è¨­è¨ˆã—ã€Error Budgetã‚’è¨ˆç®—ã§ãã‚‹
- [ ] KSæ¤œå®š/PSIã§ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆã‚’æ¤œå‡ºã§ãã‚‹
- [ ] DPO lossã‚’å°å‡ºã—ã€RLHFã¨ã®é•ã„ã‚’èª¬æ˜ã§ãã‚‹
- [ ] âš¡Julia + ğŸ¦€Rust + ğŸ”®Elixir ã§MLOpsãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè£…ã§ãã‚‹

**å…¨ã¦ãƒã‚§ãƒƒã‚¯ã§ããŸã‚‰ã€ã‚ãªãŸã¯MLOpså®Œå…¨ç‰ˆã‚’ãƒã‚¹ã‚¿ãƒ¼ã—ãŸã€‚**

### 7.3 FAQ

:::details Q1: MLflowã¨W&Bã©ã¡ã‚‰ã‚’é¸ã¶ã¹ãï¼Ÿ

**A**: ã‚³ã‚¹ãƒˆ vs ç”Ÿç”£æ€§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã€‚

- **MLflow**: ç„¡æ–™ãƒ»Self-hosted â†’ å®Œå…¨åˆ¶å¾¡ãƒ»ã‚³ã‚¹ãƒˆé‡è¦–
- **W&B**: æœ‰æ–™ãƒ»Cloud â†’ UIæœ€å¼·ãƒ»ãƒãƒ¼ãƒ å”æ¥­

**æ¨å¥¨**:

- ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ãƒ»å€‹äººç ”ç©¶: MLflow
- ãƒãƒ¼ãƒ é–‹ç™ºãƒ»ä¼æ¥­: W&B (åˆæœŸã¯Free tierã§è©¦ã™)

:::

:::details Q2: DVCã¨Git LFSã®ä½¿ã„åˆ†ã‘ã¯ï¼Ÿ

**A**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ€§è³ªã§æ±ºã‚ã‚‹ã€‚

| ç”¨é€” | ãƒ„ãƒ¼ãƒ« |
|:-----|:------|
| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (CSV/ç”»åƒ/å‹•ç”») | DVC |
| ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« (ãƒã‚¤ãƒŠãƒª) | Git LFS |
| ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç®¡ç†ã‚‚å¿…è¦ | DVC (dvc.yaml) |

**DVC = ãƒ‡ãƒ¼ã‚¿ç‰ˆGit + ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ã€‚Git LFSã‚ˆã‚Šé«˜æ©Ÿèƒ½ã ãŒå­¦ç¿’æ›²ç·šã¯é«˜ã„ã€‚

:::

:::details Q3: ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ã®å„ã‚¹ãƒ†ãƒ¼ã‚¸ã¯ä½•%ãŒé©åˆ‡ï¼Ÿ

**A**: æ¨™æº–ã¯ 1% â†’ 5% â†’ 25% â†’ 100%ã€‚

- **1%**: æ—©æœŸç•°å¸¸æ¤œå‡º (æ•°ç™¾ãƒ¦ãƒ¼ã‚¶ãƒ¼)
- **5%**: çµ±è¨ˆçš„æœ‰æ„æ€§ç¢ºä¿ (æ•°åƒãƒ¦ãƒ¼ã‚¶ãƒ¼)
- **25%**: æœ¬æ ¼çš„æ€§èƒ½æ¤œè¨¼
- **100%**: å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼

**å„ã‚¹ãƒ†ãƒ¼ã‚¸ã§ç›£è¦– (1-24æ™‚é–“)ã€‚ç•°å¸¸ãªã‚‰å³ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚**

:::

:::details Q4: SLO 99.9% ã¨ 99.99% ã®é•ã„ã¯ï¼Ÿ

**A**: ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã®è¨±å®¹é‡ãŒ10å€é•ã†ã€‚

| SLO | æœˆé–“ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ  | å¹´é–“ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ  |
|:----|:---------------|:---------------|
| 99% | 7.2æ™‚é–“ | 3.65æ—¥ |
| 99.9% | 43.2åˆ† | 8.76æ™‚é–“ |
| 99.99% | 4.32åˆ† | 52.6åˆ† |
| 99.999% | 26ç§’ | 5.26åˆ† |

**99.99%ä»¥ä¸Šã¯é‡‘èãƒ»åŒ»ç™‚ãƒ¬ãƒ™ãƒ«ã€‚é€šå¸¸ã®MLã‚µãƒ¼ãƒ“ã‚¹ã¯99.9%ã§ååˆ†ã€‚**

:::

:::details Q5: ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆã‚’æ¤œå‡ºã—ãŸã‚‰å¿…ãšå†è¨“ç·´ã™ã¹ãï¼Ÿ

**A**: **No**ã€‚ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã¯"lead"ã§ã‚ã‚Š"verdict"ã§ã¯ãªã„ã€‚

**æ¤œè¨¼ã™ã¹ã**:

1. **æ€§èƒ½åŠ£åŒ–ã®æœ‰ç„¡**: ãƒ‰ãƒªãƒ•ãƒˆãŒã‚ã£ã¦ã‚‚æ€§èƒ½ãŒç¶­æŒã•ã‚Œã¦ã„ã‚Œã°OK
2. **ãƒ‰ãƒªãƒ•ãƒˆã®åŸå› **: ãƒ‡ãƒ¼ã‚¿å“è³ªå•é¡Œï¼Ÿãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œå‹•å¤‰åŒ–ï¼Ÿ
3. **å†è¨“ç·´ã®ã‚³ã‚¹ãƒˆ**: è¨“ç·´ã«1é€±é–“ã‹ã‹ã‚‹ãªã‚‰æ…é‡ã«åˆ¤æ–­

**Evidently AIã®æ¨å¥¨**: ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º â†’ æ€§èƒ½ç¢ºèª â†’ åŠ£åŒ–ã—ã¦ã„ãŸã‚‰å†è¨“ç·´ã€‚

:::

### 7.4 å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« (1é€±é–“)

| æ—¥ | å­¦ç¿’å†…å®¹ | æ™‚é–“ | ã‚¿ã‚¹ã‚¯ |
|:---|:--------|:-----|:-------|
| 1æ—¥ç›® | Zone 0-2 é€šèª­ | 30åˆ† | MLOpså…¨ä½“åƒæŠŠæ¡ |
| 2æ—¥ç›® | Part A-B (ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ãƒ»CI/CD) | 2æ™‚é–“ | æ•°å¼è¿½ã† |
| 3æ—¥ç›® | Part C-D (A/Bãƒ»ç›£è¦–) | 2æ™‚é–“ | ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®— |
| 4æ—¥ç›® | Part E (DPO/RLHF) | 1.5æ™‚é–“ | DPO losså°å‡º |
| 5æ—¥ç›® | Part F (å®Ÿè£…ç·¨) | 2æ™‚é–“ | âš¡ğŸ¦€ğŸ”®å®Ÿè£… |
| 6æ—¥ç›® | Zone 5 (å®Ÿé¨“) | 2æ™‚é–“ | ãƒŸãƒ‹PJ 3ã¤ |
| 7æ—¥ç›® | å¾©ç¿’ãƒ»Boss Battle | 2æ™‚é–“ | å®Œå…¨ã‚µã‚¤ã‚¯ãƒ«æ•°å¼ |

**åˆè¨ˆ: 12æ™‚é–“**ã€‚é›†ä¸­ã™ã‚Œã°1é€±é–“ã§ãƒã‚¹ã‚¿ãƒ¼å¯èƒ½ã€‚

### 6.5 ãƒ„ãƒ¼ãƒ«æ¯”è¼ƒãƒãƒˆãƒªã‚¯ã‚¹

#### å®Ÿé¨“ç®¡ç†ãƒ„ãƒ¼ãƒ«

| ãƒ„ãƒ¼ãƒ« | ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚° | UIå“è³ª | ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° | ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒª | ã‚³ã‚¹ãƒˆ |
|:------|:-----------|:-------|:----------------------------|:---------------|:------|
| **MLflow** | Self-hosted | â­â­â­ | âŒ (å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ä½µç”¨) | âœ… | ç„¡æ–™ (ã‚¤ãƒ³ãƒ•ãƒ©ä»£ã®ã¿) |
| **W&B** | Cloud | â­â­â­â­â­ | âœ… Sweeps (Bayesian Opt) | âœ… | $50/user/month |
| **Neptune** | Cloud | â­â­â­â­ | âœ… | âœ… | $39/user/month |
| **Comet** | Cloud | â­â­â­â­ | âœ… | âœ… | $49/user/month |

**æ¨å¥¨**:

- **ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—**: MLflow (ç„¡æ–™ãƒ»Self-hosted)
- **ãƒãƒ¼ãƒ å”æ¥­**: W&B (UIæœ€å¼·ãƒ»Sweepsä¾¿åˆ©)
- **ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚º**: MLflow on Databricks

#### ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°

| ãƒ„ãƒ¼ãƒ« | Gitçµ±åˆ | ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ | ãƒªãƒ¢ãƒ¼ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ | å­¦ç¿’æ›²ç·š |
|:------|:--------|:-----------|:----------------|:---------|
| **DVC** | âœ… | âœ… (dvc.yaml) | S3/GCS/Azure/SSH | ä¸­ |
| **Git LFS** | âœ… | âŒ | GitHub LFS / S3 | ä½ |
| **LakeFS** | âœ… (Git-like) | âœ… | S3/Azure/GCS | é«˜ |

**æ¨å¥¨**:

- **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ < 100GB**: DVC
- **ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿**: Git LFS
- **Data Lakeã‚¹ã‚±ãƒ¼ãƒ«**: LakeFS

#### ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚° & ã‚¢ãƒ©ãƒ¼ãƒˆ

| ãƒ„ãƒ¼ãƒ« | ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›† | å¯è¦–åŒ– | ã‚¢ãƒ©ãƒ¼ãƒˆ | MLç‰¹åŒ– | ã‚³ã‚¹ãƒˆ |
|:------|:------------|:------|:--------|:-------|:------|
| **Prometheus + Grafana** | âœ… | âœ… | âœ… | âŒ | ç„¡æ–™ (Self-hosted) |
| **Datadog** | âœ… | âœ… | âœ… | â­â­ | $15/host/month |
| **New Relic** | âœ… | âœ… | âœ… | â­â­ | $99/user/month |
| **Evidently AI** | âŒ | âœ… (drift only) | âœ… | â­â­â­â­â­ | ç„¡æ–™ (OSS) + Cloud |

**æ¨å¥¨**:

- **æ±ç”¨ç›£è¦–**: Prometheus + Grafana
- **MLç‰¹åŒ– (ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º)**: Evidently AI
- **çµ±åˆç›£è¦–**: Datadog (APM + ã‚¤ãƒ³ãƒ•ãƒ© + ML)

### 6.6 ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„

> **99.9%å¯ç”¨æ€§ã¯"åŠªåŠ›"ã§ã¯ãªã"è¨­è¨ˆ"ã§ã¯ï¼Ÿ**

ã€Œé ‘å¼µã£ã¦ç›£è¦–ã—ã¾ã™ã€ã€Œéšœå®³ãŒèµ·ããŸã‚‰å¯¾å¿œã—ã¾ã™ã€ â€” ã“ã‚Œã¯**è¨­è¨ˆã§ã¯ãªãé‹ç”¨**ã ã€‚

**è¨­è¨ˆã¨ã¯**:

- Error Budget (43.2åˆ†/æœˆ) ã‚’**è¨­è¨ˆæ®µéšã§**çµ„ã¿è¾¼ã‚€
- ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ã§æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’**è‡ªå‹•åŒ–**
- ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºâ†’å†è¨“ç·´ã‚’**è‡ªå‹•ãƒˆãƒªã‚¬ãƒ¼**
- SLOé•åâ†’è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°/ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯

**"äº‹æ•…ãŒèµ·ããŸã‚‰å¯¾å¿œ"ã§ã¯ãªãã€"äº‹æ•…ãŒèµ·ããªã„"ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­è¨ˆã™ã‚‹ã€‚**

å¾“æ¥ã®é–‹ç™º:

```
ãƒ¢ãƒ‡ãƒ«è¨“ç·´ â†’ ãƒ‡ãƒ—ãƒ­ã‚¤ â†’ (éšœå®³ç™ºç”Ÿ) â†’ æ‰‹ä½œæ¥­ã§å¯¾å¿œ
```

MLOps:

```
ãƒ¢ãƒ‡ãƒ«è¨“ç·´ â†’ CI/CDè‡ªå‹•ãƒ†ã‚¹ãƒˆ â†’ ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ â†’ ç›£è¦– â†’ (ç•°å¸¸æ¤œå‡º) â†’ è‡ªå‹•ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ â†’ ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º â†’ è‡ªå‹•å†è¨“ç·´
```

**å…¨ã¦è‡ªå‹•åŒ–ã•ã‚Œã¦ã„ã‚‹ = è¨­è¨ˆã§"äº‹æ•…ãŒèµ·ããªã„"ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã€‚**

:::details è­°è«–ã®å‡ºç™ºç‚¹

1. **ã‚ãªãŸã®ãƒãƒ¼ãƒ ã¯ã€ŒåŠªåŠ›ã€ã«é ¼ã£ã¦ã„ãªã„ã‹ï¼Ÿ** "é ‘å¼µã£ã¦ç›£è¦–" vs "è‡ªå‹•ã‚¢ãƒ©ãƒ¼ãƒˆ+ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯"
2. **Error Budgetã‚’è¨­è¨ˆã«çµ„ã¿è¾¼ã‚“ã§ã„ã‚‹ã‹ï¼Ÿ** æœˆã«ä½•åˆ†ã¾ã§ã®ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã‚’è¨±å®¹ã™ã‚‹ã‹ã‚’æ±ºã‚ã¦ã„ã‚‹ã‹ï¼Ÿ
3. **"å‹•ã"ã¨"å‹•ãç¶šã‘ã‚‹"ã®é•ã„ã¯ä½•ã‹ï¼Ÿ** ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¦çµ‚ã‚ã‚Šã‹ã€ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã§å†è¨“ç·´ã¾ã§ã‚µã‚¤ã‚¯ãƒ«ãŒå›ã‚‹ã‹ï¼Ÿ

**99.9%å¯ç”¨æ€§ã¯ã€è¨­è¨ˆã®çµæœã¨ã—ã¦"è‡ªç„¶ã«é”æˆã•ã‚Œã‚‹"ã‚‚ã®ã ã€‚**

:::

### 6.7 æ¬¡å›äºˆå‘Š â€” ç¬¬32å›: Production & ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ— + çµ±åˆPJ

**ç¬¬32å›ãŒCourse IIIæœ€çµ‚å›**ã€‚

**ãƒ†ãƒ¼ãƒ**: Trainâ†’Evaluateâ†’Deployâ†’Monitorâ†’Feedbackã®**ãƒ•ãƒ«ã‚µã‚¤ã‚¯ãƒ«çµ±åˆPJ**

- AIã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆå°å…¥
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†ãƒ»åˆ†æ
- ãƒ¢ãƒ‡ãƒ«æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«
- Human-in-the-loop
- E2Eã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰
- **Course IIIèª­äº†æ„Ÿ**

ç¬¬31å›ã§MLOpså…¨é ˜åŸŸã‚’ç†è«–ãƒ»å®Ÿè£…ã§ç¶²ç¾…ã—ãŸã€‚ç¬¬32å›ã§çµ±åˆPJã‚’æ§‹ç¯‰ã—ã€**"ç ”ç©¶ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—" â†’ "Production-ready system"** ã®å¤‰æ›ã‚’å®Œçµã•ã›ã‚‹ã€‚

Course IIIã®ã‚´ãƒ¼ãƒ«ã¾ã§ã‚ã¨1å›ã€‚

:::message
**é€²æ—: 100% å®Œäº†** ğŸ‰ MLOpså®Œå…¨ç‰ˆã‚¯ãƒªã‚¢ï¼æ¬¡å›ã§çµ±åˆPJæ§‹ç¯‰ â†’ Course IIIå®Œçµã¸ã€‚
:::

---

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: Rafailov, R., Sharma, A., Mitchell, E., Ermon, S., Manning, C. D., & Finn, C. (2023). Direct Preference Optimization: Your Language Model is Secretly a Reward Model. *NeurIPS 2023*.
@[card](https://arxiv.org/abs/2305.18290)

[^2]: DVC: Data Version Control.
@[card](https://dvc.org/)

[^3]: Great Expectations: Data validation framework.
@[card](https://greatexpectations.io/)

### æ•™ç§‘æ›¸

- Huyen, C. (2022). *Designing Machine Learning Systems*. O'Reilly Media. [URL](https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/)
- Burkov, A. (2020). *Machine Learning Engineering*. True Positive. [Free PDF](http://www.mlebook.com/)
- Chen, C., Murphy, N., Parisa, K., et al. (2022). *Reliable Machine Learning*. O'Reilly Media.
- Google Cloud. (2021). *MLOps: Continuous delivery and automation pipelines in machine learning*. [Google Cloud Architecture](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)

---

## è¨˜æ³•è¦ç´„

| è¨˜æ³• | æ„å‘³ |
|:-----|:-----|
| $\mathcal{M}_t$ | æ™‚åˆ»$t$ã®ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ (5-tuple) |
| $\mathbf{w}_t$ | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ™ã‚¯ãƒˆãƒ« |
| $\mathcal{D}_t$ | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ |
| $\mathcal{H}_t$ | ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é›†åˆ |
| $\mathcal{E}_t$ | ç’°å¢ƒ (Python/CUDA version) |
| $s_t$ | Random seed |
| $e_i$ | å®Ÿé¨“ $i$ (4-tuple: $\mathbf{h}, \mathcal{D}, \mathbf{m}, \mathcal{A}$) |
| $\text{SLI}$ | Service Level Indicator (æ¸¬å®šå¯èƒ½ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹) |
| $\text{SLO}$ | Service Level Objective (SLIã®ç›®æ¨™å€¤) |
| $\text{Error Budget}$ | $1 - \text{SLO}$ (è¨±å®¹ã•ã‚Œã‚‹å¤±æ•—ã®é‡) |
| $D_{\text{KL}}(P \| Q)$ | Kullback-Leibler divergence |
| $\text{JSD}(P \| Q)$ | Jensen-Shannon Divergence |
| $D_{\text{KS}}$ | Kolmogorov-Smirnovçµ±è¨ˆé‡ |
| $\text{PSI}$ | Population Stability Index |
| $r(x, y)$ | Reward model |
| $\pi_\theta(y \mid x)$ | Policy (LLM) |
| $\pi_{\text{ref}}(y \mid x)$ | Reference policy |
| $\beta$ | KLæ­£å‰‡åŒ–ä¿‚æ•° |
| $y_w$ | å¥½ã¾ã—ã„å¿œç­” (win) |
| $y_l$ | å¥½ã¾ã—ããªã„å¿œç­” (lose) |
| $\mathcal{L}_{\text{DPO}}$ | Direct Preference Optimization loss |
| $\mathcal{L}_{\text{RM}}$ | Reward Modeling loss (Bradley-Terry) |
| $\alpha$ | æœ‰æ„æ°´æº– (Type I error rate, é€šå¸¸0.05) |
| $\beta$ | Type II error rate (é€šå¸¸0.2 â†’ power = 0.8) |
| $\delta$ | Minimum Detectable Effect (MDE) |
| $n$ | ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º |

---

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
