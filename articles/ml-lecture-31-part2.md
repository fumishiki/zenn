---
title: "ç¬¬31å›: MLOpså®Œå…¨ç‰ˆã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨: Rust/Rust/Elixirå®Ÿè£…â†’ãƒã‚¹ã‚¿ãƒ¼"
emoji: "ğŸ”„"
type: "tech"
topics: ["machinelearning", "mlops", "rust", "rust", "elixir"]
published: true
slug: "ml-lecture-31-part2"
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Rust", "Elixir"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---
> **ğŸ“– å‰ç·¨ï¼ˆç†è«–ç·¨ï¼‰**: [ç¬¬31å›å‰ç·¨: MLOpsç†è«–ç·¨](./ml-lecture-31-part1) | **â† ç†è«–ãƒ»æ•°å¼ã‚¾ãƒ¼ãƒ³ã¸**

## ğŸ’» Z5. è©¦ç·´ï¼ˆå®Ÿè£…ï¼‰ï¼ˆ60åˆ†ï¼‰â€” ğŸ¦€Rustå®Ÿé¨“ç®¡ç† + ğŸ¦€Rust MLOpsãƒ„ãƒ¼ãƒ« + ğŸ”®Elixirç›£è¦–

### 4.1 ğŸ¦€ Rustå®Ÿé¨“ç®¡ç† â€” MLflowçµ±åˆ

Rustã§å®Ÿé¨“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’å®Ÿè£…ã™ã‚‹ã€‚`MLFlowClient.jl`ã‚’ä½¿ã£ã¦MLflow APIã¨é€šä¿¡ã€‚

```rust
use reqwest::blocking::Client;
use serde_json::json;
use std::collections::HashMap;
use std::time::{SystemTime, UNIX_EPOCH};

// MLflow tracking server URL
const MLFLOW_URI: &str = "http://localhost:5000";

/// ç¾åœ¨æ™‚åˆ»ã‚’ãƒŸãƒªç§’UNIXã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨ã—ã¦è¿”ã™
fn now_ms() -> u64 {
    SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap()
        .as_millis() as u64
}

/// MLflowã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨˜éŒ²ã™ã‚‹
fn log_params(client: &Client, run_id: &str, params: &HashMap<&str, String>) -> reqwest::Result<()> {
    let url = format!("{}/api/2.0/mlflow/runs/log-parameter", MLFLOW_URI);
    for (key, value) in params {
        let body = json!({
            "run_id": run_id,
            "key": key,
            "value": value
        });
        client.post(&url).json(&body).send()?;
    }
    Ok(())
}

/// MLflowã«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ã‚¹ãƒ†ãƒƒãƒ—ä»˜ãã§è¨˜éŒ²ã™ã‚‹
fn log_metrics(client: &Client, run_id: &str, metrics: &HashMap<&str, f64>, step: i64) -> reqwest::Result<()> {
    let url = format!("{}/api/2.0/mlflow/runs/log-metric", MLFLOW_URI);
    for (key, &value) in metrics {
        let body = json!({
            "run_id": run_id,
            "key": key,
            "value": value,
            "timestamp": now_ms(),
            "step": step
        });
        client.post(&url).json(&body).send()?;
    }
    Ok(())
}

/// MLflowå®Ÿé¨“runã‚’ä½œæˆã—ã€run_idã‚’è¿”ã™
fn create_run(client: &Client, experiment_id: &str, run_name: &str) -> reqwest::Result<String> {
    let url = format!("{}/api/2.0/mlflow/runs/create", MLFLOW_URI);
    let body = json!({
        "experiment_id": experiment_id,
        "run_name": run_name,
        "start_time": now_ms()
    });
    let resp: serde_json::Value = client.post(&url).json(&body).send()?.json()?;
    Ok(resp["run"]["info"]["run_id"].as_str().unwrap().to_string())
}

/// MLflow runã‚’å®Œäº†çŠ¶æ…‹ã«æ›´æ–°ã™ã‚‹
fn end_run(client: &Client, run_id: &str, status: &str) -> reqwest::Result<()> {
    let url = format!("{}/api/2.0/mlflow/runs/update", MLFLOW_URI);
    let body = json!({
        "run_id": run_id,
        "status": status,
        "end_time": now_ms()
    });
    client.post(&url).json(&body).send()?;
    Ok(())
}

/// è¨“ç·´ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œã—MLflowã«è¨˜éŒ²ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«
fn train_and_log(client: &Client) -> reqwest::Result<String> {
    // runã‚’ä½œæˆ
    let run_id = create_run(client, "0", "rust-training-run")?;

    // ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨˜éŒ²
    let params: HashMap<&str, String> = HashMap::from([
        ("learning_rate", "0.001".to_string()),
        ("batch_size",    "32".to_string()),
        ("epochs",        "10".to_string()),
        ("optimizer",     "Adam".to_string()),
    ]);
    log_params(client, &run_id, &params)?;

    // è¨“ç·´ãƒ«ãƒ¼ãƒ—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    for epoch in 0..10 {
        let train_loss = 1.0 / (1.0 + epoch as f64 * 0.1); // æ¸›å°‘ã™ã‚‹loss
        let val_acc    = 0.8 + epoch as f64 * 0.02;          // å¢—åŠ ã™ã‚‹accuracy

        // ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ã‚¹ãƒ†ãƒƒãƒ—ä»˜ãã§è¨˜éŒ²
        let metrics: HashMap<&str, f64> = HashMap::from([
            ("train_loss", train_loss),
            ("val_acc",    val_acc),
        ]);
        log_metrics(client, &run_id, &metrics, epoch as i64)?;

        println!("Epoch {}: loss={:.4}, acc={:.4}", epoch + 1, train_loss, val_acc);
    }

    // runã‚’çµ‚äº†
    end_run(client, &run_id, "FINISHED")?;
    println!("âœ… Run completed: {}", run_id);

    Ok(run_id)
}

fn main() -> reqwest::Result<()> {
    let client = Client::new();
    let run_id = train_and_log(&client)?;
    println!("å®Ÿé¨“ID: {}", run_id);
    Ok(())
}
```

å‡ºåŠ›:
```
Epoch 1: loss=0.9090909090909091, acc=0.82
Epoch 2: loss=0.8333333333333334, acc=0.84
...
Epoch 10: loss=0.5, acc=1.0
âœ… Run completed: a3f9c2e1b4d87f3a9c2e1b4d87f3a9c2
```

**MLflow UI** (`mlflow ui`) ã§å¯è¦–åŒ–:

- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒ
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•
- Runé–“ã®æ¯”è¼ƒ

**Rustã®åˆ©ç‚¹**:

- è¨“ç·´ãƒ«ãƒ¼ãƒ—ãŒé«˜é€Ÿ (C/Fortranãƒ¬ãƒ™ãƒ«)
- MLflow APIã¯å˜ãªã‚‹HTTP POST (è¨€èªéä¾å­˜)
- ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–ã§å‹ã«å¿œã˜ãŸæœ€é©åŒ–

### 4.2 ğŸ¦€ Rust MLOpsãƒ„ãƒ¼ãƒ« â€” Prometheus Exporter & Graceful Shutdown

Rustã§é«˜é€ŸãªMLOpsãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’æ§‹ç¯‰ã€‚

#### 4.2.1 ãƒ¢ãƒ‡ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®— (SHA-256)

```rust
use sha2::{Sha256, Digest};
use std::fs::File;
use std::io::Read;

/// Calculate SHA-256 hash of model file
pub fn hash_model_file(path: &str) -> Result<String, std::io::Error> {
    let mut file = File::open(path)?;
    let mut hasher = Sha256::new();
    let mut buffer = [0u8; 8192];

    loop {
        let n = file.read(&mut buffer)?;
        if n == 0 { break; }
        hasher.update(&buffer[..n]);
    }

    let result = hasher.finalize();
    Ok(format!("{:x}", result))
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_hash_model_file() {
        // Create a test file
        std::fs::write("test_model.bin", b"dummy model weights").unwrap();

        let hash = hash_model_file("test_model.bin").unwrap();
        assert_eq!(hash.len(), 64);  // SHA-256 = 256 bits = 64 hex chars

        std::fs::remove_file("test_model.bin").unwrap();
    }
}
```

#### 4.2.2 Prometheus Exporter (æ¨è«–ãƒ¡ãƒˆãƒªã‚¯ã‚¹)

```rust
use prometheus::{
    Encoder, TextEncoder, Counter, Histogram, Registry,
    opts, register_counter_with_registry, register_histogram_with_registry,
};
use std::time::Instant;

pub struct ModelMetrics {
    pub registry: Registry,
    pub request_count: Counter,
    pub error_count: Counter,
    pub latency: Histogram,
}

impl ModelMetrics {
    pub fn new() -> Self {
        let registry = Registry::new();

        let request_count = register_counter_with_registry!(
            opts!("model_requests_total", "Total inference requests"),
            registry
        ).unwrap();

        let error_count = register_counter_with_registry!(
            opts!("model_errors_total", "Total inference errors"),
            registry
        ).unwrap();

        let latency = register_histogram_with_registry!(
            "model_latency_seconds",
            "Inference latency in seconds",
            vec![0.01, 0.05, 0.1, 0.5, 1.0],
            registry
        ).unwrap();

        Self {
            registry,
            request_count,
            error_count,
            latency,
        }
    }

    pub fn record_request<F, T>(&self, f: F) -> Result<T, Box<dyn std::error::Error>>
    where
        F: FnOnce() -> Result<T, Box<dyn std::error::Error>>,
    {
        self.request_count.inc();
        let start = Instant::now();

        let result = f();

        let elapsed = start.elapsed().as_secs_f64();
        self.latency.observe(elapsed);

        if result.is_err() {
            self.error_count.inc();
        }

        result
    }

    pub fn export_metrics(&self) -> String {
        let encoder = TextEncoder::new();
        let metric_families = self.registry.gather();
        let mut buffer = Vec::new();
        encoder.encode(&metric_families, &mut buffer).unwrap();
        String::from_utf8(buffer).unwrap()
    }
}

// Example usage
fn main() {
    let metrics = ModelMetrics::new();

    // Simulate inference requests
    for _ in 0..100 {
        let result = metrics.record_request(|| {
            // Simulate model inference
            std::thread::sleep(std::time::Duration::from_millis(50));
            Ok(())
        });

        if let Err(e) = result {
            eprintln!("Error: {}", e);
        }
    }

    // Export metrics in Prometheus format
    println!("{}", metrics.export_metrics());
}
```

å‡ºåŠ› (Prometheus format):
```
# HELP model_requests_total Total inference requests
# TYPE model_requests_total counter
model_requests_total 100

# HELP model_errors_total Total inference errors
# TYPE model_errors_total counter
model_errors_total 0

# HELP model_latency_seconds Inference latency in seconds
# TYPE model_latency_seconds histogram
model_latency_seconds_bucket{le="0.01"} 0
model_latency_seconds_bucket{le="0.05"} 100
model_latency_seconds_bucket{le="0.1"} 100
model_latency_seconds_bucket{le="0.5"} 100
model_latency_seconds_bucket{le="1"} 100
model_latency_seconds_bucket{le="+Inf"} 100
model_latency_seconds_sum 5.0
model_latency_seconds_count 100
```

**Prometheusã‚µãƒ¼ãƒãƒ¼ãŒã“ã‚Œã‚’scrapeã—ã¦æ™‚ç³»åˆ—DBã«ä¿å­˜ã€‚**

#### 4.2.3 Axum ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ & Graceful Shutdown

```rust
use axum::{
    routing::get,
    Router,
    response::Json,
    extract::State,
};
use serde_json::{json, Value};
use std::sync::{Arc, atomic::{AtomicBool, Ordering}};
use tokio::signal;

#[derive(Clone)]
struct AppState {
    pub ready: Arc<AtomicBool>,
    pub metrics: Arc<ModelMetrics>,
}

/// Liveness probe â€” is the process alive?
async fn health_live() -> Json<Value> {
    Json(json!({"status": "ok"}))
}

/// Readiness probe â€” is the model loaded and ready?
async fn health_ready(State(state): State<AppState>) -> Json<Value> {
    if state.ready.load(Ordering::SeqCst) {
        Json(json!({"status": "ready"}))
    } else {
        Json(json!({"status": "not_ready"}))
    }
}

/// Prometheus metrics endpoint
async fn metrics_endpoint(State(state): State<AppState>) -> String {
    state.metrics.export_metrics()
}

/// Run inference server with graceful shutdown
pub async fn run_server() {
    let ready = Arc::new(AtomicBool::new(false));
    let metrics = Arc::new(ModelMetrics::new());

    let state = AppState {
        ready: ready.clone(),
        metrics: metrics.clone(),
    };

    // Load model (simulate)
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
    ready.store(true, Ordering::SeqCst);
    println!("âœ… Model loaded, server ready");

    let app = Router::new()
        .route("/health/live",  get(health_live))
        .route("/health/ready", get(health_ready))
        .route("/metrics",      get(metrics_endpoint))
        .with_state(state.clone());

    let listener = tokio::net::TcpListener::bind("0.0.0.0:8080").await.unwrap();
    println!("ğŸš€ Server listening on :8080");

    axum::serve(listener, app)
        .with_graceful_shutdown(shutdown_signal(ready.clone()))
        .await
        .unwrap();
}

/// Wait for SIGINT/SIGTERM, then mark not-ready before shutdown
async fn shutdown_signal(ready: Arc<AtomicBool>) {
    let ctrl_c = async { signal::ctrl_c().await.expect("failed ctrl-c handler") };

    #[cfg(unix)]
    let terminate = async {
        signal::unix::signal(signal::unix::SignalKind::terminate())
            .expect("failed to install SIGTERM handler")
            .recv()
            .await;
    };

    tokio::select! {
        _ = ctrl_c => {},
        _ = terminate => {},
    }

    // Mark not-ready so k8s stops routing traffic before process exits
    ready.store(false, Ordering::SeqCst);
    println!("âš ï¸  Shutdown signal received â€” draining in-flight requestsâ€¦");
    tokio::time::sleep(tokio::time::Duration::from_secs(5)).await;
    println!("ğŸ‘‹ Shutdown complete");
}
```

**k8s Readiness Probe ã¨ã®çµ±åˆ**:

```yaml
readinessProbe:
  httpGet:
    path: /health/ready
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 10
livenessProbe:
  httpGet:
    path: /health/live
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 30
```

Graceful Shutdown ã®æµã‚Œ:
1. k8s ãŒ `SIGTERM` é€ä¿¡
2. ã‚¢ãƒ—ãƒªãŒ `/health/ready` ã‚’ `not_ready` ã«å¤‰æ›´
3. k8s ãŒãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’åœæ­¢ï¼ˆæœ€å¤§ `periodSeconds` å¾…æ©Ÿï¼‰
4. é€²è¡Œä¸­ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒãƒ‰ãƒ¬ã‚¤ãƒ³ï¼ˆ5ç§’ï¼‰
5. ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†

### 4.3 ğŸ”® Elixirç›£è¦–ã‚·ã‚¹ãƒ†ãƒ  â€” Telemetry & åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°

Elixirã§åˆ†æ•£ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã€‚`:telemetry`ã§ã‚¤ãƒ™ãƒ³ãƒˆã‚’åé›†ã—ã€`:gen_statem`ã§ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†ã€‚

#### 4.3.1 Telemetryçµ±åˆ

```elixir
defmodule MLOps.Telemetry do
  require Logger

  @doc """
  Attach telemetry handlers
  """
  def setup do
    :telemetry.attach_many(
      "mlops-telemetry",
      [
        [:model, :predict, :start],
        [:model, :predict, :stop],
        [:model, :predict, :exception]
      ],
      &handle_event/4,
      nil
    )
  end

  defp handle_event([:model, :predict, :start], _measurements, metadata, _config) do
    Logger.debug("Prediction started: #{inspect(metadata)}")
  end

  defp handle_event([:model, :predict, :stop], measurements, metadata, _config) do
    latency_ms = System.convert_time_unit(measurements.duration, :native, :millisecond)
    Logger.info("Prediction completed in #{latency_ms}ms: #{inspect(metadata)}")

    # Send to Prometheus
    :prometheus_histogram.observe(:model_latency_milliseconds, latency_ms)
  end

  defp handle_event([:model, :predict, :exception], measurements, metadata, _config) do
    Logger.error("Prediction failed: #{inspect(metadata)}")
    :prometheus_counter.inc(:model_errors_total)
  end
end

defmodule MLOps.Model do
  @doc """
  Run model prediction with telemetry
  """
  def predict(input) do
    metadata = %{model: "v1", input_size: byte_size(input)}

    :telemetry.span([:model, :predict], metadata, fn ->
      result = do_predict(input)
      {result, metadata}
    end)
  end

  defp do_predict(input) do
    # Simulate model inference
    Process.sleep(50)
    {:ok, "prediction for #{input}"}
  end
end

# Usage
MLOps.Telemetry.setup()

1..100 |> Enum.each(fn i -> MLOps.Model.predict("input_#{i}") end)
```

#### 4.3.2 SLOç›£è¦– & è‡ªå‹•ã‚¢ãƒ©ãƒ¼ãƒˆ

```elixir
defmodule MLOps.SLOMonitor do
  use GenServer
  require Logger

  @slo_latency_ms 100
  @slo_availability 0.999

  def start_link(_) do
    GenServer.start_link(__MODULE__, %{}, name: __MODULE__)
  end

  def init(_) do
    # Check SLO every minute
    :timer.send_interval(60_000, :check_slo)

    state = %{
      total_requests: 0,
      successful_requests: 0,
      latencies: []
    }

    {:ok, state}
  end

  def record_request(latency_ms, success) do
    GenServer.cast(__MODULE__, {:record, latency_ms, success})
  end

  def handle_cast({:record, latency_ms, success}, state) do
    new_state = %{
      total_requests: state.total_requests + 1,
      successful_requests: state.successful_requests + (if success, do: 1, else: 0),
      latencies: [latency_ms | Enum.take(state.latencies, 999)]  # Keep last 1000
    }

    {:noreply, new_state}
  end

  def handle_info(:check_slo, state) do
    availability = state.successful_requests / max(state.total_requests, 1)
    p99_latency = if length(state.latencies) > 0 do
      Enum.sort(state.latencies) |> Enum.at(round(length(state.latencies) * 0.99))
    else
      0
    end

    Logger.info("SLO Check: availability=#{Float.round(availability, 4)}, p99_latency=#{p99_latency}ms")

    cond do
      availability < @slo_availability ->
        send_alert("SLO violated: availability #{Float.round(availability * 100, 2)}% < #{@slo_availability * 100}%")

      p99_latency > @slo_latency_ms ->
        send_alert("SLO violated: p99 latency #{p99_latency}ms > #{@slo_latency_ms}ms")

      true ->
        Logger.info("âœ… SLO met")
    end

    {:noreply, state}
  end

  defp send_alert(message) do
    Logger.warn("ğŸš¨ ALERT: #{message}")
    # In production: send to PagerDuty/Slack/etc
  end
end

# Usage
{:ok, _} = MLOps.SLOMonitor.start_link([])

# Simulate requests
Enum.each(1..1000, fn _ ->
  latency = :rand.uniform(150)
  success = latency < 120
  MLOps.SLOMonitor.record_request(latency, success)
  Process.sleep(10)
end)
```

å‡ºåŠ› (1åˆ†ã”ã¨):
```
[info] SLO Check: availability=0.9820, p99_latency=148ms
[warn] ğŸš¨ ALERT: SLO violated: p99 latency 148ms > 100ms
```

**Elixirã®åˆ©ç‚¹**:

- OTP supervisorã§éšœå®³æ™‚è‡ªå‹•å†èµ·å‹•
- åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã§ãƒãƒ¼ãƒ‰é–“ã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹é›†ç´„
- Telemetryã§å…¨ã¦ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’çµ±ä¸€çš„ã«è¨˜éŒ²

#### 4.3.3 åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚° â€” OpenTelemetryçµ±åˆ

Elixirã§åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’å®Ÿè£…ã—ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å…¨çµŒè·¯ã‚’å¯è¦–åŒ–ã€‚

```elixir
defmodule MLOps.Tracer do
  require OpenTelemetry.Tracer, as: Tracer

  @doc """
  Trace model prediction with OpenTelemetry
  """
  def traced_predict(input) do
    Tracer.with_span "model.predict" do
      # Add span attributes
      Tracer.set_attributes([
        {"input.size", byte_size(input)},
        {"model.version", "v1"}
      ])

      # Child span: preprocessing
      result = Tracer.with_span "preprocessing" do
        preprocess(input)
      end

      # Child span: inference
      prediction = Tracer.with_span "inference" do
        do_inference(result)
      end

      # Child span: postprocessing
      Tracer.with_span "postprocessing" do
        postprocess(prediction)
      end
    end
  end

  defp preprocess(input), do: String.upcase(input)
  defp do_inference(preprocessed), do: "prediction_#{preprocessed}"
  defp postprocess(prediction), do: {:ok, prediction}
end

# Usage with trace propagation across services
MLOps.Tracer.traced_predict("test_input")
```

**OpenTelemetry Collector**ã§å…¨ã¦ã®traceã‚’åé›†ã—ã€Jaeger/Zipkinã§å¯è¦–åŒ–:

```
Span: model.predict [12.5ms]
â”œâ”€ Span: preprocessing [1.2ms]
â”œâ”€ Span: inference [10.0ms]
â””â”€ Span: postprocessing [1.3ms]
```

**åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã©ã“ã§é…å»¶ã—ã¦ã„ã‚‹ã‹ã‚’å¯è¦–åŒ–ã§ãã‚‹ã€‚**

### 4.4 ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º â€” KSæ¤œå®šãƒ»PSIãƒ»JSDå®Ÿè£…ï¼ˆRustï¼‰

æœ¬ç•ªãƒ¢ãƒ‡ãƒ«ã§**ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆ**ã‚’è‡ªå‹•æ¤œå‡ºã™ã‚‹ã€‚å­¦ç¿’æ™‚åˆ†å¸ƒã¨æ¨è«–æ™‚åˆ†å¸ƒã®ä¹–é›¢ã‚’çµ±è¨ˆçš„ã«æ¤œå®šã—ã€å¿…è¦ã«å¿œã˜ã¦å†è¨“ç·´ãƒˆãƒªã‚¬ãƒ¼ã‚’ç™ºç«ã•ã›ã‚‹ã€‚

#### 4.4.1 KSæ¤œå®šï¼ˆKolmogorov-Smirnov Testï¼‰

```rust
use std::collections::HashMap;

/// KSæ¤œå®šã§ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆã‚’æ¤œå‡º
/// H0: p_ref ã¨ p_curr ã¯åŒä¸€åˆ†å¸ƒ
/// p < 0.05 ãªã‚‰æœ‰æ„ãªãƒ‰ãƒªãƒ•ãƒˆã‚ã‚Š
fn detect_drift_ks(p_ref: &[f64], p_curr: &[f64], alpha: f64) -> HashMap<&'static str, String> {
    let n1 = p_ref.len() as f64;
    let n2 = p_curr.len() as f64;

    let mut sorted1 = p_ref.to_vec();
    let mut sorted2 = p_curr.to_vec();
    sorted1.sort_unstable_by(f64::total_cmp);
    sorted2.sort_unstable_by(f64::total_cmp);

    // å…¨ç‚¹ã§çµŒé¨“CDFå·®ã®æœ€å¤§å€¤ã‚’è¨ˆç®—ï¼ˆKSçµ±è¨ˆé‡ Dï¼‰
    let mut all_vals: Vec<f64> = sorted1.iter().chain(sorted2.iter()).copied().collect();
    all_vals.sort_unstable_by(f64::total_cmp);
    all_vals.dedup();

    let ks_stat = all_vals.iter().map(|&v| {
        let cdf1 = sorted1.iter().filter(|&&x| x <= v).count() as f64 / n1;
        let cdf2 = sorted2.iter().filter(|&&x| x <= v).count() as f64 / n2;
        (cdf1 - cdf2).abs()
    }).fold(0.0_f64, f64::max);

    // på€¤ã®è¿‘ä¼¼è¨ˆç®—ï¼ˆã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•åˆ†å¸ƒï¼‰
    let n_eff = (n1 * n2) / (n1 + n2);
    let lambda = (n_eff.sqrt() + 0.12 + 0.11 / n_eff.sqrt()) * ks_stat;
    let p_value = (2.0 * (-2.0 * lambda * lambda).exp()).min(1.0).max(0.0);

    HashMap::from([
        ("test",      "KS".to_string()),
        ("statistic", format!("{:.4}", ks_stat)),
        ("p_value",   format!("{:.4}", p_value)),
        ("drifted",   (p_value < alpha).to_string()),
        ("threshold", format!("{}", alpha)),
    ])
}

fn main() {
    use rand::distributions::{Distribution, StandardNormal};
    let mut rng = rand::thread_rng();

    // --- ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ---
    // å­¦ç¿’æ™‚åˆ†å¸ƒ: N(0, 1)
    let p_ref: Vec<f64> = (0..10_000)
        .map(|_| StandardNormal.sample(&mut rng))
        .collect();

    // ã‚±ãƒ¼ã‚¹1: ãƒ‰ãƒªãƒ•ãƒˆãªã—
    let p_stable: Vec<f64> = (0..1_000)
        .map(|_| StandardNormal.sample(&mut rng))
        .collect();
    let r1 = detect_drift_ks(&p_ref, &p_stable, 0.05);
    println!("ãƒ‰ãƒªãƒ•ãƒˆãªã—: {:?}", r1);

    // ã‚±ãƒ¼ã‚¹2: å¹³å‡ã‚·ãƒ•ãƒˆ (+1.0)
    let p_shifted: Vec<f64> = (0..1_000)
        .map(|_| StandardNormal.sample::<f64, _>(&mut rng) + 1.0)
        .collect();
    let r2 = detect_drift_ks(&p_ref, &p_shifted, 0.05);
    println!("å¹³å‡ã‚·ãƒ•ãƒˆ:   {:?}", r2);

    // ã‚±ãƒ¼ã‚¹3: åˆ†æ•£æ‹¡å¤§ (Ã—2)
    let p_wider: Vec<f64> = (0..1_000)
        .map(|_| StandardNormal.sample::<f64, _>(&mut rng) * 2.0)
        .collect();
    let r3 = detect_drift_ks(&p_ref, &p_wider, 0.05);
    println!("åˆ†æ•£æ‹¡å¤§:     {:?}", r3);
}
```

å‡ºåŠ›:
```
ãƒ‰ãƒªãƒ•ãƒˆãªã—: Dict("test"=>"KS", "statistic"=>0.0183, "p_value"=>0.8412, "drifted"=>false, "threshold"=>0.05)
å¹³å‡ã‚·ãƒ•ãƒˆ:   Dict("test"=>"KS", "statistic"=>0.3421, "p_value"=>0.0001, "drifted"=>true,  "threshold"=>0.05)
åˆ†æ•£æ‹¡å¤§:     Dict("test"=>"KS", "statistic"=>0.2197, "p_value"=>0.0023, "drifted"=>true,  "threshold"=>0.05)
```

#### 4.4.2 PSIï¼ˆPopulation Stability Indexï¼‰

PSI ã¯ã‚¹ã‚³ã‚¢åˆ†å¸ƒã®å®‰å®šæ€§ã‚’å®šé‡åŒ–ã™ã‚‹æ¥­ç•Œæ¨™æº–æŒ‡æ¨™ã€‚

| PSI å€¤    | è§£é‡ˆ                         |
|:----------|:-----------------------------|
| < 0.10    | å®‰å®šï¼ˆå†è¨“ç·´ä¸è¦ï¼‰            |
| 0.10â€“0.20 | è»½åº¦ã‚·ãƒ•ãƒˆï¼ˆãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°å¼·åŒ–ï¼‰|
| > 0.20    | é‡å¤§ã‚·ãƒ•ãƒˆï¼ˆå³æ™‚å†è¨“ç·´ï¼‰      |

```rust
use std::collections::HashMap;

/// PSI (Population Stability Index) ã‚’è¨ˆç®—
/// PSI = Î£ (p_curr - p_ref) Ã— ln(p_curr / p_ref)
fn calc_psi(p_ref: &[f64], p_curr: &[f64], n_bins: usize, eps: f64) -> HashMap<&'static str, String> {
    // ãƒ“ãƒ³å¢ƒç•Œã‚’å­¦ç¿’æ™‚åˆ†å¸ƒã®ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã§æ±ºå®š
    let mut sorted_ref = p_ref.to_vec();
    sorted_ref.sort_unstable_by(f64::total_cmp);

    let edges: Vec<f64> = (0..=n_bins).map(|i| {
        let idx = ((i as f64 / n_bins as f64) * (sorted_ref.len() - 1) as f64) as usize;
        sorted_ref[idx]
    }).collect();

    let edge_min = edges[0] - eps;
    let edge_max = edges[n_bins] + eps;

    // å„ãƒ“ãƒ³ã«ã‚µãƒ³ãƒ—ãƒ«ã‚’æŒ¯ã‚Šåˆ†ã‘ã¦ã‚«ã‚¦ãƒ³ãƒˆ
    let bin_for = |x: f64| -> usize {
        let x = x.max(edge_min).min(edge_max);
        edges[1..].iter().position(|&e| x <= e).unwrap_or(n_bins - 1)
    };

    let mut ref_counts  = vec![0usize; n_bins];
    let mut curr_counts = vec![0usize; n_bins];
    for &x in p_ref  { ref_counts[bin_for(x)]  += 1; }
    for &x in p_curr { curr_counts[bin_for(x)] += 1; }

    let ref_sum  = p_ref.len()  as f64;
    let curr_sum = p_curr.len() as f64;

    // PSI è¨ˆç®—
    let psi_total: f64 = ref_counts.iter().zip(curr_counts.iter()).map(|(&r, &c)| {
        let ref_pct  = (r as f64 + eps) / ref_sum;
        let curr_pct = (c as f64 + eps) / curr_sum;
        (curr_pct - ref_pct) * (curr_pct / ref_pct).ln()
    }).sum();

    HashMap::from([
        ("psi",     format!("{:.4}", psi_total)),
        ("drifted", (psi_total > 0.20).to_string()),
        ("warning", (psi_total > 0.10).to_string()),
    ])
}

fn main() {
    use rand::distributions::{Distribution, StandardNormal};
    let mut rng = rand::thread_rng();

    let p_ref: Vec<f64>     = (0..10_000).map(|_| StandardNormal.sample(&mut rng)).collect();
    let p_stable: Vec<f64>  = (0..1_000).map(|_| StandardNormal.sample(&mut rng)).collect();
    let p_shifted: Vec<f64> = (0..1_000).map(|_| StandardNormal.sample::<f64, _>(&mut rng) + 1.0).collect();
    let p_wider: Vec<f64>   = (0..1_000).map(|_| StandardNormal.sample::<f64, _>(&mut rng) * 2.0).collect();

    println!("=== PSIåˆ†æ ===");
    println!("ãƒ‰ãƒªãƒ•ãƒˆãªã—: PSI = {}", calc_psi(&p_ref, &p_stable,  10, 1e-6)["psi"]);
    println!("å¹³å‡ã‚·ãƒ•ãƒˆ:   PSI = {}", calc_psi(&p_ref, &p_shifted, 10, 1e-6)["psi"]);
    println!("åˆ†æ•£æ‹¡å¤§:     PSI = {}", calc_psi(&p_ref, &p_wider,   10, 1e-6)["psi"]);
}
```

å‡ºåŠ›:
```
=== PSIåˆ†æ ===
ãƒ‰ãƒªãƒ•ãƒˆãªã—: PSI = 0.0041
å¹³å‡ã‚·ãƒ•ãƒˆ:   PSI = 0.3812
åˆ†æ•£æ‹¡å¤§:     PSI = 0.2253
```

#### 4.4.3 JSDï¼ˆJensen-Shannon Divergenceï¼‰& è‡ªå‹•å†è¨“ç·´ãƒˆãƒªã‚¬ãƒ¼

```rust
use std::collections::HashMap;
use chrono::Local;

/// Jensen-Shannon Divergenceï¼ˆå¯¾ç§°KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ï¼‰
/// JSD âˆˆ [0, 1]ã€å€¤ãŒå¤§ãã„ã»ã©åˆ†å¸ƒã®ä¹–é›¢ãŒå¤§
fn calc_jsd(p_ref: &[f64], p_curr: &[f64], n_bins: usize, eps: f64) -> f64 {
    let mut sorted_ref = p_ref.to_vec();
    sorted_ref.sort_unstable_by(f64::total_cmp);

    let edges: Vec<f64> = (0..=n_bins).map(|i| {
        let idx = ((i as f64 / n_bins as f64) * (sorted_ref.len() - 1) as f64) as usize;
        sorted_ref[idx]
    }).collect();
    let edge_min = edges[0] - eps;
    let edge_max = edges[n_bins] + eps;

    let bin_for = |x: f64| -> usize {
        let x = x.max(edge_min).min(edge_max);
        edges[1..].iter().position(|&e| x <= e).unwrap_or(n_bins - 1)
    };

    let mut ref_counts  = vec![0usize; n_bins];
    let mut curr_counts = vec![0usize; n_bins];
    for &x in p_ref  { ref_counts[bin_for(x)]  += 1; }
    for &x in p_curr { curr_counts[bin_for(x)] += 1; }

    // æ­£è¦åŒ–ã—ã¦ç¢ºç‡åˆ†å¸ƒã«å¤‰æ›
    let ref_sum  = p_ref.len()  as f64;
    let curr_sum = p_curr.len() as f64;
    let p: Vec<f64> = ref_counts.iter().map(|&c|  (c as f64 + eps) / ref_sum).collect();
    let q: Vec<f64> = curr_counts.iter().map(|&c| (c as f64 + eps) / curr_sum).collect();
    let m: Vec<f64> = p.iter().zip(q.iter()).map(|(pi, qi)| (pi + qi) / 2.0).collect();

    let kl_pm: f64 = p.iter().zip(m.iter()).map(|(pi, mi)| pi * (pi / mi).ln()).sum();
    let kl_qm: f64 = q.iter().zip(m.iter()).map(|(qi, mi)| qi * (qi / mi).ln()).sum();
    let jsd = (kl_pm + kl_qm) / 2.0;

    (jsd * 10000.0).round() / 10000.0
}

/// çµ±åˆãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ â€” å…¨æŒ‡æ¨™ã‚’çµ±åˆã—ã¦ã‚¢ãƒ©ãƒ¼ãƒˆ
fn drift_pipeline(p_ref: &[f64], p_curr: &[f64]) {
    let ks  = detect_drift_ks(p_ref, p_curr, 0.05);
    let psi = calc_psi(p_ref, p_curr, 10, 1e-6);
    let jsd = calc_jsd(p_ref, p_curr, 10, 1e-6);

    let psi_val: f64 = psi["psi"].parse().unwrap_or(0.0);
    let drifted: bool = ks["drifted"].parse().unwrap_or(false);
    let warning: bool = psi["warning"].parse().unwrap_or(false);

    // ã‚¢ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«ã®åˆ¤å®š
    let alert = if psi_val > 0.20 || drifted {
        "ğŸš¨ CRITICAL â€” å³æ™‚å†è¨“ç·´ãƒˆãƒªã‚¬ãƒ¼"
    } else if warning {
        "âš ï¸  WARNING  â€” ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°å¼·åŒ–"
    } else {
        "âœ… STABLE   â€” æ­£å¸¸é‹ç”¨ç¶™ç¶š"
    };

    println!("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
    println!("â”‚ ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆãƒ¬ãƒãƒ¼ãƒˆ                    â”‚");
    println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
    println!("â”‚ KSçµ±è¨ˆé‡  : {:>8}  (p={})          â”‚", ks["statistic"], ks["p_value"]);
    println!("â”‚ PSI       : {:>8}                   â”‚", psi["psi"]);
    println!("â”‚ JSD       : {:>8}                   â”‚", jsd);
    println!("â”‚ åˆ¤å®š      : {}", alert);
    println!("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");

    // è‡ªå‹•å†è¨“ç·´ãƒˆãƒªã‚¬ãƒ¼
    if psi_val > 0.20 {
        println!("ğŸ”„ å†è¨“ç·´ã‚¸ãƒ§ãƒ–ã‚’ã‚­ãƒ¥ãƒ¼æŠ•å…¥: {}", Local::now().format("%Y-%m-%dT%H:%M:%S"));
        // trigger_retrain_job("model-v1");  // å®Ÿè£…ä¾‹
    }
}

fn main() {
    use rand::distributions::{Distribution, StandardNormal};
    let mut rng = rand::thread_rng();

    let p_ref: Vec<f64>     = (0..10_000).map(|_| StandardNormal.sample(&mut rng)).collect();
    let p_stable: Vec<f64>  = (0..1_000).map(|_| StandardNormal.sample(&mut rng)).collect();
    let p_shifted: Vec<f64> = (0..1_000).map(|_| StandardNormal.sample::<f64, _>(&mut rng) + 1.0).collect();

    drift_pipeline(&p_ref, &p_stable);
    drift_pipeline(&p_ref, &p_shifted);
}
```

**KSæ¤œå®š vs PSI ã®ä½¿ã„åˆ†ã‘**:

| æŒ‡æ¨™ | å¼·ã¿ | é©ç”¨å ´é¢ |
|:-----|:-----|:---------|
| **KSæ¤œå®š** | é€£ç¶šåˆ†å¸ƒã®æœ€å¤§å·®ã‚’æ¤œå‡º | æ•°å€¤ç‰¹å¾´é‡ãƒ»ã‚¹ã‚³ã‚¢åˆ†å¸ƒ |
| **PSI** | æ¥­ç•Œæ¨™æº–ãƒ»è§£é‡ˆã—ã‚„ã™ã„ | ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚³ã‚¢ãƒ»ãƒ­ãƒ¼ãƒ³å¯©æŸ» |
| **JSD** | å¯¾ç§°ãƒ»ç¢ºç‡è«–çš„æ ¹æ‹  | ç¢ºç‡åˆ†å¸ƒé–“ã®æ¯”è¼ƒ |

### 4.5 æ¼”ç¿’: ãƒ¢ãƒ‡ãƒ«ã‚¬ãƒãƒŠãƒ³ã‚¹ & MLOpsçµ±åˆ

å®Ÿè£…ã—ãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’çµ±åˆã—ã€**ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ä½œæˆãƒ»SHAPå¯è¦–åŒ–ãƒ»ç›£æŸ»ãƒ­ã‚°ãƒ»MLflow+Prometheusç›£è¦–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

#### 4.5.1 ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰è‡ªå‹•ç”Ÿæˆï¼ˆRustï¼‰

```rust
use std::collections::HashMap;
use chrono::{DateTime, Local};
use std::fs::OpenOptions;
use std::io::Write;

/// ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰: å…¬å¹³æ€§ãƒ»æ€§èƒ½ãƒ»åˆ¶ç´„ã‚’æ–‡æ›¸åŒ–ã™ã‚‹æ¨™æº–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
struct ModelCard {
    model_name:    String,
    version:       String,
    trained_at:    DateTime<Local>,
    author:        String,
    description:   String,
    metrics:       HashMap<String, f64>,
    fairness:      HashMap<String, f64>,
    limitations:   Vec<String>,
    intended_use:  String,
    mlflow_run_id: String,
}

fn generate_model_card(card: &ModelCard) -> String {
    let metrics_md: String = card.metrics.iter()
        .map(|(k, v)| format!("- **{}**: {:.4}", k, v))
        .collect::<Vec<_>>()
        .join("\n");

    let fairness_md: String = card.fairness.iter()
        .map(|(k, v)| format!("- **{}**: {:.4}", k, v))
        .collect::<Vec<_>>()
        .join("\n");

    let limitations_md: String = card.limitations.iter()
        .map(|l| format!("- {}", l))
        .collect::<Vec<_>>()
        .join("\n");

    format!(
        "# Model Card: {} v{}\n\n\
         **ä½œæˆæ—¥**: {}\n\
         **ä½œè€…**: {}\n\
         **MLflow Run**: `{}`\n\n\
         ## æ¦‚è¦\n{}\n\n\
         ## æ„å›³ã•ã‚ŒãŸç”¨é€”\n{}\n\n\
         ## æ€§èƒ½æŒ‡æ¨™\n{}\n\n\
         ## å…¬å¹³æ€§è©•ä¾¡\n{}\n\n\
         ## æ—¢çŸ¥ã®åˆ¶é™äº‹é …\n{}\n",
        card.model_name,
        card.version,
        card.trained_at.format("%Y-%m-%d"),
        card.author,
        card.mlflow_run_id,
        card.description,
        card.intended_use,
        metrics_md,
        fairness_md,
        limitations_md,
    )
}

fn main() -> std::io::Result<()> {
    // å®Ÿéš›ã®ä½¿ç”¨ä¾‹
    let card = ModelCard {
        model_name:    "fraud-detection-xgb".to_string(),
        version:       "2.1.0".to_string(),
        trained_at:    Local::now(),
        author:        "MLOps Team".to_string(),
        description:   "XGBoostãƒ™ãƒ¼ã‚¹ã®ä¸æ­£å–å¼•æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã€‚ç‰¹å¾´é‡50å€‹ã‚’ä½¿ç”¨ã€‚".to_string(),
        metrics:       HashMap::from([
            ("accuracy".to_string(), 0.9823),
            ("f1".to_string(),       0.8741),
            ("auc_roc".to_string(),  0.9912),
        ]),
        fairness:      HashMap::from([
            ("male_fpr".to_string(),        0.012),
            ("female_fpr".to_string(),      0.011),
            ("disparity_ratio".to_string(), 1.09),
        ]),
        limitations:   vec![
            "6ãƒ¶æœˆä»¥ä¸Šå‰ã®ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã¯å¯¾å¿œã—ã¦ã„ãªã„".to_string(),
            "æ¥µç«¯ã«é«˜é¡ãªå–å¼•ï¼ˆ>$1Mï¼‰ã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸è¶³".to_string(),
        ],
        intended_use:  "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ±ºæ¸ˆã‚·ã‚¹ãƒ†ãƒ ã§ã®ä¸æ­£æ¤œå‡ºï¼ˆB2Cï¼‰".to_string(),
        mlflow_run_id: "a3f9c2e1b4d87f3a".to_string(),
    };

    let md_output = generate_model_card(&card);
    let mut file = OpenOptions::new().write(true).create(true).truncate(true)
        .open("model_card_v2.1.0.md")?;
    file.write_all(md_output.as_bytes())?;
    println!("âœ… ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ç”Ÿæˆå®Œäº†");
    Ok(())
}
```

#### 4.5.2 ç›£æŸ»ãƒ­ã‚°å®Ÿè£…ï¼ˆRust + JSON Linesï¼‰

```rust
use std::collections::HashMap;
use std::fs::OpenOptions;
use std::io::Write;
use std::time::Instant;
use chrono::{DateTime, Local};
use serde_json::json;
use uuid::Uuid;

/// ç›£æŸ»ãƒ­ã‚°: èª°ãŒãƒ»ã„ã¤ãƒ»ä½•ã‚’ãƒ»ã©ã‚“ãªå…¥å‡ºåŠ›ã§æ¨è«–ã—ãŸã‹ã‚’è¨˜éŒ²
/// GDPR/é‡‘èè¦åˆ¶å¯¾å¿œã«å¿…é ˆ
struct AuditEntry {
    request_id:    String,
    timestamp:     DateTime<Local>,
    user_id:       String,
    model_name:    String,
    model_version: String,
    input_hash:    String,   // ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·: ç”Ÿãƒ‡ãƒ¼ã‚¿ã§ã¯ãªããƒãƒƒã‚·ãƒ¥
    output:        f64,
    latency_ms:    f64,
    decision:      String,
    explanation:   HashMap<&'static str, f64>,
}

fn log_audit(entry: &AuditEntry, log_file: &str) -> std::io::Result<()> {
    let record = json!({
        "request_id":  entry.request_id,
        "timestamp":   entry.timestamp.format("%Y-%m-%dT%H:%M:%S%.3f").to_string(),
        "user_id":     entry.user_id,
        "model":       format!("{}@{}", entry.model_name, entry.model_version),
        "input_hash":  entry.input_hash,
        "output":      entry.output,
        "latency_ms":  entry.latency_ms,
        "decision":    entry.decision,
        "explanation": entry.explanation,
    });
    let mut file = OpenOptions::new().append(true).create(true).open(log_file)?;
    writeln!(file, "{}", record)?;
    Ok(())
}

fn sigmoid(x: f64) -> f64 { 1.0 / (1.0 + (-x).exp()) }

/// æ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ„ã¿è¾¼ã‚€ä¾‹
fn predict_with_audit(
    input_features: &[f64],
    user_id: &str,
    model_version: &str,
) -> (String, f64, String) {
    let request_id = Uuid::new_v4().to_string();
    let t_start = Instant::now();

    // æ¨è«– (ç–‘ä¼¼å®Ÿè£…)
    use std::collections::hash_map::DefaultHasher;
    use std::hash::{Hash, Hasher};
    let dot: f64 = input_features.iter().enumerate()
        .map(|(i, &x)| x * ((i as f64 * 1.1).sin())) // ç–‘ä¼¼é‡ã¿
        .sum();
    let score = sigmoid(dot);
    let decision = if score > 0.5 { "FRAUD" } else { "LEGITIMATE" };

    // SHAPå€¤ã«ã‚ˆã‚‹èª¬æ˜ (ç–‘ä¼¼å®Ÿè£…)
    let shap_values: HashMap<&'static str, f64> = HashMap::from([
        ("amount_usd",    0.32),
        ("merchant_risk", 0.28),
        ("user_history", -0.15),
        ("device_age",   -0.08),
    ]);

    let latency_ms = t_start.elapsed().as_secs_f64() * 1000.0;

    // ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·: å…¥åŠ›ã‚’ãƒãƒƒã‚·ãƒ¥åŒ–
    let mut hasher = DefaultHasher::new();
    for &x in input_features { x.to_bits().hash(&mut hasher); }
    let input_hash = format!("{:016x}", hasher.finish());

    let entry = AuditEntry {
        request_id: request_id.clone(),
        timestamp: Local::now(),
        user_id: user_id.to_string(),
        model_name: "fraud-detection-xgb".to_string(),
        model_version: model_version.to_string(),
        input_hash,
        output: score,
        latency_ms,
        decision: decision.to_string(),
        explanation: shap_values,
    };
    let _ = log_audit(&entry, "audit.jsonl");

    (decision.to_string(), score, request_id)
}

fn main() {
    use rand::Rng;
    let mut rng = rand::thread_rng();

    // ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    for i in 1..=5 {
        let features: Vec<f64> = (0..10).map(|_| rng.gen::<f64>() * 2.0 - 1.0).collect();
        let (decision, score, request_id) = predict_with_audit(&features, &format!("user_{}", i), "2.1.0");
        println!("Request {}â€¦: {} (score={:.3})", &request_id[..8], decision, score);
    }
    println!("âœ… ç›£æŸ»ãƒ­ã‚°è¨˜éŒ²å®Œäº† â†’ audit.jsonl");
}
```

#### 4.5.3 MLflow + Prometheus ç›£è¦–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆ

```rust
use reqwest::blocking::Client;
use serde_json::json;
use std::collections::HashMap;
use chrono::Local;

/// å®Œå…¨MLOpsãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³:
/// è¨“ç·´ â†’ MLflowè¨˜éŒ² â†’ ãƒ‰ãƒªãƒ•ãƒˆç›£è¦– â†’ Prometheusé€šçŸ¥ â†’ è‡ªå‹•å†è¨“ç·´
fn full_mlops_pipeline(
    client: &Client,
    experiment_name: &str,
    retrain_threshold_psi: f64,
) -> Result<&'static str, Box<dyn std::error::Error>> {
    println!("{}", "=".repeat(50));
    println!("ğŸš€ MLOpsçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ é–‹å§‹: {}", Local::now().format("%Y-%m-%dT%H:%M:%S"));
    println!("{}", "=".repeat(50));

    // Step 1: MLflowå®Ÿé¨“ã‚’é–‹å§‹
    let run_name = format!("monitoring-run-{}", Local::now().format("%Y%m%d-%H%M%S"));
    let run_id = create_run(client, "0", &run_name)?;
    println!("ğŸ“Š MLflow Run: {}", run_id);

    // Step 2: å‚ç…§ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆå­¦ç¿’æ™‚åˆ†å¸ƒï¼‰
    use rand::distributions::{Distribution, StandardNormal};
    let mut rng = rand::thread_rng();
    let p_ref:  Vec<f64> = (0..10_000).map(|_| StandardNormal.sample(&mut rng)).collect();
    let p_curr: Vec<f64> = (0..1_000)
        .map(|_| StandardNormal.sample::<f64, _>(&mut rng) + 0.3) // è»½åº¦ã‚·ãƒ•ãƒˆ
        .collect();

    // Step 3: ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º
    let psi_result = calc_psi(&p_ref, &p_curr, 10, 1e-6);
    let ks_result  = detect_drift_ks(&p_ref, &p_curr, 0.05);
    let jsd_val    = calc_jsd(&p_ref, &p_curr, 10, 1e-6);

    let psi_val: f64 = psi_result["psi"].parse().unwrap_or(0.0);
    let ks_stat: f64 = ks_result["statistic"].parse().unwrap_or(0.0);

    // Step 4: ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’MLflowã«è¨˜éŒ²
    let metrics: HashMap<&str, f64> = HashMap::from([
        ("psi",          psi_val),
        ("ks_statistic", ks_stat),
        ("jsd",          jsd_val),
    ]);
    log_metrics(client, &run_id, &metrics, 1)?;
    let params: HashMap<&str, String> = HashMap::from([
        ("reference_n", "10000".to_string()),
        ("current_n",   "1000".to_string()),
    ]);
    log_params(client, &run_id, &params)?;

    // Step 5: Prometheusã‚²ãƒ¼ã‚¸ã‚’æ›´æ–° (pushgatewayçµŒç”±)
    push_to_prometheus(client, &HashMap::from([
        ("model_psi",          psi_val),
        ("model_ks_statistic", ks_stat),
        ("model_jsd",          jsd_val),
    ]));

    // Step 6: è‡ªå‹•å†è¨“ç·´ãƒˆãƒªã‚¬ãƒ¼åˆ¤å®š
    if psi_val > retrain_threshold_psi {
        println!("ğŸš¨ PSI={:.4} > {} â€” å†è¨“ç·´ãƒˆãƒªã‚¬ãƒ¼ç™ºç«ï¼", psi_val, retrain_threshold_psi);
        let trigger_params: HashMap<&str, String> = HashMap::from([
            ("retrain_triggered", "true".to_string()),
            ("trigger_reason",    "PSI".to_string()),
        ]);
        log_params(client, &run_id, &trigger_params)?;
        end_run(client, &run_id, "FINISHED")?;
        return Ok("retrain_triggered");
    }

    end_run(client, &run_id, "FINISHED")?;
    println!("âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº† â€” ãƒ‰ãƒªãƒ•ãƒˆãªã—");
    Ok("stable")
}

fn push_to_prometheus(client: &Client, metrics: &HashMap<&str, f64>) {
    // Pushgateway ã¸ã® POST (å®Ÿéš›ã®é‹ç”¨ã§ã¯ä½¿ç”¨)
    let url = "http://localhost:9091/metrics/job/mlops_drift_monitor";
    let body: String = metrics.iter()
        .map(|(k, v)| format!("{} {}", k, v))
        .collect::<Vec<_>>()
        .join("\n") + "\n";
    match client.post(url).body(body).send() {
        Ok(_)  => println!("ğŸ“¡ Prometheus Pushgateway æ›´æ–°å®Œäº†"),
        Err(e) => eprintln!("Pushgateway æœªèµ·å‹•ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆæ™‚ã¯ç„¡è¦–å¯ï¼‰: {}", e),
    }
}

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let client = Client::new();
    // ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
    let status = full_mlops_pipeline(&client, "production-monitoring", 0.20)?;
    println!("æœ€çµ‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {}", status);
    Ok(())
}
```

**çµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**:

```
[Rust è¨“ç·´ãƒ«ãƒ¼ãƒ— (Candle)]
      â”‚ MLflow.log_metric()
      â–¼
[MLflow Tracking Server] â”€â”€â”€â”€â”€â”€â–º [MLflow Model Registry]
      â”‚                                    â”‚
      â”‚ ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºãƒ«ãƒ¼ãƒ—                  â”‚ ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†
      â–¼                                    â–¼
[KS/PSI/JSD è¨ˆç®—] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [Prometheus Pushgateway]
      â”‚                                    â”‚
      â”‚ PSI > 0.20                         â”‚ scrape
      â–¼                                    â–¼
[å†è¨“ç·´ã‚¸ãƒ§ãƒ–ã‚­ãƒ¥ãƒ¼]              [Grafana ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰]
      â”‚                                    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Slack/PagerDuty ã‚¢ãƒ©ãƒ¼ãƒˆ â—„â”˜
```

> **ãƒ¢ãƒ‡ãƒ«ã‚¬ãƒãƒŠãƒ³ã‚¹ ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**
> - [ ] ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã«å…¬å¹³æ€§æŒ‡æ¨™ï¼ˆgender/raceåˆ¥FPR disparity < 1.2ï¼‰ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹
> - [ ] å…¨æ¨è«–ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒç›£æŸ»ãƒ­ã‚°ï¼ˆJSON Linesï¼‰ã«è¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹
> - [ ] ãƒ‰ãƒªãƒ•ãƒˆç›£è¦–ï¼ˆPSI/KSï¼‰ãŒæœ¬ç•ªç’°å¢ƒã§ç¨¼åƒã—ã¦ã„ã‚‹
> - [ ] MLflow Run IDã§ä»»æ„ã®å®Ÿé¨“ã‚’å®Œå…¨å†ç¾ã§ãã‚‹
> - [ ] Graceful Shutdown å®Ÿè£…ã«ã‚ˆã‚Š k8s ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§æ¨è«–ã‚¼ãƒ­ãƒ€ã‚¦ãƒ³

---

> Progress: 90%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. Rust + MLflowã«ã‚ˆã‚‹å®Ÿé¨“ç®¡ç†ã§ã€`log_metric` ã¨ `log_param` ã‚’ä½¿ã„åˆ†ã‘ã‚‹è¨­è¨ˆåŸå‰‡ã¨ã€Artifactç®¡ç†ã«ã‚ˆã‚‹å†ç¾æ€§ä¿è¨¼ã‚’èª¬æ˜ã›ã‚ˆã€‚
> 2. PSIï¼ˆPopulation Stability Indexï¼‰ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã«ãŠã„ã¦ã€é–¾å€¤ï¼ˆPSI > 0.2 = Significant Shiftï¼‰ã®çµ±è¨ˆçš„æ ¹æ‹ ã¨ã€KSæ¤œå®šã¨ã®ä½¿ã„åˆ†ã‘ã‚’èª¬æ˜ã›ã‚ˆã€‚

### ğŸ”¬ å®Ÿé¨“ãƒ»æ¤œè¨¼ï¼ˆ30åˆ†ï¼‰â€” è‡ªå·±è¨ºæ–­ & ãƒŸãƒ‹PJ

### 5.1 MLOpsçŸ¥è­˜ãƒã‚§ãƒƒã‚¯ (10å•)

<details><summary>å•é¡Œ1: ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã®5-tuple</summary>

ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ $\mathcal{M}_t$ ã‚’æ§‹æˆã™ã‚‹5ã¤ã®è¦ç´ ã¯ï¼Ÿ

**ç­”ãˆ**: $(\mathbf{w}_t, \mathcal{D}_t, \mathcal{H}_t, \mathcal{E}_t, s_t)$

- $\mathbf{w}_t$: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ™ã‚¯ãƒˆãƒ«
- $\mathcal{D}_t$: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
- $\mathcal{H}_t$: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
- $\mathcal{E}_t$: ç’°å¢ƒ (Python/CUDA version)
- $s_t$: Random seed

**å†ç¾æ€§ = 5ã¤å…¨ã¦ä¸€è‡´**

</details>

<details><summary>å•é¡Œ2: Error Budgetã®è¨ˆç®—</summary>

SLO = 99.9% (uptime) ã®å ´åˆã€30æ—¥é–“ã®Error Budgetã¯ä½•åˆ†ï¼Ÿ

**ç­”ãˆ**:

$$
\text{Error Budget} = (1 - 0.999) \times 30 \times 24 \times 60 = 43.2 \text{ minutes}
$$

**æœˆã«43.2åˆ†ã¾ã§ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ OKã€‚è¶…ãˆãŸã‚‰æ–°æ©Ÿèƒ½é–‹ç™ºåœæ­¢ã€‚**

</details>

<details><summary>å•é¡Œ3: A/Bãƒ†ã‚¹ãƒˆã®ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º</summary>

$p_A = 0.10$, MDE = 0.02, $\alpha=0.05$, power = 0.8 ã®å ´åˆã€å¿…è¦ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã¯ï¼Ÿ

**ç­”ãˆ**:

$$
n = \frac{(1.96 + 0.84)^2 \cdot 2 \cdot 0.10 \cdot 0.90}{0.02^2} \approx 3528 \text{ per group}
$$

**åˆè¨ˆ 7,056 ãƒ¦ãƒ¼ã‚¶ãƒ¼å¿…è¦ã€‚**

</details>

<details><summary>å•é¡Œ4: KSæ¤œå®šã®på€¤è§£é‡ˆ</summary>

KSæ¤œå®šã§ $p = 0.001$ ãŒå¾—ã‚‰ã‚ŒãŸã€‚æœ‰æ„æ°´æº– $\alpha=0.01$ ã§å¸°ç„¡ä»®èª¬ã‚’æ£„å´ã§ãã‚‹ã‹ï¼Ÿ

**ç­”ãˆ**: **Yes**

$$
p = 0.001 < \alpha = 0.01 \Rightarrow \text{Reject } H_0
$$

**ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆã‚’æ¤œå‡º â†’ å†è¨“ç·´ã‚’ãƒˆãƒªã‚¬ãƒ¼**

</details>

<details><summary>å•é¡Œ5: PSIã®é–¾å€¤</summary>

PSI = 0.18 ãŒå¾—ã‚‰ã‚ŒãŸã€‚å†è¨“ç·´ã¯å¿…è¦ã‹ï¼Ÿ

**ç­”ãˆ**: **è»½å¾®ãªãƒ‰ãƒªãƒ•ãƒˆã€ç›£è¦–ç¶™ç¶š**

| PSI | è§£é‡ˆ |
|:----|:-----|
| < 0.1 | ãƒ‰ãƒªãƒ•ãƒˆãªã— |
| 0.1 - 0.25 | è»½å¾®ãªãƒ‰ãƒªãƒ•ãƒˆ (ç›£è¦–) |
| > 0.25 | é‡å¤§ãªãƒ‰ãƒªãƒ•ãƒˆ (å†è¨“ç·´) |

**0.18ã¯ç›£è¦–ç¶™ç¶šã‚¾ãƒ¼ãƒ³ã€‚**

</details>

<details><summary>å•é¡Œ6: DPO lossã®å¼</summary>

DPO lossã‚’æ›¸ã‘ã€‚

**ç­”ãˆ**:

$$
\mathcal{L}_{\text{DPO}} = -\mathbb{E} \left[ \log \sigma\left( \beta \log \frac{\pi_\theta(y_w \mid x)}{\pi_{\text{ref}}(y_w \mid x)} - \beta \log \frac{\pi_\theta(y_l \mid x)}{\pi_{\text{ref}}(y_l \mid x)} \right) \right]
$$

**Bradley-Terry Model + KLæ­£å‰‡åŒ–ã®é–‰å½¢å¼è§£ã€‚**

</details>

<details><summary>å•é¡Œ7: Canary Deploymentã®æ®µéš</summary>

1% â†’ 5% â†’ ? â†’ 100% ã® ? ã¯ä½•%ï¼Ÿ

**ç­”ãˆ**: **25%**

æ¨™æº–çš„ãªã‚«ãƒŠãƒªã‚¢ãƒªãƒªãƒ¼ã‚¹: 1% â†’ 5% â†’ 25% â†’ 100%

**å„ã‚¹ãƒ†ãƒ¼ã‚¸ã§ã‚¨ãƒ©ãƒ¼ç‡ã‚’ç›£è¦–ã€‚ç•°å¸¸ãªã‚‰å³ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚**

</details>

<details><summary>å•é¡Œ8: RED Metricsã®3è¦ç´ </summary>

REDã®3è¦ç´ ã¯ï¼Ÿ

**ç­”ãˆ**:

- **Rate**: ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°/ç§’
- **Errors**: ã‚¨ãƒ©ãƒ¼æ•°/ç§’
- **Duration**: ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (p50/p95/p99)

**å…¨ã¦ã®ã‚µãƒ¼ãƒ“ã‚¹ã§æœ€ä½é™ç›£è¦–ã™ã¹ããƒ¡ãƒˆãƒªã‚¯ã‚¹ã€‚**

</details>

<details><summary>å•é¡Œ9: Reward Modelingã®æå¤±é–¢æ•°</summary>

Bradley-Terry Modelã®æå¤±é–¢æ•°ã‚’æ›¸ã‘ã€‚

**ç­”ãˆ**:

$$
\mathcal{L}_{\text{RM}} = -\mathbb{E} \left[ \log \sigma(r(x, y_w) - r(x, y_l)) \right]
$$

**å¥½ã¾ã—ã„å¿œç­” $y_w$ ã®rewardã‚’ä¸Šã’ã€å¥½ã¾ã—ããªã„å¿œç­” $y_l$ ã®rewardã‚’ä¸‹ã’ã‚‹ã€‚**

</details>

<details><summary>å•é¡Œ10: Git LFSã¨DVCã®é•ã„</summary>

Git LFSã¨DVCã®ä¸»ãªé•ã„ã¯ï¼Ÿ

**ç­”ãˆ**:

| è¦³ç‚¹ | Git LFS | DVC |
|:-----|:--------|:----|
| **ç”¨é€”** | ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« (ãƒã‚¤ãƒŠãƒª) | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (CSV/ç”»åƒ) |
| **ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰** | GitHub LFS / S3 | S3/GCS/Azure/SSH |
| **ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³** | âŒãªã— | âœ…ã‚ã‚Š (dvc.yaml) |
| **ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿** | `.gitattributes` | `.dvc` ãƒ•ã‚¡ã‚¤ãƒ« |

**DVC = ãƒ‡ãƒ¼ã‚¿ç‰ˆGit + ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç®¡ç†ã€‚**

</details>

### 5.2 ãƒŸãƒ‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ1: ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²ã‚·ã‚¹ãƒ†ãƒ 

**ç›®æ¨™**: ğŸ¦€Rustã§è¨“ç·´ãƒ«ãƒ¼ãƒ—ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’MLflowã«è¨˜éŒ²ã€‚

```rust
use reqwest::blocking::Client;
use std::collections::HashMap;

// (4.1ã®MLflowé–¢æ•°ã‚’ä½¿ç”¨)

fn train_tiny_model(client: &Client, lr: f64, epochs: usize)
    -> Result<String, Box<dyn std::error::Error>>
{
    let run_id = create_run(client, "0", &format!("tiny-model-lr-{}", lr))?;

    // ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨˜éŒ²
    let params: HashMap<&str, String> = HashMap::from([
        ("lr",     lr.to_string()),
        ("epochs", epochs.to_string()),
    ]);
    log_params(client, &run_id, &params)?;

    // è¨“ç·´ãƒ«ãƒ¼ãƒ—
    for epoch in 0..epochs {
        // ç–‘ä¼¼è¨“ç·´
        let train_loss = 1.0 / (1.0 + (epoch + 1) as f64 * lr);
        let val_acc    = 0.7 + (epoch + 1) as f64 * 0.03;

        // ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²
        let metrics: HashMap<&str, f64> = HashMap::from([
            ("train_loss", train_loss),
            ("val_acc",    val_acc),
        ]);
        log_metrics(client, &run_id, &metrics, epoch as i64)?;
    }

    end_run(client, &run_id, "FINISHED")?;
    Ok(run_id)
}

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let client = Client::new();

    // ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚¹ã‚¤ãƒ¼ãƒ—ã‚’å®Ÿè¡Œ
    for &lr in &[0.001_f64, 0.01, 0.1] {
        let run_id = train_tiny_model(&client, lr, 10)?;
        println!("Completed run: {} with lr={}", run_id, lr);
    }
    Ok(())
}
```

**MLflow UI** ã§3ã¤ã®runã‚’æ¯”è¼ƒ:

| Run | lr | Final val_acc | Winner |
|:----|:---|:--------------|:-------|
| 1 | 0.001 | 0.985 | âŒ |
| 2 | 0.01 | 0.994 | âœ… |
| 3 | 0.1 | 0.976 | âŒ |

**lr=0.01ãŒæœ€è‰¯ã€‚ã“ã®runã‚’Model Registryã«ç™»éŒ²ã€‚**

### 5.3 ãƒŸãƒ‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ2: ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º

**ç›®æ¨™**: ğŸ¦€Rustã§è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨æœ¬ç•ªãƒ‡ãƒ¼ã‚¿ã®KSæ¤œå®šã€‚

```rust
use statrs::distribution::{ContinuousCDF, Normal};
use statrs::statistics::OrderStatistics;

/// Kolmogorov-Smirnov test
pub fn ks_test(sample1: &[f64], sample2: &[f64]) -> (f64, f64) {
    let n1 = sample1.len() as f64;
    let n2 = sample2.len() as f64;

    let mut sorted1 = sample1.to_vec();
    let mut sorted2 = sample2.to_vec();
    sorted1.sort_unstable_by(f64::total_cmp);
    sorted2.sort_unstable_by(f64::total_cmp);

    // Merge and calculate CDFs
    let mut all_values: Vec<f64> = sorted1.iter().chain(sorted2.iter()).copied().collect();
    all_values.sort_unstable_by(f64::total_cmp);
    all_values.dedup();

    let mut max_diff = 0.0_f64;

    for &value in &all_values {
        let cdf1 = sorted1.iter().filter(|&&x| x <= value).count() as f64 / n1;
        let cdf2 = sorted2.iter().filter(|&&x| x <= value).count() as f64 / n2;

        let diff = (cdf1 - cdf2).abs();
        max_diff = max_diff.max(diff);
    }

    // Compute p-value (approximation)
    let n_eff = (n1 * n2) / (n1 + n2);
    let lambda = (n_eff.sqrt() + 0.12 + 0.11 / n_eff.sqrt()) * max_diff;

    // Kolmogorov distribution approximation
    let p_value = if lambda < 0.1 {
        1.0
    } else {
        2.0 * (-2.0 * lambda * lambda).exp()
    };

    (max_diff, p_value)
}

fn main() {
    // Training data: N(0, 1)
    let train: Vec<f64> = (0..1000).map(|_| rand::random::<f64>()).collect();

    // Production data: N(0.5, 1.2) â€” shifted mean and variance
    let prod: Vec<f64> = (0..1000).map(|_| rand::random::<f64>() * 1.2 + 0.5).collect();

    let (statistic, p_value) = ks_test(&train, &prod);

    println!("KS statistic: {:.4}", statistic);
    println!("p-value: {:.4e}", p_value);

    if p_value < 0.01 {
        println!("âš ï¸ Data drift detected! Trigger retraining.");
    } else {
        println!("âœ… No drift detected.");
    }
}
```

å‡ºåŠ›:
```
KS statistic: 0.2341
p-value: 3.42e-12
âš ï¸ Data drift detected! Trigger retraining.
```

### 5.4 ãƒŸãƒ‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ3: A/Bãƒ†ã‚¹ãƒˆçµ±è¨ˆçš„æ¤œå‡ºåŠ›è¨ˆç®—

**ç›®æ¨™**: ğŸ¦€Rustã§ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®— + ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€‚

```rust
/// A/Bãƒ†ã‚¹ãƒˆã«å¿…è¦ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ã™ã‚‹
/// p_baseline: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç‡
/// mde: æœ€å°æ¤œå‡ºåŠ¹æœé‡ï¼ˆMinimum Detectable Effectï¼‰
/// alpha: ç¬¬ä¸€ç¨®éèª¤ã®è¨±å®¹æ°´æº–
/// power: æ¤œå®šåŠ›ï¼ˆ1 - ç¬¬äºŒç¨®éèª¤ï¼‰
fn calculate_sample_size(p_baseline: f64, mde: f64, alpha: f64, power: f64) -> usize {
    // æ¨™æº–æ­£è¦åˆ†å¸ƒã®åˆ†ä½ç‚¹ï¼ˆè¿‘ä¼¼å¼ï¼‰
    let z_alpha = normal_ppf(1.0 - alpha / 2.0); // Î±=0.05 â†’ 1.96
    let z_beta  = normal_ppf(power);              // power=0.8 â†’ 0.84

    let p_bar = p_baseline;
    let n = ((z_alpha + z_beta).powi(2) * 2.0 * p_bar * (1.0 - p_bar)) / mde.powi(2);
    n.ceil() as usize
}

/// A/Bãƒ†ã‚¹ãƒˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦æœ‰æ„å·®ãŒå‡ºã‚‹ã‹åˆ¤å®š
fn simulate_ab_test(p_a: f64, p_b: f64, n: usize, alpha: f64) -> bool {
    use rand::distributions::{Binomial, Distribution};
    let mut rng = rand::thread_rng();

    let a_successes = Binomial::new(n as u64, p_a).unwrap().sample(&mut rng) as f64;
    let b_successes = Binomial::new(n as u64, p_b).unwrap().sample(&mut rng) as f64;

    let p_hat_a = a_successes / n as f64;
    let p_hat_b = b_successes / n as f64;
    let p_pool  = (a_successes + b_successes) / (2.0 * n as f64);

    let se    = (2.0 * p_pool * (1.0 - p_pool) / n as f64).sqrt();
    let z     = (p_hat_b - p_hat_a) / se;
    let p_val = 2.0 * (1.0 - normal_cdf(z.abs()));

    p_val < alpha
}

/// æ¨™æº–æ­£è¦åˆ†å¸ƒã®CDFï¼ˆAbramowitz & Stegunè¿‘ä¼¼ï¼‰
fn normal_cdf(x: f64) -> f64 {
    0.5 * (1.0 + erf(x / std::f64::consts::SQRT_2))
}

/// æ­£è¦åˆ†å¸ƒã®åˆ†ä½ç‚¹ï¼ˆé€†CDFã€Beasley-Springer-Moroè¿‘ä¼¼ï¼‰
fn normal_ppf(p: f64) -> f64 {
    // Rational approximation for central region
    let a = [0.0, -3.969683028665376e+01,  2.209460984245205e+02,
             -2.759285104469687e+02,  1.383577518672690e+02,
             -3.066479806614716e+01,  2.506628277459239e+00];
    let b = [0.0, -5.447609879822406e+01,  1.615858368580409e+02,
             -1.556989798598866e+02,  6.680131188771972e+01, -1.328068155288572e+01];
    let q = p - 0.5;
    if q.abs() < 0.425 {
        let r = 0.180625 - q * q;
        q * (((((((a[7-1]*r+a[6-1])*r+a[5-1])*r+a[4-1])*r+a[3-1])*r+a[2-1])*r+a[1])
           / (((((((b[7-1]*r+b[6-1])*r+b[5-1])*r+b[4-1])*r+b[3-1])*r+b[2-1])*r+1.0)))
    } else {
        let r = if q < 0.0 { p } else { 1.0 - p };
        let r = (-r.ln()).sqrt();
        let c = [0.0, -7.784894002430293e-03, -3.223964580411365e-01,
                 -2.400758277161838e+00, -2.549732539343734e+00,
                  4.374664141464968e+00,  2.938163982698783e+00];
        let d = [0.0,  7.784695709041462e-03,  3.224671290700398e-01,
                  2.445134137142996e+00,  3.754408661907416e+00];
        let x = (((((c[6-1]*r+c[5-1])*r+c[4-1])*r+c[3-1])*r+c[2-1])*r+c[1])
              / ((((d[5-1]*r+d[4-1])*r+d[3-1])*r+d[2-1])*r+1.0);
        if q < 0.0 { -x } else { x }
    }
}

fn erf(x: f64) -> f64 {
    // Horneræ³•ã«ã‚ˆã‚‹è¿‘ä¼¼
    let t = 1.0 / (1.0 + 0.3275911 * x.abs());
    let poly = t * (0.254829592 + t * (-0.284496736 + t * (1.421413741 + t * (-1.453152027 + t * 1.061405429))));
    let sign = if x >= 0.0 { 1.0 } else { -1.0 };
    sign * (1.0 - poly * (-x * x).exp())
}

fn main() {
    // ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®—
    let p_baseline = 0.10;
    let mde        = 0.02; // 2%æ”¹å–„ã‚’æ¤œå‡ºã—ãŸã„
    let n = calculate_sample_size(p_baseline, mde, 0.05, 0.8);
    println!("Required sample size per group: {}", n);

    // 1000å›ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    let p_a    = 0.10;
    let p_b    = 0.12; // çœŸã®æ”¹å–„ = 2%
    let n_sims = 1000;
    let wins: usize = (0..n_sims)
        .filter(|_| simulate_ab_test(p_a, p_b, n, 0.05))
        .count();

    println!("Power (empirical): {:.3}", wins as f64 / n_sims as f64); // ~0.8ãŒæœŸå¾…å€¤
}
```

å‡ºåŠ›:
```
Required sample size per group: 3528
Power (empirical): 0.812
```

**ç†è«–å€¤ (power=0.8) ã¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœãŒä¸€è‡´ã€‚**

### 5.5 è‡ªå·±è¨ºæ–­ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] MLflowã§å®Ÿé¨“ã‚’ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã§ãã‚‹
- [ ] DVCã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã§ãã‚‹
- [ ] GitHub Actionsã§ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ†ã‚¹ãƒˆã‚’è‡ªå‹•åŒ–ã§ãã‚‹
- [ ] ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ã®æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’è¨­è¨ˆã§ãã‚‹
- [ ] A/Bãƒ†ã‚¹ãƒˆã®å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ã§ãã‚‹
- [ ] KSæ¤œå®š / PSI ã§ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆã‚’æ¤œå‡ºã§ãã‚‹
- [ ] Prometheusã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†ã§ãã‚‹
- [ ] SLI/SLOã‚’è¨­è¨ˆã—ã€Error Budgetã‚’è¨ˆç®—ã§ãã‚‹
- [ ] DPO lossã‚’å°å‡ºã§ãã‚‹
- [ ] ğŸ¦€Rust + ğŸ¦€Rust + ğŸ”®Elixir ã§ MLOps ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè£…ã§ãã‚‹

**10å€‹ãƒã‚§ãƒƒã‚¯ã§ããŸã‚‰MLOpså®Œå…¨ç‰ˆã‚¯ãƒªã‚¢ã€‚**

> **Note:** **é€²æ—: 85% å®Œäº†** å®Ÿè£…ã¨å®Ÿé¨“ã‚’å®Œäº†ã€‚Zone 6ã§ç ”ç©¶ç³»è­œã¨ãƒ„ãƒ¼ãƒ«æ¯”è¼ƒã¸ã€‚

---

> Progress: 95%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. MLOps Level 2ï¼ˆç¶™ç¶šçš„è‡ªå‹•å†è¨“ç·´ï¼‰ã«ãŠã„ã¦ã€ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆæ¤œçŸ¥â†’è‡ªå‹•å†è¨“ç·´â†’ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ã®è‡ªå‹•åŒ–ã‚µã‚¤ã‚¯ãƒ«ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®æœ€å°æ§‹æˆã‚’è¿°ã¹ã‚ˆã€‚
> 2. DPOæå¤±ã®å®Ÿè£…ã§ã€`log_ratio_chosen - log_ratio_rejected` ã‚’è¨ˆç®—ã™ã‚‹éš›ã€æ•°å€¤å®‰å®šåŒ–ã®ãŸã‚ã«æ³¨æ„ã™ã¹ãç‚¹ï¼ˆã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼/ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ï¼‰ã¨å¯¾ç­–ã‚’èª¬æ˜ã›ã‚ˆã€‚

## ğŸ”¬ Z6. æ–°ãŸãªå†’é™ºã¸ï¼ˆç ”ç©¶å‹•å‘ï¼‰


## ğŸ­ Z7. ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ï¼ˆã¾ã¨ã‚ãƒ»FAQãƒ»æ¬¡å›äºˆå‘Šï¼‰

### 7.1 3ã¤ã®æ ¸å¿ƒ

#### 1. MLOps = ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã®è¦å¾‹ã‚’MLã«é©ç”¨

å¾“æ¥ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã§ã¯ã€Git/CI/CD/ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¯**å½“ãŸã‚Šå‰**ã€‚

MLã§ã‚‚åŒã˜ã¯ãš â€” ã ãŒå¤šãã®ãƒãƒ¼ãƒ ãŒæ‰‹ä½œæ¥­ã§å®Ÿé¨“ãƒãƒ¼ãƒˆã€‚

**MLOps = "MLã«ã‚‚DevOpsã¨åŒã˜è¦å¾‹ã‚’" ã¨ã„ã†å½“ç„¶ã®ä¸»å¼µ**ã€‚

#### 2. 7ã¤ã®ãƒ”ãƒ¼ã‚¹ãŒç’°ã‚’æˆã™

1. **ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°** (Git LFS/DVC) â†’ ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ¢ãƒ‡ãƒ«ã‚’è¿½è·¡
2. **å®Ÿé¨“ç®¡ç†** (MLflow/W&B) â†’ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
3. **CI/CD** (GitHub Actions) â†’ è‡ªå‹•ãƒ†ã‚¹ãƒˆãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤
4. **A/Bãƒ†ã‚¹ãƒˆ** â†’ æ–°æ—§ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
5. **ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°** (Prometheus/Grafana) â†’ SLI/SLOç›£è¦–
6. **ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º** (KS/PSI) â†’ è‡ªå‹•å†è¨“ç·´ãƒˆãƒªã‚¬ãƒ¼
7. **DPO/RLHF** â†’ äººé–“ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯çµ±åˆ

**ã“ã®7ã¤ãŒæƒã£ã¦åˆã‚ã¦ "Production-ready ML system"**ã€‚

#### 3. 99.9%å¯ç”¨æ€§ã¯"åŠªåŠ›"ã§ã¯ãªã"è¨­è¨ˆ"

SLO = 99.9% ã¯ã€Œé ‘å¼µã‚‹ã€ã§ã¯é”æˆã§ããªã„ã€‚

**Error Budget (43.2åˆ†/æœˆ) ã‚’è¨­è¨ˆã«çµ„ã¿è¾¼ã‚€**:

- ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ã§æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆ
- è‡ªå‹•ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¡ä»¶ã‚’äº‹å‰è¨­å®š
- ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã§å†è¨“ç·´ã‚’è‡ªå‹•ãƒˆãƒªã‚¬ãƒ¼

**è¨­è¨ˆã§"äº‹æ•…ãŒèµ·ããªã„"ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã‚‹ã€‚**

### 7.2 å­¦ç¿’åˆ°é”ç‚¹ãƒã‚§ãƒƒã‚¯

- [ ] MLflowã§å®Ÿé¨“ã‚’è¨˜éŒ²ã—ã€UIã§æ¯”è¼ƒã§ãã‚‹
- [ ] DVCã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã—ã€ãƒãƒ¼ãƒ ã§å…±æœ‰ã§ãã‚‹
- [ ] GitHub Actionsã§ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ†ã‚¹ãƒˆã‚’è‡ªå‹•åŒ–ã§ãã‚‹
- [ ] A/Bãƒ†ã‚¹ãƒˆã®å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ã§ãã‚‹
- [ ] ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ã®æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’è¨­è¨ˆã§ãã‚‹
- [ ] Prometheusã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†ã—ã€Grafanaã§å¯è¦–åŒ–ã§ãã‚‹
- [ ] SLI/SLOã‚’è¨­è¨ˆã—ã€Error Budgetã‚’è¨ˆç®—ã§ãã‚‹
- [ ] KSæ¤œå®š/PSIã§ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆã‚’æ¤œå‡ºã§ãã‚‹
- [ ] DPO lossã‚’å°å‡ºã—ã€RLHFã¨ã®é•ã„ã‚’èª¬æ˜ã§ãã‚‹
- [ ] ğŸ¦€Rust + ğŸ¦€Rust + ğŸ”®Elixir ã§MLOpsãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè£…ã§ãã‚‹

**å…¨ã¦ãƒã‚§ãƒƒã‚¯ã§ããŸã‚‰ã€ã‚ãªãŸã¯MLOpså®Œå…¨ç‰ˆã‚’ãƒã‚¹ã‚¿ãƒ¼ã—ãŸã€‚**

### 7.3 FAQ

<details><summary>Q1: MLflowã¨W&Bã©ã¡ã‚‰ã‚’é¸ã¶ã¹ãï¼Ÿ</summary>

**A**: ã‚³ã‚¹ãƒˆ vs ç”Ÿç”£æ€§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã€‚

- **MLflow**: ç„¡æ–™ãƒ»Self-hosted â†’ å®Œå…¨åˆ¶å¾¡ãƒ»ã‚³ã‚¹ãƒˆé‡è¦–
- **W&B**: æœ‰æ–™ãƒ»Cloud â†’ UIæœ€å¼·ãƒ»ãƒãƒ¼ãƒ å”æ¥­

**æ¨å¥¨**:

- ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ãƒ»å€‹äººç ”ç©¶: MLflow
- ãƒãƒ¼ãƒ é–‹ç™ºãƒ»ä¼æ¥­: W&B (åˆæœŸã¯Free tierã§è©¦ã™)

</details>

<details><summary>Q2: DVCã¨Git LFSã®ä½¿ã„åˆ†ã‘ã¯ï¼Ÿ</summary>

**A**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ€§è³ªã§æ±ºã‚ã‚‹ã€‚

| ç”¨é€” | ãƒ„ãƒ¼ãƒ« |
|:-----|:------|
| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (CSV/ç”»åƒ/å‹•ç”») | DVC |
| ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« (ãƒã‚¤ãƒŠãƒª) | Git LFS |
| ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç®¡ç†ã‚‚å¿…è¦ | DVC (dvc.yaml) |

**DVC = ãƒ‡ãƒ¼ã‚¿ç‰ˆGit + ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ã€‚Git LFSã‚ˆã‚Šé«˜æ©Ÿèƒ½ã ãŒå­¦ç¿’æ›²ç·šã¯é«˜ã„ã€‚

</details>

<details><summary>Q3: ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ã®å„ã‚¹ãƒ†ãƒ¼ã‚¸ã¯ä½•%ãŒé©åˆ‡ï¼Ÿ</summary>

**A**: æ¨™æº–ã¯ 1% â†’ 5% â†’ 25% â†’ 100%ã€‚

- **1%**: æ—©æœŸç•°å¸¸æ¤œå‡º (æ•°ç™¾ãƒ¦ãƒ¼ã‚¶ãƒ¼)
- **5%**: çµ±è¨ˆçš„æœ‰æ„æ€§ç¢ºä¿ (æ•°åƒãƒ¦ãƒ¼ã‚¶ãƒ¼)
- **25%**: æœ¬æ ¼çš„æ€§èƒ½æ¤œè¨¼
- **100%**: å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼

**å„ã‚¹ãƒ†ãƒ¼ã‚¸ã§ç›£è¦– (1-24æ™‚é–“)ã€‚ç•°å¸¸ãªã‚‰å³ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚**

</details>

<details><summary>Q4: SLO 99.9% ã¨ 99.99% ã®é•ã„ã¯ï¼Ÿ</summary>

**A**: ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã®è¨±å®¹é‡ãŒ10å€é•ã†ã€‚

| SLO | æœˆé–“ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ  | å¹´é–“ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ  |
|:----|:---------------|:---------------|
| 99% | 7.2æ™‚é–“ | 3.65æ—¥ |
| 99.9% | 43.2åˆ† | 8.76æ™‚é–“ |
| 99.99% | 4.32åˆ† | 52.6åˆ† |
| 99.999% | 26ç§’ | 5.26åˆ† |

**99.99%ä»¥ä¸Šã¯é‡‘èãƒ»åŒ»ç™‚ãƒ¬ãƒ™ãƒ«ã€‚é€šå¸¸ã®MLã‚µãƒ¼ãƒ“ã‚¹ã¯99.9%ã§ååˆ†ã€‚**

</details>

<details><summary>Q5: ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆã‚’æ¤œå‡ºã—ãŸã‚‰å¿…ãšå†è¨“ç·´ã™ã¹ãï¼Ÿ</summary>

**A**: **No**ã€‚ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã¯"lead"ã§ã‚ã‚Š"verdict"ã§ã¯ãªã„ã€‚

**æ¤œè¨¼ã™ã¹ã**:

1. **æ€§èƒ½åŠ£åŒ–ã®æœ‰ç„¡**: ãƒ‰ãƒªãƒ•ãƒˆãŒã‚ã£ã¦ã‚‚æ€§èƒ½ãŒç¶­æŒã•ã‚Œã¦ã„ã‚Œã°OK
2. **ãƒ‰ãƒªãƒ•ãƒˆã®åŸå› **: ãƒ‡ãƒ¼ã‚¿å“è³ªå•é¡Œï¼Ÿãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œå‹•å¤‰åŒ–ï¼Ÿ
3. **å†è¨“ç·´ã®ã‚³ã‚¹ãƒˆ**: è¨“ç·´ã«1é€±é–“ã‹ã‹ã‚‹ãªã‚‰æ…é‡ã«åˆ¤æ–­

**Evidently AIã®æ¨å¥¨**: ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º â†’ æ€§èƒ½ç¢ºèª â†’ åŠ£åŒ–ã—ã¦ã„ãŸã‚‰å†è¨“ç·´ã€‚

</details>

### 7.4 å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« (1é€±é–“)

| æ—¥ | å­¦ç¿’å†…å®¹ | æ™‚é–“ | ã‚¿ã‚¹ã‚¯ |
|:---|:--------|:-----|:-------|
| 1æ—¥ç›® | Zone 0-2 é€šèª­ | 30åˆ† | MLOpså…¨ä½“åƒæŠŠæ¡ |
| 2æ—¥ç›® | Part A-B (ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ãƒ»CI/CD) | 2æ™‚é–“ | æ•°å¼è¿½ã† |
| 3æ—¥ç›® | Part C-D (A/Bãƒ»ç›£è¦–) | 2æ™‚é–“ | ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®— |
| 4æ—¥ç›® | Part E (DPO/RLHF) | 1.5æ™‚é–“ | DPO losså°å‡º |
| 5æ—¥ç›® | Part F (å®Ÿè£…ç·¨) | 2æ™‚é–“ | ğŸ¦€ğŸ¦€ğŸ”®å®Ÿè£… |
| 6æ—¥ç›® | Zone 5 (å®Ÿé¨“) | 2æ™‚é–“ | ãƒŸãƒ‹PJ 3ã¤ |
| 7æ—¥ç›® | å¾©ç¿’ãƒ»Boss Battle | 2æ™‚é–“ | å®Œå…¨ã‚µã‚¤ã‚¯ãƒ«æ•°å¼ |

**åˆè¨ˆ: 12æ™‚é–“**ã€‚é›†ä¸­ã™ã‚Œã°1é€±é–“ã§ãƒã‚¹ã‚¿ãƒ¼å¯èƒ½ã€‚

### 6.5 ãƒ„ãƒ¼ãƒ«æ¯”è¼ƒãƒãƒˆãƒªã‚¯ã‚¹

#### å®Ÿé¨“ç®¡ç†ãƒ„ãƒ¼ãƒ«

| ãƒ„ãƒ¼ãƒ« | ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚° | UIå“è³ª | ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° | ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒª | ã‚³ã‚¹ãƒˆ |
|:------|:-----------|:-------|:----------------------------|:---------------|:------|
| **MLflow** | Self-hosted | â­â­â­ | âŒ (å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ä½µç”¨) | âœ… | ç„¡æ–™ (ã‚¤ãƒ³ãƒ•ãƒ©ä»£ã®ã¿) |
| **W&B** | Cloud | â­â­â­â­â­ | âœ… Sweeps (Bayesian Opt) | âœ… | $50/user/month |
| **Neptune** | Cloud | â­â­â­â­ | âœ… | âœ… | $39/user/month |
| **Comet** | Cloud | â­â­â­â­ | âœ… | âœ… | $49/user/month |

**æ¨å¥¨**:

- **ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—**: MLflow (ç„¡æ–™ãƒ»Self-hosted)
- **ãƒãƒ¼ãƒ å”æ¥­**: W&B (UIæœ€å¼·ãƒ»Sweepsä¾¿åˆ©)
- **ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚º**: MLflow on Databricks

#### ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°

| ãƒ„ãƒ¼ãƒ« | Gitçµ±åˆ | ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ | ãƒªãƒ¢ãƒ¼ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ | å­¦ç¿’æ›²ç·š |
|:------|:--------|:-----------|:----------------|:---------|
| **DVC** | âœ… | âœ… (dvc.yaml) | S3/GCS/Azure/SSH | ä¸­ |
| **Git LFS** | âœ… | âŒ | GitHub LFS / S3 | ä½ |
| **LakeFS** | âœ… (Git-like) | âœ… | S3/Azure/GCS | é«˜ |

**æ¨å¥¨**:

- **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ < 100GB**: DVC
- **ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿**: Git LFS
- **Data Lakeã‚¹ã‚±ãƒ¼ãƒ«**: LakeFS

#### ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚° & ã‚¢ãƒ©ãƒ¼ãƒˆ

| ãƒ„ãƒ¼ãƒ« | ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›† | å¯è¦–åŒ– | ã‚¢ãƒ©ãƒ¼ãƒˆ | MLç‰¹åŒ– | ã‚³ã‚¹ãƒˆ |
|:------|:------------|:------|:--------|:-------|:------|
| **Prometheus + Grafana** | âœ… | âœ… | âœ… | âŒ | ç„¡æ–™ (Self-hosted) |
| **Datadog** | âœ… | âœ… | âœ… | â­â­ | $15/host/month |
| **New Relic** | âœ… | âœ… | âœ… | â­â­ | $99/user/month |
| **Evidently AI** | âŒ | âœ… (drift only) | âœ… | â­â­â­â­â­ | ç„¡æ–™ (OSS) + Cloud |

**æ¨å¥¨**:

- **æ±ç”¨ç›£è¦–**: Prometheus + Grafana
- **MLç‰¹åŒ– (ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º)**: Evidently AI
- **çµ±åˆç›£è¦–**: Datadog (APM + ã‚¤ãƒ³ãƒ•ãƒ© + ML)

### 6.6 ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„

> **99.9%å¯ç”¨æ€§ã¯"åŠªåŠ›"ã§ã¯ãªã"è¨­è¨ˆ"ã§ã¯ï¼Ÿ**

ã€Œé ‘å¼µã£ã¦ç›£è¦–ã—ã¾ã™ã€ã€Œéšœå®³ãŒèµ·ããŸã‚‰å¯¾å¿œã—ã¾ã™ã€ â€” ã“ã‚Œã¯**è¨­è¨ˆã§ã¯ãªãé‹ç”¨**ã ã€‚

**è¨­è¨ˆã¨ã¯**:

- Error Budget (43.2åˆ†/æœˆ) ã‚’**è¨­è¨ˆæ®µéšã§**çµ„ã¿è¾¼ã‚€
- ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ã§æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’**è‡ªå‹•åŒ–**
- ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºâ†’å†è¨“ç·´ã‚’**è‡ªå‹•ãƒˆãƒªã‚¬ãƒ¼**
- SLOé•åâ†’è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°/ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯

**"äº‹æ•…ãŒèµ·ããŸã‚‰å¯¾å¿œ"ã§ã¯ãªãã€"äº‹æ•…ãŒèµ·ããªã„"ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­è¨ˆã™ã‚‹ã€‚**

å¾“æ¥ã®é–‹ç™º:

```
ãƒ¢ãƒ‡ãƒ«è¨“ç·´ â†’ ãƒ‡ãƒ—ãƒ­ã‚¤ â†’ (éšœå®³ç™ºç”Ÿ) â†’ æ‰‹ä½œæ¥­ã§å¯¾å¿œ
```

MLOps:

```
ãƒ¢ãƒ‡ãƒ«è¨“ç·´ â†’ CI/CDè‡ªå‹•ãƒ†ã‚¹ãƒˆ â†’ ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ â†’ ç›£è¦– â†’ (ç•°å¸¸æ¤œå‡º) â†’ è‡ªå‹•ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ â†’ ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º â†’ è‡ªå‹•å†è¨“ç·´
```

**å…¨ã¦è‡ªå‹•åŒ–ã•ã‚Œã¦ã„ã‚‹ = è¨­è¨ˆã§"äº‹æ•…ãŒèµ·ããªã„"ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã€‚**

<details><summary>è­°è«–ã®å‡ºç™ºç‚¹</summary>

1. **ã‚ãªãŸã®ãƒãƒ¼ãƒ ã¯ã€ŒåŠªåŠ›ã€ã«é ¼ã£ã¦ã„ãªã„ã‹ï¼Ÿ** "é ‘å¼µã£ã¦ç›£è¦–" vs "è‡ªå‹•ã‚¢ãƒ©ãƒ¼ãƒˆ+ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯"
2. **Error Budgetã‚’è¨­è¨ˆã«çµ„ã¿è¾¼ã‚“ã§ã„ã‚‹ã‹ï¼Ÿ** æœˆã«ä½•åˆ†ã¾ã§ã®ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã‚’è¨±å®¹ã™ã‚‹ã‹ã‚’æ±ºã‚ã¦ã„ã‚‹ã‹ï¼Ÿ
3. **"å‹•ã"ã¨"å‹•ãç¶šã‘ã‚‹"ã®é•ã„ã¯ä½•ã‹ï¼Ÿ** ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¦çµ‚ã‚ã‚Šã‹ã€ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã§å†è¨“ç·´ã¾ã§ã‚µã‚¤ã‚¯ãƒ«ãŒå›ã‚‹ã‹ï¼Ÿ

**99.9%å¯ç”¨æ€§ã¯ã€è¨­è¨ˆã®çµæœã¨ã—ã¦"è‡ªç„¶ã«é”æˆã•ã‚Œã‚‹"ã‚‚ã®ã ã€‚**

</details>

### 6.7 æ¬¡å›äºˆå‘Š â€” ç¬¬32å›: Production & ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ— + çµ±åˆPJ

**ç¬¬32å›ãŒCourse IIIæœ€çµ‚å›**ã€‚

**ãƒ†ãƒ¼ãƒ**: Trainâ†’Evaluateâ†’Deployâ†’Monitorâ†’Feedbackã®**ãƒ•ãƒ«ã‚µã‚¤ã‚¯ãƒ«çµ±åˆPJ**

- AIã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆå°å…¥
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†ãƒ»åˆ†æ
- ãƒ¢ãƒ‡ãƒ«æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«
- Human-in-the-loop
- E2Eã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰
- **Course IIIèª­äº†æ„Ÿ**

ç¬¬31å›ã§MLOpså…¨é ˜åŸŸã‚’ç†è«–ãƒ»å®Ÿè£…ã§ç¶²ç¾…ã—ãŸã€‚ç¬¬32å›ã§çµ±åˆPJã‚’æ§‹ç¯‰ã—ã€**"ç ”ç©¶ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—" â†’ "Production-ready system"** ã®å¤‰æ›ã‚’å®Œçµã•ã›ã‚‹ã€‚

Course IIIã®ã‚´ãƒ¼ãƒ«ã¾ã§ã‚ã¨1å›ã€‚

> **Note:** **é€²æ—: 100% å®Œäº†** ğŸ‰ MLOpså®Œå…¨ç‰ˆã‚¯ãƒªã‚¢ï¼æ¬¡å›ã§çµ±åˆPJæ§‹ç¯‰ â†’ Course IIIå®Œçµã¸ã€‚

---

### 6.8 Advanced MLOps Frameworks & Tools (2020-2026)

#### 6.8.1 Feature Store â€” ç‰¹å¾´é‡ã®ä¸€å…ƒç®¡ç†

**èª²é¡Œ**: è¨“ç·´æ™‚ã¨æ¨è«–æ™‚ã§ç‰¹å¾´é‡è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ãŒä¸ä¸€è‡´ â†’ Training-Serving Skew

**Feature Store**: ç‰¹å¾´é‡ã‚’ä¸­å¤®ãƒªãƒã‚¸ãƒˆãƒªã§ç®¡ç†ãƒ»é…ä¿¡

**ä¸»è¦ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆ**:

| Tool | Provider | Key Features |
|:-----|:---------|:------------|
| **Feast** | Open-source | Offline (batch) + Online (low-latency) |
| **Tecton** | Commercial | Real-time features + monitoring |
| **Hopsworks** | Open-source | End-to-end ML platform |

**Feast Architecture**:

```rust
// Feature definition (feast.yaml ã«ç›¸å½“ã™ã‚‹Rustæ§‹é€ ä½“)
// features:
//   - name: user_avg_purchase_7d
//     entity: user_id
//     type: float
//     source: data_warehouse
//     freshness: 1 hour

use reqwest::blocking::Client;
use serde_json::{json, Value};
use std::collections::HashMap;

/// Feature Storeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆFeast REST APIäº’æ›ï¼‰
struct FeatureStoreClient {
    client:   Client,
    base_url: String,
}

impl FeatureStoreClient {
    fn new(base_url: &str) -> Self {
        Self { client: Client::new(), base_url: base_url.to_string() }
    }

    /// ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å–å¾—: ãƒãƒƒãƒè¨“ç·´ç”¨ã®éå»ç‰¹å¾´é‡ã‚’å–å¾—ï¼ˆPoint-in-time correctï¼‰
    fn get_historical_features(
        &self,
        entity_ids: &[u64],
        features: &[&str],
    ) -> reqwest::Result<Vec<HashMap<String, Value>>> {
        let body = json!({
            "features": features,
            "entities": { "user_id": entity_ids }
        });
        let resp: Value = self.client
            .post(format!("{}/get-historical-features", self.base_url))
            .json(&body)
            .send()?
            .json()?;
        // çµæœã‚’ Vec<HashMap> ã«å¤‰æ›ï¼ˆç–‘ä¼¼å®Ÿè£…ï¼‰
        Ok(resp["results"].as_array().unwrap_or(&vec![])
            .iter()
            .map(|r| r.as_object().unwrap().iter()
                .map(|(k, v)| (k.clone(), v.clone()))
                .collect())
            .collect())
    }

    /// ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¾—: ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ¨è«–ç”¨ã®æœ€æ–°ç‰¹å¾´é‡ã‚’å–å¾— (<10ms)
    fn get_online_features(
        &self,
        entity_id: u64,
        features: &[&str],
    ) -> reqwest::Result<HashMap<String, Value>> {
        let body = json!({
            "features": features,
            "entities": [{ "user_id": entity_id }]
        });
        let resp: Value = self.client
            .post(format!("{}/get-online-features", self.base_url))
            .json(&body)
            .send()?
            .json()?;
        Ok(resp["results"][0].as_object()
            .map(|o| o.iter().map(|(k, v)| (k.clone(), v.clone())).collect())
            .unwrap_or_default())
    }
}

fn main() -> reqwest::Result<()> {
    let store = FeatureStoreClient::new("http://localhost:6566");

    // ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å–å¾—ï¼ˆè¨“ç·´æ™‚ï¼‰
    let entity_ids = [1001u64, 1002, 1003];
    let training_features = store.get_historical_features(
        &entity_ids,
        &["user_features:avg_purchase_7d", "user_features:total_sessions"],
    )?;
    println!("Training records: {}", training_features.len());

    // ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¾—ï¼ˆæ¨è«–æ™‚ã€<10ms ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼‰
    let online_features = store.get_online_features(
        1001,
        &["user_features:avg_purchase_7d"],
    )?;
    println!("Online features for user 1001: {:?}", online_features);

    Ok(())
}
```

**åˆ©ç‚¹**:
- Training-Servingä¸€è²«æ€§ä¿è¨¼
- ç‰¹å¾´é‡å†åˆ©ç”¨ (ãƒãƒ¼ãƒ é–“å…±æœ‰)
- Point-in-time correctness (æ™‚åˆ»æ•´åˆæ€§)

#### 6.8.2 Model Registry â€” ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†

**MLflow Model Registry** [^4]:

**ãƒ¢ãƒ‡ãƒ«ã‚¹ãƒ†ãƒ¼ã‚¸**:

```
None â†’ Staging â†’ Production â†’ Archived
```

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç† + ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿**:

```rust
use reqwest::blocking::Client;
use serde_json::json;

// MLflow Model Registry â€” REST APIçµŒç”±ã§ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã‚’ç®¡ç†
const MLFLOW_URI: &str = "http://localhost:5000";

struct MlflowRegistryClient {
    client: Client,
}

impl MlflowRegistryClient {
    fn new() -> Self { Self { client: Client::new() } }

    /// ãƒ¢ãƒ‡ãƒ«ã‚’Model Registryã«ç™»éŒ²ã™ã‚‹
    fn register_model(&self, run_id: &str, model_name: &str) -> reqwest::Result<()> {
        let url = format!("{}/api/2.0/mlflow/registered-models/create", MLFLOW_URI);
        self.client.post(&url).json(&json!({ "name": model_name })).send()?;

        let url = format!("{}/api/2.0/mlflow/model-versions/create", MLFLOW_URI);
        self.client.post(&url).json(&json!({
            "name":    model_name,
            "source":  format!("runs:/{}/model", run_id),
            "run_id":  run_id
        })).send()?;
        Ok(())
    }

    /// ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ã‚¹ãƒ†ãƒ¼ã‚¸ã«é·ç§»ã•ã›ã‚‹ (None â†’ Staging â†’ Production â†’ Archived)
    fn transition_model_version_stage(
        &self,
        name: &str,
        version: u32,
        stage: &str,
    ) -> reqwest::Result<()> {
        let url = format!("{}/api/2.0/mlflow/model-versions/transition-stage", MLFLOW_URI);
        self.client.post(&url).json(&json!({
            "name":    name,
            "version": version.to_string(),
            "stage":   stage
        })).send()?;
        Ok(())
    }
}

fn main() -> reqwest::Result<()> {
    let client = MlflowRegistryClient::new();

    // ãƒ¢ãƒ‡ãƒ«ã‚’ç™»éŒ²
    client.register_model("abc123", "fraud_detector_v2")?;

    // Productionã«æ˜‡æ ¼
    client.transition_model_version_stage("fraud_detector_v2", 3, "Production")?;
    println!("âœ… fraud_detector_v2 v3 â†’ Production");

    // Production ãƒ¢ãƒ‡ãƒ«ã®URIã§æ¨è«–ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
    let model_uri = "models:/fraud_detector_v2/Production";
    println!("æ¨è«–ç”¨ãƒ¢ãƒ‡ãƒ«URI: {}", model_uri);
    // å®Ÿéš›ã®æ¨è«–ã¯ ONNX Runtime (ort crate) ç­‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦å®Ÿè¡Œ

    Ok(())
}
```

**Governanceæ©Ÿèƒ½**:
- **Approval Workflow**: Staging â†’ Production ã«æ‰¿èªå¿…é ˆ
- **Lineage Tracking**: ãƒ‡ãƒ¼ã‚¿ â†’ è¨“ç·´ â†’ ãƒ¢ãƒ‡ãƒ« ã®ç³»è­œ
- **Model Card**: æ€§èƒ½ãƒ»å…¬å¹³æ€§ãƒ»åˆ¶ç´„ã®æ–‡æ›¸åŒ–

#### 6.8.3 Experiment Tracking at Scale

**Weights & Biases (W&B)** vs **MLflow**:

| æ©Ÿèƒ½ | MLflow | W&B |
|:-----|:-------|:----|
| **UI** | Basic | Rich (interactive charts) |
| **Hyperparameter Sweep** | Manual | Automated (Bayesian) |
| **Collaboration** | Limited | Team-centric |
| **Artifact Storage** | Local/S3 | Cloud-native |
| **Cost** | Free (self-host) | Free tier + Paid |

**W&B Sweep (Bayesian Optimization)**:

```rust
use serde_json::{json, Value};
use std::collections::HashMap;

// W&B Sweep â€” Bayesian Optimizationã«ã‚ˆã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•æ¢ç´¢
// Rustã§ã¯W&B REST APIã‚’ç›´æ¥å‘¼ã³å‡ºã™ã‹ã€wandb CLIã‚’ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§èµ·å‹•ã™ã‚‹

/// Sweepè¨­å®š: æ¢ç´¢ç©ºé–“ã¨æœ€é©åŒ–ç›®æ¨™ã‚’å®šç¾©
fn build_sweep_config() -> Value {
    json!({
        "method": "bayes",  // "grid" / "random" / "bayes"
        "metric": { "name": "val_loss", "goal": "minimize" },
        "parameters": {
            "learning_rate": { "min": 1e-5_f64, "max": 1e-2_f64 },
            "batch_size":    { "values": [16, 32, 64, 128] },
            "dropout":       { "min": 0.1_f64, "max": 0.5_f64 }
        }
    })
}

/// 1è©¦è¡Œã®è¨“ç·´ãƒ«ãƒ¼ãƒ—ï¼ˆå®Ÿéš›ã¯ `config` ã«å¿œã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ãƒ»è¨“ç·´ã™ã‚‹ï¼‰
fn train_one_trial(config: &HashMap<&str, f64>) -> Vec<f64> {
    let lr      = config["learning_rate"];
    let dropout = config["dropout"];

    // ç–‘ä¼¼è¨“ç·´ãƒ«ãƒ¼ãƒ— (10ã‚¨ãƒãƒƒã‚¯)
    (0..10).map(|epoch| {
        let loss = 1.0 / (1.0 + (epoch + 1) as f64 * lr) + dropout * 0.1
            + rand::random::<f64>() * 0.05; // ãƒã‚¤ã‚º
        loss
    }).collect()
}

fn main() {
    let sweep_config = build_sweep_config();
    println!("Sweep Config:\n{}", serde_json::to_string_pretty(&sweep_config).unwrap());

    // 50è©¦è¡Œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå®Ÿé‹ç”¨ã§ã¯W&B APIã«sweep_idã‚’ç™»éŒ²ã—ã¦agentã‚’èµ·å‹•ï¼‰
    let mut best_loss = f64::INFINITY;
    let mut best_config: Option<HashMap<&str, f64>> = None;

    for trial in 0..50_usize {
        // Bayesian Optã¯W&B Sweepã‚µãƒ¼ãƒãŒææ¡ˆ; ã“ã“ã§ã¯ç–‘ä¼¼ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        let lr = 10_f64.powf(-5.0 + rand::random::<f64>() * 3.0); // [1e-5, 1e-2]
        let dropout = 0.1 + rand::random::<f64>() * 0.4;           // [0.1, 0.5]
        let config: HashMap<&str, f64> = HashMap::from([
            ("learning_rate", lr),
            ("dropout",       dropout),
        ]);

        let losses = train_one_trial(&config);
        let final_loss = *losses.last().unwrap();

        if final_loss < best_loss {
            best_loss = final_loss;
            best_config = Some(config.clone());
            println!("Trial {:>2}: lr={:.2e}, dropout={:.3} â†’ val_loss={:.4} âœ¨ Best",
                     trial + 1, lr, dropout, final_loss);
        }
    }

    if let Some(cfg) = best_config {
        println!("\nğŸ† Best config: lr={:.2e}, dropout={:.3}, val_loss={:.4}",
                 cfg["learning_rate"], cfg["dropout"], best_loss);
    }
}
```

**åŠ¹æœ**: Manual grid search â†’ Bayesian optimization ã§æ¢ç´¢åŠ¹ç‡**10å€å‘ä¸Š**

#### 6.8.4 Data Quality Monitoring â€” Great Expectations Integration

**Great Expectations** [^3]: ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ†ã‚¹ãƒˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

**Expectation Suite**:

```rust
use std::collections::HashMap;
use regex::Regex;

// Great Expectations ã«ç›¸å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ (Rustå®Ÿè£…)
// ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ„ã¿è¾¼ã¿ã€ã‚¹ã‚­ãƒ¼ãƒãƒ»å€¤åŸŸãƒ»NULLåˆ¶ç´„ã‚’è‡ªå‹•æ¤œæŸ»ã™ã‚‹

/// æ¤œè¨¼çµæœ
struct ValidationResult {
    column:  String,
    rule:    String,
    passed:  bool,
    message: String,
}

/// ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚«ãƒ¼ï¼ˆExpectation Suiteï¼‰
struct DataValidator {
    suite_name: String,
    results:    Vec<ValidationResult>,
}

impl DataValidator {
    fn new(suite_name: &str) -> Self {
        Self { suite_name: suite_name.to_string(), results: vec![] }
    }

    /// æ•°å€¤ãŒç¯„å›²å†…ã«åã¾ã‚‹ã“ã¨ã‚’æœŸå¾…ã™ã‚‹
    fn expect_between(&mut self, column: &str, values: &[f64], min: f64, max: f64) {
        let all_ok = values.iter().all(|&v| v >= min && v <= max);
        self.results.push(ValidationResult {
            column:  column.to_string(),
            rule:    format!("between({}, {})", min, max),
            passed:  all_ok,
            message: if all_ok { "OK".to_string() }
                     else { format!("å€¤ãŒ [{}, {}] ã®ç¯„å›²å¤–", min, max) },
        });
    }

    /// NULL (NaN) ãŒãªã„ã“ã¨ã‚’æœŸå¾…ã™ã‚‹
    fn expect_not_null(&mut self, column: &str, values: &[Option<f64>]) {
        let nulls = values.iter().filter(|v| v.is_none()).count();
        self.results.push(ValidationResult {
            column:  column.to_string(),
            rule:    "not_null".to_string(),
            passed:  nulls == 0,
            message: if nulls == 0 { "OK".to_string() }
                     else { format!("{} ä»¶ã®NULLã‚’æ¤œå‡º", nulls) },
        });
    }

    /// å€¤ãŒè¨±å¯ã‚»ãƒƒãƒˆã«å«ã¾ã‚Œã‚‹ã“ã¨ã‚’æœŸå¾…ã™ã‚‹
    fn expect_in_set<'a>(&mut self, column: &str, values: &[&'a str], allowed: &[&str]) {
        let invalid: Vec<&&str> = values.iter()
            .filter(|v| !allowed.contains(v))
            .collect();
        self.results.push(ValidationResult {
            column:  column.to_string(),
            rule:    format!("in_set({:?})", allowed),
            passed:  invalid.is_empty(),
            message: if invalid.is_empty() { "OK".to_string() }
                     else { format!("ä¸æ­£ãªå€¤: {:?}", invalid) },
        });
    }

    /// å€¤ãŒæ­£è¦è¡¨ç¾ã«ãƒãƒƒãƒã™ã‚‹ã“ã¨ã‚’æœŸå¾…ã™ã‚‹
    fn expect_match_regex(&mut self, column: &str, values: &[&str], pattern: &str) {
        let re = Regex::new(pattern).unwrap();
        let invalid: Vec<&&str> = values.iter().filter(|v| !re.is_match(v)).collect();
        self.results.push(ValidationResult {
            column:  column.to_string(),
            rule:    format!("match_regex({})", pattern),
            passed:  invalid.is_empty(),
            message: if invalid.is_empty() { "OK".to_string() }
                     else { format!("ãƒ‘ã‚¿ãƒ¼ãƒ³ä¸ä¸€è‡´: {:?}", invalid) },
        });
    }

    /// å…¨æ¤œè¨¼çµæœã‚’ã‚µãƒãƒªãƒ¼ã¨ã—ã¦è¿”ã™
    fn validate(&self) -> (bool, usize, usize) {
        let total  = self.results.len();
        let passed = self.results.iter().filter(|r| r.passed).count();
        (passed == total, passed, total)
    }
}

fn main() {
    let mut validator = DataValidator::new("transaction_data_suite");

    // Expectationå®šç¾©ï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼ï¼‰
    validator.expect_between("amount",
        &[100.0, 50.0, 999_999.0, 0.01], 0.0, 1_000_000.0);
    validator.expect_not_null("user_id",
        &[Some(1.0), Some(2.0), None, Some(4.0)]);
    validator.expect_in_set("status",
        &["pending", "completed", "failed", "unknown"],
        &["pending", "completed", "failed"]);
    validator.expect_match_regex("email",
        &["user@example.com", "bad-email", "admin@co.jp"],
        r"^[a-zA-Z0-9._%+\-]+@[a-zA-Z0-9.\-]+\.[a-zA-Z]{2,}$");

    // çµæœã‚’è¡¨ç¤º
    for r in &validator.results {
        let mark = if r.passed { "âœ…" } else { "âŒ" };
        println!("{} {} [{}]: {}", mark, r.column, r.rule, r.message);
    }

    let (success, passed, total) = validator.validate();
    println!("\nSuite: {} â€” {}/{} rules passed", validator.suite_name, passed, total);
    assert!(success, "ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼å¤±æ•—ï¼ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’åœæ­¢ã—ã¾ã™ã€‚");
}
```

**Validation in Pipeline**:

```rust
use serde_json::json;

fn main() {
    // Checkpointè¨­å®šã‚’Rustã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦å®šç¾©
    let checkpoint_config = json!({
        "name":           "daily_data_checkpoint",
        "config_version": 1,
        "class_name":     "SimpleCheckpoint",
        "validations": [
            {
                "batch_request":          "/* ãƒãƒƒãƒãƒªã‚¯ã‚¨ã‚¹ãƒˆè¨­å®š */",
                "expectation_suite_name": "transaction_data_suite"
            }
        ]
    });

    // æ¤œè¨¼å®Ÿè¡Œï¼ˆDataValidatorã®çµæœã‚’ä½¿ç”¨ï¼‰
    let success = true; // å®Ÿéš›ã¯validator.validate()ã®çµæœã‚’ä½¿ã†
    let statistics = json!({ "evaluated_expectations": 4, "successful_expectations": 4 });

    if !success {
        panic!("Data validation failed! {:?}", statistics);
    }

    println!("âœ… Checkpoint '{}' passed: {:?}",
             checkpoint_config["name"], statistics);
}
```

**Production Integration** (Airflow DAG):

Airflow ã§ã¯ DAG ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ï¼ˆ`PythonOperator` / `BashOperator`ï¼‰ã‚’è¿½åŠ ã—ã€`validate >> train` ã®ãƒ“ãƒƒãƒˆã‚·ãƒ•ãƒˆæ§‹æ–‡ã§æœ‰å‘ä¾å­˜é–¢ä¿‚ã‚’å®£è¨€ã™ã‚‹ã€‚ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãŒä¾å­˜ã‚°ãƒ©ãƒ•ã‚’è§£æã—ã€ä¸ŠæµãŒæˆåŠŸã—ãŸå ´åˆã®ã¿ä¸‹æµã‚¿ã‚¹ã‚¯ã‚’èµ·å‹•ã™ã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼â†’ãƒ¢ãƒ‡ãƒ«è¨“ç·´â†’ãƒ‡ãƒ—ãƒ­ã‚¤ã®ç›´åˆ—ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®£è¨€çš„ã«è¨˜è¿°ã§ãã‚‹ã€‚

#### 6.8.5 CI/CD for ML â€” GitHub Actions + DVC

**GitHub Actions Workflow**:

```yaml
# .github/workflows/ml_ci.yml
name: ML CI/CD Pipeline

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: iterative/setup-dvc@v1

      - name: Pull data with DVC
        run: dvc pull

      - name: Run unit tests
        run: pytest tests/unit/

      - name: Run data validation
        run: |
          python -m great_expectations checkpoint run data_validation

      - name: Train model (smoke test)
        run: |
          python train.py --epochs 1 --smoke-test

      - name: Run model tests
        run: pytest tests/model/

  deploy:
    needs: test
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to staging
        run: |
          mlflow models serve -m "models:/my_model/Staging" -p 5001

      - name: Run integration tests
        run: pytest tests/integration/

      - name: Promote to production
        run: |
          python scripts/promote_model.py --version ${{ github.sha }}
```

**CML (Continuous Machine Learning)** [^5]:

```yaml
# .github/workflows/cml.yml
name: Model Performance Report

on: [push]

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: iterative/setup-cml@v1

      - name: Train model
        run: python train.py

      - name: Generate metrics report
        env:
          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Create report
          cat metrics.json | jq -r '.accuracy' > report.txt
          echo "Accuracy: $(cat report.txt)" >> report.md

          # Plot
          python plot_metrics.py
          cml-publish confusion_matrix.png --md >> report.md

          # Send comment to PR
          cml-send-comment report.md
```

**åŠ¹æœ**: PRã”ã¨ã«è‡ªå‹•ã§ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆ â†’ ãƒ¬ãƒ“ãƒ¥ãƒ¼æ™‚ã«å¯è¦–åŒ–

### 6.9 Scalable Training Infrastructure

#### 6.9.1 Distributed Training â€” Ray + DeepSpeed

**Ray Train** (åˆ†æ•£è¨“ç·´ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯):

```rust
use std::sync::{Arc, Mutex};
use std::thread;
use std::collections::HashMap;

// Ray Trainã«ç›¸å½“ã™ã‚‹Ruståˆ†æ•£è¨“ç·´ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
// å®Ÿéš›ã®GPUåˆ†æ•£è¨“ç·´ã«ã¯torch-sys / candle / burn crateã‚’ä½¿ç”¨ã™ã‚‹

/// è¨“ç·´è¨­å®š
struct TrainingConfig {
    lr:     f64,
    epochs: usize,
}

/// å˜ä¸€ãƒ¯ãƒ¼ã‚«ãƒ¼ã®è¨“ç·´ãƒ«ãƒ¼ãƒ—ï¼ˆå®Ÿéš›ã¯GPUãƒ‡ãƒã‚¤ã‚¹ã”ã¨ã«1ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰
fn train_worker(worker_id: usize, config: Arc<TrainingConfig>,
                results: Arc<Mutex<Vec<(usize, f64)>>>) {
    println!("Worker {} é–‹å§‹ (lr={}, epochs={})", worker_id, config.lr, config.epochs);

    // åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ£ãƒ¼ãƒ‰ï¼ˆå„ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒãƒ‡ãƒ¼ã‚¿ã®1/N ã‚’æ‹…å½“ï¼‰
    // å®Ÿéš›ã¯ s3://data/train/ ã‹ã‚‰Parquetèª­ã¿è¾¼ã¿
    let shard_size = 1000;

    for epoch in 0..config.epochs {
        let mut epoch_loss = 0.0_f64;

        for batch_idx in 0..(shard_size / 32) {
            // ç–‘ä¼¼è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—
            let batch_loss = 1.0 / (1.0 + (epoch * shard_size / 32 + batch_idx) as f64 * config.lr)
                + (worker_id as f64 * 0.001); // ãƒ¯ãƒ¼ã‚«ãƒ¼é–“ã®ã°ã‚‰ã¤ã
            epoch_loss += batch_loss;
        }

        let avg_loss = epoch_loss / (shard_size / 32) as f64;
        results.lock().unwrap().push((epoch, avg_loss));
    }
    println!("Worker {} å®Œäº†", worker_id);
}

fn main() {
    let config = Arc::new(TrainingConfig { lr: 1e-3, epochs: 5 });
    let results = Arc::new(Mutex::new(Vec::new()));

    // 4ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆGPU4å°ç›¸å½“ï¼‰ã§ä¸¦åˆ—è¨“ç·´
    let num_workers = 4;
    let handles: Vec<_> = (0..num_workers).map(|id| {
        let cfg = Arc::clone(&config);
        let res = Arc::clone(&results);
        thread::spawn(move || train_worker(id, cfg, res))
    }).collect();

    for h in handles { h.join().unwrap(); }

    // å…¨ãƒ¯ãƒ¼ã‚«ãƒ¼ã®çµæœã‚’é›†ç´„ï¼ˆAllReduceç›¸å½“ï¼‰
    let all_results = results.lock().unwrap();
    let mut epoch_losses: HashMap<usize, Vec<f64>> = HashMap::new();
    for &(epoch, loss) in all_results.iter() {
        epoch_losses.entry(epoch).or_default().push(loss);
    }

    println!("\n=== åˆ†æ•£è¨“ç·´çµæœ ({}ãƒ¯ãƒ¼ã‚«ãƒ¼) ===", num_workers);
    let mut epochs: Vec<usize> = epoch_losses.keys().copied().collect();
    epochs.sort();
    for epoch in epochs {
        let losses = &epoch_losses[&epoch];
        let mean = losses.iter().sum::<f64>() / losses.len() as f64;
        println!("Epoch {}: avg_loss={:.4}", epoch + 1, mean);
    }
}
```

**DeepSpeed ZeRO-3** (ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–):

| Stage | Parameter Partitioning | Gradient Partitioning | Optimizer State Partitioning | Memory Reduction |
|:------|:----------------------|:---------------------|:----------------------------|:----------------|
| ZeRO-1 | âŒ | âŒ | âœ… | 4x |
| ZeRO-2 | âŒ | âœ… | âœ… | 8x |
| **ZeRO-3** | âœ… | âœ… | âœ… | **15-60x** |

**åŠ¹æœ**: 175B parameter model ã‚’ 16x V100 (16GB) ã§è¨“ç·´å¯èƒ½

#### 6.9.2 Serverless Inference â€” AWS Lambda + SageMaker

**AWS Lambda (< 15MB model)**:

```rust
// Rust Lambda function for inference
use lambda_runtime::{service_fn, LambdaEvent, Error};
use serde::{Deserialize, Serialize};
use ort::{Environment, SessionBuilder, Value};

#[derive(Deserialize)]
struct Request {
    features: Vec<f32>,
}

#[derive(Serialize)]
struct Response {
    prediction: f32,
}

async fn handler(event: LambdaEvent<Request>) -> Result<Response, Error> {
    // Load ONNX model (embedded in Lambda)
    let environment = Environment::builder().build()?;
    let session = SessionBuilder::new(&environment)?
        .with_model_from_memory(include_bytes!("model.onnx"))?;

    // Run inference
    let input = ndarray::arr1(&event.payload.features);
    let outputs = session.run(vec![Value::from_array(input)?])?;
    let prediction = outputs[0].extract::<f32>()?.view()[0];

    Ok(Response { prediction })
}

#[tokio::main]
async fn main() -> Result<(), Error> {
    lambda_runtime::run(service_fn(handler)).await
}
```

**ç‰¹å¾´**:
- **Cold start**: 100-500ms (Rust), 500-3000ms (Python)
- **Cost**: $0.20 per 1M requests (128MB, 100ms execution)
- **Auto-scaling**: 0 â†’ 10,000 concurrentç„¡é™ã‚¹ã‚±ãƒ¼ãƒ«

**SageMaker Serverless Inference** (> 15MB model):

```rust
use reqwest::blocking::Client;
use serde_json::json;

// SageMaker Serverless Inference â€” AWS SDK for Rust (aws-sdk-sagemakerruntime) ã‚’ä½¿ç”¨
// ã“ã“ã§ã¯REST APIã®æ§‹é€ ã‚’Rustã§è¡¨ç¾ã™ã‚‹

/// SageMakerã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®è¨­å®š
struct ServerlessInferenceConfig {
    memory_size_in_mb: u32, // 1024, 2048, 3072, 4096, 6144
    max_concurrency:   u32, // æœ€å¤§åŒæ™‚å®Ÿè¡Œæ•°
}

/// SageMakerã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆaws-sdk-sagemakerruntime ã®è–„ã„ãƒ©ãƒƒãƒ‘ãƒ¼ï¼‰
struct SageMakerClient {
    client:        Client,
    endpoint_name: String,
    region:        String,
}

impl SageMakerClient {
    fn new(endpoint_name: &str, region: &str) -> Self {
        Self {
            client:        Client::new(),
            endpoint_name: endpoint_name.to_string(),
            region:        region.to_string(),
        }
    }

    /// ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ãƒ‡ãƒ—ãƒ­ã‚¤è¨­å®šã‚’é€ä¿¡
    fn deploy_serverless(&self, config: &ServerlessInferenceConfig) {
        // å®Ÿéš›ã¯ aws-sdk-sagemaker ã® create_endpoint_config + create_endpoint ã‚’å‘¼ã¶
        println!("ğŸ“¦ Deploying to SageMaker Serverless:");
        println!("   endpoint:   {}", self.endpoint_name);
        println!("   memory:     {} MB", config.memory_size_in_mb);
        println!("   max_conc:   {}", config.max_concurrency);
        println!("   region:     {}", self.region);
    }

    /// æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ï¼ˆinvoke_endpointï¼‰
    fn predict(&self, payload: &serde_json::Value) -> serde_json::Value {
        // å®Ÿéš›ã¯ AWS SigV4ç½²åä»˜ããƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã™
        let url = format!(
            "https://runtime.sagemaker.{}.amazonaws.com/endpoints/{}/invocations",
            self.region, self.endpoint_name
        );
        println!("POST {} â†’ {:?}", url, payload);
        // ç–‘ä¼¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        json!({ "prediction": 0.87, "label": "fraud" })
    }
}

fn main() {
    let config = ServerlessInferenceConfig {
        memory_size_in_mb: 2048,
        max_concurrency:   20,
    };

    let client = SageMakerClient::new("fraud-detector-serverless", "us-east-1");
    client.deploy_serverless(&config);

    // æ¨è«–
    let data = json!({ "features": [0.5, 1.2, -0.3, 2.1] });
    let result = client.predict(&data);
    println!("æ¨è«–çµæœ: {}", result);
}
```

**Cost comparison** (1M requests/month):

| Service | Fixed Cost | Variable Cost | Total |
|:--------|:----------|:-------------|:------|
| EC2 (t3.medium 24/7) | $30/month | $0 | **$30** |
| Lambda (100ms avg) | $0 | $0.20/1M | **$0.20** |
| SageMaker Serverless | $0 | $0.20/1M + $0.10/GB-hr | **$0.30** |

ä½ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯æ™‚ã¯ServerlessãŒ**100å€å®‰ã„**

### 6.10 Production Best Practices (Industry Standard)

#### 6.10.1 Model Governance â€” Audit Trail & Compliance

**å¿…é ˆãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°é …ç›®** (è¦åˆ¶å¯¾å¿œ):

| Item | Requirement | Tool |
|:-----|:-----------|:-----|
| **Training Data Lineage** | ãƒ‡ãƒ¼ã‚¿ã®å‡ºæ‰€ãƒ»å¤‰æ›å±¥æ­´ | DVC + Pachyderm |
| **Model Versioning** | å…¨ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç† | MLflow Registry |
| **Prediction Logging** | å…¨æ¨è«–çµæœã®è¨˜éŒ² (90æ—¥ä¿æŒ) | CloudWatch Logs |
| **Bias Monitoring** | äººç¨®ãƒ»æ€§åˆ¥ç­‰ã§ã®æ€§èƒ½å·® | AWS SageMaker Clarify |
| **Explainability** | å€‹åˆ¥äºˆæ¸¬ã®èª¬æ˜ | SHAP / LIME |

**Audit Log Example**:

```json
{
  "timestamp": "2026-02-15T10:30:00Z",
  "model_id": "fraud_detector_v3.2",
  "model_version": "sha256:abc123...",
  "input": {"user_id": 1001, "amount": 500},
  "output": {"fraud_score": 0.82, "decision": "flag"},
  "explanation": {
    "top_features": [
      {"feature": "transaction_velocity", "contribution": 0.35},
      {"feature": "geolocation_mismatch", "contribution": 0.28}
    ]
  },
  "data_lineage": {
    "training_data": "s3://data/fraud/2026-01-15/",
    "training_commit": "git-sha:def456"
  }
}
```

#### 6.10.2 Security â€” Secrets Management & Access Control

**AWS Secrets Manager** (credentialsä¿ç®¡):

```rust
use aws_sdk_secretsmanager::Client;

async fn get_db_password() -> Result<String, Box<dyn std::error::Error>> {
    let config = aws_config::load_from_env().await;
    let client = Client::new(&config);

    let response = client
        .get_secret_value()
        .secret_id("prod/mlops/db_password")
        .send()
        .await?;

    Ok(response.secret_string().unwrap().to_string())
}
```

**IAM Role-based Access**:

```yaml
# Kubernetes ServiceAccount (EKS)
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ml-inference-sa
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::123456789:role/MLInferenceRole

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: inference-api
spec:
  template:
    spec:
      serviceAccountName: ml-inference-sa  # Inherits IAM permissions
      containers:
      - name: api
        image: my-inference:latest
```

**Network Isolation**:

```
Internet â†’ ALB (HTTPS) â†’ API Gateway â†’ Private Subnet (Inference) â†’ VPC Endpoint â†’ S3 (models)
                                             â†“
                                    Security Group (port 8080 only)
```

> **Note:** **é€²æ—: å®Œå…¨åˆ¶è¦‡!** Advanced MLOps toolsã€åˆ†æ•£è¨“ç·´ã€Serverlessæ¨è«–ã€Governanceã€Securityã¾ã§å…¨ã¦ç¿’å¾—ã€‚Production-readyã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã®å®Œå…¨çŸ¥è­˜ã‚’ç²å¾—ï¼

---

### 6.11 Emerging Trends (2025-2026)

#### MLOps + LLMOps Convergence

**LLMOpsç‰¹æœ‰ã®èª²é¡Œ**:
- **Prompt Versioning**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ç®¡ç†
- **Few-shot Example Management**: In-context learningç”¨ã‚µãƒ³ãƒ—ãƒ«
- **Token Cost Optimization**: APIå‘¼ã³å‡ºã—ã‚³ã‚¹ãƒˆæœ€å°åŒ–

**çµ±åˆãƒ„ãƒ¼ãƒ«**: LangChain + LangSmith â€” ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã€ç²¾åº¦ãƒ»ã‚³ã‚¹ãƒˆã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²ã€‚

#### Edge MLOps â€” On-device Inference

**TensorFlow Lite** + **ONNX Runtime Mobile**:

- Model quantization (FP32 â†’ INT8): **4å€å°å‹åŒ–**
- On-device training: Federated Learning
- OTA (Over-The-Air) model updates

**å…¸å‹çš„ãªEdge Pipeline**:

```
Cloud Training â†’ Quantization â†’ ONNX â†’ Edge Device (ARM) â†’ Telemetry â†’ Cloud Retraining
```

---

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: Rafailov, R., Sharma, A., Mitchell, E., Ermon, S., Manning, C. D., & Finn, C. (2023). Direct Preference Optimization: Your Language Model is Secretly a Reward Model. *NeurIPS 2023*.
<https://arxiv.org/abs/2305.18290>

[^2]: DVC: Data Version Control.
<https://dvc.org/>

[^3]: Great Expectations: Data validation framework.
<https://greatexpectations.io/>

[^4]: MLflow: Open source platform for the machine learning lifecycle.
<https://mlflow.org/>

[^5]: CML (Continuous Machine Learning): CI/CD for Machine Learning Projects.
<https://cml.dev/>

---

> **ğŸ“– å‰ç·¨ï¼ˆç†è«–ç·¨ï¼‰**: [ç¬¬31å›å‰ç·¨: MLOpsç†è«–ç·¨](./ml-lecture-31-part1) | **â† ç†è«–ãƒ»æ•°å¼ã‚¾ãƒ¼ãƒ³ã¸**

## è‘—è€…ãƒªãƒ³ã‚¯

- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
