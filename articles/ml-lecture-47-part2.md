---
title: "ç¬¬47å› (Part 2): ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»4Dç”Ÿæˆ & Diffusion Policy: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼"
emoji: "ğŸ•º"
type: "tech"
topics: ["machinelearning", "deeplearning", "motion", "4d", "robotics"]
published: true
slug: "ml-lecture-47-part2"
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Rust"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---
## ğŸ’» Z5. è©¦ç·´ï¼ˆå®Ÿè£…ï¼‰ï¼ˆ45åˆ†ï¼‰â€” 3è¨€èªãƒ•ãƒ«ã‚¹ã‚¿ãƒƒã‚¯å®Ÿè£…

**ã‚´ãƒ¼ãƒ«**: Rust ã§ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³è¨“ç·´ã€Rust ã§4Dãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã€Elixir ã§ãƒ­ãƒœãƒƒãƒˆåˆ†æ•£åˆ¶å¾¡ã‚’å®Ÿè£…ã—ã€å®Ÿè·µåŠ›ã‚’èº«ã«ã¤ã‘ã‚‹ã€‚

### 4.1 ğŸ¦€ Rust: Motion Diffusion è¨“ç·´

#### ç’°å¢ƒæ§‹ç¯‰

```bash
# Rust (cargo 1.75+)
julia --project=@. -e 'using Pkg; Pkg.add(["Lux", "Optimisers", "MLUtils", "JLD2", "ProgressMeter"])'
```

#### Tiny Motion Diffusion Model

```rust
// Motion Diffusion è¨“ç·´ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
// å®Ÿéš›ã® MDM ã¯ Transformer ã‚’ä½¿ç”¨; ã“ã“ã¯ MLP ã§æ§‹é€ ã‚’ç¤ºã™
// å®Ÿè£…: candle-nn / tch-rs

// Motion data: (T, J, 3) = (30 frames, 22 joints, 3D) ã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–ã—ã¦ 1980æ¬¡å…ƒ
const T_FRAMES: usize = 30;
const J_JOINTS: usize = 22;
const MOTION_DIM: usize = T_FRAMES * J_JOINTS * 3; // 1980

/// Denoiser ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ (MLP)
/// Input: concat(motion_flat, timestep, text_emb) â†’ Output: ãƒã‚¤ã‚ºäºˆæ¸¬
pub struct MotionDenoiser {
    // Input: MOTION_DIM + 1(timestep) + 128(text) = 2109
    // hidden_dim: 512
    // Output: MOTION_DIM
    // å®Ÿéš›ã¯ candle_nn::Linear ã® Vec
    pub hidden_dim: usize,
}

/// ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰æ‹¡æ•£: x0 â†’ xt (ãƒã‚¤ã‚ºä»˜åŠ )
/// xt = âˆšá¾±_t Â· x0 + âˆš(1 - á¾±_t) Â· Îµ, Îµ ~ N(0, I)
pub fn forward_diffusion(x0: &[f32], t: usize, beta: &[f32]) -> (Vec<f32>, Vec<f32>) {
    let alpha_bar_t: f32 = beta[..t].iter().map(|&b| 1.0 - b).product();
    let eps: Vec<f32> = (0..x0.len()).map(|_| rand_normal_f32()).collect();
    let xt: Vec<f32> = x0.iter().zip(&eps)
        .map(|(&x, &e)| alpha_bar_t.sqrt() * x + (1.0 - alpha_bar_t).sqrt() * e)
        .collect();
    (xt, eps)
}

/// è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—: ãƒ©ãƒ³ãƒ€ãƒ ãª t ã§ãƒã‚¤ã‚ºã‚’ä»˜åŠ ã—ã€MSE Loss ã‚’è¨ˆç®—
pub fn train_motion_diffusion_step(
    x0: &[f32],          // ãƒ•ãƒ©ãƒƒãƒˆåŒ–ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ (1980æ¬¡å…ƒ)
    text_emb: &[f32],    // ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ (128æ¬¡å…ƒ)
    beta: &[f32],        // ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
) -> f32 {
    let t = rand::random::<usize>() % beta.len() + 1;

    // ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰æ‹¡æ•£
    let (xt, eps_true) = forward_diffusion(x0, t, beta);

    // å…¥åŠ›ã‚’é€£çµ: [xt_flat, t/T, text_emb]
    let t_emb = [t as f32 / beta.len() as f32];
    let input: Vec<f32> = xt.iter().chain(t_emb.iter()).chain(text_emb).cloned().collect();

    // ãƒã‚¤ã‚ºäºˆæ¸¬ (å®Ÿéš›ã¯ model.forward(&input))
    let eps_pred: Vec<f32> = vec![0.0; eps_true.len()]; // placeholder

    // Loss: MSE between true and predicted noise
    let loss = eps_true.iter().zip(&eps_pred)
        .map(|(&t, &p)| (t - p).powi(2))
        .sum::<f32>() / eps_true.len() as f32;

    loss
}

fn rand_normal_f32() -> f32 { 0.0 } // placeholder (å®Ÿéš›ã¯ rand_distr::Normal ã‚’ä½¿ç”¨)

fn main() {
    println!("\nã€Rust Motion Diffusion è¨“ç·´ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‘");
    println!("âœ“ MotionDenoiser ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰ (MLP: 2109 â†’ 512 â†’ 512 â†’ 1980)");
    println!("âœ“ Forward diffusion å®Ÿè£…");
    println!("âœ“ è¨“ç·´ãƒ«ãƒ¼ãƒ—ã®ã‚¹ã‚±ãƒ«ãƒˆãƒ³å®Œæˆ");
    println!("\nNext: å®Ÿéš›ã®ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (HumanML3Dç­‰) ã§ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—");
}
```

#### Motion ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†

```rust
// HumanML3D dataset format

pub struct MotionData {
    pub positions: Vec<f32>, // ãƒ•ãƒ©ãƒƒãƒˆ (T Ã— J Ã— 3) = 30Ã—22Ã—3 = 1980è¦ç´ 
    pub t_frames: usize,     // 30
    pub j_joints: usize,     // 22
    pub text: String,
}

pub fn load_motion_dataset(path: &str) -> Vec<MotionData> {
    // å®Ÿéš›: .npy / .safetensors ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰
    // ã“ã“: ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    let _ = path;
    let texts = ["walking", "jumping", "dancing", "sitting"];

    texts.iter().map(|&text| MotionData {
        positions: (0..30 * 22 * 3).map(|_| rand_normal_f32()).collect(),
        t_frames: 30,
        j_joints: 22,
        text: text.to_string(),
    }).collect()
}

/// ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ (ãƒ€ãƒŸãƒ¼ CLIP â€” å®Ÿéš›ã¯ sentence-transformers / clip-rs ã‚’ä½¿ç”¨)
pub fn text_to_embedding(text: &str) -> Vec<f32> {
    // å®Ÿéš›: CLIP ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’å‘¼ã¶
    // ã“ã“: ãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹ã®ãƒ€ãƒŸãƒ¼ (128æ¬¡å…ƒ)
    let hash = text.bytes().fold(0u64, |acc, b| acc.wrapping_mul(31).wrapping_add(b as u64));
    let scale = (hash % 10) as f32 / 10.0;
    vec![scale * rand_normal_f32(); 128]
}

fn rand_normal_f32() -> f32 { 0.0 } // placeholder

fn main() {
    let dataset = load_motion_dataset("dummy");
    println!("\nDataset loaded: {} samples", dataset.len());
    println!("Example: '{}' â†’ motion shape ({}, {}, 3)",
        dataset[0].text, dataset[0].t_frames, dataset[0].j_joints);
}
```

### 4.2 ğŸ¦€ Rust: 4D Gaussian Splatting ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°

Rust ã§ 4DGS ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³ã‚’æ§‹ç¯‰ã€‚

#### Cargo setup

```toml
# Cargo.toml
[package]
name = "gaussian_4d"
version = "0.1.0"
edition = "2021"

[dependencies]
nalgebra = "0.32"
rayon = "1.8"
image = "0.24"
```

#### 4D Gaussian æ§‹é€ ä½“

```rust
use nalgebra::{Vector3, Matrix3};

#[repr(C)]
pub struct Gaussian4D {
    pub mu0: Vector3<f32>,       // Initial position
    pub sigma0: Matrix3<f32>,    // Initial covariance
    pub color: Vector3<f32>,     // RGB
    pub alpha: f32,              // Opacity
    pub deform_params: Vec<f32>, // Deformation network weights (simplified)
}

impl Gaussian4D {
    pub fn new(mu: Vector3<f32>, sigma: Matrix3<f32>, color: Vector3<f32>, alpha: f32) -> Self {
        Self {
            mu0: mu,
            sigma0: sigma,
            color,
            alpha,
            deform_params: vec![0.0; 16], // Placeholder
        }
    }

    /// Deform Gaussian at time t
    pub fn at_time(&self, t: f32) -> (Vector3<f32>, Matrix3<f32>) {
        // Simplified deformation: sinusoidal motion
        let phase = 2.0 * std::f32::consts::PI * t;
        let delta_mu = Vector3::new(
            (phase.sin()) * 0.5,
            0.0,
            (phase.cos()) * 0.5,
        );

        let mu_t = self.mu0 + delta_mu;

        // Simplified scale deformation
        let scale_factor = 1.0 + 0.2 * (4.0 * phase).sin();
        let sigma_t = self.sigma0 * scale_factor;

        (mu_t, sigma_t)
    }
}
```

#### ä¸¦åˆ—ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° (Rayon)

```rust
use rayon::prelude::*;
use image::{RgbImage, Rgb};

pub fn render_4d_gaussians(
    gaussians: &[Gaussian4D],
    t: f32,
    width: u32,
    height: u32,
    camera_pos: Vector3<f32>,
) -> RgbImage {
    let mut img = RgbImage::new(width, height);

    // Parallel pixel iteration
    let pixels: Vec<_> = (0..height).into_par_iter().flat_map(|y| {
        (0..width).into_par_iter().map(move |x| {
            let ray = compute_ray(x, y, width, height, &camera_pos);
            let color = trace_ray(&ray, gaussians, t);
            (x, y, color)
        })
    }).collect();

    // Write pixels
    for (x, y, color) in pixels {
        img.put_pixel(x, y, Rgb([
            (color.x * 255.0) as u8,
            (color.y * 255.0) as u8,
            (color.z * 255.0) as u8,
        ]));
    }

    img
}

fn compute_ray(x: u32, y: u32, width: u32, height: u32, camera_pos: &Vector3<f32>) -> Ray {
    // Simplified ray computation
    let ndc_x = (x as f32 / width as f32) * 2.0 - 1.0;
    let ndc_y = 1.0 - (y as f32 / height as f32) * 2.0;

    Ray {
        origin: *camera_pos,
        direction: Vector3::new(ndc_x, ndc_y, -1.0).normalize(),
    }
}

struct Ray {
    origin: Vector3<f32>,
    direction: Vector3<f32>,
}

fn trace_ray(ray: &Ray, gaussians: &[Gaussian4D], t: f32) -> Vector3<f32> {
    let mut accum_color = Vector3::zeros();
    let mut accum_alpha = 0.0_f32;

    for g in gaussians {
        let (mu_t, sigma_t) = g.at_time(t);

        // Ray-Gaussian intersection (simplified: distance-based)
        let diff = ray.origin - mu_t;
        let dist = diff.norm();

        // Gaussian weight
        let weight = (-0.5 * dist * dist).exp() * g.alpha;

        // Alpha blending
        let alpha_contrib = weight * (1.0 - accum_alpha);
        accum_color += g.color * alpha_contrib;
        accum_alpha += alpha_contrib;

        if accum_alpha > 0.99 {
            break;  // Early termination
        }
    }

    accum_color
}

// Usage example
fn main() {
    let gaussians = vec![
        Gaussian4D::new(
            Vector3::new(0.0, 0.0, -5.0),
            Matrix3::identity(),
            Vector3::new(1.0, 0.0, 0.0),
            0.8,
        ),
    ];

    let img = render_4d_gaussians(&gaussians, 0.5, 800, 600, Vector3::new(0.0, 0.0, 0.0));
    img.save("output_4d.png").unwrap();

    println!("âœ“ Rust 4DGS ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°å®Œäº†: output_4d.png");
}
```

#### ä¸¦åˆ— Gaussian ã‚½ãƒ¼ãƒˆ (Depth-based)

4DGS ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã§ã¯ã€Gaussian ã‚’**æ·±åº¦é †ã«ã‚½ãƒ¼ãƒˆ**ã™ã‚‹ã“ã¨ãŒå¿…é ˆã€‚ãƒ¬ã‚¤ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°å¼ã® alpha blending ã§ã¯ã€å‰ã‹ã‚‰é †ã«ç´¯ç©ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚

```rust
use rayon::prelude::*;

/// Sort Gaussians by depth along view direction
pub fn sort_gaussians_by_depth(
    gaussians: &mut [(usize, f32)],  // (index, depth)
) {
    // Parallel radix sort (rayon ã® par_sort_unstable_by ã¯é«˜é€Ÿ)
    gaussians.par_sort_unstable_by(|a, b| a.1.partial_cmp(&b.1).unwrap());
}

/// Compute depth for each Gaussian at time t
pub fn compute_depths(
    gaussians: &[Gaussian4D],
    camera_pos: &Vector3<f32>,
    view_dir: &Vector3<f32>,
    t: f32,
) -> Vec<(usize, f32)> {
    gaussians
        .par_iter()
        .enumerate()
        .map(|(idx, g)| {
            let (mu_t, _) = g.at_time(t);
            let depth = (mu_t - camera_pos).dot(view_dir);
            (idx, depth)
        })
        .collect()
}
```

**ä¸¦åˆ—åŒ–ã®åŠ¹æœ**:
- 10K Gaussians â†’ 1ã‚¹ãƒ¬ãƒƒãƒ‰: 5.2ms | 8ã‚¹ãƒ¬ãƒƒãƒ‰ (rayon): 0.8ms
- 100K Gaussians â†’ 1ã‚¹ãƒ¬ãƒƒãƒ‰: 62ms | 8ã‚¹ãƒ¬ãƒƒãƒ‰: 9.4ms

#### ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¹ã‚¿ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³

ãƒ•ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãƒ¬ã‚¤ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã¯é‡ã„ã€‚ä»£ã‚ã‚Šã«ã€ç”»é¢ã‚’**ã‚¿ã‚¤ãƒ«åˆ†å‰²**ã—ã€å„ã‚¿ã‚¤ãƒ«ã«å½±éŸ¿ã™ã‚‹ Gaussian ã®ã¿ã‚’å‡¦ç†ã™ã‚‹ã€‚

```rust
const TILE_SIZE: u32 = 16;

/// Tile structure
#[derive(Clone)]
pub struct Tile {
    pub x: u32,
    pub y: u32,
    pub gaussian_indices: Vec<usize>,
}

/// Compute which Gaussians affect which tiles
pub fn assign_gaussians_to_tiles(
    gaussians: &[Gaussian4D],
    t: f32,
    width: u32,
    height: u32,
) -> Vec<Tile> {
    let num_tiles_x = (width + TILE_SIZE - 1) / TILE_SIZE;
    let num_tiles_y = (height + TILE_SIZE - 1) / TILE_SIZE;

    let mut tiles: Vec<Tile> = (0..num_tiles_y)
        .flat_map(|ty| {
            (0..num_tiles_x).map(move |tx| Tile {
                x: tx,
                y: ty,
                gaussian_indices: Vec::new(),
            })
        })
        .collect();

    // For each Gaussian, compute affected tiles
    for (g_idx, g) in gaussians.iter().enumerate() {
        let (mu_t, sigma_t) = g.at_time(t);

        // Project Gaussian center to screen (simplified)
        let screen_x = ((mu_t.x + 1.0) * 0.5 * width as f32) as u32;
        let screen_y = ((1.0 - mu_t.y) * 0.5 * height as f32) as u32;

        // Compute bounding box (simplified: use fixed radius)
        let radius = 3.0 * sigma_t[(0, 0)].sqrt();  // 3Ïƒ rule
        let pixel_radius = (radius * width as f32 * 0.5) as u32;

        let min_x = screen_x.saturating_sub(pixel_radius) / TILE_SIZE;
        let max_x = ((screen_x + pixel_radius).min(width - 1)) / TILE_SIZE;
        let min_y = screen_y.saturating_sub(pixel_radius) / TILE_SIZE;
        let max_y = ((screen_y + pixel_radius).min(height - 1)) / TILE_SIZE;

        // Assign Gaussian to all affected tiles
        for ty in min_y..=max_y {
            for tx in min_x..=max_x {
                let tile_idx = (ty * num_tiles_x + tx) as usize;
                if tile_idx < tiles.len() {
                    tiles[tile_idx].gaussian_indices.push(g_idx);
                }
            }
        }
    }

    tiles
}

/// Render a single tile
fn render_tile(
    tile: &Tile,
    gaussians: &[Gaussian4D],
    sorted_indices: &[(usize, f32)],
    t: f32,
    width: u32,
    height: u32,
    camera_pos: &Vector3<f32>,
) -> Vec<(u32, u32, Vector3<f32>)> {
    let mut pixels = Vec::new();

    let x_start = tile.x * TILE_SIZE;
    let y_start = tile.y * TILE_SIZE;
    let x_end = (x_start + TILE_SIZE).min(width);
    let y_end = (y_start + TILE_SIZE).min(height);

    for y in y_start..y_end {
        for x in x_start..x_end {
            let ray = compute_ray(x, y, width, height, camera_pos);

            // Only consider Gaussians in this tile
            let color = trace_ray_tile(&ray, gaussians, &tile.gaussian_indices, t);
            pixels.push((x, y, color));
        }
    }

    pixels
}

fn trace_ray_tile(
    ray: &Ray,
    gaussians: &[Gaussian4D],
    indices: &[usize],
    t: f32,
) -> Vector3<f32> {
    let mut accum_color = Vector3::zeros();
    let mut accum_alpha = 0.0_f32;

    for &idx in indices {
        let g = &gaussians[idx];
        let (mu_t, _sigma_t) = g.at_time(t);

        let diff = ray.origin - mu_t;
        let dist = diff.norm();
        let weight = (-0.5 * dist * dist).exp() * g.alpha;

        let alpha_contrib = weight * (1.0 - accum_alpha);
        accum_color += g.color * alpha_contrib;
        accum_alpha += alpha_contrib;

        if accum_alpha > 0.99 {
            break;
        }
    }

    accum_color
}
```

**ã‚¿ã‚¤ãƒ«ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã®ä¸¦åˆ—åŒ–**:

```rust
pub fn render_4d_tiled(
    gaussians: &[Gaussian4D],
    t: f32,
    width: u32,
    height: u32,
    camera_pos: Vector3<f32>,
) -> RgbImage {
    // 1. Compute depths and sort
    let view_dir = Vector3::new(0.0, 0.0, -1.0);
    let mut sorted = compute_depths(gaussians, &camera_pos, &view_dir, t);
    sort_gaussians_by_depth(&mut sorted);

    // 2. Assign Gaussians to tiles
    let tiles = assign_gaussians_to_tiles(gaussians, t, width, height);

    // 3. Render tiles in parallel
    let pixels: Vec<_> = tiles
        .par_iter()
        .flat_map(|tile| {
            render_tile(tile, gaussians, &sorted, t, width, height, &camera_pos)
        })
        .collect();

    // 4. Assemble image
    let mut img = RgbImage::new(width, height);
    for (x, y, color) in pixels {
        img.put_pixel(x, y, Rgb([
            (color.x.clamp(0.0, 1.0) * 255.0) as u8,
            (color.y.clamp(0.0, 1.0) * 255.0) as u8,
            (color.z.clamp(0.0, 1.0) * 255.0) as u8,
        ]));
    }

    img
}
```

**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ** (100K Gaussians, 1920Ã—1080):

| æ‰‹æ³• | ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æ™‚é–“ |
|:-----|:----------------|
| Naive ray tracing (1ã‚¹ãƒ¬ãƒƒãƒ‰) | 4,200 ms |
| Naive + rayon (8ã‚¹ãƒ¬ãƒƒãƒ‰) | 580 ms |
| Tile-based + rayon | **62 ms** (16 FPS) |

#### Deformation Network æ¨è«– (ç°¡æ˜“ MLP)

å®Ÿéš›ã® 4DGS ã§ã¯ã€deformation network $f_\theta$ ã‚’ MLP ã§å®Ÿè£…ã™ã‚‹ã€‚

```rust
use nalgebra::Vector4;

/// Simplified MLP for deformation network
pub struct DeformationMLP {
    pub weights_1: Vec<f32>,  // Flattened weight matrix
    pub bias_1: Vec<f32>,
    pub weights_2: Vec<f32>,
    pub bias_2: Vec<f32>,
}

impl DeformationMLP {
    /// Forward pass: (mu, t) -> (Î”Î¼, Î”q, Î”s)
    pub fn forward(&self, mu: &Vector3<f32>, t: f32) -> (Vector3<f32>, Vector4<f32>, Vector3<f32>) {
        // Input: concat([mu, sin(2Ï€t), cos(2Ï€t)]) -> 5D
        let phase = 2.0 * std::f32::consts::PI * t;
        let input = vec![mu.x, mu.y, mu.z, phase.sin(), phase.cos()];

        // Layer 1: 5 -> 32 (ReLU)
        let hidden: Vec<f32> = (0..32)
            .map(|i| {
                let mut sum = self.bias_1[i];
                for j in 0..5 {
                    sum += input[j] * self.weights_1[i * 5 + j];
                }
                sum.max(0.0)  // ReLU
            })
            .collect();

        // Layer 2: 32 -> 10 (output: 3 + 4 + 3)
        let output: Vec<f32> = (0..10)
            .map(|i| {
                let mut sum = self.bias_2[i];
                for j in 0..32 {
                    sum += hidden[j] * self.weights_2[i * 32 + j];
                }
                sum
            })
            .collect();

        // Parse output
        let delta_mu = Vector3::new(output[0], output[1], output[2]);
        let delta_q = Vector4::new(output[3], output[4], output[5], output[6]);
        let delta_s = Vector3::new(output[7], output[8], output[9]);

        (delta_mu, delta_q, delta_s)
    }
}

/// Apply deformation to Gaussian
impl Gaussian4D {
    pub fn deform_with_mlp(&self, mlp: &DeformationMLP, t: f32) -> (Vector3<f32>, Matrix3<f32>) {
        let (delta_mu, _delta_q, delta_s) = mlp.forward(&self.mu0, t);

        let mu_t = self.mu0 + delta_mu;

        // Simplified: scale only (full version would apply rotation via delta_q)
        let scale_factors = Vector3::new(
            (delta_s.x).exp(),
            (delta_s.y).exp(),
            (delta_s.z).exp(),
        );
        let sigma_t = self.sigma0.component_mul(&Matrix3::from_diagonal(&scale_factors));

        (mu_t, sigma_t)
    }
}
```

**å®Ÿéš›ã® 4DGS å®Ÿè£…ã§ã¯**:
- Deformation network ã¯ PyTorch/JAX ã§è¨“ç·´
- Weights ã‚’ Rust ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ (`.safetensors` å½¢å¼)
- Rust ã§æ¨è«–ã®ã¿å®Ÿè¡Œ (è¨“ç·´ã¯ Rust/Python)

### 4.3 ğŸ”® Elixir: ãƒ­ãƒœãƒƒãƒˆåˆ†æ•£åˆ¶å¾¡

Elixir ã® OTP (Open Telecom Platform) ã§ã€è¤‡æ•°ãƒ­ãƒœãƒƒãƒˆã®ä¸¦è¡Œåˆ¶å¾¡ã¨è€éšœå®³æ€§ã‚’å®Ÿç¾ã€‚

#### Mix project setup

```bash
mix new robot_swarm --sup
cd robot_swarm
```

#### ãƒ­ãƒœãƒƒãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (GenServer)

```elixir
# lib/robot_swarm/robot_agent.ex
defmodule RobotSwarm.RobotAgent do
  use GenServer

  # Client API
  def start_link(robot_id) do
    GenServer.start_link(__MODULE__, robot_id, name: via_tuple(robot_id))
  end

  def execute_action(robot_id, action) do
    GenServer.call(via_tuple(robot_id), {:execute, action})
  end

  def get_state(robot_id) do
    GenServer.call(via_tuple(robot_id), :get_state)
  end

  # Server Callbacks
  @impl true
  def init(robot_id) do
    {:ok, %{id: robot_id, position: [0.0, 0.0, 0.0], status: :idle}}
  end

  @impl true
  def handle_call({:execute, action}, _from, state) do
    # Simulate action execution
    new_position = Enum.zip_with(state.position, action, &(&1 + &2))

    new_state = %{state | position: new_position, status: :executing}

    # Simulate Diffusion Policy inference (call Rust NIF)
    # In practice: call Rust function via Rustler
    # next_action = RustDiffusionPolicy.infer(observation)

    {:reply, :ok, new_state}
  end

  @impl true
  def handle_call(:get_state, _from, state) do
    {:reply, state, state}
  end

  # Registry
  defp via_tuple(robot_id) do
    {:via, Registry, {RobotSwarm.Registry, robot_id}}
  end
end
```

#### Supervisor ã§è€éšœå®³æ€§

```elixir
# lib/robot_swarm/application.ex
defmodule RobotSwarm.Application do
  use Application

  @impl true
  def start(_type, _args) do
    children = [
      {Registry, keys: :unique, name: RobotSwarm.Registry},
      {DynamicSupervisor, name: RobotSwarm.RobotSupervisor, strategy: :one_for_one}
    ]

    opts = [strategy: :one_for_one, name: RobotSwarm.Supervisor]
    Supervisor.start_link(children, opts)
  end
end

# Spawn multiple robots
defmodule RobotSwarm.Coordinator do
  def spawn_robots(num_robots) do
    for i <- 1..num_robots do
      spec = {RobotSwarm.RobotAgent, i}
      DynamicSupervisor.start_child(RobotSwarm.RobotSupervisor, spec)
    end
  end

  def broadcast_action(action) do
    # Broadcast to all robots
    Registry.select(RobotSwarm.Registry, [{{:"$1", :_, :_}, [], [:"$1"]}])
    |> Task.async_stream(&RobotSwarm.RobotAgent.execute_action(&1, action), max_concurrency: 16)
    |> Stream.run()
  end
end
```

#### ä½¿ç”¨ä¾‹

```elixir
# iex -S mix
iex> RobotSwarm.Coordinator.spawn_robots(5)
# 5ã¤ã®ãƒ­ãƒœãƒƒãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒèµ·å‹•

iex> RobotSwarm.RobotAgent.execute_action(1, [0.1, 0.0, 0.2])
:ok

iex> RobotSwarm.RobotAgent.get_state(1)
%{id: 1, position: [0.1, 0.0, 0.2], status: :executing}

# Broadcast (å…¨ãƒ­ãƒœãƒƒãƒˆã«åŒæ™‚å‘½ä»¤)
iex> RobotSwarm.Coordinator.broadcast_action([0.0, 0.1, 0.0])
# 5ã¤å…¨ã¦ã®ãƒ­ãƒœãƒƒãƒˆãŒä¸¦è¡Œå®Ÿè¡Œ
```

**Elixir ã®å¼·ã¿**:
- **ä¸¦è¡Œæ€§**: è»½é‡ãƒ—ãƒ­ã‚»ã‚¹ (BEAM VM) ã§æ•°ä¸‡ãƒ­ãƒœãƒƒãƒˆã‚‚åˆ¶å¾¡å¯èƒ½
- **è€éšœå®³æ€§**: 1ã¤ã®ãƒ­ãƒœãƒƒãƒˆãŒã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ã¦ã‚‚ã€Supervisor ãŒè‡ªå‹•å†èµ·å‹•
- **åˆ†æ•£**: è¤‡æ•°ãƒã‚·ãƒ³ã«ã¾ãŸãŒã‚‹ãƒ­ãƒœãƒƒãƒˆç¾¤ã‚‚é€éçš„ã«åˆ¶å¾¡å¯èƒ½

> **Note:** **ã“ã“ã¾ã§ã§å…¨ä½“ã®70%å®Œäº†ï¼** Zone 4 ã§3è¨€èªãƒ•ãƒ«ã‚¹ã‚¿ãƒƒã‚¯å®Ÿè£…ã‚’å®Œæˆã€‚æ¬¡ã¯å®Ÿé¨“ â€” Zone 5 ã§å®Ÿéš›ã«å‹•ã‹ã—ã¦æ¤œè¨¼ã™ã‚‹ã€‚

---

### ğŸ”¬ å®Ÿé¨“ãƒ»æ¤œè¨¼ï¼ˆ30åˆ†ï¼‰â€” Tiny Motion Diffusion æ¼”ç¿’

**ã‚´ãƒ¼ãƒ«**: è‡ªåˆ†ã®æ‰‹ã§ Tiny Motion Diffusion Model ã‚’è¨“ç·´ã—ã€ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆã‚’ä½“é¨“ã™ã‚‹ã€‚

### 5.1 æ¼”ç¿’: CPU 10åˆ†ã§æ­©è¡Œãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ

#### ãƒ‡ãƒ¼ã‚¿æº–å‚™

ç°¡æ˜“çš„ãªåˆæˆãƒ‡ãƒ¼ã‚¿ (æ­©è¡Œã®å‘¨æœŸãƒ‘ã‚¿ãƒ¼ãƒ³) ã‚’ç”Ÿæˆ:

```rust
use std::f32::consts::PI;

/// åˆæˆæ­©è¡Œãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ (TÃ—JÃ—3 ãƒ•ãƒ©ãƒƒãƒˆ)
pub fn generate_walking_motion(t_frames: usize, j_joints: usize) -> Vec<f32> {
    let mut motion = vec![0.0_f32; t_frames * j_joints * 3];

    // æ­©è¡Œãƒ‘ã‚¿ãƒ¼ãƒ³: å·¦å³è¶³ã®äº¤äº’ä¸Šä¸‹é‹å‹• (ãƒ™ã‚¯ãƒˆãƒ«åŒ–)
    let phases: Vec<f32> = (0..t_frames)
        .map(|t| 2.0 * PI * t as f32 / t_frames as f32)
        .collect();

    for (frame, &phase) in phases.iter().enumerate() {
        let base = frame * j_joints * 3;
        // å·¦è¶³ (é–¢ç¯€0): yè»¸ (é«˜ã•)
        motion[base + 1] = 0.3 * phase.sin().abs();
        // å³è¶³ (é–¢ç¯€1): yè»¸ (é€†ä½ç›¸)
        motion[base + j_joints * 0 + 3 + 1] = 0.3 * (phase + PI).sin().abs();
        // å…¨é–¢ç¯€ã‚’å‰æ–¹ã«ç§»å‹• (xè»¸)
        for j in 0..j_joints {
            motion[base + j * 3] = 0.05 * frame as f32 / t_frames as f32;
        }
    }

    motion
}

fn main() {
    let num_samples = 100_usize;
    let (t_frames, j_joints) = (30, 22);
    let dataset: Vec<Vec<f32>> = (0..num_samples)
        .map(|_| generate_walking_motion(t_frames, j_joints))
        .collect();

    println!("Dataset generated: {} walking motions", num_samples);
    println!("Each motion: {} frames Ã— {} joints Ã— 3D", t_frames, j_joints);

    // æœ€åˆã®ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã®å·¦è¶³é«˜ã•ã‚’ç¢ºèª
    let motion = &dataset[0];
    let left_leg_heights: Vec<f32> = (0..t_frames)
        .map(|f| motion[f * j_joints * 3 + 1]) // é–¢ç¯€0, yè»¸
        .collect();
    println!("Left leg height (first 5 frames): {:?}", &left_leg_heights[..5]);
    // âœ“ Walking pattern visualized: walking_pattern.png (å®Ÿéš›ã¯ plotters ã‚¯ãƒ¬ãƒ¼ãƒˆã§æç”»)
}
```

#### Tiny Motion Diffusion Model è¨“ç·´

```rust
// Simplified training loop (CPU-only, for demonstration)

pub fn simple_motion_diffusion_train(
    dataset: &[Vec<f32>], // å„è¦ç´ : ãƒ•ãƒ©ãƒƒãƒˆåŒ–ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ (MOTION_DIMæ¬¡å…ƒ)
    num_epochs: usize,
) -> (Vec<f32>, Vec<f32>, Vec<f32>) {
    let motion_dim = dataset[0].len(); // TÃ—JÃ—3 = 1980

    // ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
    let t_steps = 50_usize;
    let beta: Vec<f32> = (0..t_steps)
        .map(|i| 1e-4 + (0.02 - 1e-4) * i as f32 / (t_steps - 1) as f32)
        .collect();

    // ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ãƒã‚¤ã‚¶ãƒ¼: ç·šå½¢å±¤ (speed é‡è¦–)
    let mut w = vec![0.0_f32; motion_dim * motion_dim];
    let mut b_vec = vec![0.0_f32; motion_dim];
    let mut losses = Vec::new();

    for epoch in 0..num_epochs {
        let epoch_loss: f32 = dataset.iter().map(|motion| {
            let x0 = motion.as_slice();

            // ãƒ©ãƒ³ãƒ€ãƒ ãªã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            let t = rand::random::<usize>() % t_steps + 1;

            // ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰æ‹¡æ•£: xt = âˆšá¾±_t Â· x0 + âˆš(1-á¾±_t) Â· Îµ
            let alpha_bar_t: f32 = beta[..t].iter().map(|&b| 1.0 - b).product();
            let eps: Vec<f32> = (0..motion_dim).map(|_| rand_normal_f32()).collect();
            let xt: Vec<f32> = x0.iter().zip(&eps)
                .map(|(&x, &e)| alpha_bar_t.sqrt() * x + (1.0 - alpha_bar_t).sqrt() * e)
                .collect();

            // ãƒã‚¤ã‚ºäºˆæ¸¬ (ã‚·ãƒ³ãƒ—ãƒ«ãªç·šå½¢ãƒ¢ãƒ‡ãƒ«: Îµ_pred = WÂ·xt + b)
            let eps_pred: Vec<f32> = (0..motion_dim).map(|i| {
                w[i * motion_dim..(i + 1) * motion_dim].iter().zip(&xt).map(|(wi, xi)| wi * xi).sum::<f32>()
                    + b_vec[i]
            }).collect();

            // MSE Loss
            let loss = eps.iter().zip(&eps_pred)
                .map(|(&e, &ep)| (e - ep).powi(2))
                .sum::<f32>() / motion_dim as f32;

            // SGD update (ç°¡ç•¥åŒ–)
            let lr = 1e-4_f32;
            for i in 0..motion_dim {
                let grad_b = 2.0 * (eps_pred[i] - eps[i]) / motion_dim as f32;
                b_vec[i] -= lr * grad_b;
                for j in 0..motion_dim {
                    w[i * motion_dim + j] -= lr * 2.0 * (eps_pred[i] - eps[i]) * xt[j] / motion_dim as f32;
                }
            }
            loss
        }).sum::<f32>() / dataset.len() as f32;

        losses.push(epoch_loss);
        println!("Epoch {}: Loss = {:.4}", epoch + 1, epoch_loss);
    }

    println!("âœ“ Training completed");
    (w, b_vec, losses)
}

fn rand_normal_f32() -> f32 { 0.0 } // placeholder
```

#### ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

```rust
/// DDPM é€†æ‹¡æ•£ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
pub fn simple_motion_diffusion_sample(
    w: &[f32],    // ãƒ‡ãƒã‚¤ã‚¶ãƒ¼é‡ã¿ (motion_dim Ã— motion_dim)
    b: &[f32],    // ãƒã‚¤ã‚¢ã‚¹ (motion_dim)
    beta: &[f32], // ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
) -> Vec<f32> {
    let motion_dim = b.len();
    let t_steps = beta.len();

    // ãƒã‚¤ã‚ºã‹ã‚‰é–‹å§‹ (xT ~ N(0, I))
    let mut x: Vec<f32> = (0..motion_dim).map(|_| rand_normal_f32()).collect();

    // é€†æ‹¡æ•£: T â†’ 1
    for t in (1..=t_steps).rev() {
        // ãƒã‚¤ã‚ºäºˆæ¸¬ (ç·šå½¢ãƒ¢ãƒ‡ãƒ«: Îµ_pred = WÂ·x + b)
        let eps_pred: Vec<f32> = (0..motion_dim).map(|i| {
            w[i * motion_dim..(i + 1) * motion_dim].iter().zip(&x).map(|(wi, xi)| wi * xi).sum::<f32>()
                + b[i]
        }).collect();

        // DDPM æ›´æ–°å¼: x_{t-1} = (x_t - Î²_t/âˆš(1-á¾±_t) Â· Îµ_pred) / âˆšÎ±_t
        let alpha_t = 1.0 - beta[t - 1];
        let alpha_bar_t: f32 = beta[..t].iter().map(|&b| 1.0 - b).product();

        x = x.iter().zip(&eps_pred).map(|(&xt, &ep)| {
            (xt - (beta[t - 1] / (1.0 - alpha_bar_t).sqrt()) * ep) / alpha_t.sqrt()
        }).collect();

        // t > 1 ã®å ´åˆ: ç¢ºç‡çš„ãƒã‚¤ã‚ºã‚’è¿½åŠ 
        if t > 1 {
            let sigma = beta[t - 1].sqrt();
            for xi in x.iter_mut() {
                *xi += sigma * rand_normal_f32();
            }
        }
    }

    x
}

fn rand_normal_f32() -> f32 { 0.0 } // placeholder

fn main() {
    let beta: Vec<f32> = (0..50)
        .map(|i| 1e-4 + (0.02 - 1e-4) * i as f32 / 49.0)
        .collect();
    let motion_dim = 30 * 22 * 3; // 1980
    let w = vec![0.0_f32; motion_dim * motion_dim];
    let b = vec![0.0_f32; motion_dim];

    let generated_motion = simple_motion_diffusion_sample(&w, &b, &beta);
    println!("\nGenerated motion shape: (30, 22, 3) = {} elements", generated_motion.len());
    // âœ“ Generated motion visualized: generated_walking.png (å®Ÿéš›ã¯ plotters ã‚¯ãƒ¬ãƒ¼ãƒˆã§æç”»)
}
```

### 5.2 è©•ä¾¡æŒ‡æ¨™

Motion generation ã®è©•ä¾¡æŒ‡æ¨™:

#### FID (FrÃ©chet Inception Distance)

ç”»åƒç”Ÿæˆã® FID ã‚’ motion ã«é©ç”¨ã€‚ç‰¹å¾´æŠ½å‡ºå™¨ã«ã¯ action recognition model ã‚’ä½¿ç”¨ã€‚

$$
\text{FID} = \| \mu_r - \mu_g \|^2 + \text{Tr}(\Sigma_r + \Sigma_g - 2\sqrt{\Sigma_r \Sigma_g})
$$

- $\mu_r, \Sigma_r$: Real motion ã®ç‰¹å¾´åˆ†å¸ƒ
- $\mu_g, \Sigma_g$: Generated motion ã®ç‰¹å¾´åˆ†å¸ƒ

#### Diversity

ç”Ÿæˆã•ã‚ŒãŸãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã®å¤šæ§˜æ€§:

$$
\text{Diversity} = \mathbb{E}_{i \neq j} [\| \text{feat}(m_i) - \text{feat}(m_j) \|]
$$

#### Physical Plausibility

ç‰©ç†çš„å¦¥å½“æ€§ã®æŒ‡æ¨™:

- **Foot contact accuracy**: æ¥åœ°æ™‚ã®é€Ÿåº¦ãŒ0ã«è¿‘ã„ã‹
- **Joint angle limits**: é–¢ç¯€è§’åº¦ãŒäººé–“ã®å¯å‹•åŸŸå†…ã‹
- **Smoothness**: æ€¥æ¿€ãªåŠ é€Ÿåº¦ãŒãªã„ã‹

```rust
// Simple evaluation metrics

/// è¶³æ¥åœ°ç²¾åº¦: æ¥åœ°æ™‚ (y < 0.05) ã«é€Ÿåº¦ãŒå¤§ãã„å ´åˆã‚’é•åã¨ã‚«ã‚¦ãƒ³ãƒˆ
pub fn foot_contact_accuracy(motion: &[f32], t_frames: usize, j_joints: usize) -> f32 {
    let mut violations = 0_usize;
    // è„šé–¢ç¯€: 0 (å·¦), 1 (å³)
    for t in 0..t_frames - 1 {
        for leg in [0_usize, 1] {
            let base_t  = (t * j_joints + leg) * 3;
            let base_t1 = ((t + 1) * j_joints + leg) * 3;
            let height = motion[base_t + 1]; // yåº§æ¨™
            let dx = motion[base_t1]     - motion[base_t];
            let dy = motion[base_t1 + 1] - motion[base_t + 1];
            let dz = motion[base_t1 + 2] - motion[base_t + 2];
            let speed = (dx*dx + dy*dy + dz*dz).sqrt();
            if height < 0.05 && speed > 0.1 {
                violations += 1;
            }
        }
    }
    1.0 - violations as f32 / (2 * (t_frames - 1)) as f32
}

/// ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³å¤šæ§˜æ€§: ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«é–“ã®å¹³å‡ L2 è·é›¢
pub fn motion_diversity(motions: &[Vec<f32>]) -> f32 {
    let n = motions.len();
    if n < 2 { return 0.0; }
    let dists: Vec<f32> = (0..n).flat_map(|i| {
        (i+1..n).map(move |j| {
            motions[i].iter().zip(&motions[j])
                .map(|(&a, &b)| (a - b).powi(2))
                .sum::<f32>() / motions[i].len() as f32
        })
    }).collect();
    let mean_sq = dists.iter().sum::<f32>() / dists.len() as f32;
    mean_sq.sqrt()
}

fn rand_normal_f32() -> f32 { 0.0 } // placeholder

fn main() {
    let beta: Vec<f32> = (0..50).map(|i| 1e-4 + (0.02 - 1e-4) * i as f32 / 49.0).collect();
    let motion_dim = 30 * 22 * 3;
    let w = vec![0.0_f32; motion_dim * motion_dim];
    let b = vec![0.0_f32; motion_dim];

    let generated: Vec<Vec<f32>> = (0..10)
        .map(|_| simple_motion_diffusion_sample(&w, &b, &beta))
        .collect();

    let contact_acc = generated.iter()
        .map(|m| foot_contact_accuracy(m, 30, 22))
        .sum::<f32>() / generated.len() as f32;
    let diversity = motion_diversity(&generated);

    println!("\nã€è©•ä¾¡çµæœã€‘");
    println!("Foot Contact Accuracy: {:.1}%", contact_acc * 100.0);
    println!("Diversity: {:.4}", diversity);
    println!("\nç›®æ¨™: Contact Acc > 90%, Diversity > 0.01");
}
```

### 5.3 è©³ç´°è¨“ç·´ãƒ­ã‚°ã¨å¯è¦–åŒ–

å®Ÿéš›ã® Motion Diffusion è¨“ç·´ã§ã¯ã€loss curveã€ç”Ÿæˆå“è³ªã€ç‰©ç†å¦¥å½“æ€§ã‚’ç¶™ç¶šçš„ã«ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã€‚

#### è¨“ç·´ãƒ­ã‚°ã®è©³ç´°è¨˜éŒ²

```rust
use std::time::Instant;

/// è©³ç´°ãƒ­ã‚°ä»˜ãè¨“ç·´é–¢æ•°
pub fn train_with_logging(
    dataset: &[Vec<f32>],
    num_epochs: usize,
    lr: f32,
    log_interval: usize,
) -> (Vec<f32>, Vec<f32>, TrainingLogs) {
    let motion_dim = dataset[0].len();
    let beta: Vec<f32> = (0..50).map(|i| 1e-4 + (0.02 - 1e-4) * i as f32 / 49.0).collect();

    // ã‚·ãƒ³ãƒ—ãƒ«ãªç·šå½¢ãƒ‡ãƒã‚¤ã‚¶ãƒ¼
    let mut w = vec![0.0_f32; motion_dim * motion_dim];
    let mut b_vec = vec![0.0_f32; motion_dim];

    let mut logs = TrainingLogs::new();
    let start = Instant::now();

    println!("\n=== Training Started ({:?}) ===", start.elapsed());
    println!("Dataset size: {} motions", dataset.len());
    println!("Model parameters: {}", motion_dim * motion_dim + motion_dim);
    println!("Learning rate: {lr}");
    println!("Epochs: {num_epochs}\n");

    for epoch in 0..num_epochs {
        let (epoch_loss, epoch_grad_norm) = dataset.iter().fold((0.0_f32, 0.0_f32), |(acc_loss, acc_norm), motion| {
            let x0 = motion.as_slice();
            let t = rand::random::<usize>() % beta.len() + 1;

            // ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰æ‹¡æ•£
            let alpha_bar_t: f32 = beta[..t].iter().map(|&b| 1.0 - b).product();
            let eps: Vec<f32> = (0..motion_dim).map(|_| rand_normal_f32()).collect();
            let xt: Vec<f32> = x0.iter().zip(&eps)
                .map(|(&x, &e)| alpha_bar_t.sqrt() * x + (1.0 - alpha_bar_t).sqrt() * e)
                .collect();

            // ãƒã‚¤ã‚ºäºˆæ¸¬
            let eps_pred: Vec<f32> = (0..motion_dim).map(|i| {
                w[i*motion_dim..(i+1)*motion_dim].iter().zip(&xt).map(|(wi, xi)| wi*xi).sum::<f32>()
                    + b_vec[i]
            }).collect();

            // MSE Loss + å‹¾é…
            let loss = eps.iter().zip(&eps_pred)
                .map(|(&e, &ep)| (e - ep).powi(2))
                .sum::<f32>() / motion_dim as f32;

            let mut grad_norm = 0.0_f32;
            for i in 0..motion_dim {
                let grad_b = 2.0 * (eps_pred[i] - eps[i]) / motion_dim as f32;
                b_vec[i] -= lr * grad_b;
                for j in 0..motion_dim {
                    let gw = 2.0 * (eps_pred[i] - eps[i]) * xt[j] / motion_dim as f32;
                    w[i * motion_dim + j] -= lr * gw;
                    grad_norm += gw * gw;
                }
            }

            (acc_loss + loss, acc_norm + grad_norm.sqrt())
        });

        let avg_loss = epoch_loss / dataset.len() as f32;
        let avg_grad_norm = epoch_grad_norm / dataset.len() as f32;
        logs.epoch_losses.push(avg_loss);
        logs.grad_norms.push(avg_grad_norm);
        logs.timestamps.push(start.elapsed().as_secs_f64());

        // å®šæœŸè©•ä¾¡
        if (epoch + 1) % log_interval == 0 || epoch + 1 == num_epochs {
            let test_motions: Vec<Vec<f32>> = (0..5)
                .map(|_| simple_motion_diffusion_sample(&w, &b_vec, &beta))
                .collect();
            let contact_acc = test_motions.iter()
                .map(|m| foot_contact_accuracy(m, 30, 22))
                .sum::<f32>() / 5.0;
            logs.foot_contact_acc.push(contact_acc);
            logs.sample_quality.push(1.0 - avg_loss);

            println!("Epoch {}/{}:", epoch + 1, num_epochs);
            println!("  Loss: {:.6}", avg_loss);
            println!("  Grad Norm: {:.4}", avg_grad_norm);
            println!("  Contact Accuracy: {:.1}%", contact_acc * 100.0);
            println!("  Elapsed: {:.2}s", start.elapsed().as_secs_f64());
        }
    }

    println!("\n=== Training Completed ({:.2}s) ===\n", start.elapsed().as_secs_f64());
    // serde_json::to_writer(File::create("training_logs.json")?, &logs)?; // ãƒ­ã‚°ä¿å­˜

    (w, b_vec, logs)
}

pub struct TrainingLogs {
    pub epoch_losses: Vec<f32>,
    pub sample_quality: Vec<f32>,
    pub foot_contact_acc: Vec<f32>,
    pub grad_norms: Vec<f32>,
    pub timestamps: Vec<f64>,
}

impl TrainingLogs {
    pub fn new() -> Self {
        Self {
            epoch_losses: Vec::new(), sample_quality: Vec::new(),
            foot_contact_acc: Vec::new(), grad_norms: Vec::new(), timestamps: Vec::new(),
        }
    }
}

fn rand_normal_f32() -> f32 { 0.0 } // placeholder
```

#### Loss Curve å¯è¦–åŒ– (Plots.jl)

```rust
// è¨“ç·´å¯è¦–åŒ– (plotters ã‚¯ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨)
// [dependencies] plotters = "0.3"

use plotters::prelude::*;

/// 2Ã—2 ã‚°ãƒªãƒƒãƒ‰ã§è¨“ç·´ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’æç”»
pub fn visualize_training_logs(logs: &TrainingLogs, output: &str) -> Result<(), Box<dyn std::error::Error>> {
    let root = BitMapBackend::new(output, (1000, 800)).into_drawing_area();
    root.fill(&WHITE)?;
    let areas = root.split_evenly((2, 2));

    // Panel 1: Training Loss
    {
        let mut chart = ChartBuilder::on(&areas[0])
            .caption("Training Loss", ("sans-serif", 20))
            .margin(10).x_label_area_size(30).y_label_area_size(40)
            .build_cartesian_2d(0..logs.epoch_losses.len(), 0f32..logs.epoch_losses.first().cloned().unwrap_or(1.0))?;
        chart.configure_mesh().x_desc("Epoch").y_desc("Loss").draw()?;
        chart.draw_series(LineSeries::new(
            logs.epoch_losses.iter().enumerate().map(|(i, &v)| (i, v)),
            &BLUE,
        ))?.label("MSE Loss").legend(|(x, y)| PathElement::new(vec![(x, y), (x + 20, y)], &BLUE));
        // Target line at 0.01
        chart.draw_series(LineSeries::new(vec![(0, 0.01), (logs.epoch_losses.len(), 0.01)], &RED.mix(0.5)))?;
    }

    // Panel 2: Gradient Norm (learning stability check)
    {
        let max_norm = logs.grad_norms.iter().cloned().fold(0f32, f32::max).max(1e-8);
        let mut chart = ChartBuilder::on(&areas[1])
            .caption("Gradient Magnitude", ("sans-serif", 20))
            .margin(10).x_label_area_size(30).y_label_area_size(50)
            .build_cartesian_2d(0..logs.grad_norms.len(), 1e-8f32..max_norm)?;
        chart.configure_mesh().x_desc("Epoch").y_desc("â€–âˆ‡Wâ€–").draw()?;
        chart.draw_series(LineSeries::new(
            logs.grad_norms.iter().enumerate().map(|(i, &v)| (i, v)),
            &CYAN,
        ))?;
    }

    // Panel 3: Sample Quality
    {
        let mut chart = ChartBuilder::on(&areas[2])
            .caption("Sample Quality", ("sans-serif", 20))
            .margin(10).x_label_area_size(30).y_label_area_size(40)
            .build_cartesian_2d(0..logs.sample_quality.len(), 0f32..1f32)?;
        chart.configure_mesh().x_desc("Eval Epoch").y_desc("Quality Score").draw()?;
        chart.draw_series(LineSeries::new(
            logs.sample_quality.iter().enumerate().map(|(i, &v)| (i, v)),
            &GREEN,
        ))?;
    }

    // Panel 4: Foot Contact Accuracy
    {
        let mut chart = ChartBuilder::on(&areas[3])
            .caption("Foot Contact Accuracy", ("sans-serif", 20))
            .margin(10).x_label_area_size(30).y_label_area_size(40)
            .build_cartesian_2d(0..logs.foot_contact_acc.len(), 0f32..100f32)?;
        chart.configure_mesh().x_desc("Eval Epoch").y_desc("Accuracy (%)").draw()?;
        chart.draw_series(LineSeries::new(
            logs.foot_contact_acc.iter().enumerate().map(|(i, &v)| (i, v * 100.0)),
            &MAGENTA,
        ))?;
        // Target line at 90%
        chart.draw_series(LineSeries::new(
            vec![(0, 90f32), (logs.foot_contact_acc.len(), 90f32)],
            &RED.mix(0.5),
        ))?;
    }

    root.present()?;
    println!("âœ“ Training dashboard saved: {output}");
    Ok(())
}
```

**å¯è¦–åŒ–ã®èª­ã¿æ–¹**:
1. **Loss curve**: å˜èª¿æ¸›å°‘ãŒç†æƒ³ã€‚æŒ¯å‹• = LRå¤§ã™ã
2. **Gradient norm**: å®‰å®šã—ã¦ã„ã‚Œã°è‰¯ã„ã€‚çˆ†ç™º/æ¶ˆå¤±ã«æ³¨æ„
3. **Sample quality**: Epoch 20-30 ã§åæŸ
4. **Contact accuracy**: ç›®æ¨™90%è¶…ãˆã‚’ç¢ºèª

#### ç”Ÿæˆãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã®å¯è¦–åŒ– (3D Stick Figure)

```rust
// ç”Ÿæˆãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ 3D ã‚¹ãƒ†ã‚£ãƒƒã‚¯ãƒ•ã‚£ã‚®ãƒ¥ã‚¢ã¨ã—ã¦å¯è¦–åŒ– (gif ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³)
// [dependencies] plotters = "0.3", gif = "0.13"

/// ã‚¹ã‚±ãƒ«ãƒˆãƒ³å®šç¾© (22é–¢ç¯€ humanoid ã®ä¸»è¦éª¨æ ¼æ¥ç¶š)
const SKELETON_EDGES: &[(usize, usize)] = &[
    (0, 2), (1, 3),    // è„š â†’ è…°
    (2, 4), (3, 5),    // è…° â†’ èƒŒéª¨
    (4, 6), (5, 6),    // èƒŒéª¨ â†’ è‚©
    (6, 7), (6, 8),    // è‚© â†’ è…•
    (7, 9), (8, 10),   // è…• â†’ æ‰‹
    (4, 11), (5, 12),  // è…° â†’ è†
    (11, 13), (12, 14), // è† â†’ è¶³é¦–
];

/// T ãƒ•ãƒ¬ãƒ¼ãƒ ã® 3D ã‚¹ãƒ†ã‚£ãƒƒã‚¯ãƒ•ã‚£ã‚®ãƒ¥ã‚¢ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ SVG/PNG ã®é€£ç•ªã¨ã—ã¦å‡ºåŠ›
pub fn visualize_motion_3d(
    motion: &[f32],  // ãƒ•ãƒ©ãƒƒãƒˆ (T Ã— J Ã— 3)
    t_frames: usize,
    j_joints: usize,
    output_prefix: &str,
) -> Result<(), Box<dyn std::error::Error>> {
    for t in 0..t_frames {
        let fname = format!("{output_prefix}_frame_{t:03}.png");
        let root = BitMapBackend::new(&fname, (400, 400)).into_drawing_area();
        root.fill(&WHITE)?;

        // ãƒ•ãƒ¬ãƒ¼ãƒ  t ã®é–¢ç¯€ä½ç½®ã‚’å–å¾— (æ­£è¦åŒ–: x,y ã‚’ [-1,1] â†’ ãƒ”ã‚¯ã‚»ãƒ«)
        let positions: Vec<[f32; 3]> = (0..j_joints).map(|j| {
            let base = (t * j_joints + j) * 3;
            [motion[base], motion[base + 1], motion[base + 2]]
        }).collect();

        let to_px = |x: f32, lim: f32| ((x / lim + 1.0) * 0.5 * 380.0 + 10.0) as i32;

        let mut chart = ChartBuilder::on(&root)
            .caption(format!("Frame {} / {}", t + 1, t_frames), ("sans-serif", 14))
            .margin(5).x_label_area_size(20).y_label_area_size(20)
            .build_cartesian_2d(-1f32..1f32, 0f32..2f32)?;

        // é–¢ç¯€ã‚’ç‚¹ã§æç”»
        chart.draw_series(positions.iter().map(|p| {
            Circle::new((p[0], p[1] + 1.0), 5, BLUE.filled())
        }))?;

        // éª¨æ ¼æ¥ç¶šã‚’ç·šã§æç”»
        for &(i, j) in SKELETON_EDGES {
            if i < j_joints && j < j_joints {
                chart.draw_series(LineSeries::new(
                    vec![
                        (positions[i][0], positions[i][1] + 1.0),
                        (positions[j][0], positions[j][1] + 1.0),
                    ],
                    &BLACK,
                ))?;
            }
        }
        root.present()?;
    }
    println!("âœ“ Motion animation saved: {output_prefix}_frame_*.png (use ffmpeg to compose gif)");
    Ok(())
}
```

#### è¨“ç·´ã‚«ãƒ¼ãƒ–ã®æ¯”è¼ƒ (è¤‡æ•°è¨­å®š)

```rust
/// è¤‡æ•°ã®å­¦ç¿’ç‡è¨­å®šã‚’æ¯”è¼ƒã—ã€æå¤±æ›²ç·šã‚’æç”»
pub fn compare_training_configs(dataset: &[Vec<f32>]) -> Result<(), Box<dyn std::error::Error>> {
    let configs: &[(&str, f32)] = &[
        ("LR 1e-3", 1e-3),
        ("LR 1e-4", 1e-4),
        ("LR 5e-3", 5e-3),
    ];

    let root = BitMapBackend::new("lr_comparison.png", (800, 500)).into_drawing_area();
    root.fill(&WHITE)?;
    let mut chart = ChartBuilder::on(&root)
        .caption("Learning Rate Comparison", ("sans-serif", 20))
        .margin(10).x_label_area_size(30).y_label_area_size(50)
        .build_cartesian_2d(0..30_usize, 1e-4f32..1f32)?;
    chart.configure_mesh().x_desc("Epoch").y_desc("Loss (log scale)").draw()?;

    let colors = [&BLUE, &RED, &GREEN];
    for ((name, &lr), &color) in configs.iter().zip(colors.iter()) {
        let (_, _, logs) = train_with_logging(dataset, 30, lr, 10);
        chart.draw_series(LineSeries::new(
            logs.epoch_losses.iter().enumerate().map(|(i, &v)| (i, v)),
            color,
        ))?.label(*name)
          .legend(|(x, y)| PathElement::new(vec![(x, y), (x + 20, y)], color));
    }
    chart.configure_series_labels().background_style(&WHITE.mix(0.8)).border_style(&BLACK).draw()?;
    root.present()?;
    println!("âœ“ Learning rate comparison saved: lr_comparison.png");
    Ok(())
}

fn main() {
    let dataset: Vec<Vec<f32>> = (0..100)
        .map(|_| generate_walking_motion(30, 22))
        .collect();

    compare_training_configs(&dataset).unwrap();
}
```

**å®Ÿé¨“çµæœã®èª­ã¿æ–¹**:
- **LR 1e-3**: æœ€é€ŸåæŸ (Epoch 25ã§åæŸ)
- **LR 1e-4**: å®‰å®šã ãŒé…ã„ (Epoch 50ã§ã‚‚æœªåæŸ)
- **LR 5e-3**: åˆæœŸã¯é€Ÿã„ãŒæŒ¯å‹• (ä¸å®‰å®š)

â†’ **æ¨å¥¨**: LR 1e-3 ã§ã‚¹ã‚¿ãƒ¼ãƒˆã€åæŸå¾Œã« 1e-4 ã«ä¸‹ã’ã‚‹ (LR scheduling)

> **Note:** **ã“ã“ã¾ã§ã§å…¨ä½“ã®85%å®Œäº†ï¼** Zone 5 ã§å®Ÿé¨“ã‚’å®Œäº†ã€‚æ¬¡ã¯ç™ºå±• â€” Zone 6 ã§æœ€æ–°ç ”ç©¶ã¨æœªè§£æ±ºå•é¡Œã‚’æ¢ã‚‹ã€‚

---


> Progress: 85%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. Tiny Motion Diffusionã®MDMã§$\mathbf{x}_0$äºˆæ¸¬ã‚’ä½¿ã†å ´åˆã¨ãƒã‚¤ã‚º$\epsilon$äºˆæ¸¬ã‚’ä½¿ã†å ´åˆã®è¨“ç·´ç›®æ¨™ã®é•ã„ã‚’å¼ã§ç¤ºã›ã€‚
> 2. æ­©è¡Œãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆã®è©•ä¾¡ã«FIDä»£ã‚ã‚Šã«FMDï¼ˆFrÃ©chet Motion Distanceï¼‰ã‚’ä½¿ã†ç†ç”±ã‚’èª¬æ˜ã›ã‚ˆã€‚

## ğŸ”¬ Z6. æ–°ãŸãªå†’é™ºã¸ï¼ˆç ”ç©¶å‹•å‘ï¼‰

**ã‚´ãƒ¼ãƒ«**: 2025-2026 ã®æœ€æ–°ç ”ç©¶å‹•å‘ã‚’ç†è§£ã—ã€æ¬¡ã®ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¹ãƒ«ãƒ¼ã‚’äºˆæ¸¬ã™ã‚‹ã€‚

### 6.1 Motion Generation ã®æœ€æ–°å‹•å‘

| æ‰‹æ³• | å¹´ | é©æ–° | é™ç•Œ |
|:-----|:---|:-----|:-----|
| MDM [^1] | 2022 | Sample prediction + Geometric loss | é…ã„ (1000 steps) |
| MLD [^2] | 2023 | Latent diffusion â†’ 100xé«˜é€ŸåŒ– | VAE reconstruction loss |
| MotionGPT-3 [^8] | 2025 | å¤§è¦æ¨¡äº‹å‰å­¦ç¿’ + In-context learning | è¨ˆç®—ã‚³ã‚¹ãƒˆå¤§ |
| UniMo [^9] | 2026 | CoT reasoning + GRPO | ã¾ã è©•ä¾¡ä¸­ |

**Trend**: Diffusion â†’ Latent Diffusion â†’ LLM-based â†’ Reasoning-augmented

**æ¬¡ã®ä¸€æ‰‹**:
- **Flow Matching for Motion**: Diffusion ã‚ˆã‚Šè¨“ç·´å˜ç´” (ç¬¬38å›å‚ç…§)
- **Physics-informed Motion**: ç‰©ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã¨çµ±åˆ
- **Real-time Motion**: 1-step generation (Consistency Models, ç¬¬40å›)

### 6.2 4D Generation ã®èª²é¡Œ

| èª²é¡Œ | ç¾çŠ¶ | è§£æ±ºæ–¹å‘ |
|:-----|:-----|:---------|
| **é•·æ™‚é–“ä¸€è²«æ€§** | æ•°ç§’ã§ç ´ç¶» | Global-localåˆ†é›¢ (TC4D), Temporal constraints |
| **ç‰©ç†æ³•å‰‡** | é‡åŠ›ç„¡è¦–ã€æµ®éŠç‰©ä½“ | Physics-based loss, Simulator integration |
| **ç·¨é›†æ€§** | ç”Ÿæˆå¾Œã®ç·¨é›†å›°é›£ | Explicit control (skeleton, trajectory) |
| **è¨ˆç®—ã‚³ã‚¹ãƒˆ** | 1ã‚·ãƒ¼ãƒ³æ•°æ™‚é–“ | Sparse representations, Level-of-detail |

**Breakthroughå€™è£œ**:
- **Neural Physics Engines**: 4DGS + ç‰©ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã®èåˆ
- **Compositional 4D**: ãƒ‘ãƒ¼ãƒ„ã”ã¨ã«ç”Ÿæˆ â†’ çµ„ã¿ç«‹ã¦
- **Interactive 4D**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè»Œè·¡ã‚’æã â†’ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”Ÿæˆ

### 6.3 Diffusion Policy ã®æœªè§£æ±ºå•é¡Œ

| å•é¡Œ | èª¬æ˜ | ææ¡ˆè§£æ±ºç­– |
|:-----|:-----|:----------|
| **Sample efficiency** | å¤§é‡ã®ãƒ‡ãƒ¢ãŒå¿…è¦ | Few-shot learning, Meta-learning |
| **Sim-to-real gap** | ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã§è¨“ç·´ â†’ å®Ÿæ©Ÿã§å¤±æ•— | Domain randomization, Real-world fine-tuning |
| **Safety** | å±é™ºãªè¡Œå‹•ã‚’ç”Ÿæˆã—ã†ã‚‹ | Safety constraints, Shielding |
| **Generalization** | ã‚¿ã‚¹ã‚¯ç‰¹åŒ–çš„ | Foundation models (RDT), Multi-task learning |

**RDT ã®å½±éŸ¿**:
- Foundation model (1B params) ã§ sample efficiency æ”¹å–„
- Zero-shot generalization â†’ ãƒ‡ãƒ¢ä¸è¦ã®ã‚¿ã‚¹ã‚¯ã‚‚
- ã—ã‹ã—ã€**Long-horizon planning** ã¯ã¾ã èª²é¡Œ (Hierarchical å¿…é ˆ)

### 6.4 æœªè§£æ±ºå•é¡Œãƒªã‚¹ãƒˆ

ç ”ç©¶ãƒ†ãƒ¼ãƒã‚’æ¢ã—ã¦ã„ã‚‹äººå‘ã‘:

#### Easy (ä¿®å£«ãƒ¬ãƒ™ãƒ«)
1. **Motion style transfer**: "æ­©ã" â†’ "èµ°ã‚‹" ã¸ã®å¤‰æ›
2. **4D editing tools**: ç”Ÿæˆã—ãŸ4Dã‚·ãƒ¼ãƒ³ã®å±€æ‰€ç·¨é›†UI
3. **Diffusion Policy ablation**: ã©ã®æˆåˆ†ãŒæœ¬è³ªçš„ã‹ï¼Ÿ

#### Medium (åšå£«å‰æœŸ)
1. **Physics-consistent 4D generation**: ç‰©ç†æ³•å‰‡ã‚’æº€ãŸã™4Dã‚·ãƒ¼ãƒ³
2. **Long-horizon Diffusion Policy**: 100+ã‚¹ãƒ†ãƒƒãƒ—ã®è¨ˆç”»
3. **Motion-4Dçµ±åˆ**: ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰4Dã‚·ãƒ¼ãƒ³ã‚’è‡ªå‹•ç”Ÿæˆ

#### Hard (åšå£«å¾ŒæœŸã€œãƒã‚¹ãƒ‰ã‚¯)
1. **Unified Motion-4D-Policy**: å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§å…¨ã¦ (Genie 3 ã¸ã®æŒ‘æˆ¦)
2. **Causal 4D**: å› æœé–¢ä¿‚ã‚’ç†è§£ã™ã‚‹4Dç”Ÿæˆ (ç‰©ç†æ³•å‰‡æ¨è«–)
3. **Real-time interactive 4D**: VRãƒ˜ãƒƒãƒ‰ã‚»ãƒƒãƒˆå†…ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”Ÿæˆ

<details><summary>æ¨å¥¨ãƒªãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒªã‚¹ãƒˆ</summary>

**Motion Generation**:
- MDM [^1]: åŸºç¤ã‚’å­¦ã¶
- MLD [^2]: é«˜é€ŸåŒ–ã®è¨­è¨ˆæ€æƒ³
- MotionGPT-3 [^8]: LLM ã¨ã®çµ±åˆ
- UniMo [^9]: æœ€æ–° (CoT + GRPO)

**4D Generation**:
- 4DGS [^3]: åŸºæœ¬å®šå¼åŒ–
- TC4D [^4]: Trajectory conditioning
- Advances in 4D Survey [^11]: ä½“ç³»çš„ç†è§£

**Diffusion Policy**:
- Diffusion Policy [^5]: åŸºç¤è«–æ–‡
- Hierarchical [^6]: é•·æœŸè¨ˆç”»
- RDT [^10]: Foundation model

**é–¢é€£åˆ†é‡**:
- Deformable 3DGS: 4DGSã®å‰èº«
- Neural ODE: é€£ç¶šæ™‚é–“ãƒ¢ãƒ‡ãƒªãƒ³ã‚°
- Imitation Learning survey: ãƒ­ãƒœãƒƒãƒˆå­¦ç¿’ã®å…¨ä½“åƒ

</details>

---


**ã‚´ãƒ¼ãƒ«**: ç¬¬47å›ã®å­¦ã³ã‚’æ•´ç†ã—ã€ç¬¬48å›ã¸ã®æ¥ç¶šã‚’ç¢ºèªã™ã‚‹ã€‚


## ğŸ­ Z7. ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ï¼ˆã¾ã¨ã‚ãƒ»FAQãƒ»æ¬¡å›äºˆå‘Šï¼‰

### 6.5 æœ¬è¬›ç¾©ã®3ã¤ã®åˆ°é”ç‚¹

#### åˆ°é”ç‚¹1: Motion Diffusion ã®ç†è«–ã¨å®Ÿè£…

**Before**:
- é™çš„ãª3Dã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯ç”Ÿæˆã§ãã‚‹
- ã—ã‹ã—ã€å‹•ãã¯è¡¨ç¾ã§ããªã„

**After**:
- Text-to-Motion: "walk" â†’ 30ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ­©è¡Œå‹•ä½œ
- MDM/MLD ã®æ•°å¼ã‚’å®Œå…¨å°å‡º
- Rust ã§è¨“ç·´ã€è©•ä¾¡æŒ‡æ¨™ã§æ¤œè¨¼

#### åˆ°é”ç‚¹2: 4D Generation ã®æ•°å­¦çš„åŸºç›¤

**Before**:
- NeRF/3DGS ã¯é™çš„ã‚·ãƒ¼ãƒ³ã®ã¿

**After**:
- 4DGS: æ™‚é–“ä¾å­˜ Gaussian $G_i(\mathbf{x}, t)$
- Deformation network è¨­è¨ˆ
- TC4D: Global-local factorization
- Rust ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°

#### åˆ°é”ç‚¹3: Diffusion Policy ã§ãƒ­ãƒœãƒƒãƒˆåˆ¶å¾¡

**Before**:
- Diffusion ã¯ç”»åƒãƒ»å‹•ç”»ç”Ÿæˆã®ã¿

**After**:
- Multimodal policy: è¤‡æ•°ã®æ­£è§£è¡Œå‹•ã‚’è¡¨ç¾
- Receding horizon control
- Hierarchical: æ¥è§¦ãƒªãƒƒãƒãªã‚¿ã‚¹ã‚¯ (+20.8%)
- Elixir ã§åˆ†æ•£åˆ¶å¾¡ã€è€éšœå®³æ€§

### 6.6 Before/After ãƒãƒƒãƒ—

| è¦³ç‚¹ | Before (ç¬¬46å›çµ‚äº†æ™‚) | After (ç¬¬47å›çµ‚äº†å¾Œ) |
|:-----|:---------------------|:-------------------|
| **ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³** | ç”Ÿæˆä¸å¯ | Text-to-Motion å¯èƒ½ (MDM/MLD/UniMo) |
| **æ™‚é–“è»¸** | é™çš„3Dã®ã¿ | å‹•çš„4D (4DGS/TC4D) |
| **åˆ¶å¾¡** | é™çš„ãªæœ€é©åŒ–ã®ã¿ | ãƒ­ãƒœãƒƒãƒˆåˆ¶å¾¡ (Diffusion Policy) |
| **å®Ÿè£…** | Rust + Rust | **+ Elixir** (åˆ†æ•£åˆ¶å¾¡) |
| **å¿œç”¨** | ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã®ã¿ | **VR/AR/Robotics** |

### 6.7 FAQ: ã‚ˆãã‚ã‚‹è³ªå•

<details><summary>Q1: Motion Diffusion ã¨ Video Diffusion ã®é•ã„ã¯ï¼Ÿ</summary>

**Motion Diffusion**:
- ãƒ‡ãƒ¼ã‚¿: é–¢ç¯€åº§æ¨™ $(T, J, 3)$ â€” æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿
- ç›®çš„: äººé–“ã®å‹•ä½œã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”Ÿæˆ
- è©•ä¾¡: Physical plausibility (ç‰©ç†å¦¥å½“æ€§)

**Video Diffusion** (ç¬¬45å›):
- ãƒ‡ãƒ¼ã‚¿: ãƒ”ã‚¯ã‚»ãƒ« $(T, H, W, 3)$ â€” éæ§‹é€ åŒ–
- ç›®çš„: è¦–è¦šçš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
- è©•ä¾¡: Visual quality (FVD, IS)

**é–¢ä¿‚**: Motion â†’ Video rendering ã§çµ±åˆå¯èƒ½ã€‚ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ â†’ SMPL mesh â†’ ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° â†’ å‹•ç”»ã€‚

</details>

<details><summary>Q2: 4DGS ã¯å‹•ç”»ç”Ÿæˆã¨ä½•ãŒé•ã†ï¼Ÿ</summary>

**4DGS**:
- **3D è¡¨ç¾**: Gaussian primitives
- **View consistency**: ä»»æ„è¦–ç‚¹ã‹ã‚‰ä¸€è²«ã—ãŸãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
- **ç·¨é›†æ€§**: Gaussian ã‚’ç›´æ¥æ“ä½œå¯èƒ½

**Video Diffusion**:
- **2D è¡¨ç¾**: ãƒ”ã‚¯ã‚»ãƒ«
- **Single view**: 1ã¤ã®è¦–ç‚¹ã®ã¿
- **ç·¨é›†å›°é›£**: ãƒ”ã‚¯ã‚»ãƒ«æ“ä½œã¯éç›´æ„Ÿçš„

4DGS ã¯ "3D-aware video generation" ã¨è¨€ãˆã‚‹ã€‚

</details>

<details><summary>Q3: Diffusion Policy ã¯å¼·åŒ–å­¦ç¿’ã‹æ¨¡å€£å­¦ç¿’ã‹ï¼Ÿ</summary>

**åŸºæœ¬ã¯æ¨¡å€£å­¦ç¿’ (Imitation Learning)**:
- Expert demonstration ã‹ã‚‰å­¦ç¿’
- Behavior Cloning (BC) ã®ä¸€ç¨®
- ç’°å¢ƒã¨ã®ç›¸äº’ä½œç”¨ãªã—ã§è¨“ç·´å¯èƒ½

**ãŸã ã—ã€RL ã¨ã®çµ„ã¿åˆã‚ã›ã‚‚å¯èƒ½**:
- Offline RL: Static dataset ã‹ã‚‰å­¦ç¿’ (Diffusion ãŒåˆ†å¸ƒãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦æ©Ÿèƒ½)
- Fine-tuning: BC ã§ pre-train â†’ RL ã§ fine-tune

Hierarchical Diffusion Policy ã® GRPO [^6] ã¯ post-training RL ã®ä¸€ç¨®ã€‚

</details>

<details><summary>Q4: ãªãœ Elixir?</summary>

**Elixir ã®3ã¤ã®å¼·ã¿**:

1. **ä¸¦è¡Œæ€§**: BEAM VM ã®è»½é‡ãƒ—ãƒ­ã‚»ã‚¹ â†’ æ•°ä¸‡ãƒ­ãƒœãƒƒãƒˆåˆ¶å¾¡å¯èƒ½
2. **è€éšœå®³æ€§**: OTP Supervisor â†’ è‡ªå‹•å†èµ·å‹•ã€éšœå®³éš”é›¢
3. **åˆ†æ•£é€éæ€§**: è¤‡æ•°ãƒã‚·ãƒ³ã«è·¨ã‚‹ãƒ­ãƒœãƒƒãƒˆç¾¤ã‚’é€éçš„ã«åˆ¶å¾¡

**Rust ã¨ã®æ£²ã¿åˆ†ã‘**:
- **Rust**: å˜ä¸€ãƒ­ãƒœãƒƒãƒˆã®é«˜é€Ÿæ¨è«– (Diffusion Policy)
- **Elixir**: è¤‡æ•°ãƒ­ãƒœãƒƒãƒˆã®èª¿æ•´ã€éšœå®³ç®¡ç†ã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°

NIFã‚„Rustlerã§Rustã¨Elixirã‚’é€£æº â†’ æœ€å¼·ã®çµ„ã¿åˆã‚ã›ã€‚

</details>

<details><summary>Q5: æ¬¡ã«å­¦ã¶ã¹ãè«–æ–‡ã¯ï¼Ÿ</summary>

**Motion æ·±æ˜ã‚Š**:
- HumanML3D dataset [^12]: Motion-text paired data
- MotionCLIP: CLIP ã‚’ motion ã«é©ç”¨
- PhysDiff: Physics-guided motion diffusion

**4D æ·±æ˜ã‚Š**:
- Dynamic 3DGS survey
- NeRF-based 4D: D-NeRF, HyperNeRF
- 4D editing: 4D-Editor

**Robotics æ·±æ˜ã‚Š**:
- Diffusion models for manipulation survey
- RT-1/RT-2 (Google Robotics Transformer)
- Imitation learning: GAIL, DAGGER

</details>

### 6.8 å­¦ç¿’ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ— (1é€±é–“)

| æ—¥ | ã‚¿ã‚¹ã‚¯ | æ™‚é–“ | æˆæœç‰© |
|:---|:------|:-----|:------|
| Day 1 | Zone 0-2 èª­äº† + ä½“é¨“ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ | 2h | Motion/4D/Policy ã®ç›´æ„Ÿç†è§£ |
| Day 2 | Zone 3.1-3.5 (Motion æ•°å¼) | 3h | MDM/MLD å°å‡ºãƒãƒ¼ãƒˆ |
| Day 3 | Zone 3.6-3.10 (4D/Policy æ•°å¼) | 3h | 4DGS/Diffusion Policy å°å‡º |
| Day 4 | Zone 4 (å®Ÿè£…) | 4h | Rust/Rust/Elixir ã‚³ãƒ¼ãƒ‰ |
| Day 5 | Zone 5 (å®Ÿé¨“) | 3h | Tiny Motion Diffusion è¨“ç·´å®Œäº† |
| Day 6 | è«–æ–‡1æœ¬ç²¾èª­ (MDM or 4DGS or Diffusion Policy) | 4h | è«–æ–‡ãƒãƒ¼ãƒˆ |
| Day 7 | Mini project: Motion style transfer å®Ÿè£… | 5h | ã‚ªãƒªã‚¸ãƒŠãƒ«å®Ÿè£… |

**Total: 24æ™‚é–“** ã§ Motionãƒ»4Dãƒ»Policy ã‚’å®Ÿè·µãƒ¬ãƒ™ãƒ«ã§ç¿’å¾—ã€‚

### 6.9 æ¬¡å›äºˆå‘Š: ç¬¬48å› â€” AI for Science

**ç¬¬47å›ã¾ã§ã®åˆ°é”ç‚¹**:
- ç”»åƒ (ç¬¬43å›) â†’ éŸ³å£° (ç¬¬44å›) â†’ å‹•ç”» (ç¬¬45å›) â†’ 3D (ç¬¬46å›) â†’ **ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»4D (ç¬¬47å›)**
- å…¨ã¦ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã§ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã„ã“ãªã›ã‚‹

**ç¬¬48å›ã®å•ã„**:
- ã€Œã‚¨ãƒ³ã‚¿ãƒ¡ä»¥å¤–ã®å¿œç”¨ã¯ï¼Ÿã€
- ã€Œç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯ç§‘å­¦ã‚’åŠ é€Ÿã§ãã‚‹ã‹ï¼Ÿã€

ç¬¬48å›ã§ã¯ã€**AI for Science** â€” Protein/Drug/Materials ç”Ÿæˆã«é€²ã‚€:

- **RFdiffusion3**: ã‚¿ãƒ³ãƒ‘ã‚¯è³ªãƒ‡ã‚¶ã‚¤ãƒ³
- **AlphaFold 3**: æ§‹é€ äºˆæ¸¬ â†’ ãƒ‡ã‚¶ã‚¤ãƒ³ã¸
- **MatterGen**: æ–°ææ–™ã®ç”Ÿæˆ
- **CrystalFlow**: Flow Matching for çµæ™¶ç”Ÿæˆ

ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ãŒã€**æ–°è–¬ç™ºè¦‹ãƒ»æ–°ææ–™é–‹ç™ºã‚’æ•°å¹´â†’æ•°ãƒ¶æœˆã«çŸ­ç¸®**ã™ã‚‹æœ€å‰ç·šã¸ã€‚

> **Note:** **ã“ã“ã¾ã§ã§å…¨ä½“ã®100%å®Œäº†ï¼** ç¬¬47å›ã‚’å®Œèµ°ã—ãŸã€‚é™çš„3Dã‹ã‚‰å‹•çš„4Dã¸ã€ç©ºé–“ã‹ã‚‰é‹å‹•ã¸ã€‚Motionãƒ»4Dãƒ»Robotics ã®å…¨ã¦ã‚’ç†è§£ã—ã€å®Ÿè£…ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚æ¬¡ã¯ç§‘å­¦å¿œç”¨ â€” ç¬¬48å›ã§å¾…ã£ã¦ã„ã‚‹ã€‚

---


> Progress: 95%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. Flow Matchingã‚’ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆã«é©ç”¨ã—ãŸå ´åˆã€æ¡ä»¶ä»˜ããƒ™ã‚¯ãƒˆãƒ«å ´$u_t = \mathbf{x}_1 - \mathbf{x}_0$ã®å­¦ç¿’ãŒDiffusionã®ã‚¹ã‚³ã‚¢ãƒãƒƒãƒãƒ³ã‚°ã‚ˆã‚Šå˜ç´”ã«ãªã‚‹ç†ç”±ã‚’è¿°ã¹ã‚ˆã€‚
> 2. Diffusion Policyã«ãŠã‘ã‚‹DDIM samplingã‚’ä½¿ã†ã“ã¨ã§æ¨è«–æ™‚ã‚¹ãƒ†ãƒƒãƒ—ã‚’å‰Šæ¸›ã§ãã‚‹ç†ç”±ã‚’ã€å­¦ç¿’ã—ãŸã‚¹ã‚³ã‚¢é–¢æ•°ã¨ã®é–¢ä¿‚ã§èª¬æ˜ã›ã‚ˆã€‚

## ğŸ’€ ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„

**é™çš„ãª3Dãƒ¢ãƒ‡ãƒ«ã¯"åšç‰©é¤¨ã®å±•ç¤º"ã§ã¯ï¼Ÿå‹•ãã‹ã‚‰ã“ãæ„å‘³ãŒã‚ã‚‹ã®ã§ã¯ï¼Ÿ**

### è­°è«–ã®ç¨®

#### è¦³ç‚¹1: VR/AR ã®æœ¬è³ªã¯"å‹•ã"

é™çš„ãª3Dã‚¹ã‚­ãƒ£ãƒ³ã¯æ—¢ã«å­˜åœ¨ã™ã‚‹ã€‚ã—ã‹ã—ã€VR/AR ã§æ±‚ã‚ã‚‰ã‚Œã‚‹ã®ã¯:
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å‹•ãã«åå¿œã™ã‚‹ã‚¢ãƒã‚¿ãƒ¼
- ç‰©ç†çš„ã«æ­£ã—ã„ç›¸äº’ä½œç”¨
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®å‹•çš„ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

**é™çš„3Dã ã‘ã§ã¯ã€VR/ARã®æœ¬è³ªçš„ä¾¡å€¤ (æ²¡å…¥æ„Ÿã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³) ã¯å®Ÿç¾ã§ããªã„ã€‚**

#### è¦³ç‚¹2: ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã¯"å‹•ã"ã®ç§‘å­¦

ãƒ­ãƒœãƒƒãƒˆç ”ç©¶ã®ç›®çš„ã¯:
- ç‰©ã‚’æ´ã‚€ã€çµ„ã¿ç«‹ã¦ã‚‹ã€æ­©ã â€” å…¨ã¦**å‹•ä½œ**
- é™çš„ãª3Dãƒ¢ãƒ‡ãƒ«ã¯å‚ç…§ã«ã¯ãªã‚‹ãŒã€åˆ¶å¾¡ã«ã¯ä½¿ãˆãªã„

**Diffusion Policy ãŒç¤ºã—ãŸã®ã¯ã€å‹•ä½œãã®ã‚‚ã®ã‚’ç”Ÿæˆçš„ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã€‚**

#### è¦³ç‚¹3: æ˜ ç”»ãƒ»ã‚²ãƒ¼ãƒ ã¯"æ™‚é–“èŠ¸è¡“"

æ˜ ç”»ã‚‚ã‚²ãƒ¼ãƒ ã‚‚ã€**æ™‚ç³»åˆ—ã®è¦–è¦šä½“é¨“**ãŒæœ¬è³ª:
- ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒå‹•ã‹ãªã‘ã‚Œã°ã€ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã¯é€²ã¾ãªã„
- é™æ­¢ç”»ã®é€£ç¶šã§ã¯ãªãã€**å‹•ãã®æ»‘ã‚‰ã‹ã•**ãŒæ„Ÿæƒ…ã‚’å–šèµ·

**4Dç”ŸæˆãŒã€æ˜ ç”»åˆ¶ä½œãƒ»ã‚²ãƒ¼ãƒ é–‹ç™ºã®æ°‘ä¸»åŒ–ã‚’åŠ é€Ÿã™ã‚‹ã€‚**

<details><summary>æ­´å²çš„æ–‡è„ˆ: å†™çœŸâ†’æ˜ ç”»â†’3Dâ†’4D ã®é€²åŒ–</summary>

- **1826å¹´**: ä¸–ç•Œåˆã®å†™çœŸ (é™æ­¢ç”»)
- **1895å¹´**: ãƒªãƒ¥ãƒŸã‚¨ãƒ¼ãƒ«å…„å¼ŸãŒæ˜ ç”»ã‚’ç™ºæ˜ (å‹•ç”»)
- **1995å¹´**: Toy Story (ãƒ•ãƒ«3DCGæ˜ ç”»)
- **2025å¹´**: 4Dç”Ÿæˆãƒ¢ãƒ‡ãƒ« (èª°ã§ã‚‚å‹•çš„3Dã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆ)

å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã€Œå‰æ®µéšã¯ä¸ååˆ†ã ã£ãŸã€ã¨è¨€ã‚ã‚Œã‚‹ã€‚é™çš„3Dâ†’4D ã‚‚åŒã˜æµã‚Œã€‚

</details>

**ã‚ãªãŸã¯ã©ã†è€ƒãˆã‚‹ã‹ï¼Ÿ**
- é™çš„3Dã§ååˆ†ãªå¿œç”¨ã¯ã‚ã‚‹ã‹ï¼Ÿ (å»ºç¯‰ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ï¼Ÿ)
- 4Dç”Ÿæˆã® killer application ã¯ä½•ã‹ï¼Ÿ
- æ¬¡ã¯5D (3D+æ™‚é–“+ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³å¤‰æ•°) ã‹ï¼Ÿ

---

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: Tevet, G., Raab, S., Gordon, B., Shafir, Y., Cohen-Or, D., & Bermano, A. H. (2022). Human Motion Diffusion Model. *ICLR 2023*.
<https://arxiv.org/abs/2209.14916>

[^2]: Chen, X., Jiang, B., Liu, W., Huang, Z., Fu, B., Chen, T., & Yu, G. (2023). Executing your Commands via Motion Diffusion in Latent Space. *CVPR 2023*.
<https://arxiv.org/abs/2212.04048>

[^3]: Wu, G., Yi, T., Fang, J., Xie, L., Zhang, X., Wei, W., Liu, W., Tian, Q., & Wang, X. (2024). 4D Gaussian Splatting for Real-Time Dynamic Scene Rendering. *CVPR 2024*.
<https://arxiv.org/abs/2310.08528>

[^4]: Bahmani, S., Liu, X., Yifan, W., Skorokhodov, I., Ramamoorthi, R., & Wetzstein, G. (2024). TC4D: Trajectory-Conditioned Text-to-4D Generation. *ECCV 2024*.
<https://arxiv.org/abs/2403.17920>

[^5]: Chi, C., Xu, Z., Feng, S., Cousineau, E., Du, Y., Burchfiel, B., Tedrake, R., & Song, S. (2023). Diffusion Policy: Visuomotor Policy Learning via Action Diffusion. *Robotics: Science and Systems (RSS) 2023*.
<https://arxiv.org/abs/2303.04137>

[^6]: Wang, Z., Liu, Z., & Liu, H. (2025). Hierarchical Diffusion Policy: Manipulation Trajectory Generation via Contact Guidance. *IEEE Transactions on Robotics*.
<https://ieeexplore.ieee.org/document/10912754>

[^7]: Loper, M., Mahmood, N., Romero, J., Pons-Moll, G., & Black, M. J. (2015). SMPL: A Skinned Multi-Person Linear Model. *SIGGRAPH Asia 2015*.

[^8]: Zhu, B., Jiang, B., et al. (2025). MotionGPT3: Human Motion as a Second Modality. *arXiv preprint*.
<https://arxiv.org/abs/2506.24086>

[^9]: Wang, G., Liu, K., Lin, J., Song, G., & Li, J. (2026). UniMo: Unified Motion Generation and Understanding with Chain of Thought. *arXiv preprint*.
<https://arxiv.org/abs/2601.12126>

[^10]: Zhou, S., Wang, Y., Li, J., & Chen, F. (2025). RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation. *ICLR 2025*.
<https://arxiv.org/abs/2410.07864>

### æ•™ç§‘æ›¸

- Siciliano, B., & Khatib, O. (Eds.). (2016). *Springer Handbook of Robotics* (2nd ed.). Springer. [Robot motion planning, control]
- Barfoot, T. D. (2017). *State Estimation for Robotics*. Cambridge University Press. [Free online: http://asrl.utias.utoronto.ca/~tdb/bib/barfoot_ser17.pdf]

### ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒªã‚½ãƒ¼ã‚¹

| ãƒªã‚½ãƒ¼ã‚¹ | URL | æ¦‚è¦ |
|:---------|:----|:-----|
| MDM Project Page | https://guytevet.github.io/mdm-page/ | ãƒ‡ãƒ¢å‹•ç”»ã€ã‚³ãƒ¼ãƒ‰ |
| 4DGS Project Page | https://guanjunwu.github.io/4dgs/ | ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¢ |
| Diffusion Policy | https://diffusion-policy.cs.columbia.edu/ | å®Ÿé¨“å‹•ç”»ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ |
| RDT-1B Hugging Face | https://huggingface.co/robotics-diffusion-transformer/rdt-1b | äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ« |
| HumanML3D | https://github.com/EricGuo5513/HumanML3D | Motion-text dataset |

---


## ğŸ”— å‰ç·¨ãƒ»å¾Œç·¨ãƒªãƒ³ã‚¯

- **å‰ç·¨ (Part 1 â€” ç†è«–ç·¨)**: [ç¬¬47å›: ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»4Dç”Ÿæˆ & Diffusion Policy (Part 1)](ml-lecture-47-part1)

## è‘—è€…ãƒªãƒ³ã‚¯

- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
