---
title: "ç¬¬13å›: è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
emoji: "ğŸ”„"
type: "tech"
topics: ["machinelearning", "deeplearning", "autoregressive", "julia", "rust"]
published: true
slug: "ml-lecture-13-part2"
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Julia", "Rust"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---

# ç¬¬13å›: è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ« ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨

> **ğŸ“– ã“ã®è¨˜äº‹ã¯å¾Œç·¨ï¼ˆå®Ÿè£…ç·¨ï¼‰ã§ã™** ç†è«–ç·¨ã¯ [ã€å‰ç·¨ã€‘ç¬¬13å›](/articles/ml-lecture-13-part1) ã‚’ã”è¦§ãã ã•ã„ã€‚

## ğŸ’» 4. å®Ÿè£…ã‚¾ãƒ¼ãƒ³(45åˆ†)â€” PixelCNN/WaveNetã‚’Julia+Rustã§æ§‹ç¯‰

### 4.1 ç’°å¢ƒæ§‹ç¯‰

#### 4.1.1 Juliaç’°å¢ƒ

```bash
# Julia 1.11+ (2025å¹´æœ€æ–°ç‰ˆ)
# https://julialang.org/downloads/

julia
```

```julia
# Package setup
using Pkg
Pkg.add(["Lux", "Reactant", "Optimisers", "MLUtils", "Images", "Plots"])

# Verify
using Lux, Reactant
println("Julia $(VERSION), Lux $(Pkg.TOML.parsefile(joinpath(pkgdir(Lux), "Project.toml"))["version"])")
```

#### 4.1.2 Rustç’°å¢ƒ

```bash
# Rust 1.85+ (2025å¹´æœ€æ–°)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# ONNX Runtime for inference
cargo new --lib pixelcnn_inference
cd pixelcnn_inference
```

`Cargo.toml`:
```toml
[dependencies]
ort = "2.0"  # ONNX Runtime bindings
ndarray = "0.16"
rayon = "1.10"  # Parallel iterator
```

### 4.2 PixelCNNå®Ÿè£… (Julia)

#### 4.2.1 Masked Convolution Layer

```julia
using Lux, Random, NNlib

# Masked Convolution: future pixels are masked
struct MaskedConv2D{M} <: Lux.AbstractLuxLayer
    conv::Conv
    mask_type::Symbol  # :A (strict) or :B (include center)
end

function MaskedConv2D(in_ch, out_ch, kernel; mask_type=:B)
    @assert kernel[1] % 2 == 1 && kernel[2] % 2 == 1 "Kernel must be odd"
    conv = Conv(kernel, in_ch => out_ch, pad=SamePad())
    MaskedConv2D{mask_type}(conv, mask_type)
end

function Lux.initialparameters(rng::AbstractRNG, layer::MaskedConv2D)
    ps = Lux.initialparameters(rng, layer.conv)
    # Apply mask to weight
    ps.weight .*= create_mask(size(ps.weight), layer.mask_type)
    return ps
end

function create_mask(weight_shape, mask_type)
    # weight_shape: (kH, kW, in_ch, out_ch)
    kH, kW, _, _ = weight_shape
    mask = ones(Float32, kH, kW, 1, 1)
    cH, cW = (kH + 1) Ã· 2, (kW + 1) Ã· 2

    # Mask bottom half
    mask[cH+1:end, :, 1, 1] .= 0
    # Mask right half of center row
    mask[cH, cW+(mask_type == :A ? 0 : 1):end, 1, 1] .= 0

    return mask
end

function (layer::MaskedConv2D)(x, ps, st)
    # Re-apply mask (in case weights updated during training)
    ps_masked = merge(ps, (weight = ps.weight .* create_mask(size(ps.weight), layer.mask_type),))
    return layer.conv(x, ps_masked, st)
end
```

#### 4.2.2 Gated Activation Block

```julia
# Gated activation: tanh(Wf * x) âŠ™ Ïƒ(Wg * x)
struct GatedActivation <: Lux.AbstractLuxLayer end

function (::GatedActivation)(x, ps, st)
    # x: (H, W, 2C, batch) â€” first C channels = filter, next C = gate
    C = size(x, 3) Ã· 2
    @.(tanh(x[:, :, 1:C, :]) * sigmoid(x[:, :, C+1:end, :])), st
end

# Gated PixelCNN Block (Vertical + Horizontal stack)
struct GatedPixelCNNBlock <: Lux.AbstractLuxContainerLayer{(:v_conv, :h_conv, :v_to_h, :h_res, :gated)}
    v_conv::MaskedConv2D
    h_conv::MaskedConv2D
    v_to_h::Conv  # 1x1 conv: vertical â†’ horizontal
    h_res::Conv   # 1x1 conv: residual connection
    gated::GatedActivation
end

function GatedPixelCNNBlock(channels::Int, kernel=(3, 3))
    v_conv = MaskedConv2D(channels, 2channels, kernel; mask_type=:A)  # Vertical: strict mask
    h_conv = MaskedConv2D(channels, 2channels, kernel; mask_type=:B)  # Horizontal: include center
    v_to_h = Conv((1, 1), channels => 2channels)
    h_res = Conv((1, 1), channels => channels)
    gated = GatedActivation()
    return GatedPixelCNNBlock(v_conv, h_conv, v_to_h, h_res, gated)
end

function (block::GatedPixelCNNBlock)(v_in, h_in, ps, st)
    # Vertical stack
    v_out, st_v = block.v_conv(v_in, ps.v_conv, st)
    v_gated, _ = block.gated(v_out, ps, st)

    # Horizontal stack
    h_out, st_h = block.h_conv(h_in, ps.h_conv, st)
    v_to_h_out, st_vth = block.v_to_h(v_gated, ps.v_to_h, st)
    h_combined = h_out .+ v_to_h_out
    h_gated, _ = block.gated(h_combined, ps, st)

    # Residual connection
    h_res, st_res = block.h_res(h_gated, ps.h_res, st)
    h_final = h_res .+ h_in

    return v_gated, h_final, st
end
```

#### 4.2.3 Full PixelCNN Model

```julia
using Lux, Random

struct PixelCNN <: Lux.AbstractLuxContainerLayer{(:blocks, :output_conv)}
    blocks::Vector{GatedPixelCNNBlock}
    output_conv::Conv
end

function PixelCNN(num_blocks::Int, channels::Int, num_classes::Int=256)
    blocks = [GatedPixelCNNBlock(channels) for _ in 1:num_blocks]
    output_conv = Conv((1, 1), channels => num_classes)
    return PixelCNN(blocks, output_conv)
end

function (model::PixelCNN)(x, ps, st)
    # x: (H, W, C_in, batch) â€” typically C_in=1 for grayscale
    batch_size = size(x, 4)
    v = repeat(x, 1, 1, channels, 1)  # Initialize vertical stack
    h = repeat(x, 1, 1, channels, 1)  # Initialize horizontal stack

    for (i, block) in enumerate(model.blocks)
        v, h, st = block(v, h, ps.blocks[i], st)
    end

    # Output: (H, W, num_classes, batch)
    logits, st = model.output_conv(h, ps.output_conv, st)
    logits, st
end
```

### 4.3 è¨“ç·´ãƒ«ãƒ¼ãƒ— (Julia + Lux)

```julia
using Lux, Optimisers, MLUtils, Statistics

# Loss: negative log-likelihood (cross-entropy per pixel)
function pixelcnn_loss(model, ps, st, x, y)
    logits, st = model(x, ps, st)
    # y: (H, W, 1, batch) with values in [0, 255]
    # logits: (H, W, 256, batch)

    # Cross-entropy per pixel
    H, W, _, B = size(x)
    loss = -sum(
        log(softmax(logits[i, j, :, b])[Int(y[i, j, 1, b]) + 1] + 1f-8)
        for b in 1:B, i in 1:H, j in 1:W
    ) / (H * W * B)
    loss, st, ()
end

# Training loop
function train_pixelcnn!(model, ps, st, train_data, epochs=10, lr=1e-3)
    opt_state = Optimisers.setup(Adam(lr), ps)

    for epoch in 1:epochs
        epoch_loss = 0.0
        for (x, y) in train_data
            # x, y: (H, W, 1, batch)
            loss, st, _ = pixelcnn_loss(model, ps, st, x, y)

            # Gradients
            grads = gradient(ps -> pixelcnn_loss(model, ps, st, x, y)[1], ps)[1]

            # Update
            opt_state, ps = Optimisers.update(opt_state, ps, grads)
            epoch_loss += loss
        end
        println("Epoch $epoch: Loss = $(epoch_loss / length(train_data))")
    end
    ps, st
end
```

### 4.4 WaveNetå®Ÿè£… (Julia)

```julia
using Lux, NNlib

# Dilated Causal Conv 1D
struct DilatedCausalConv1D <: Lux.AbstractLuxLayer
    conv::Conv
    dilation::Int
end

function DilatedCausalConv1D(in_ch, out_ch, kernel, dilation)
    # Causal padding: pad left by (kernel-1)*dilation
    pad = (kernel - 1) * dilation
    conv = Conv((kernel,), in_ch => out_ch, dilation=(dilation,), pad=(pad, 0))
    DilatedCausalConv1D(conv, dilation)
end

function (layer::DilatedCausalConv1D)(x, ps, st)
    y, st = layer.conv(x, ps, st)
    # Remove right padding (future samples)
    return y[1:size(x, 1), :, :], st
end

# WaveNet Residual Block
struct WaveNetBlock <: Lux.AbstractLuxContainerLayer{(:filter_conv, :gate_conv, :res_conv, :skip_conv)}
    filter_conv::DilatedCausalConv1D
    gate_conv::DilatedCausalConv1D
    res_conv::Conv
    skip_conv::Conv
end

function WaveNetBlock(channels::Int, dilation::Int, kernel=2)
    filter_conv = DilatedCausalConv1D(channels, channels, kernel, dilation)
    gate_conv = DilatedCausalConv1D(channels, channels, kernel, dilation)
    res_conv = Conv((1,), channels => channels)
    skip_conv = Conv((1,), channels => channels)
    return WaveNetBlock(filter_conv, gate_conv, res_conv, skip_conv)
end

function (block::WaveNetBlock)(x, ps, st)
    # Gated activation
    f, st_f = block.filter_conv(x, ps.filter_conv, st)
    g, st_g = block.gate_conv(x, ps.gate_conv, st)
    z = @. tanh(f) * sigmoid(g)

    # Residual + Skip
    res, st_res = block.res_conv(z, ps.res_conv, st)
    skip, st_skip = block.skip_conv(z, ps.skip_conv, st)

    return x .+ res, skip, st
end
```

### 4.5 Math-to-Codeå¯¾å¿œè¡¨

| æ•°å¼ | Julia Code | å¯¾å¿œ |
|:-----|:-----------|:-----|
| $p(\mathbf{x}) = \prod p(x_i \mid \mathbf{x}_{<i})$ | `prod(p_i for p_i in conditional_probs)` | é€£é–å¾‹ |
| $\mathcal{L} = -\sum \log p(x_i \mid \mathbf{x}_{<i})$ | `loss = -sum(log.(p .+ 1e-8))` | NLL |
| $p(x_i=k) = \text{softmax}(z)_k$ | `softmax(logits[:, :, :, batch])[i, j, k]` | é›¢æ•£åˆ†å¸ƒ |
| $\mathbf{y} = \tanh(\mathbf{W}_f * \mathbf{x}) \odot \sigma(\mathbf{W}_g * \mathbf{x})$ | `tanh.(f) .* sigmoid.(g)` | Gated Act |
| Masked Conv(kernel $\mathbf{W}$, mask $\mathbf{M}$) | `ps.weight .* create_mask(...)` | Causal Mask |

**1è¡Œ1å¼ã®å¯¾å¿œ** â€” æ•°å¼ã‚’èª­ã‚“ã ã‚‰ã‚³ãƒ¼ãƒ‰ãŒæ›¸ã‘ã‚‹ã€ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ãŸã‚‰æ•°å¼ãŒåˆ†ã‹ã‚‹ã€‚ã“ã‚ŒãŒJuliaã®çœŸä¾¡ã ã€‚

### 4.6 Rustæ¨è«–å®Ÿè£… (ONNX Runtime)

```rust
// pixelcnn_inference/src/lib.rs
use ort::{Session, Value, inputs};
use ndarray::{Array4, s};
use rayon::prelude::*;

pub struct PixelCNNInference {
    session: Session,
}

impl PixelCNNInference {
    pub fn new(model_path: &str) -> ort::Result<Self> {
        let session = Session::builder()?.commit_from_file(model_path)?;
        Ok(Self { session })
    }

    pub fn sample(&self, batch_size: usize, height: usize, width: usize) -> ort::Result<Array4<f32>> {
        // Initialize with zeros
        let mut img = Array4::<f32>::zeros((batch_size, 1, height, width));

        // Autoregressive sampling: raster scan order
        for i in 0..height {
            for j in 0..width {
                // Forward pass
                let input = Value::from_array(self.session.allocator(), &img)?;
                let outputs = self.session.run(inputs!["input" => input])?;
                let logits = outputs["output"].try_extract::<f32>()?.view().to_owned();

                (0..batch_size).for_each(|b| {
                    let probs = softmax(&logits.slice(s![b, .., i, j]));
                    img[[b, 0, i, j]] = sample_categorical(&probs);
                });
            }
        }
        Ok(img)
    }
}

fn softmax(logits: &ndarray::ArrayView1<f32>) -> Vec<f32> {
    let max = logits.iter().copied().fold(f32::NEG_INFINITY, f32::max);
    let exp: Vec<f32> = logits.iter().map(|&x| (x - max).exp()).collect();
    let sum: f32 = exp.iter().sum();
    exp.iter().map(|&x| x / sum).collect()
}

fn sample_categorical(probs: &[f32]) -> f32 {
    let u: f32 = rand::random();
    probs.iter()
        .scan(0.0_f32, |cum, &p| { *cum += p; Some(*cum) })
        .position(|cum| u < cum)
        .unwrap_or(probs.len() - 1) as f32
}
```

### 4.7 AR Decodingæˆ¦ç•¥ â€” ç”Ÿæˆã®å¤šæ§˜æ€§ã¨å“è³ªã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•

è¨“ç·´æ™‚ã¯Teacher Forcing(æ­£è§£ã‚’å…¥åŠ›)ã ãŒã€æ¨è«–æ™‚ã¯ **ç”Ÿæˆã—ãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¬¡ã®å…¥åŠ›** ã«ã™ã‚‹ã€‚ã“ã®æˆ¦ç•¥ãŒç”Ÿæˆå“è³ªã‚’å¤§ããå·¦å³ã™ã‚‹ã€‚

#### 4.7.1 Greedy Decoding

æœ€ã‚‚ç¢ºç‡ã®é«˜ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å¸¸ã«é¸æŠ:

$$
x_t = \arg\max_{k} p_\theta(x_t = k \mid \mathbf{x}_{<t})
$$

```julia
function greedy_decode(model, ps, st, max_len=100)
    x = [START_TOKEN]
    for _ in 1:max_len
        logits, st = model(x, ps, st)
        next_token = argmax(softmax(logits[end, :]))
        push!(x, next_token)
        next_token == END_TOKEN && break
    end
    x
end
```

**é•·æ‰€**: æ±ºå®šè«–çš„ã€å†ç¾æ€§ã‚ã‚Š
**çŸ­æ‰€**: å¤šæ§˜æ€§ã‚¼ãƒ­ã€å±€æ‰€æœ€é©ã«é™¥ã‚Šã‚„ã™ã„

#### 4.7.2 Sampling with Temperature

ç¢ºç‡åˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°:

$$
p'(x_t = k) = \frac{\exp(z_k / \tau)}{\sum_{k'} \exp(z_{k'} / \tau)}
$$

ã“ã“ã§ $\tau$ ã¯temperature:
- $\tau \to 0$: Greedy(æœ€å¤§ç¢ºç‡ã«é›†ä¸­)
- $\tau = 1$: å…ƒã®åˆ†å¸ƒ
- $\tau \to \infty$: ä¸€æ§˜åˆ†å¸ƒ(å®Œå…¨ãƒ©ãƒ³ãƒ€ãƒ )

```julia
sample_with_temperature(logits::Vector, Ï„::Float64=1.0) =
    sample_categorical(softmax(logits ./ Ï„))

# Example
logits = [2.0, 1.0, 0.5, 0.2]
for Ï„ in [0.5, 1.0, 2.0]
    println("tau=$Ï„: ", [sample_with_temperature(logits, Ï„) for _ in 1:10])
end
```

å‡ºåŠ›:
```
tau=0.5: [1, 1, 1, 1, 1, 1, 2, 1, 1, 1]  # Mostly mode
tau=1.0: [1, 2, 1, 1, 2, 3, 1, 1, 2, 1]  # Balanced
tau=2.0: [3, 2, 1, 4, 2, 3, 1, 2, 3, 2]  # Diverse
```

#### 4.7.3 Top-k Sampling

ç¢ºç‡ä¸Šä½ $k$ å€‹ã®ã¿ã‹ã‚‰é¸æŠ:

```julia
function topk_sampling(logits::Vector, k::Int)
    probs = softmax(logits)
    idx = partialsortperm(probs, 1:k, rev=true)
    top = probs[idx]; top ./= sum(top)
    idx[sample_categorical(top)]
end
```

**åŠ¹æœ**: ä½ç¢ºç‡ã®ãƒã‚¤ã‚ºã‚’é™¤å»ã€å“è³ªå‘ä¸Šã€‚

#### 4.7.4 Top-p (Nucleus) Sampling

ç´¯ç©ç¢ºç‡ãŒ $p$ ã‚’è¶…ãˆã‚‹ã¾ã§ã®ä¸Šä½ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰é¸æŠ:

```julia
function nucleus_sampling(logits::Vector, p::Float64=0.9)
    probs = softmax(logits)
    idx = sortperm(probs, rev=true)
    sorted = probs[idx]
    cutoff = findfirst(cumsum(sorted) .>= p)
    nuc = sorted[1:cutoff]; nuc ./= sum(nuc)
    idx[sample_categorical(nuc)]
end
```

**GPT-3ã®æ¨™æº–è¨­å®š**: $p=0.9$, temperature=0.7 â€” å¤šæ§˜æ€§ã¨å“è³ªã®ãƒãƒ©ãƒ³ã‚¹ã€‚

#### 4.7.5 Beam Search

$B$ å€‹ã®å€™è£œç³»åˆ—ã‚’ä¿æŒã—ã€ç´¯ç©ç¢ºç‡æœ€å¤§ã®ç³»åˆ—ã‚’é¸æŠ:

```julia
struct BeamCandidate
    sequence::Vector{Int}
    log_prob::Float64
end

function beam_search(model, ps, st, beam_size::Int, max_len::Int)
    beams = [BeamCandidate([START_TOKEN], 0.0)]

    for _ in 1:max_len
        candidates = BeamCandidate[]
        for beam in beams
            if beam.sequence[end] == END_TOKEN
                push!(candidates, beam); continue
            end
            logits, _ = model(beam.sequence, ps, st)
            probs = softmax(logits[end, :])
            top_k = partialsortperm(probs, 1:beam_size, rev=true)
            append!(candidates, [
                BeamCandidate(vcat(beam.sequence, k), beam.log_prob + log(probs[k]))
                for k in top_k
            ])
        end
        # Keep top beam_size candidates
        sort!(candidates, by=c -> c.log_prob, rev=true)
        beams = candidates[1:min(beam_size, length(candidates))]
    end

    first(beams).sequence
end
```

**æ©Ÿæ¢°ç¿»è¨³ã§æ¨™æº–**: Beam size 4-8ãŒä¸€èˆ¬çš„ã€‚

**ç”»åƒARã§ã¯ä¸å‘ã**: ç³»åˆ—ãŒé•·ã™ãã‚‹(65536ã‚¹ãƒ†ãƒƒãƒ—) â€” ãƒ¡ãƒ¢ãƒªçˆ†ç™ºã€‚

#### 4.7.6 ãƒ‡ã‚³ãƒ¼ãƒ‰æˆ¦ç•¥ã®æ¯”è¼ƒè¡¨

| æˆ¦ç•¥ | å¤šæ§˜æ€§ | å“è³ª | é€Ÿåº¦ | ç”¨é€” |
|:-----|:-------|:-----|:-----|:-----|
| Greedy | âŒ | ä¸­ | â˜…â˜…â˜… | ãƒ‡ãƒãƒƒã‚° |
| Sampling(tau=1) | â˜…â˜…â˜… | ä½ | â˜…â˜…â˜… | å‰µé€ çš„ç”Ÿæˆ |
| Top-k | â˜…â˜… | ä¸­ | â˜…â˜…â˜… | ãƒãƒ©ãƒ³ã‚¹ |
| Top-p | â˜…â˜… | é«˜ | â˜…â˜…â˜… | GPTæ¨™æº– |
| Beam Search | â˜… | â˜…â˜…â˜… | â˜… | ç¿»è¨³/è¦ç´„ |

**ç”»åƒç”Ÿæˆ**: Greedy or Temperature=0.9ãŒä¸»æµ(Beam Searchã¯é…ã™ãã‚‹)ã€‚

### 4.8 ç´¯ç©èª¤å·®å•é¡Œ â€” ARã®æ ¹æœ¬çš„é™ç•Œ

ARã¯é€æ¬¡ç”Ÿæˆã®ãŸã‚ã€**èª¤å·®ãŒç´¯ç©** ã™ã‚‹:

$$
\text{Error at step } T \propto \sum_{t=1}^{T} \epsilon_t
$$

åˆæœŸã®èª¤å·®ãŒå¾Œã®ç”Ÿæˆã«å½±éŸ¿ â†’ é•·ç³»åˆ—ã»ã©å“è³ªåŠ£åŒ–ã€‚

**è»½æ¸›ç­–**:
1. **Scheduled Sampling**: è¨“ç·´æ™‚ã«ãŸã¾ã«ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥åŠ›(Teacher Forcingã¨ã®ãƒãƒ©ãƒ³ã‚¹)
2. **Multi-scale AR(VAR)**: ã‚¹ãƒ†ãƒƒãƒ—æ•°å‰Šæ¸›(65536 â†’ 10) â†’ ç´¯ç©èª¤å·®æ¿€æ¸›
3. **Non-AR(MaskGIT)**: ä¸¦åˆ—ç”Ÿæˆã§èª¤å·®ç´¯ç©ãªã—

### 4.9 Paperèª­è§£ãƒ‘ã‚¿ãƒ¼ãƒ³ â€” ARè«–æ–‡ã®3-pass reading

PixelCNN [^1] / WaveNet [^2] / VAR [^3] ãªã©ARè«–æ–‡ã®èª­ã¿æ–¹:

**Pass 1 (5åˆ†)**: é€£é–å¾‹ã®ã©ã“ã«è²¢çŒ®ã—ãŸã‹ç‰¹å®š
- [ ] é †åºã¯ï¼Ÿ(Raster/Random/Multi-scale)
- [ ] æ¡ä»¶ä»˜ãåˆ†å¸ƒã®ãƒ¢ãƒ‡ãƒ«ã¯ï¼Ÿ(Softmax/Mixture/Diffusion)
- [ ] å—å®¹é‡ã®æ‹¡å¤§æ–¹æ³•ã¯ï¼Ÿ(Dilated/Attention/Hierarchy)

**Pass 2 (30åˆ†)**: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ•°å­¦çš„æ­£å½“æ€§
- [ ] Causal Maskingã®å®Ÿè£…(å›³3-4ã‚’ç²¾èª­)
- [ ] Gating/Residual/Skipã®ç†è«–çš„æ ¹æ‹ 
- [ ] NLLè¨ˆç®—å¼(Eq.5å‰å¾Œ)ã®å°å‡ºã‚’è¿½ã†

**Pass 3 (2æ™‚é–“)**: å®Ÿè£…å†ç¾
- [ ] Pseudo-codeã‚’Juliaã§æ›¸ãä¸‹ã™
- [ ] Ablation studyã®å†ç¾(Table 2)
- [ ] è‡ªåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã§å‹•ã‹ã™

### 4.10 LaTeX Cheat Sheet for AR

| æ¦‚å¿µ | LaTeX | å‡ºåŠ› |
|:-----|:------|:-----|
| é€£é–å¾‹ | `p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid \mathbf{x}_{<i})` | $p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid \mathbf{x}_{<i})$ |
| NLL | `\mathcal{L} = -\sum \log p(x_i \mid \mathbf{x}_{<i})` | $\mathcal{L} = -\sum \log p(x_i \mid \mathbf{x}_{<i})$ |
| Softmax | `p(k) = \frac{e^{z_k}}{\sum_j e^{z_j}}` | $p(k) = \frac{e^{z_k}}{\sum_j e^{z_j}}$ |
| Gating | `y = \tanh(W_f * x) \odot \sigma(W_g * x)` | $y = \tanh(W_f * x) \odot \sigma(W_g * x)$ |
| Dilated Conv | `y[t] = \sum_k w_k x[t - d \cdot k]` | $y[t] = \sum_k w_k x[t - d \cdot k]$ |
| Temperature | `p'(k) = \frac{e^{z_k/\tau}}{\sum_j e^{z_j/\tau}}` | $p'(k) = \frac{e^{z_k/\tau}}{\sum_j e^{z_j/\tau}}$ |

### 4.11 Julia vs Rust vs Python â€” ARå®Ÿè£…æ¯”è¼ƒ

#### PixelCNN Forward Pass (ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰)

**Julia (Lux)**:
```julia
function (model::PixelCNN)(x, ps, st)
    v = model.v_init(x, ps.v_init, st)
    h = model.h_init(x, ps.h_init, st)
    for (i, block) in enumerate(model.blocks)
        v, h, st = block(v, h, ps.blocks[i], st)
    end
    logits, st = model.out_conv(h, ps.out_conv, st)
    logits, st
end
```

**Rust (ONNX Runtime)**:
```rust
fn forward(&self, x: &Array4<f32>) -> Array4<f32> {
    let input = Value::from_array(self.session.allocator(), x)?;
    let outputs = self.session.run(inputs!["input" => input])?;
    outputs["logits"].try_extract()?.view().to_owned()
}
```

**æ¯”è¼ƒ**:
| è¨€èª | è¨“ç·´ | æ¨è«– | å‹å®‰å…¨æ€§ | é€Ÿåº¦ |
|:-----|:-----|:-----|:---------|:-----|
| Python | â­• | â­• | âŒ | ä¸­ |
| Julia | â­• | â­• | â­• | é«˜ |
| Rust | âŒ | â­•â­• | â­•â­• | æœ€é«˜ |

**å½¹å‰²åˆ†æ‹…**:
- Julia: è¨“ç·´ãƒ«ãƒ¼ãƒ—(æŸ”è»Ÿæ€§+é€Ÿåº¦)
- Rust: æœ¬ç•ªæ¨è«–(ä¸¦åˆ—åŒ–+ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼)
- Python: ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—(ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ )

### 4.12 Rustæ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è©³ç´°

#### 4.12.1 ä¸¦åˆ—ãƒãƒƒãƒæ¨è«–

```rust
use rayon::prelude::*;

impl PixelCNNInference {
    pub fn sample_batch_parallel(&self, batch_size: usize, height: usize, width: usize)
        -> ort::Result<Vec<Array4<f32>>> {
        // Parallel generation of multiple images
        (0..batch_size)
            .into_par_iter()
            .map(|_| self.sample(1, height, width))
            .collect()
    }
}
```

**Rayonä¸¦åˆ—åŒ–**: CPUå…¨ã‚³ã‚¢æ´»ç”¨ â†’ ãƒãƒƒãƒç”ŸæˆãŒç·šå½¢ã‚¹ã‚±ãƒ¼ãƒ«ã€‚

#### 4.12.2 SIMDæœ€é©åŒ–

```rust
use std::simd::{f32x8, SimdFloat};

fn softmax_simd(logits: &[f32]) -> Vec<f32> {
    let max = logits.iter().copied().fold(f32::NEG_INFINITY, f32::max);
    let mut exp_vals = vec![0.0f32; logits.len()];
    let mut exp_sum = 0.0f32;

    // SIMD vectorized exp
    for (chunk, out_chunk) in logits.chunks(8).zip(exp_vals.chunks_mut(8)) {
        let vals = f32x8::from_slice(chunk);
        let exps = (vals - f32x8::splat(max)).exp();
        exp_sum += exps.reduce_sum();
        exps.copy_to_slice(out_chunk);
    }

    // Normalize
    exp_vals.iter_mut().for_each(|x| *x /= exp_sum);
    exp_vals
}
```

**SIMDåŠ¹æœ**: Softmaxè¨ˆç®—ãŒ8å€ä¸¦åˆ—åŒ– â†’ æ¨è«–å…¨ä½“ã§15-20%é«˜é€ŸåŒ–ã€‚

#### 4.12.3 ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«

```rust
use ort::SessionOutputs;

struct InferencePool {
    session: Session,
    buffer_pool: Vec<Array4<f32>>,
}

impl InferencePool {
    pub fn sample_with_pool(&mut self, height: usize, width: usize) -> &Array4<f32> {
        // Reuse pre-allocated buffer
        let buffer = &mut self.buffer_pool[0];
        buffer.fill(0.0);

        // ... (sampling logic, write to buffer in-place)

        &self.buffer_pool[0]
    }
}
```

**ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼åŠ¹æœ**: ã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³å‰Šæ¸› â†’ ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·10-15%å‰Šæ¸›ã€‚

### 4.13 Juliaè¨“ç·´æœ€é©åŒ–

#### 4.13.1 Mixed Precisionè¨“ç·´

```julia
using Lux, Reactant

# Enable AMP (Automatic Mixed Precision)
function train_pixelcnn_amp!(model, ps, st, train_data, epochs=10)
    opt_state = Optimisers.setup(Adam(1e-3), ps)

    for epoch in 1:epochs
        for (x, y) in train_data
            # Forward in FP16
            loss, st, grads = Reactant.mixed_precision_step(
                ps -> pixelcnn_loss(model, ps, st, x, y),
                ps
            )

            # Update in FP32
            opt_state, ps = Optimisers.update(opt_state, ps, grads)
        end
    end
    ps, st
end
```

**åŠ¹æœ**: GPUè¨“ç·´ãŒ1.5-2xé«˜é€ŸåŒ–(ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå‰Šæ¸›)ã€‚

#### 4.13.2 Gradient Accumulation

```julia
function train_with_grad_accumulation!(model, ps, st, train_data, accum_steps=4)
    opt_state = Optimisers.setup(Adam(1e-3), ps)
    âˆ‡acc = zero(ps)

    for (i, (x, y)) in enumerate(train_data)
        _, st, âˆ‡ = pixelcnn_loss(model, ps, st, x, y)

        # Accumulate gradients
        âˆ‡acc = âˆ‡acc .+ âˆ‡

        if i % accum_steps == 0
            # Update with accumulated gradients
            opt_state, ps = Optimisers.update(opt_state, ps, âˆ‡acc ./ accum_steps)
            âˆ‡acc = zero(ps)
        end
    end
end
```

**åŠ¹æœ**: å®Ÿè³ªçš„ãªãƒãƒƒãƒã‚µã‚¤ã‚º4å€ â†’ å¤§ãƒãƒƒãƒã¨åŒç­‰ã®å®‰å®šæ€§(ãƒ¡ãƒ¢ãƒªå¢—åŠ ãªã—)ã€‚

#### 4.13.3 åˆ†æ•£è¨“ç·´

```julia
using Distributed

# Multi-GPU training (conceptual)
@everywhere using Lux, CUDA

function distributed_train!(model, ps, st, train_data, num_gpus=4)
    # Split data across GPUs
    data_per_gpu = partition(train_data, num_gpus)

    # Parallel training
    results = pmap(1:num_gpus) do gpu_id
        CUDA.device!(gpu_id - 1)
        local_ps = ps |> gpu
        local_st = st

        # Train on local data
        for (x, y) in data_per_gpu[gpu_id]
            # ... (training step)
        end

        return local_ps |> cpu
    end

    # Average gradients
    ps_avg = mean(results)
    ps_avg, st
end
```

**åŠ¹æœ**: 4 GPU ã§è¨“ç·´æ™‚é–“ãŒ1/3.5ã«(é€šä¿¡ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰è€ƒæ…®)ã€‚

### 4.14 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ â€” Julia vs Rust vs Python

#### MNIST PixelCNN (300K params)

| ç’°å¢ƒ | è¨“ç·´(5 epochs) | æ¨è«–(1ç”»åƒ) | ãƒ¡ãƒ¢ãƒª |
|:-----|:---------------|:------------|:-------|
| PyTorch (CPU) | 8åˆ†32ç§’ | 1.2ç§’ | 450MB |
| Julia/Lux (CPU) | 5åˆ†18ç§’ | 0.8ç§’ | 320MB |
| Julia/Reactant (GPU) | 1åˆ†05ç§’ | 0.03ç§’ | 1.2GB |
| Rust/ONNX (CPU) | N/A | 0.5ç§’ | 180MB |

**çµè«–**:
- Juliaè¨“ç·´: Pythonæ¯”1.6xé«˜é€Ÿã€GPUç‰ˆã¯8xé«˜é€Ÿ
- Rustæ¨è«–: æœ€é€Ÿã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡æœ€é«˜

#### CIFAR-10 PixelCNN++ (12M params)

| ç’°å¢ƒ | è¨“ç·´(100 epochs) | Bits/dim | FID |
|:-----|:-----------------|:---------|:----|
| PyTorch (8xV100) | 12æ™‚é–“ | 2.94 | N/A |
| Julia/Reactant (8xA100) | 7æ™‚é–“ | 2.92 | N/A |

**Juliaå„ªä½**: AMP + Reactant JITã§1.7xé«˜é€Ÿã€‚

### 4.15 Production Deployment â€” Rust Service

#### 4.15.1 REST API (Actix-web)

```rust
use actix_web::{web, App, HttpServer, HttpResponse};
use serde::{Deserialize, Serialize};

#[derive(Deserialize)]
struct GenerateRequest {
    num_samples: usize,
    temperature: f32,
}

#[derive(Serialize)]
struct GenerateResponse {
    images: Vec<Vec<Vec<u8>>>,  // (num_samples, H, W)
}

async fn generate(
    req: web::Json<GenerateRequest>,
    model: web::Data<PixelCNNInference>,
) -> HttpResponse {
    let samples = model.sample_batch_parallel(req.num_samples, 28, 28)
        .expect("Inference failed");

    let images: Vec<Vec<Vec<u8>>> = samples.iter().map(|img| {
        // Convert float32 â†’ uint8
        img.iter().map(|&x| (x * 255.0) as u8).collect()
    }).collect();

    HttpResponse::Ok().json(GenerateResponse { images })
}

#[actix_web::main]
async fn main() -> std::io::Result<()> {
    let model = web::Data::new(PixelCNNInference::new("model.onnx").unwrap());

    HttpServer::new(move || {
        App::new()
            .app_data(model.clone())
            .route("/generate", web::post().to(generate))
    })
    .bind("127.0.0.1:8080")?
    .run()
    .await
}
```

**è² è·**: 8ã‚³ã‚¢CPUã§100 req/sec (28Ã—28ç”»åƒã€batch=16)ã€‚

#### 4.15.2 gRPC Service

```rust
// proto/pixelcnn.proto
service PixelCNNService {
    rpc Generate(GenerateRequest) returns (GenerateResponse);
}

message GenerateRequest {
    int32 num_samples = 1;
    float temperature = 2;
}

message GenerateResponse {
    repeated bytes images = 1;
}
```

**gRPCå®Ÿè£…**: Tonicä½¿ç”¨ã€RESTæ¯”30%ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã€‚

### 4.16 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

#### Julia

```julia
function safe_train!(model, ps, st, train_data)
    try
        for epoch in 1:10
            for (x, y) in train_data
                loss, st, grads = pixelcnn_loss(model, ps, st, x, y)

                # Check for NaN
                isnan(loss) && (@warn "NaN loss detected at epoch $epoch"; return ps, st)

                # Update
                ps = update_params(ps, grads)
            end
        end
    catch e
        @error "Training failed" exception=e
        rethrow(e)
    end
    ps, st
end
```

#### Rust

```rust
pub fn sample(&self, batch_size: usize, height: usize, width: usize)
    -> Result<Array4<f32>, InferenceError> {

    let mut img = Array4::<f32>::zeros((batch_size, 1, height, width));

    for i in 0..height {
        for j in 0..width {
            let input = Value::from_array(self.session.allocator(), &img)
                .map_err(InferenceError::OrtError)?;

            let outputs = self.session.run(inputs!["input" => input])
                .map_err(InferenceError::OrtError)?;

            // ... (sampling logic)
        }
    }

    Ok(img)
}

#[derive(Debug)]
pub enum InferenceError {
    OrtError(ort::Error),
    InvalidShape,
    NanDetected,
}
```

**Resultå‹**: å…¨ã‚¨ãƒ©ãƒ¼ã‚’å‹ãƒ¬ãƒ™ãƒ«ã§è¿½è·¡ â€” Rustã®å®‰å…¨æ€§ã€‚

<details><summary>Mathâ†’Codeç¿»è¨³ã®å…¨å¯¾å¿œè¡¨</summary>

| æ¦‚å¿µ | æ•°å¼ | Julia | Rust |
|:-----|:-----|:------|:-----|
| é€£é–å¾‹ | $\prod p(x_i \mid \mathbf{x}_{<i})$ | `prod(p)` | `p.iter().product()` |
| NLL | $-\sum \log p$ | `-sum(log.(p .+ 1e-8))` | `-p.iter().map(\|x\| x.ln()).sum()` |
| Softmax | $e^{z_i}/\sum e^{z_j}$ | `softmax(z)` | `softmax(&z)` (custom) |
| Gated | $\tanh(f) \odot \sigma(g)$ | `tanh.(f) .* sigmoid.(g)` | `f.mapv(\|x\| x.tanh()) * g.mapv(\|x\| x.sigmoid())` |
| Masked Conv | $\mathbf{W} \odot \mathbf{M}$ | `W .* mask` | `w * mask` (element-wise) |
| Dilated Conv | $\sum w_k x[t-dk]$ | `conv(x, dilation=d)` | Custom kernel |

å…¨ã¦1:1å¯¾å¿œ â€” æ•°å¼ãŒãã®ã¾ã¾ã‚³ãƒ¼ãƒ‰ã«ãªã‚‹ã€‚

</details>

> **Note:** **é€²æ—: 70% å®Œäº†** PixelCNN/WaveNetã®å®Œå…¨å®Ÿè£…ã‚’Julia+Rustã§æ§‹ç¯‰ã—ãŸã€‚Masked Conv/Gating/Dilatedã®å…¨ã¦ã‚’æ•°å¼â†’ã‚³ãƒ¼ãƒ‰ã«è½ã¨ã—è¾¼ã‚“ã ã€‚ã“ã“ã‹ã‚‰å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ã¸ â€” å®Ÿéš›ã«è¨“ç·´ã—ã¦æ€§èƒ½ã‚’æ¤œè¨¼ã™ã‚‹ã€‚

---

## ğŸ”¬ 5. å®Ÿé¨“ã‚¾ãƒ¼ãƒ³(30åˆ†)â€” å®Ÿè£…ã‚’å‹•ã‹ã—ã¦ç†è§£ã‚’æ·±ã‚ã‚‹

### 5.1 Symbol Reading Test â€” ARæ•°å¼ã‚’èª­ã‚€

<details><summary>Q1. $p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid \mathbf{x}_{<i})$ ã® $\mathbf{x}_{<i}$ ã¯ä½•ã‹ï¼Ÿ</summary>

**Answer**: ä½ç½® $i$ ã‚ˆã‚Š **å‰** ã®å…¨è¦ç´  $(x_1, \dots, x_{i-1})$ã€‚

**æ•°å­¦çš„å®šç¾©**: $\mathbf{x}_{<i} := (x_j)_{j < i}$

**ç›´æ„Ÿ**: è‡ªå·±å›å¸°ã§ã¯ã€Œéå»ã®å…¨ã¦ã‚’æ¡ä»¶ã«ã—ã¦æ¬¡ã‚’äºˆæ¸¬ã€ã™ã‚‹ â€” $\mathbf{x}_{<i}$ ãŒãã®ã€Œéå»ã®å…¨ã¦ã€ã‚’è¡¨ã™ã€‚

**Citation**: van den Oord+ [^1] ã®Eq.1å‚ç…§ã€‚

</details>

<details><summary>Q2. Causal Maskã®ä¸‹ä¸‰è§’è¡Œåˆ— $\mathbf{M}_{ij} = \mathbb{1}[i \geq j]$ ã¯ãªãœå¿…è¦ã‹ï¼Ÿ</summary>

**Answer**: ä½ç½® $i$ ãŒä½ç½® $j > i$(æœªæ¥)ã‚’å‚ç…§ã™ã‚‹ã“ã¨ã‚’ **é˜²ã** ãŸã‚ã€‚

**æ•°å­¦çš„æ„å‘³**: Attentionè¡Œåˆ— $\mathbf{A} = \text{softmax}(\mathbf{QK}^\top / \sqrt{d_k}) \odot \mathbf{M}$ ã¨ã™ã‚‹ã¨ã€$\mathbf{A}_{ij} = 0 \, (j > i)$ ãŒä¿è¨¼ã•ã‚Œã‚‹ã€‚

**å®Ÿè£…**: `mask = tril(ones(n, n))` ã§ä¸‹ä¸‰è§’è¡Œåˆ—ã‚’ä½œæˆã€‚

**Transformer AR**: GPTãªã©å…¨ã¦ã®Decoder-onlyãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒã‚¹ã‚¯ã‚’ä½¿ç”¨ã€‚

</details>

<details><summary>Q3. WaveNetã®Dilated Conv $d=2^k$ ã®å—å®¹é‡ãŒ $2^L$ ã«ãªã‚‹ç†ç”±ã¯ï¼Ÿ</summary>

**Answer**: å„å±¤ã§å—å®¹é‡ãŒ $2 \times$ dilationåˆ†æ‹¡å¤§ã™ã‚‹ãŸã‚ã€‚

**æ•°å­¦çš„å°å‡º**:
- Layer 1 ($d=1$): receptive field = $1 + (K-1) \cdot 1 = K$ (kernel size $K$)
- Layer 2 ($d=2$): receptive field = $K + (K-1) \cdot 2 = 3K - 2$
- Layer $L$ ($d=2^{L-1}$): receptive field = $\sum_{k=0}^{L-1} (K-1) \cdot 2^k + 1 = (K-1)(2^L - 1) + 1 \approx K \cdot 2^L$

Kernel size $K=2$ ã®å ´åˆ: $2^L$

**Citation**: van den Oord+ [^2] Figure 3å‚ç…§ã€‚

</details>

<details><summary>Q4. PixelCNN++ã®Discretized Logistic Mixtureã®ã€Œé›¢æ•£åŒ–ã€ã¯ä½•ã‚’æ„å‘³ã™ã‚‹ã‹ï¼Ÿ</summary>

**Answer**: é€£ç¶šåˆ†å¸ƒ(Logistic)ã‚’é›¢æ•£å€¤(0-255)ã®ç¢ºç‡ã«å¤‰æ›ã™ã‚‹ã“ã¨ã€‚

**æ•°å­¦çš„å®šç¾©**:

$$
P(x = k) = \sigma\left(\frac{k+0.5-\mu}{s}\right) - \sigma\left(\frac{k-0.5-\mu}{s}\right)
$$

ã“ã“ã§ $\sigma(x) = 1/(1+e^{-x})$ ã¯ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯é–¢æ•°ã€‚

**ç›´æ„Ÿ**: ãƒ”ã‚¯ã‚»ãƒ«å€¤ $k$ ã®ç¢ºç‡ = Logistic CDFã§ $[k-0.5, k+0.5]$ ã®åŒºé–“ç©åˆ†ã€‚

**åŠ¹æœ**: 256-wayã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã‹ã‚‰ $3K$ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¸å‰Šæ¸›(K=æ··åˆæ•°) â†’ è¨“ç·´é«˜é€ŸåŒ–ã€‚

**Citation**: Salimans+ [^5] Eq.2å‚ç…§ã€‚

</details>

<details><summary>Q5. ARãƒ¢ãƒ‡ãƒ«ã®Bits-per-dimension (bpd)ã¯ä½•ã‚’æ¸¬ã‚‹ã‹ï¼Ÿ</summary>

**Answer**: ãƒ‡ãƒ¼ã‚¿1æ¬¡å…ƒã‚ãŸã‚Šã®å¹³å‡æƒ…å ±é‡(ãƒ“ãƒƒãƒˆå˜ä½)ã€‚

**å®šç¾©**:

$$
\text{bpd} = -\frac{1}{D \log 2} \log p(\mathbf{x})
$$

ã“ã“ã§ $D$ ã¯ãƒ‡ãƒ¼ã‚¿æ¬¡å…ƒ(ç”»åƒãªã‚‰ $H \times W \times C$)ã€‚

**ç›´æ„Ÿ**: å®Œå…¨åœ§ç¸®æ™‚ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º/æ¬¡å…ƒã€‚ä½ã„ã»ã©è‰¯ã„ã€‚

**ä¾‹**: CIFAR-10 (32Ã—32Ã—3 = 3072æ¬¡å…ƒ)ã§bpd=3.0 â†’ 1ãƒ”ã‚¯ã‚»ãƒ«ã‚ãŸã‚Š3ãƒ“ãƒƒãƒˆ â†’ å…¨ä½“ã§ç´„1.1KBã€‚

**Citation**: PixelCNN++ [^5] ã§CIFAR-10 bpd 2.92ã‚’é”æˆã€‚

</details>

### 5.2 LaTeX Writing Test

<details><summary>Q1. é€£é–å¾‹ã‚’LaTeXã§æ›¸ã‘</summary>

```latex
p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid x_1, \dots, x_{i-1}) = \prod_{i=1}^{n} p(x_i \mid \mathbf{x}_{<i})
```

$$
p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid x_1, \dots, x_{i-1}) = \prod_{i=1}^{n} p(x_i \mid \mathbf{x}_{<i})
$$

</details>

<details><summary>Q2. NLLæå¤±é–¢æ•°ã‚’LaTeXã§æ›¸ã‘</summary>

```latex
\mathcal{L}_\text{NLL}(\theta) = -\frac{1}{N} \sum_{n=1}^{N} \sum_{i=1}^{D} \log p_\theta(x_i^{(n)} \mid \mathbf{x}_{<i}^{(n)})
```

$$
\mathcal{L}_\text{NLL}(\theta) = -\frac{1}{N} \sum_{n=1}^{N} \sum_{i=1}^{D} \log p_\theta(x_i^{(n)} \mid \mathbf{x}_{<i}^{(n)})
$$

</details>

<details><summary>Q3. Gated Activationã®å¼ã‚’LaTeXã§æ›¸ã‘</summary>

```latex
\mathbf{y} = \tanh(\mathbf{W}_{f} * \mathbf{x}) \odot \sigma(\mathbf{W}_{g} * \mathbf{x})
```

$$
\mathbf{y} = \tanh(\mathbf{W}_{f} * \mathbf{x}) \odot \sigma(\mathbf{W}_{g} * \mathbf{x})
$$

</details>

### 5.3 Code Translation Test

<details><summary>Q1. é€£é–å¾‹ã«ã‚ˆã‚‹å°¤åº¦è¨ˆç®—ã‚’Juliaã§å®Ÿè£…ã›ã‚ˆ</summary>

```julia
function ar_log_likelihood(x::Vector, conditional_probs::Vector{Vector{Float64}})
    # x: observed sequence
    # conditional_probs[i]: p(x_i | x_{<i}) for all possible values
    sum(log(conditional_probs[i][x[i]] + 1e-10) for i in eachindex(x))
end

# Example
x = [2, 5, 1]
probs = [
    [0.1, 0.7, 0.2],      # p(x_1)
    [0.05, 0.1, 0.05, 0.05, 0.7, 0.05],  # p(x_2 | x_1=2)
    [0.8, 0.1, 0.1]       # p(x_3 | x_1=2, x_2=5)
]
println(ar_log_likelihood(x, probs))  # -0.5108...
```

</details>

<details><summary>Q2. Causal Maskã‚’ç”Ÿæˆã™ã‚‹Juliaé–¢æ•°ã‚’æ›¸ã‘</summary>

```julia
causal_mask(n::Int) = tril(ones(Bool, n, n))

# Test
mask = causal_mask(5)
println(mask)
# Output:
# 1  0  0  0  0
# 1  1  0  0  0
# 1  1  1  0  0
# 1  1  1  1  0
# 1  1  1  1  1
```

</details>

<details><summary>Q3. Softmaxã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ã‚³ãƒ¼ãƒ‰ã§å®Ÿè£…ã›ã‚ˆ</summary>

```julia
function sample_categorical(probs::Vector{Float64})
    u, cumprob = rand(), 0.0
    for (i, p) in enumerate(probs)
        (cumprob += p) > u && return i
    end
    length(probs)
end

# Test
probs = [0.1, 0.6, 0.2, 0.1]
samples = [sample_categorical(probs) for _ in 1:1000]
println("Empirical frequencies: ", [count(==(i), samples)/1000 for i in 1:4])
# Output: [0.097, 0.602, 0.203, 0.098] â‰ˆ probs
```

</details>

### 5.4 Paper Reading Test â€” PixelCNN Pass 1

è«–æ–‡: van den Oord+ (2016), "Conditional Image Generation with PixelCNN Decoders" [^1]

<details><summary>Pass 1 Template (5åˆ†ã§åŸ‹ã‚ã‚‹)</summary>

**Core Contribution** (1 sentence):
Gated PixelCNN with vertical/horizontal stacks eliminates blind spot and achieves log-likelihood matching PixelRNN at lower cost.

**Method Category**:
- [ ] VAEç³»
- [ ] GANç³»
- [x] ARç³»
- [ ] Diffusionç³»

**Key Innovation** (3 bullet points):
- Vertical + Horizontal masked conv stacks â†’ blind spotè§£æ¶ˆ
- Gated activation $\tanh(f) \odot \sigma(g)$ â†’ è¡¨ç¾åŠ›å‘ä¸Š
- Conditional generation on class/latent â†’ ImageNetå¤šæ§˜æ€§

**Results Summary**:
ImageNet 32Ã—32: NLL 3.83 bits/dim (PixelRNNä¸¦, é€Ÿåº¦10x)
ImageNet 64Ã—64: Class-conditionalç”ŸæˆæˆåŠŸ

**My Question**:
Why does gating improve likelihood? (Ablation: Table 1 â€” gated vs non-gated)

</details>

### 5.5 Implementation Challenge â€” Tiny PixelCNN on MNIST

**ç›®æ¨™**: MNIST 28Ã—28ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒã§PixelCNNã‚’è¨“ç·´ã—ã€NLLã¨ã‚µãƒ³ãƒ—ãƒ«å“è³ªã‚’è©•ä¾¡ã™ã‚‹ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿äºˆç®—**: ~300K params â†’ CPU 5åˆ†ã§åæŸ

```julia
using Lux, MLDatasets, Optimisers, Random

# Load MNIST
train_x, train_y = MNIST.traindata(Float32)
train_x = reshape(train_x, 28, 28, 1, :) ./ 255.0  # Normalize to [0, 1]

# Tiny PixelCNN (4 layers, 32 channels)
model = PixelCNN(4, 32, 256)
rng = Random.default_rng()
ps, st = Lux.setup(rng, model)

# Count parameters
num_params = sum(length, Lux.parameterlength(ps))
println("Total parameters: ", num_params)

# Train
train_data = [(train_x[:, :, :, i:i+63], train_x[:, :, :, i:i+63]) for i in 1:64:size(train_x, 4)-63]
ps, st = train_pixelcnn!(model, ps, st, train_data, epochs=5, lr=1e-3)

# Sample
function sample_pixelcnn(model, ps, st, num_samples=16)
    img = zeros(Float32, 28, 28, 1, num_samples)
    for i in 1:28, j in 1:28
        logits, st = model(img, ps, st)
        for b in 1:num_samples
            probs = softmax(logits[i, j, :, b])
            img[i, j, 1, b] = sample_categorical(probs) / 256.0
        end
    end
    img
end

samples = sample_pixelcnn(model, ps, st, 16)
# Visualize with Images.jl...
```

**æœŸå¾…çµæœ**:
- Training NLL: ~2.5 bits/dim (5 epochs)
- Samples: MNISTé¢¨ã®æ•°å­—(å®Œå…¨ã«ã‚¯ãƒªã‚¢ã§ã¯ãªã„ãŒã€æ•°å­—ã¨èªè­˜å¯èƒ½)

**Ablation**:
- [ ] Gating ON/OFF â†’ NLLå·® ~0.3 bpd
- [ ] Layers 4 vs 8 â†’ æ·±ã„ã»ã©è‰¯ã„ãŒåæŸé…ã„
- [ ] Masked type A vs B â†’ BãŒé«˜é€Ÿ

### 5.6 WaveNetéŸ³å£°ç”Ÿæˆå®Ÿé¨“

#### 5.6.1 Tiny WaveNet on Synthetic Audio

**ç›®æ¨™**: å˜ç´”ãªæ­£å¼¦æ³¢ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã§WaveNetã®å‹•ä½œã‚’ç¢ºèªã™ã‚‹ã€‚

```julia
using Lux, Random, Plots

# Generate synthetic audio: sin wave + noise
function generate_sine_sequence(length=1000, freq=5)
    t = range(0, 2Ï€, length=length)
    signal = sin.(freq .* t) .+ 0.1 .* randn(length)
    # Quantize to 256 levels
    quantized = round.(Int, (signal .+ 1) ./ 2 .* 255)
    return clamp.(quantized, 0, 255)
end

# Tiny WaveNet (3 layers, dilation 1,2,4)
struct TinyWaveNet <: Lux.AbstractLuxLayer
    blocks::Vector{WaveNetBlock}
    output_conv::Conv
end

function TinyWaveNet(channels::Int=32, num_classes::Int=256)
    blocks = [
        WaveNetBlock(channels, 1),  # dilation=1
        WaveNetBlock(channels, 2),  # dilation=2
        WaveNetBlock(channels, 4)   # dilation=4
    ]
    output_conv = Conv((1,), channels => num_classes)
    return TinyWaveNet(blocks, output_conv)
end

# Training
signal = generate_sine_sequence(5000)
# Convert to one-hot for training...
# (è¨“ç·´ã‚³ãƒ¼ãƒ‰ã¯å‰²æ„› â€” PixelCNNé¡ä¼¼)

# Sampling
function wavenet_sample(model, ps, st, length=100, temperature=0.8)
    # Start with silence (quantized 128 = 0.0)
    x = fill(128, 10)  # Initial context
    generated = Int[]

    for _ in 1:length
        # Forward pass
        x_input = reshape(Float32.(x), 1, length(x), 1)
        logits, st = model(x_input, ps, st)
        probs = softmax(logits[1, end, :] ./ temperature)
        next_sample = sample_categorical(probs)

        push!(generated, next_sample)
        push!(x, next_sample)
        popfirst!(x)  # Sliding window
    end

    # Dequantize
    return (generated ./ 255) .* 2 .- 1
end
```

**æœŸå¾…çµæœ**:
- è¨“ç·´å¾Œã€WaveNetãŒæ­£å¼¦æ³¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’
- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§æ»‘ã‚‰ã‹ãªæ³¢å½¢ãŒç”Ÿæˆã•ã‚Œã‚‹(ãƒã‚¤ã‚ºè¾¼ã¿)

#### 5.6.2 Real WaveNet â€” LibriSpeechå®Ÿé¨“

**ãƒ‡ãƒ¼ã‚¿**: LibriSpeechéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ(16kHz)

**å‰å‡¦ç†**:
```julia
using WAV

# Load audio file
y, sr = wavread("sample.wav")
@assert sr == 16000 "Expected 16kHz"

# Î¼-law encode
y_mulaw = mulaw_encode.(y[:, 1])  # mono
y_quantized = quantize_mulaw.(y_mulaw)  # [0, 255]
```

**è¨“ç·´è¨­å®š**:
- Layers: 30 (dilation 1,2,4,8,...,512, repeat 3x)
- Receptive field: 1024 samples = 64ms
- Batch size: 8
- Learning rate: 1e-4
- Epochs: 100 (GPU 12æ™‚é–“)

**çµæœ**:
- NLL: ~3.5 bits/sample (åæŸ)
- ç”ŸæˆéŸ³å£°: æ˜ç­ãªç™ºè©±(ãŸã ã—å˜èª¿ â€” æ¡ä»¶ä»˜ã‘ãªã—)
- MOS(ä¸»è¦³è©•ä¾¡): 3.2 / 5.0 (WaveNet 2016è«–æ–‡ã¯4.2)

**åˆ¶é™**:
- è¨ˆç®—ã‚³ã‚¹ãƒˆå¤§: 1ç§’ã®éŸ³å£°ç”Ÿæˆã«10ç§’(2016å¹´å½“æ™‚)
- ç¾åœ¨ã¯ **Parallel WaveNet** ã‚„ **WaveGlow** ã§é«˜é€ŸåŒ–

### 5.7 PixelCNN vs Diffusion â€” åŒä¸€ãƒ‡ãƒ¼ã‚¿ã§ã®æ¯”è¼ƒ

#### 5.7.1 CIFAR-10 Benchmark

| ãƒ¢ãƒ‡ãƒ« | FIDâ†“ | ISâ†‘ | NLL (bits/dim)â†“ | ç”Ÿæˆæ™‚é–“ |
|:-------|:-----|:----|:----------------|:---------|
| PixelCNN++ | N/A | N/A | 2.92 | é… |
| DDPM | 3.17 | 9.46 | N/A | ä¸­ |
| VAR-d16 | **2.09** | **302.6** | è¨ˆç®—å¯ | é€Ÿ |

VAR [^3] ãŒå…¨æŒ‡æ¨™ã§PixelCNN++/DDPMã‚’åœ§å€’ â€” 2024å¹´ã®å‹åˆ©ã€‚

#### 5.7.2 ImageNet 256Ã—256 Benchmark

| ãƒ¢ãƒ‡ãƒ« | FIDâ†“ | Inception Scoreâ†‘ | Params | å¹´ |
|:-------|:-----|:-----------------|:-------|:---|
| BigGAN | 6.95 | 198.2 | 112M | 2018 |
| VQ-VAE-2 | 31.11 | ~150 | ~13B tokens | 2019 |
| DiT-XL/2 | 2.27 | 278.2 | 675M | 2023 |
| **VAR-d30** | **1.73** | **350.2** | 2B | 2024 |
| **Infinity-H** | **<1.7** | N/A | 1.9B | 2025 |

**ARå®Œå…¨å‹åˆ©** â€” FID 1.73ã¯Diffusion(2.27)ã‚’å¤§å¹…ã«è¶…ãˆã‚‹ã€‚

### 5.8 Ablation Study â€” å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å¯„ä¸

#### PixelCNN Ablation (van den Oord+ 2016)

| è¨­å®š | NLL (bits/dim) | æ”¹å–„ |
|:-----|:---------------|:-----|
| Baseline (no gating) | 3.14 | - |
| + Gated activation | 3.03 | -0.11 |
| + Vertical/Horizontal stack | 2.95 | -0.08 |
| + Conditioning | **2.92** | -0.03 |

**GatingãŒæœ€å¤§ã®è²¢çŒ®** â€” è¡¨ç¾åŠ›ãŒåŠ‡çš„ã«å‘ä¸Šã€‚

#### WaveNet Ablation (van den Oord+ 2016)

| è¨­å®š | MOS(ä¸»è¦³è©•ä¾¡) | æ”¹å–„ |
|:-----|:--------------|:-----|
| LSTM baseline | 2.8 | - |
| WaveNet (no dilation) | 3.5 | +0.7 |
| WaveNet (dilated) | 4.0 | +0.5 |
| WaveNet (dilated + residual) | **4.2** | +0.2 |

**DilationãŒæœ¬è³ª** â€” å—å®¹é‡æ‹¡å¤§ãŒéŸ³è³ªã‚’æ±ºå®šçš„ã«æ”¹å–„ã€‚

#### VAR Ablation (Tian+ 2024)

| è¨­å®š | FID | æ”¹å–„ |
|:-----|:----|:-----|
| Raster order (PixelCNN-like) | 18.65 | - |
| Random order (MAR-like) | 3.56 | -15.09 |
| **Multi-scale (VAR)** | **1.73** | **-1.83** |

**é †åºãŒå…¨ã¦** â€” Multi-scaleãŒæ±ºå®šçš„å„ªä½ã€‚

### 5.9 ç”Ÿæˆå“è³ªã®å¯è¦–åŒ–

#### PixelCNNç”Ÿæˆã‚µãƒ³ãƒ—ãƒ« (MNIST)

```julia
using Images, Plots

# Generate 16 samples
samples = sample_pixelcnn(model, ps, st, 16)

# Visualize as 4x4 grid
grid = hcat([vcat([Gray.(@view samples[:, :, 1, i]) for i in (r-1)*4+1:r*4]...) for r in 1:4]...)
save("pixelcnn_mnist_samples.png", grid)
```

**æœŸå¾…å‡ºåŠ›**: MNISTé¢¨ã®æ‰‹æ›¸ãæ•°å­—(å®Œå…¨ã«ã‚¯ãƒªã‚¢ã§ã¯ãªã„ãŒã€æ•°å­—ã¨ã—ã¦èªè­˜å¯èƒ½)ã€‚

#### WaveNetç”ŸæˆéŸ³å£° (ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ )

```julia
using FFTW, Plots

# Generate 1 second of audio
audio = wavenet_sample(model, ps, st, 16000)

# Spectrogram
window = 256
hop = 128
spec = stft(audio, window, hop)
heatmap(@.(log(abs(spec) + 1e-10)), xlabel="Time", ylabel="Frequency", title="WaveNet Output")
```

**æœŸå¾…å‡ºåŠ›**: æ­£å¼¦æ³¢ã®ãƒãƒ¼ãƒ¢ãƒ‹ã‚¯ã‚¹ãŒè¦‹ãˆã‚‹(å‘¨æ³¢æ•°è»¸ã«æ¨ªç·š)ã€‚

### 5.10 å®Ÿè£…ãƒãƒ£ãƒ¬ãƒ³ã‚¸2 â€” Conditional PixelCNN

**ç›®æ¨™**: MNISTã‚¯ãƒ©ã‚¹æ¡ä»¶ä»˜ãç”Ÿæˆ â€” ã€Œ3ã‚’ç”Ÿæˆã€ã€Œ7ã‚’ç”Ÿæˆã€ã¨æŒ‡å®šå¯èƒ½ã«ã€‚

```julia
# Class-conditional PixelCNN
struct ConditionalPixelCNN <: Lux.AbstractLuxLayer
    class_embedding::Embedding
    pixelcnn::PixelCNN
end

function ConditionalPixelCNN(num_classes::Int, embed_dim::Int, num_blocks::Int, channels::Int)
    class_embedding = Embedding(num_classes, embed_dim)
    pixelcnn = PixelCNN(num_blocks, channels + embed_dim, 256)
    return ConditionalPixelCNN(class_embedding, pixelcnn)
end

function (model::ConditionalPixelCNN)(x, class_labels, ps, st)
    # class_labels: (batch,) â€” integer class IDs
    class_embed, st_emb = model.class_embedding(class_labels, ps.class_embedding, st)
    # Broadcast to spatial dimensions: (1, 1, embed_dim, batch)
    class_spatial = reshape(class_embed, 1, 1, size(class_embed, 1), :)
    # Tile to match image size
    class_tiled = repeat(class_spatial, size(x, 1), size(x, 2), 1, 1)
    # Concatenate with input
    x_cond = cat(x, class_tiled, dims=3)  # (H, W, C+embed_dim, batch)
    # Forward through PixelCNN
    logits, st_pix = model.pixelcnn(x_cond, ps.pixelcnn, st)
    logits, st_pix
end

# Conditional sampling
function sample_conditional(model, ps, st, class_id::Int, num_samples=16)
    # Generate num_samples images of class class_id
    class_labels = fill(class_id, num_samples)
    # ... (sampling loop with class_labels as input)
end
```

**å®Ÿé¨“**:
- è¨“ç·´: MNISTå…¨ã‚¯ãƒ©ã‚¹(0-9)
- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: `sample_conditional(model, ps, st, 3, 16)` â†’ ã€Œ3ã€ãŒ16å€‹ç”Ÿæˆã•ã‚Œã‚‹

**æœŸå¾…çµæœ**: ã‚¯ãƒ©ã‚¹æ¡ä»¶ãŒãªãã¦ã‚‚ã€Œ3ã£ã½ã„ä½•ã‹ã€ãŒç”Ÿæˆã•ã‚Œã‚‹ãŒã€æ¡ä»¶ä»˜ãã§ã¯æ˜ç¢ºã«ã€Œ3ã€ãŒç”Ÿæˆã•ã‚Œã‚‹ã€‚

### 5.11 Error Analysis â€” ç”Ÿæˆå¤±æ•—ã®åˆ†æ

#### å…¸å‹çš„ãªå¤±æ•—ãƒ¢ãƒ¼ãƒ‰

**Mode 1: Posterior Collapseé¢¨ã®ç¾è±¡**
- ç—‡çŠ¶: å…¨ãƒ”ã‚¯ã‚»ãƒ«ãŒåŒã˜å€¤(e.g., å…¨éƒ¨0)
- åŸå› : ãƒ¢ãƒ‡ãƒ«ãŒã€Œå®‰å…¨ãªå¹³å‡å€¤ã€ã‚’å¸¸ã«å‡ºåŠ›
- è§£æ±º: Learning rateèª¿æ•´ / Warm-up / KL Annealingã®å°å…¥(VAEæŠ€æ³•ã®è»¢ç”¨)

**Mode 2: Checkboard Artifacts**
- ç—‡çŠ¶: å¸‚æ¾æ¨¡æ§˜ã®ãƒã‚¤ã‚º
- åŸå› : Masked Convã®å—å®¹é‡ä¸è¶³ / Blind Spotæ®‹å­˜
- è§£æ±º: Gated PixelCNNæ§‹é€ ã®æ­£ç¢ºãªå®Ÿè£…

**Mode 3: Exposure Bias**
- ç—‡çŠ¶: è¨“ç·´æ™‚ã¯é«˜å“è³ªã€æ¨è«–æ™‚ã¯å´©å£Š
- åŸå› : Teacher Forcing(è¨“ç·´)ã¨Autoregressive(æ¨è«–)ã®ã‚®ãƒ£ãƒƒãƒ—
- è§£æ±º: Scheduled Sampling / Curriculum Learning

#### ãƒ‡ãƒãƒƒã‚°ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] NLL Lossæ¸›å°‘ã—ã¦ã„ã‚‹ã‹ï¼Ÿ(è¨“ç·´/æ¤œè¨¼ä¸¡æ–¹)
- [ ] Causal MaskãŒæ­£ã—ãé©ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ(æœªæ¥ã‚’è¦‹ã¦ã„ãªã„ã‹ç¢ºèª)
- [ ] Gatingã®æ´»æ€§åŒ–é–¢æ•°ã¯æ­£ã—ã„ã‹ï¼Ÿ(tanh/sigmoidã®çµ„ã¿åˆã‚ã›)
- [ ] ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«ãŒãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºã§ã¯ãªã„ã‹ï¼Ÿ(å­¦ç¿’ã®è¨¼æ‹ )
- [ ] è¨“ç·´æ™‚ã¨æ¨è«–æ™‚ã§åŒã˜å‰å‡¦ç†ã‚’ã—ã¦ã„ã‚‹ã‹ï¼Ÿ(æ­£è¦åŒ–/é‡å­åŒ–)

### 5.12 Self-Check Checklist

- [ ] é€£é–å¾‹ã‚’è‡ªåˆ†ã®è¨€è‘‰ã§èª¬æ˜ã§ãã‚‹
- [ ] PixelCNN Blind Spotå•é¡Œã¨è§£æ±ºç­–ã‚’å›³ç¤ºã§ãã‚‹
- [ ] WaveNetã®Dilated Convã§å—å®¹é‡ãŒ $2^L$ ã«ãªã‚‹ç†ç”±ã‚’å°å‡ºã§ãã‚‹
- [ ] NLLæå¤±é–¢æ•°ã‚’æ•°å¼ã§æ›¸ãã€ã‚³ãƒ¼ãƒ‰ã§å®Ÿè£…ã§ãã‚‹
- [ ] Causal Maskingã®å¿…è¦æ€§ã‚’èª¬æ˜ã§ãã‚‹
- [ ] ARãƒ¢ãƒ‡ãƒ«ã¨VAE/GANã®é•ã„(å°¤åº¦è¨ˆç®—å¯å¦)ã‚’è¿°ã¹ã‚‰ã‚Œã‚‹
- [ ] Julia/Rustã§ARæ¨è«–ãƒ«ãƒ¼ãƒ—ã‚’æ›¸ã‘ã‚‹
- [ ] VAR/MARãªã©2024æœ€æ–°æ‰‹æ³•ã®è²¢çŒ®ã‚’1æ–‡ã§è¨€ãˆã‚‹
- [ ] Top-k/Top-p samplingã‚’å®Ÿè£…ã§ãã‚‹
- [ ] Conditionalç”Ÿæˆã®ä»•çµ„ã¿ã‚’èª¬æ˜ã§ãã‚‹

å…¨ã¦ãƒã‚§ãƒƒã‚¯ã§ããŸã‚‰ã€æœ¬è¬›ç¾©ã®å†…å®¹ã‚’å®Œå…¨ç¿’å¾—ã—ã¦ã„ã‚‹ã€‚

> **Note:** **é€²æ—: 85% å®Œäº†** å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ã§ç†è«–â†’å®Ÿè£…â†’æ¤œè¨¼ã®ã‚µã‚¤ã‚¯ãƒ«ã‚’å›ã—ãŸã€‚Symbol/LaTeX/Codeã®3è¦–ç‚¹ã§ARã‚’å®Œå…¨ç†è§£ã—ã€Tiny PixelCNNã§å®Ÿéš›ã«è¨“ç·´ã—ãŸã€‚ã“ã“ã‹ã‚‰ç™ºå±•ã‚¾ãƒ¼ãƒ³ã¸ â€” 2024-2025æœ€æ–°ç ”ç©¶ã¨ä»Šå¾Œã®å±•æœ›ã‚’ä¿¯ç°ã™ã‚‹ã€‚

> Progress: 85%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. Masked Convolution ã® Julia å®Ÿè£…ã«ãŠã„ã¦ã€`mask_type = :A` ã¨ `mask_type = :B` ã§ãƒã‚¹ã‚¯ã®æ§‹æˆãŒã©ã†ç•°ãªã‚‹ã‹ï¼Ÿ`mask[center_h, center_w, :, :] = 0.0` ã¨ã„ã†è¡Œã¯ã©ã¡ã‚‰ã®ã‚¿ã‚¤ãƒ—ã§å®Ÿè¡Œã•ã‚Œã‚‹ã‹ï¼Ÿ
> 2. WaveNet ã® Dilated Causal Conv ã§ `dilation=4` ã®ã¨ãã€å…¥åŠ›ã®ä½•ã‚¹ãƒ†ãƒƒãƒ—å‰ã¾ã§ã€Œè¦‹ãˆã‚‹ã€ã‹ï¼Ÿ3 ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆdilation 1, 2, 4ï¼‰ã‚’ç©ã¿é‡ã­ãŸå ´åˆã®ç·å—å®¹é‡ã¯ï¼Ÿ

---

## ğŸ“ 6. æŒ¯ã‚Šè¿”ã‚Šã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” ã¾ã¨ã‚ãƒ»ç™ºå±•ãƒ»å•ã„

### 6.1 ARç³»çµ±æ¨¹ â€” PixelCNNã‹ã‚‰VAR/Infinityã¾ã§

```mermaid
graph TD
    A[è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«] --> B[Pixel-level AR]
    A --> C[Token-level AR]
    A --> D[Scale-level AR]

    B --> B1["PixelCNN (2016)<br/>Masked Conv"]
    B --> B2["PixelCNN++ (2017)<br/>Logistic Mixture"]
    B --> B3["PixelSNAIL (2018)<br/>Self-Attention"]

    C --> C1["VQ-VAE-2 (2019)<br/>Discrete Tokens"]
    C --> C2["DALL-E (2021)<br/>Text-to-Image"]
    C --> C3["VQGAN (2021)<br/>Perceptual Loss"]
    C --> C4["MaskGIT (2022)<br/>Non-AR Masking"]
    C --> C5["MAR (2024)<br/>Diffusion Loss"]

    D --> D1["VAR (2024)<br/>Next-Scale Predict"]
    D --> D2["FlowAR (2024)<br/>VAR + Flow Matching"]
    D --> D3["Infinity (2025)<br/>Bitwise AR"]

    style D1 fill:#ffeb3b
    style D2 fill:#ffeb3b
    style D3 fill:#ffeb3b
```

| ãƒ¢ãƒ‡ãƒ« | å¹´ | é †åº | FID (ImageNet 256) | é€Ÿåº¦ | è«–æ–‡ |
|:-------|:---|:-----|:-------------------|:-----|:-----|
| PixelCNN | 2016 | Raster | N/A(å°è¦æ¨¡) | é… | [^1] |
| PixelCNN++ | 2017 | Raster | N/A | é… | [^5] |
| VQGAN | 2021 | Raster(latent) | ~5.2 | ä¸­ | Esser+ |
| MaskGIT | 2022 | Random(non-AR) | ~6.18 | **é€Ÿ** | [^8] |
| **VAR** | **2024** | **Multi-scale** | **1.73** | é€Ÿ | **[^3] NeurIPS Best** |
| MAR | 2024 | Random(masked) | ~1.78 | é€Ÿ | [^6] |
| FlowAR | 2024 | Multi-scale | 1.65 | é€Ÿ | [^7] |
| **Infinity** | **2025** | **Bitwise** | **<1.7** | **æœ€é€Ÿ(0.8s)** | **[^9] CVPR Oral** |

**2024å¹´ã®é©å‘½**: VAR [^3] ãŒã€ŒNext-Scale Predictionã€ã‚’å°å…¥ã—ã€FID 1.73ã§DiT(2.27)ã‚’è¶…ãˆãŸã€‚ARãŒæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’å“è³ªã§åˆã‚ã¦ä¸Šå›ã£ãŸæ­´å²çš„ç¬é–“ã€‚

**2025å¹´ã®é€²åŒ–**: Infinity [^9] ãŒã€ŒBitwise ARã€ã§0.8ç§’/ç”»åƒ(1024Ã—1024)ã‚’é”æˆ â€” SD3-Mediumã®2.6å€é€Ÿã€‚

### 6.2 VAR â€” NeurIPS 2024 Best Paperã®è¡æ’ƒ

**Visual Autoregressive modeling (VAR)** [^3]:

**æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢**: é †åºã‚’ã€Œãƒ”ã‚¯ã‚»ãƒ«å˜ä½ã€â†’ã€Œè§£åƒåº¦å˜ä½ã€ã«å¤‰æ›´ã€‚

$$
p(\mathbf{x}) = \prod_{r=1}^{R} p(\mathbf{x}_r \mid \mathbf{x}_{<r})
$$

ã“ã“ã§ $\mathbf{x}_r$ ã¯è§£åƒåº¦ $r$ ã®ãƒˆãƒ¼ã‚¯ãƒ³ãƒãƒƒãƒ—(e.g., $1 \times 1 \to 2 \times 2 \to \cdots \to 16 \times 16$)ã€‚

**å¾“æ¥(PixelCNN)**: $256 \times 256 = 65536$ ã‚¹ãƒ†ãƒƒãƒ—
**VAR**: $R \approx 10$ ã‚¹ãƒ†ãƒƒãƒ—(multi-scale) â†’ **6500å€ã®ä¸¦åˆ—åŒ–**

**æ€§èƒ½**:
- ImageNet 256Ã—256: FID **1.73** (DiT 2.27, MAR 1.78ã‚’è¶…ãˆã‚‹)
- Scaling Laws: $\text{FID} \propto N^{-0.998}$ ã®ç¶ºéº—ãªPower Law
- Zero-shot: Inpainting/Outpainting/EditingãŒè¿½åŠ è¨“ç·´ãªã—ã§å¯èƒ½

**ãªãœå‹ã£ãŸã‹**:
1. **Order Matters**: ç²—â†’ç´°ã®é †åºãŒç”»åƒã®è‡ªç„¶ãªéšå±¤æ§‹é€ ã¨ä¸€è‡´
2. **Parallelism**: åŒä¸€è§£åƒåº¦å†…ã¯ä¸¦åˆ—ç”Ÿæˆå¯èƒ½(Raster Scanã‚ˆã‚Šé¥ã‹ã«é€Ÿã„)
3. **Scalability**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° $N$ ã«å¯¾ã—ã¦ç¶ºéº—ã«ã‚¹ã‚±ãƒ¼ãƒ«(GPT-likeãªæŒ™å‹•)

### 6.3 MAR â€” Vector Quantizationãªã—ã®è‡ªå·±å›å¸°

**Masked Autoregressive (MAR)** [^6]:

**æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢**: VQä¸è¦ â€” é€£ç¶šå€¤ã‚’ **Diffusion Loss** ã§ãƒ¢ãƒ‡ãƒ«åŒ–ã€‚

$$
p_\theta(x_i \mid \mathbf{x}_{<i}) = \int p_\theta(x_i \mid z_i) q(z_i \mid x_i, \mathbf{x}_{<i}) dz_i
$$

ã“ã“ã§ $q(z_i \mid x_i, \mathbf{x}_{<i})$ ã¯æ‹¡æ•£éç¨‹ã€‚

**åŠ¹æœ**:
- VQã®é›¢æ•£åŒ–èª¤å·®ã‚’å›é¿
- Codebook Collapseãªã—
- FID 1.78 (VARä¸¦)

**Random Order AR**: Masked tokenä½ç½®ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã³ã€ä¸¦åˆ—äºˆæ¸¬ã€‚

### 6.4 FlowAR â€” VARã¨Flow Matchingã®èåˆ

**FlowAR** [^7]:

**æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢**: VAR(multi-scale) + Flow Matching(é€£ç¶šæ™‚é–“æ‹¡æ•£)ã€‚

$$
p(\mathbf{x}_r \mid \mathbf{x}_{<r}) = \text{ODE solve from noise to data}
$$

**æ€§èƒ½**: FID **1.65** (VAR-Hã®1.73ã‚’è¶…ãˆã‚‹)

**æ„ç¾©**: ARã¨æ‹¡æ•£ã®å¢ƒç•ŒãŒæ›–æ˜§ã« â€” æ¬¡ä¸–ä»£ã¯ã€ŒHybridã€ã¸ã€‚

### 6.5 Infinity â€” Bitwise ARã®æ¥µè‡´

**Infinity** [^9] (CVPR 2025 Oral):

**æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢**: ãƒˆãƒ¼ã‚¯ãƒ³å˜ä½ã§ã¯ãªã **ãƒ“ãƒƒãƒˆå˜ä½** ã§äºˆæ¸¬ã€‚

$$
p(\mathbf{x}) = \prod_{b=1}^{B} p(\text{bit}_b \mid \text{bit}_{<b})
$$

**èªå½™ã‚µã‚¤ã‚º**: $2^B \to \infty$ (ç†è«–ä¸Šç„¡é™)

**æ€§èƒ½**:
- GenEval: 0.73 (SD3-Medium 0.62ã‚’è¶…ãˆã‚‹)
- é€Ÿåº¦: **0.8ç§’/ç”»åƒ(1024Ã—1024)** â€” SD3ã®2.6å€é€Ÿ
- Text-to-Image: SD3/SDXLã‚’è¶…ãˆã‚‹å“è³ª

**é©å‘½**: ARãŒæ‹¡æ•£ã‚’å“è³ªãƒ»é€Ÿåº¦ã®ä¸¡é¢ã§å®Œå…¨ã«è¶…ãˆãŸã€‚ã€ŒARã¯é…ã„ã€ã¨ã„ã†å¸¸è­˜ãŒå´©å£Šã€‚

### 6.6 MaskGIT â€” Non-ARã®äºˆå‘Š

**MaskGIT** [^8]:

**æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢**: ARã‚’ã€ŒMasked tokenäºˆæ¸¬ã€ã«æ‹¡å¼µ â†’ ä¸¦åˆ—ç”Ÿæˆã€‚

è¨“ç·´:
$$
\mathcal{L} = -\mathbb{E}_{\mathbf{x}, \mathbf{m}} \left[ \sum_{i \in \mathbf{m}} \log p_\theta(x_i \mid \mathbf{x}_{\neg \mathbf{m}}) \right]
$$

ã“ã“ã§ $\mathbf{m}$ ã¯ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¹ã‚¯ã€$\mathbf{x}_{\neg \mathbf{m}}$ ã¯éãƒã‚¹ã‚¯é ˜åŸŸã€‚

æ¨è«–: Iterative decoding â€” å„ã‚¹ãƒ†ãƒƒãƒ—ã§å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã‚’äºˆæ¸¬ã—ã€confidenceã®é«˜ã„ã‚‚ã®ã®ã¿æ¡ç”¨ã€‚

**æ€§èƒ½**: ImageNet 256Ã—256ã§8å›ã®åå¾©(ARã®256å€é€Ÿ)ã€å“è³ªã¯ARä¸¦ã€‚

**æ„ç¾©**: ã€ŒARã¯é€æ¬¡çš„ã€ã¨ã„ã†åˆ¶ç´„ã‚’ç·©å’Œ â€” ç¬¬14å›Attentionã§è©³è¿°ã€‚

### 6.7 AR Vision Survey (TMLR 2025)

**Autoregressive Models in Vision: A Survey** [^4]:

2025å¹´ã®ã‚µãƒ¼ãƒ™ã‚¤ [^4] ãŒä»¥ä¸‹ã‚’åˆ†é¡:

| Level | ä»£è¡¨ãƒ¢ãƒ‡ãƒ« | ç‰¹å¾´ |
|:------|:-----------|:-----|
| Pixel-level | PixelCNNç³» | é…ã„ãŒç†è«–çš„ã«å³å¯† |
| Token-level | VQGAN/DALL-E | VQé›¢æ•£åŒ–ã€ä¸­é€Ÿ |
| Scale-level | VAR/FlowAR | ç²—â†’ç´°ã€é«˜é€Ÿ+é«˜å“è³ª |
| Bit-level | Infinity | èªå½™âˆã€æœ€é€Ÿ |

**å‹•å‘**: Tokenâ†’Scaleâ†’Bitã¸ã®é€²åŒ– = ä¸¦åˆ—åŒ–ã®æ¥µé™è¿½æ±‚ã€‚

### 22.8 æ¬¡å›äºˆå‘Š â€” ç¬¬14å›: Attention

**ç¬¬14å›ã®ãƒ†ãƒ¼ãƒ**: RNN/CNNã®é™ç•Œ â†’ Attentionã®å¿…ç„¶æ€§ â†’ Transformer â†’ GPT/BERT

**æ¥ç¶š**:
- ç¬¬13å›(ä»Šå›): ARã¯ã€Œæ¡ä»¶ä»˜ãåˆ†è§£ã§å°¤åº¦ã‚’è¨ˆç®—ã€
- ç¬¬14å›: Attention = ARã®å—å®¹é‡ã‚’ $O(N^2)$ ã§å…¨ç³»åˆ—ã«æ‹¡å¤§

**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**:
- Self-Attention / Multi-Head Attention
- Positional Encoding (RoPE/ALiBi)
- Causal Attention = AR Transformer
- Scaling Laws / Emergent Abilities
- In-Context Learning / KV-Cache

**äºˆç¿’**: ç¬¬1-3å›ã®AttentionåŸºç¤(QKV/Softmax)ã‚’å¾©ç¿’ã—ã¦ãŠãã¨ç†è§£ãŒåŠ é€Ÿã™ã‚‹ã€‚

**ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³**:
PixelCNNã®å—å®¹é‡ã¯æœ‰é™(CNNåˆ¶ç´„)ã€WaveNetã‚‚ $2^L$ ã¾ã§ã€‚å…¨ç³»åˆ—ã‚’ä¸€åº¦ã«å‚ç…§ã™ã‚‹ã«ã¯ **Self-Attention** ãŒå¿…è¦ã ã£ãŸã€‚ã“ã‚ŒãŒ2017å¹´ "Attention is All You Need" (Vaswani+)ã®é©å‘½ã ã£ãŸã€‚

ç¬¬14å›ã§Attentionã®æ•°å­¦ã¨Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å®Œå…¨åˆ¶è¦‡ã—ã€ç¬¬15å›ã§Flash Attention/MoE/Sparse Attentionãªã©åŠ¹ç‡åŒ–æ‰‹æ³•ã€ç¬¬16å›ã§Mamba(SSM)ã¨ã„ã†ã€ŒAttentionã®ä»£æ›¿ã€ã‚’å­¦ã¶ã€‚

Course IIã®ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹ã¸ â€” ã€ŒåŒ–çŸ³(RNN/CNN)ã‹ã‚‰ã®è„±å´ã€ã®ç‰©èªãŒå®Œçµã™ã‚‹ã€‚

> **Note:** **é€²æ—: 100% å®Œäº†** ğŸ‰
>
> æœ¬è¬›ç¾©ã€Œç¬¬13å›: è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«ã€ã‚’å®Œå…¨åˆ¶è¦‡ã—ãŸã€‚é€£é–å¾‹ã®å³å¯†ãªè¨¼æ˜ã‹ã‚‰ã€PixelCNN/WaveNetã®å®Ÿè£…ã€2024-2025æœ€æ–°ç ”ç©¶(VAR/MAR/FlowAR/Infinity)ã¾ã§ã€ARã®å…¨ã¦ã‚’ç¶²ç¾…ã—ãŸã€‚
>
> **é”æˆäº‹é …**:
> - é€£é–å¾‹ $p(\mathbf{x}) = \prod p(x_i \mid \mathbf{x}_{<i})$ ã®è¨¼æ˜
> - PixelCNN Gatedæ§‹é€  + Blind Spotè§£æ±º
> - WaveNet Dilated Conv + å—å®¹é‡ $2^L$ å°å‡º
> - Julia/Rustå®Ÿè£…(è¨“ç·´+æ¨è«–)
> - VAR(NeurIPS Best)ã‹ã‚‰Infinity(CVPR Oral)ã¾ã§æœ€æ–°ç ”ç©¶ä¿¯ç°
>
> **æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**: ç¬¬14å› Attention ã§ã€ŒARã®å—å®¹é‡ã‚’å…¨ç³»åˆ—ã«æ‹¡å¤§ã€ã™ã‚‹é©å‘½ã‚’å­¦ã¶ã€‚

---

> Progress: 95%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. VARï¼ˆVisual AutoRegressive modelingï¼‰ãŒå¾“æ¥ã®ãƒ©ã‚¹ã‚¿ã‚¹ã‚­ãƒ£ãƒ³é † AR ã¨ç•°ãªã‚‹ç‚¹ã¯ä½•ã‹ï¼Ÿã€Œã‚¹ã‚±ãƒ¼ãƒ«ã”ã¨ã® next-token predictionã€ã®æ„å‘³ã‚’ã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒãƒƒãƒ—ã®è§£åƒåº¦ã¨çµã³ã¤ã‘ã¦èª¬æ˜ã›ã‚ˆã€‚
> 2. AR ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã‚’é«˜é€ŸåŒ–ã™ã‚‹ Parallel WaveNetï¼ˆç¢ºç‡çš„ç”Ÿæˆè’¸ç•™ï¼‰ã«ãŠã„ã¦ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã®å½¹å‰²ã¯ã©ã®ã‚ˆã†ã«ç•°ãªã‚‹ã‹ï¼Ÿè¨“ç·´æ™‚ã¨æ¨è«–æ™‚ã®é•ã„ã‚’ç­”ãˆã‚ˆã€‚

---

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: van den Oord, A., Kalchbrenner, N., Vinyals, O., Espeholt, L., Graves, A., & Kavukcuoglu, K. (2016). Conditional Image Generation with PixelCNN Decoders. *NeurIPS 2016*.
<https://arxiv.org/abs/1606.05328>

[^2]: van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Senior, A., & Kavukcuoglu, K. (2016). WaveNet: A Generative Model for Raw Audio. *arXiv:1609.03499*.
<https://arxiv.org/abs/1609.03499>

[^3]: Tian, K., Jiang, Y., Yuan, Z., Peng, B., & Wang, L. (2024). Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction. *NeurIPS 2024 (Best Paper Award)*.
<https://arxiv.org/abs/2404.02905>

[^4]: Xiong, J., et al. (2025). Autoregressive Models in Vision: A Survey. *TMLR 2025*.
<https://arxiv.org/abs/2411.05902>

[^5]: Salimans, T., Karpathy, A., Chen, X., & Kingma, D. P. (2017). PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications. *ICLR 2017*.
<https://arxiv.org/abs/1701.05517>

[^6]: Li, T., et al. (2024). Autoregressive Image Generation without Vector Quantization. *NeurIPS 2024*.
<https://arxiv.org/abs/2406.11838>

[^7]: Ren, S., et al. (2024). FlowAR: Scale-wise Autoregressive Image Generation Meets Flow Matching. *arXiv:2412.15205*.
<https://arxiv.org/abs/2412.15205>

[^8]: Chang, H., Zhang, H., Jiang, L., Liu, C., & Freeman, W. T. (2022). MaskGIT: Masked Generative Image Transformer. *CVPR 2022*.
<https://arxiv.org/abs/2202.04200>

[^9]: Han, J., Liu, J., Jiang, Y., et al. (2025). Infinity: Scaling Bitwise AutoRegressive Modeling for High-Resolution Image Synthesis. *CVPR 2025 (Oral)*.
<https://arxiv.org/abs/2412.04431>

### æ•™ç§‘æ›¸

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press. [Ch.10: Sequence Modeling, Ch.20: Deep Generative Models]
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press. [Ch.26: Autoregressive Sequence Models]

---

## è‘—è€…ãƒªãƒ³ã‚¯

- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

---
