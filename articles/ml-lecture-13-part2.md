---
title: "ç¬¬13å›: è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
emoji: "ğŸ”„"
type: "tech"
topics: ["machinelearning", "deeplearning", "autoregressive", "julia", "rust"]
published: true
---

## ğŸ’» 4. å®Ÿè£…ã‚¾ãƒ¼ãƒ³(45åˆ†)â€” PixelCNN/WaveNetã‚’Julia+Rustã§æ§‹ç¯‰

### 4.1 ç’°å¢ƒæ§‹ç¯‰

#### 4.1.1 Juliaç’°å¢ƒ

```bash
# Julia 1.11+ (2025å¹´æœ€æ–°ç‰ˆ)
# https://julialang.org/downloads/

julia
```

```julia
# Package setup
using Pkg
Pkg.add(["Lux", "Reactant", "Optimisers", "MLUtils", "Images", "Plots"])

# Verify
using Lux, Reactant
println("Julia $(VERSION), Lux $(Pkg.TOML.parsefile(joinpath(pkgdir(Lux), "Project.toml"))["version"])")
```

#### 4.1.2 Rustç’°å¢ƒ

```bash
# Rust 1.85+ (2025å¹´æœ€æ–°)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# ONNX Runtime for inference
cargo new --lib pixelcnn_inference
cd pixelcnn_inference
```

`Cargo.toml`:
```toml
[dependencies]
ort = "2.0"  # ONNX Runtime bindings
ndarray = "0.16"
rayon = "1.10"  # Parallel iterator
```

### 4.2 PixelCNNå®Ÿè£… (Julia)

#### 4.2.1 Masked Convolution Layer

```julia
using Lux, Random, NNlib

# Masked Convolution: future pixels are masked
struct MaskedConv2D{M} <: Lux.AbstractLuxLayer
    conv::Conv
    mask_type::Symbol  # :A (strict) or :B (include center)
end

function MaskedConv2D(in_ch, out_ch, kernel; mask_type=:B)
    @assert kernel[1] % 2 == 1 && kernel[2] % 2 == 1 "Kernel must be odd"
    conv = Conv(kernel, in_ch => out_ch, pad=SamePad())
    MaskedConv2D{mask_type}(conv, mask_type)
end

function Lux.initialparameters(rng::AbstractRNG, layer::MaskedConv2D)
    ps = Lux.initialparameters(rng, layer.conv)
    # Apply mask to weight
    ps.weight .*= create_mask(size(ps.weight), layer.mask_type)
    return ps
end

function create_mask(weight_shape, mask_type)
    # weight_shape: (kH, kW, in_ch, out_ch)
    kH, kW, _, _ = weight_shape
    mask = ones(Float32, kH, kW, 1, 1)
    cH, cW = (kH + 1) Ã· 2, (kW + 1) Ã· 2

    # Mask bottom half
    mask[cH+1:end, :, 1, 1] .= 0
    # Mask right half of center row
    mask[cH, cW+(mask_type == :A ? 0 : 1):end, 1, 1] .= 0

    return mask
end

function (layer::MaskedConv2D)(x, ps, st)
    # Re-apply mask (in case weights updated during training)
    ps_masked = merge(ps, (weight = ps.weight .* create_mask(size(ps.weight), layer.mask_type),))
    return layer.conv(x, ps_masked, st)
end
```

#### 4.2.2 Gated Activation Block

```julia
# Gated activation: tanh(Wf * x) âŠ™ Ïƒ(Wg * x)
struct GatedActivation <: Lux.AbstractLuxLayer end

function (::GatedActivation)(x, ps, st)
    # x: (H, W, 2C, batch) â€” first C channels = filter, next C = gate
    C = size(x, 3) Ã· 2
    f = tanh.(x[:, :, 1:C, :])
    g = sigmoid.(x[:, :, C+1:end, :])
    return f .* g, st
end

# Gated PixelCNN Block (Vertical + Horizontal stack)
struct GatedPixelCNNBlock <: Lux.AbstractLuxContainerLayer{(:v_conv, :h_conv, :v_to_h, :h_res, :gated)}
    v_conv::MaskedConv2D
    h_conv::MaskedConv2D
    v_to_h::Conv  # 1x1 conv: vertical â†’ horizontal
    h_res::Conv   # 1x1 conv: residual connection
    gated::GatedActivation
end

function GatedPixelCNNBlock(channels::Int, kernel=(3, 3))
    v_conv = MaskedConv2D(channels, 2channels, kernel; mask_type=:A)  # Vertical: strict mask
    h_conv = MaskedConv2D(channels, 2channels, kernel; mask_type=:B)  # Horizontal: include center
    v_to_h = Conv((1, 1), channels => 2channels)
    h_res = Conv((1, 1), channels => channels)
    gated = GatedActivation()
    return GatedPixelCNNBlock(v_conv, h_conv, v_to_h, h_res, gated)
end

function (block::GatedPixelCNNBlock)(v_in, h_in, ps, st)
    # Vertical stack
    v_out, st_v = block.v_conv(v_in, ps.v_conv, st)
    v_gated, _ = block.gated(v_out, ps, st)

    # Horizontal stack
    h_out, st_h = block.h_conv(h_in, ps.h_conv, st)
    v_to_h_out, st_vth = block.v_to_h(v_gated, ps.v_to_h, st)
    h_combined = h_out .+ v_to_h_out
    h_gated, _ = block.gated(h_combined, ps, st)

    # Residual connection
    h_res, st_res = block.h_res(h_gated, ps.h_res, st)
    h_final = h_res .+ h_in

    return v_gated, h_final, st
end
```

#### 4.2.3 Full PixelCNN Model

```julia
using Lux, Random

struct PixelCNN <: Lux.AbstractLuxContainerLayer{(:blocks, :output_conv)}
    blocks::Vector{GatedPixelCNNBlock}
    output_conv::Conv
end

function PixelCNN(num_blocks::Int, channels::Int, num_classes::Int=256)
    blocks = [GatedPixelCNNBlock(channels) for _ in 1:num_blocks]
    output_conv = Conv((1, 1), channels => num_classes)
    return PixelCNN(blocks, output_conv)
end

function (model::PixelCNN)(x, ps, st)
    # x: (H, W, C_in, batch) â€” typically C_in=1 for grayscale
    batch_size = size(x, 4)
    v = repeat(x, 1, 1, channels, 1)  # Initialize vertical stack
    h = repeat(x, 1, 1, channels, 1)  # Initialize horizontal stack

    for (i, block) in enumerate(model.blocks)
        v, h, st = block(v, h, ps.blocks[i], st)
    end

    # Output: (H, W, num_classes, batch)
    logits, st = model.output_conv(h, ps.output_conv, st)
    return logits, st
end
```

### 4.3 è¨“ç·´ãƒ«ãƒ¼ãƒ— (Julia + Lux)

```julia
using Lux, Optimisers, MLUtils, Statistics

# Loss: negative log-likelihood (cross-entropy per pixel)
function pixelcnn_loss(model, ps, st, x, y)
    logits, st = model(x, ps, st)
    # y: (H, W, 1, batch) with values in [0, 255]
    # logits: (H, W, 256, batch)

    # Cross-entropy per pixel
    H, W, _, B = size(x)
    loss = 0.0f0
    for b in 1:B, i in 1:H, j in 1:W
        target = Int(y[i, j, 1, b]) + 1  # 1-indexed
        loss += -log(softmax(logits[i, j, :, b])[target] + 1f-8)
    end
    return loss / (H * W * B), st, ()
end

# Training loop
function train_pixelcnn!(model, ps, st, train_data, epochs=10, lr=1e-3)
    opt_state = Optimisers.setup(Adam(lr), ps)

    for epoch in 1:epochs
        epoch_loss = 0.0
        for (x, y) in train_data
            # x, y: (H, W, 1, batch)
            loss, st, _ = pixelcnn_loss(model, ps, st, x, y)

            # Gradients
            grads = gradient(ps -> pixelcnn_loss(model, ps, st, x, y)[1], ps)[1]

            # Update
            opt_state, ps = Optimisers.update(opt_state, ps, grads)
            epoch_loss += loss
        end
        println("Epoch $epoch: Loss = $(epoch_loss / length(train_data))")
    end
    return ps, st
end
```

### 4.4 WaveNetå®Ÿè£… (Julia)

```julia
using Lux, NNlib

# Dilated Causal Conv 1D
struct DilatedCausalConv1D <: Lux.AbstractLuxLayer
    conv::Conv
    dilation::Int
end

function DilatedCausalConv1D(in_ch, out_ch, kernel, dilation)
    # Causal padding: pad left by (kernel-1)*dilation
    pad = (kernel - 1) * dilation
    conv = Conv((kernel,), in_ch => out_ch, dilation=(dilation,), pad=(pad, 0))
    DilatedCausalConv1D(conv, dilation)
end

function (layer::DilatedCausalConv1D)(x, ps, st)
    y, st = layer.conv(x, ps, st)
    # Remove right padding (future samples)
    return y[1:size(x, 1), :, :], st
end

# WaveNet Residual Block
struct WaveNetBlock <: Lux.AbstractLuxContainerLayer{(:filter_conv, :gate_conv, :res_conv, :skip_conv)}
    filter_conv::DilatedCausalConv1D
    gate_conv::DilatedCausalConv1D
    res_conv::Conv
    skip_conv::Conv
end

function WaveNetBlock(channels::Int, dilation::Int, kernel=2)
    filter_conv = DilatedCausalConv1D(channels, channels, kernel, dilation)
    gate_conv = DilatedCausalConv1D(channels, channels, kernel, dilation)
    res_conv = Conv((1,), channels => channels)
    skip_conv = Conv((1,), channels => channels)
    return WaveNetBlock(filter_conv, gate_conv, res_conv, skip_conv)
end

function (block::WaveNetBlock)(x, ps, st)
    # Gated activation
    f, st_f = block.filter_conv(x, ps.filter_conv, st)
    g, st_g = block.gate_conv(x, ps.gate_conv, st)
    z = tanh.(f) .* sigmoid.(g)

    # Residual + Skip
    res, st_res = block.res_conv(z, ps.res_conv, st)
    skip, st_skip = block.skip_conv(z, ps.skip_conv, st)

    return x .+ res, skip, st
end
```

### 4.5 Math-to-Codeå¯¾å¿œè¡¨

| æ•°å¼ | Julia Code | å¯¾å¿œ |
|:-----|:-----------|:-----|
| $p(\mathbf{x}) = \prod p(x_i \mid \mathbf{x}_{<i})$ | `prod(p_i for p_i in conditional_probs)` | é€£é–å¾‹ |
| $\mathcal{L} = -\sum \log p(x_i \mid \mathbf{x}_{<i})$ | `loss = -sum(log.(p .+ 1e-8))` | NLL |
| $p(x_i=k) = \text{softmax}(z)_k$ | `softmax(logits[:, :, :, batch])[i, j, k]` | é›¢æ•£åˆ†å¸ƒ |
| $\mathbf{y} = \tanh(\mathbf{W}_f * \mathbf{x}) \odot \sigma(\mathbf{W}_g * \mathbf{x})$ | `tanh.(f) .* sigmoid.(g)` | Gated Act |
| Masked Conv(kernel $\mathbf{W}$, mask $\mathbf{M}$) | `ps.weight .* create_mask(...)` | Causal Mask |

**1è¡Œ1å¼ã®å¯¾å¿œ** â€” æ•°å¼ã‚’èª­ã‚“ã ã‚‰ã‚³ãƒ¼ãƒ‰ãŒæ›¸ã‘ã‚‹ã€ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ãŸã‚‰æ•°å¼ãŒåˆ†ã‹ã‚‹ã€‚ã“ã‚ŒãŒJuliaã®çœŸä¾¡ã ã€‚

### 4.6 Rustæ¨è«–å®Ÿè£… (ONNX Runtime)

```rust
// pixelcnn_inference/src/lib.rs
use ort::{Session, Value, inputs};
use ndarray::{Array4, s};
use rayon::prelude::*;

pub struct PixelCNNInference {
    session: Session,
}

impl PixelCNNInference {
    pub fn new(model_path: &str) -> ort::Result<Self> {
        let session = Session::builder()?.commit_from_file(model_path)?;
        Ok(Self { session })
    }

    pub fn sample(&self, batch_size: usize, height: usize, width: usize) -> ort::Result<Array4<f32>> {
        // Initialize with zeros
        let mut img = Array4::<f32>::zeros((batch_size, 1, height, width));

        // Autoregressive sampling: raster scan order
        for i in 0..height {
            for j in 0..width {
                // Forward pass
                let input = Value::from_array(self.session.allocator(), &img)?;
                let outputs = self.session.run(inputs!["input" => input])?;
                let logits = outputs["output"].try_extract::<f32>()?.view().to_owned();

                // Sample from categorical distribution at position (i, j)
                for b in 0..batch_size {
                    let probs = softmax(&logits.slice(s![b, .., i, j]));
                    img[[b, 0, i, j]] = sample_categorical(&probs);
                }
            }
        }
        Ok(img)
    }
}

fn softmax(logits: &ndarray::ArrayView1<f32>) -> Vec<f32> {
    let max = logits.iter().cloned().fold(f32::NEG_INFINITY, f32::max);
    let exp: Vec<f32> = logits.iter().map(|&x| (x - max).exp()).collect();
    let sum: f32 = exp.iter().sum();
    exp.iter().map(|&x| x / sum).collect()
}

fn sample_categorical(probs: &[f32]) -> f32 {
    let u: f32 = rand::random();
    let mut cumsum = 0.0;
    for (i, &p) in probs.iter().enumerate() {
        cumsum += p;
        if u < cumsum {
            return i as f32;
        }
    }
    (probs.len() - 1) as f32
}
```

### 4.7 AR Decodingæˆ¦ç•¥ â€” ç”Ÿæˆã®å¤šæ§˜æ€§ã¨å“è³ªã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•

è¨“ç·´æ™‚ã¯Teacher Forcing(æ­£è§£ã‚’å…¥åŠ›)ã ãŒã€æ¨è«–æ™‚ã¯ **ç”Ÿæˆã—ãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¬¡ã®å…¥åŠ›** ã«ã™ã‚‹ã€‚ã“ã®æˆ¦ç•¥ãŒç”Ÿæˆå“è³ªã‚’å¤§ããå·¦å³ã™ã‚‹ã€‚

#### 4.7.1 Greedy Decoding

æœ€ã‚‚ç¢ºç‡ã®é«˜ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å¸¸ã«é¸æŠ:

$$
x_t = \arg\max_{k} p_\theta(x_t = k \mid \mathbf{x}_{<t})
$$

```julia
function greedy_decode(model, ps, st, max_len=100)
    x = [START_TOKEN]
    for t in 1:max_len
        logits, st = model(x, ps, st)
        probs = softmax(logits[end, :])  # last position
        next_token = argmax(probs)
        push!(x, next_token)
        if next_token == END_TOKEN
            break
        end
    end
    return x
end
```

**é•·æ‰€**: æ±ºå®šè«–çš„ã€å†ç¾æ€§ã‚ã‚Š
**çŸ­æ‰€**: å¤šæ§˜æ€§ã‚¼ãƒ­ã€å±€æ‰€æœ€é©ã«é™¥ã‚Šã‚„ã™ã„

#### 4.7.2 Sampling with Temperature

ç¢ºç‡åˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°:

$$
p'(x_t = k) = \frac{\exp(z_k / \tau)}{\sum_{k'} \exp(z_{k'} / \tau)}
$$

ã“ã“ã§ $\tau$ ã¯temperature:
- $\tau \to 0$: Greedy(æœ€å¤§ç¢ºç‡ã«é›†ä¸­)
- $\tau = 1$: å…ƒã®åˆ†å¸ƒ
- $\tau \to \infty$: ä¸€æ§˜åˆ†å¸ƒ(å®Œå…¨ãƒ©ãƒ³ãƒ€ãƒ )

```julia
function sample_with_temperature(logits::Vector, tau::Float64=1.0)
    scaled = logits ./ tau
    probs = softmax(scaled)
    return sample_categorical(probs)
end

# Example
logits = [2.0, 1.0, 0.5, 0.2]
println("tau=0.5: ", [sample_with_temperature(logits, 0.5) for _ in 1:10])
println("tau=1.0: ", [sample_with_temperature(logits, 1.0) for _ in 1:10])
println("tau=2.0: ", [sample_with_temperature(logits, 2.0) for _ in 1:10])
```

å‡ºåŠ›:
```
tau=0.5: [1, 1, 1, 1, 1, 1, 2, 1, 1, 1]  # Mostly mode
tau=1.0: [1, 2, 1, 1, 2, 3, 1, 1, 2, 1]  # Balanced
tau=2.0: [3, 2, 1, 4, 2, 3, 1, 2, 3, 2]  # Diverse
```

#### 4.7.3 Top-k Sampling

ç¢ºç‡ä¸Šä½ $k$ å€‹ã®ã¿ã‹ã‚‰é¸æŠ:

```julia
function topk_sampling(logits::Vector, k::Int)
    probs = softmax(logits)
    top_indices = partialsortperm(probs, 1:k, rev=true)
    top_probs = probs[top_indices]
    top_probs ./= sum(top_probs)  # Renormalize
    selected = sample_categorical(top_probs)
    return top_indices[selected]
end
```

**åŠ¹æœ**: ä½ç¢ºç‡ã®ãƒã‚¤ã‚ºã‚’é™¤å»ã€å“è³ªå‘ä¸Šã€‚

#### 4.7.4 Top-p (Nucleus) Sampling

ç´¯ç©ç¢ºç‡ãŒ $p$ ã‚’è¶…ãˆã‚‹ã¾ã§ã®ä¸Šä½ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰é¸æŠ:

```julia
function nucleus_sampling(logits::Vector, p::Float64=0.9)
    probs = softmax(logits)
    sorted_indices = sortperm(probs, rev=true)
    sorted_probs = probs[sorted_indices]

    cumsum_probs = cumsum(sorted_probs)
    cutoff = findfirst(cumsum_probs .>= p)
    nucleus_indices = sorted_indices[1:cutoff]
    nucleus_probs = sorted_probs[1:cutoff]
    nucleus_probs ./= sum(nucleus_probs)

    selected = sample_categorical(nucleus_probs)
    return nucleus_indices[selected]
end
```

**GPT-3ã®æ¨™æº–è¨­å®š**: $p=0.9$, temperature=0.7 â€” å¤šæ§˜æ€§ã¨å“è³ªã®ãƒãƒ©ãƒ³ã‚¹ã€‚

#### 4.7.5 Beam Search

$B$ å€‹ã®å€™è£œç³»åˆ—ã‚’ä¿æŒã—ã€ç´¯ç©ç¢ºç‡æœ€å¤§ã®ç³»åˆ—ã‚’é¸æŠ:

```julia
struct BeamCandidate
    sequence::Vector{Int}
    log_prob::Float64
end

function beam_search(model, ps, st, beam_size::Int, max_len::Int)
    beams = [BeamCandidate([START_TOKEN], 0.0)]

    for t in 1:max_len
        candidates = BeamCandidate[]
        for beam in beams
            if beam.sequence[end] == END_TOKEN
                push!(candidates, beam)
                continue
            end
            logits, _ = model(beam.sequence, ps, st)
            probs = softmax(logits[end, :])
            top_k = partialsortperm(probs, 1:beam_size, rev=true)

            for k in top_k
                new_seq = vcat(beam.sequence, k)
                new_log_prob = beam.log_prob + log(probs[k])
                push!(candidates, BeamCandidate(new_seq, new_log_prob))
            end
        end
        # Keep top beam_size candidates
        sort!(candidates, by=x -> x.log_prob, rev=true)
        beams = candidates[1:min(beam_size, length(candidates))]
    end

    return beams[1].sequence  # Best sequence
end
```

**æ©Ÿæ¢°ç¿»è¨³ã§æ¨™æº–**: Beam size 4-8ãŒä¸€èˆ¬çš„ã€‚

**ç”»åƒARã§ã¯ä¸å‘ã**: ç³»åˆ—ãŒé•·ã™ãã‚‹(65536ã‚¹ãƒ†ãƒƒãƒ—) â€” ãƒ¡ãƒ¢ãƒªçˆ†ç™ºã€‚

#### 4.7.6 ãƒ‡ã‚³ãƒ¼ãƒ‰æˆ¦ç•¥ã®æ¯”è¼ƒè¡¨

| æˆ¦ç•¥ | å¤šæ§˜æ€§ | å“è³ª | é€Ÿåº¦ | ç”¨é€” |
|:-----|:-------|:-----|:-----|:-----|
| Greedy | âŒ | ä¸­ | â˜…â˜…â˜… | ãƒ‡ãƒãƒƒã‚° |
| Sampling(tau=1) | â˜…â˜…â˜… | ä½ | â˜…â˜…â˜… | å‰µé€ çš„ç”Ÿæˆ |
| Top-k | â˜…â˜… | ä¸­ | â˜…â˜…â˜… | ãƒãƒ©ãƒ³ã‚¹ |
| Top-p | â˜…â˜… | é«˜ | â˜…â˜…â˜… | GPTæ¨™æº– |
| Beam Search | â˜… | â˜…â˜…â˜… | â˜… | ç¿»è¨³/è¦ç´„ |

**ç”»åƒç”Ÿæˆ**: Greedy or Temperature=0.9ãŒä¸»æµ(Beam Searchã¯é…ã™ãã‚‹)ã€‚

### 4.8 ç´¯ç©èª¤å·®å•é¡Œ â€” ARã®æ ¹æœ¬çš„é™ç•Œ

ARã¯é€æ¬¡ç”Ÿæˆã®ãŸã‚ã€**èª¤å·®ãŒç´¯ç©** ã™ã‚‹:

$$
\text{Error at step } T \propto \sum_{t=1}^{T} \epsilon_t
$$

åˆæœŸã®èª¤å·®ãŒå¾Œã®ç”Ÿæˆã«å½±éŸ¿ â†’ é•·ç³»åˆ—ã»ã©å“è³ªåŠ£åŒ–ã€‚

**è»½æ¸›ç­–**:
1. **Scheduled Sampling**: è¨“ç·´æ™‚ã«ãŸã¾ã«ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥åŠ›(Teacher Forcingã¨ã®ãƒãƒ©ãƒ³ã‚¹)
2. **Multi-scale AR(VAR)**: ã‚¹ãƒ†ãƒƒãƒ—æ•°å‰Šæ¸›(65536 â†’ 10) â†’ ç´¯ç©èª¤å·®æ¿€æ¸›
3. **Non-AR(MaskGIT)**: ä¸¦åˆ—ç”Ÿæˆã§èª¤å·®ç´¯ç©ãªã—

### 4.9 Paperèª­è§£ãƒ‘ã‚¿ãƒ¼ãƒ³ â€” ARè«–æ–‡ã®3-pass reading

PixelCNN [^1] / WaveNet [^2] / VAR [^3] ãªã©ARè«–æ–‡ã®èª­ã¿æ–¹:

**Pass 1 (5åˆ†)**: é€£é–å¾‹ã®ã©ã“ã«è²¢çŒ®ã—ãŸã‹ç‰¹å®š
- [ ] é †åºã¯ï¼Ÿ(Raster/Random/Multi-scale)
- [ ] æ¡ä»¶ä»˜ãåˆ†å¸ƒã®ãƒ¢ãƒ‡ãƒ«ã¯ï¼Ÿ(Softmax/Mixture/Diffusion)
- [ ] å—å®¹é‡ã®æ‹¡å¤§æ–¹æ³•ã¯ï¼Ÿ(Dilated/Attention/Hierarchy)

**Pass 2 (30åˆ†)**: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ•°å­¦çš„æ­£å½“æ€§
- [ ] Causal Maskingã®å®Ÿè£…(å›³3-4ã‚’ç²¾èª­)
- [ ] Gating/Residual/Skipã®ç†è«–çš„æ ¹æ‹ 
- [ ] NLLè¨ˆç®—å¼(Eq.5å‰å¾Œ)ã®å°å‡ºã‚’è¿½ã†

**Pass 3 (2æ™‚é–“)**: å®Ÿè£…å†ç¾
- [ ] Pseudo-codeã‚’Juliaã§æ›¸ãä¸‹ã™
- [ ] Ablation studyã®å†ç¾(Table 2)
- [ ] è‡ªåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã§å‹•ã‹ã™

### 4.10 LaTeX Cheat Sheet for AR

| æ¦‚å¿µ | LaTeX | å‡ºåŠ› |
|:-----|:------|:-----|
| é€£é–å¾‹ | `p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid \mathbf{x}_{<i})` | $p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid \mathbf{x}_{<i})$ |
| NLL | `\mathcal{L} = -\sum \log p(x_i \mid \mathbf{x}_{<i})` | $\mathcal{L} = -\sum \log p(x_i \mid \mathbf{x}_{<i})$ |
| Softmax | `p(k) = \frac{e^{z_k}}{\sum_j e^{z_j}}` | $p(k) = \frac{e^{z_k}}{\sum_j e^{z_j}}$ |
| Gating | `y = \tanh(W_f * x) \odot \sigma(W_g * x)` | $y = \tanh(W_f * x) \odot \sigma(W_g * x)$ |
| Dilated Conv | `y[t] = \sum_k w_k x[t - d \cdot k]` | $y[t] = \sum_k w_k x[t - d \cdot k]$ |
| Temperature | `p'(k) = \frac{e^{z_k/\tau}}{\sum_j e^{z_j/\tau}}` | $p'(k) = \frac{e^{z_k/\tau}}{\sum_j e^{z_j/\tau}}$ |

### 4.11 Julia vs Rust vs Python â€” ARå®Ÿè£…æ¯”è¼ƒ

#### PixelCNN Forward Pass (ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰)

**Python (PyTorch)**:
```python
def forward(self, x):
    v = self.v_init(x)
    h = self.h_init(x)
    for block in self.blocks:
        v, h = block(v, h)
    logits = self.out_conv(h)
    return logits
```

**Julia (Lux)**:
```julia
function (model::PixelCNN)(x, ps, st)
    v = model.v_init(x, ps.v_init, st)
    h = model.h_init(x, ps.h_init, st)
    for (i, block) in enumerate(model.blocks)
        v, h, st = block(v, h, ps.blocks[i], st)
    end
    logits, st = model.out_conv(h, ps.out_conv, st)
    return logits, st
end
```

**Rust (ONNX Runtime)**:
```rust
fn forward(&self, x: &Array4<f32>) -> Array4<f32> {
    let input = Value::from_array(self.session.allocator(), x)?;
    let outputs = self.session.run(inputs!["input" => input])?;
    outputs["logits"].try_extract()?.view().to_owned()
}
```

**æ¯”è¼ƒ**:
| è¨€èª | è¨“ç·´ | æ¨è«– | å‹å®‰å…¨æ€§ | é€Ÿåº¦ |
|:-----|:-----|:-----|:---------|:-----|
| Python | â­• | â­• | âŒ | ä¸­ |
| Julia | â­• | â­• | â­• | é«˜ |
| Rust | âŒ | â­•â­• | â­•â­• | æœ€é«˜ |

**å½¹å‰²åˆ†æ‹…**:
- Julia: è¨“ç·´ãƒ«ãƒ¼ãƒ—(æŸ”è»Ÿæ€§+é€Ÿåº¦)
- Rust: æœ¬ç•ªæ¨è«–(ä¸¦åˆ—åŒ–+ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼)
- Python: ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—(ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ )

### 4.12 Rustæ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è©³ç´°

#### 4.12.1 ä¸¦åˆ—ãƒãƒƒãƒæ¨è«–

```rust
use rayon::prelude::*;

impl PixelCNNInference {
    pub fn sample_batch_parallel(&self, batch_size: usize, height: usize, width: usize)
        -> ort::Result<Vec<Array4<f32>>> {
        // Parallel generation of multiple images
        (0..batch_size)
            .into_par_iter()
            .map(|_| self.sample(1, height, width))
            .collect()
    }
}
```

**Rayonä¸¦åˆ—åŒ–**: CPUå…¨ã‚³ã‚¢æ´»ç”¨ â†’ ãƒãƒƒãƒç”ŸæˆãŒç·šå½¢ã‚¹ã‚±ãƒ¼ãƒ«ã€‚

#### 4.12.2 SIMDæœ€é©åŒ–

```rust
use std::simd::{f32x8, SimdFloat};

fn softmax_simd(logits: &[f32]) -> Vec<f32> {
    let max = logits.iter().cloned().fold(f32::NEG_INFINITY, f32::max);
    let mut exp_sum = 0.0f32;
    let mut exp_vals = vec![0.0f32; logits.len()];

    // SIMD vectorized exp
    for (chunk, out_chunk) in logits.chunks(8).zip(exp_vals.chunks_mut(8)) {
        let vals = f32x8::from_slice(chunk);
        let exp_vals = (vals - f32x8::splat(max)).exp();
        exp_sum += exp_vals.reduce_sum();
        exp_vals.copy_to_slice(out_chunk);
    }

    // Normalize
    exp_vals.iter().map(|&x| x / exp_sum).collect()
}
```

**SIMDåŠ¹æœ**: Softmaxè¨ˆç®—ãŒ8å€ä¸¦åˆ—åŒ– â†’ æ¨è«–å…¨ä½“ã§15-20%é«˜é€ŸåŒ–ã€‚

#### 4.12.3 ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«

```rust
use ort::SessionOutputs;

struct InferencePool {
    session: Session,
    buffer_pool: Vec<Array4<f32>>,
}

impl InferencePool {
    pub fn sample_with_pool(&mut self, height: usize, width: usize) -> &Array4<f32> {
        // Reuse pre-allocated buffer
        let buffer = &mut self.buffer_pool[0];
        buffer.fill(0.0);

        // ... (sampling logic, write to buffer in-place)

        &self.buffer_pool[0]
    }
}
```

**ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼åŠ¹æœ**: ã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³å‰Šæ¸› â†’ ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·10-15%å‰Šæ¸›ã€‚

### 4.13 Juliaè¨“ç·´æœ€é©åŒ–

#### 4.13.1 Mixed Precisionè¨“ç·´

```julia
using Lux, Reactant

# Enable AMP (Automatic Mixed Precision)
function train_pixelcnn_amp!(model, ps, st, train_data, epochs=10)
    opt_state = Optimisers.setup(Adam(1e-3), ps)

    for epoch in 1:epochs
        for (x, y) in train_data
            # Forward in FP16
            loss, st, grads = Reactant.mixed_precision_step(
                ps -> pixelcnn_loss(model, ps, st, x, y),
                ps
            )

            # Update in FP32
            opt_state, ps = Optimisers.update(opt_state, ps, grads)
        end
    end
    return ps, st
end
```

**åŠ¹æœ**: GPUè¨“ç·´ãŒ1.5-2xé«˜é€ŸåŒ–(ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå‰Šæ¸›)ã€‚

#### 4.13.2 Gradient Accumulation

```julia
function train_with_grad_accumulation!(model, ps, st, train_data, accum_steps=4)
    opt_state = Optimisers.setup(Adam(1e-3), ps)
    accumulated_grads = zero(ps)

    for (i, (x, y)) in enumerate(train_data)
        loss, st, grads = pixelcnn_loss(model, ps, st, x, y)

        # Accumulate gradients
        accumulated_grads = accumulated_grads .+ grads

        if i % accum_steps == 0
            # Update with accumulated gradients
            opt_state, ps = Optimisers.update(opt_state, ps, accumulated_grads ./ accum_steps)
            accumulated_grads = zero(ps)
        end
    end
end
```

**åŠ¹æœ**: å®Ÿè³ªçš„ãªãƒãƒƒãƒã‚µã‚¤ã‚º4å€ â†’ å¤§ãƒãƒƒãƒã¨åŒç­‰ã®å®‰å®šæ€§(ãƒ¡ãƒ¢ãƒªå¢—åŠ ãªã—)ã€‚

#### 4.13.3 åˆ†æ•£è¨“ç·´

```julia
using Distributed

# Multi-GPU training (conceptual)
@everywhere using Lux, CUDA

function distributed_train!(model, ps, st, train_data, num_gpus=4)
    # Split data across GPUs
    data_per_gpu = partition(train_data, num_gpus)

    # Parallel training
    results = pmap(1:num_gpus) do gpu_id
        CUDA.device!(gpu_id - 1)
        local_ps = ps |> gpu
        local_st = st

        # Train on local data
        for (x, y) in data_per_gpu[gpu_id]
            # ... (training step)
        end

        return local_ps |> cpu
    end

    # Average gradients
    ps_avg = mean(results)
    return ps_avg, st
end
```

**åŠ¹æœ**: 4 GPU ã§è¨“ç·´æ™‚é–“ãŒ1/3.5ã«(é€šä¿¡ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰è€ƒæ…®)ã€‚

### 4.14 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ â€” Julia vs Rust vs Python

#### MNIST PixelCNN (300K params)

| ç’°å¢ƒ | è¨“ç·´(5 epochs) | æ¨è«–(1ç”»åƒ) | ãƒ¡ãƒ¢ãƒª |
|:-----|:---------------|:------------|:-------|
| PyTorch (CPU) | 8åˆ†32ç§’ | 1.2ç§’ | 450MB |
| Julia/Lux (CPU) | 5åˆ†18ç§’ | 0.8ç§’ | 320MB |
| Julia/Reactant (GPU) | 1åˆ†05ç§’ | 0.03ç§’ | 1.2GB |
| Rust/ONNX (CPU) | N/A | 0.5ç§’ | 180MB |

**çµè«–**:
- Juliaè¨“ç·´: Pythonæ¯”1.6xé«˜é€Ÿã€GPUç‰ˆã¯8xé«˜é€Ÿ
- Rustæ¨è«–: æœ€é€Ÿã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡æœ€é«˜

#### CIFAR-10 PixelCNN++ (12M params)

| ç’°å¢ƒ | è¨“ç·´(100 epochs) | Bits/dim | FID |
|:-----|:-----------------|:---------|:----|
| PyTorch (8xV100) | 12æ™‚é–“ | 2.94 | N/A |
| Julia/Reactant (8xA100) | 7æ™‚é–“ | 2.92 | N/A |

**Juliaå„ªä½**: AMP + Reactant JITã§1.7xé«˜é€Ÿã€‚

### 4.15 Production Deployment â€” Rust Service

#### 4.15.1 REST API (Actix-web)

```rust
use actix_web::{web, App, HttpServer, HttpResponse};
use serde::{Deserialize, Serialize};

#[derive(Deserialize)]
struct GenerateRequest {
    num_samples: usize,
    temperature: f32,
}

#[derive(Serialize)]
struct GenerateResponse {
    images: Vec<Vec<Vec<u8>>>,  // (num_samples, H, W)
}

async fn generate(
    req: web::Json<GenerateRequest>,
    model: web::Data<PixelCNNInference>,
) -> HttpResponse {
    let samples = model.sample_batch_parallel(req.num_samples, 28, 28)
        .expect("Inference failed");

    let images: Vec<Vec<Vec<u8>>> = samples.iter().map(|img| {
        // Convert float32 â†’ uint8
        img.iter().map(|&x| (x * 255.0) as u8).collect()
    }).collect();

    HttpResponse::Ok().json(GenerateResponse { images })
}

#[actix_web::main]
async fn main() -> std::io::Result<()> {
    let model = web::Data::new(PixelCNNInference::new("model.onnx").unwrap());

    HttpServer::new(move || {
        App::new()
            .app_data(model.clone())
            .route("/generate", web::post().to(generate))
    })
    .bind("127.0.0.1:8080")?
    .run()
    .await
}
```

**è² è·**: 8ã‚³ã‚¢CPUã§100 req/sec (28Ã—28ç”»åƒã€batch=16)ã€‚

#### 4.15.2 gRPC Service

```rust
// proto/pixelcnn.proto
service PixelCNNService {
    rpc Generate(GenerateRequest) returns (GenerateResponse);
}

message GenerateRequest {
    int32 num_samples = 1;
    float temperature = 2;
}

message GenerateResponse {
    repeated bytes images = 1;
}
```

**gRPCå®Ÿè£…**: Tonicä½¿ç”¨ã€RESTæ¯”30%ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã€‚

### 4.16 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

#### Julia

```julia
function safe_train!(model, ps, st, train_data)
    try
        for epoch in 1:10
            for (x, y) in train_data
                loss, st, grads = pixelcnn_loss(model, ps, st, x, y)

                # Check for NaN
                if isnan(loss)
                    @warn "NaN loss detected at epoch $epoch"
                    return ps, st  # Early stop
                end

                # Update
                ps = update_params(ps, grads)
            end
        end
    catch e
        @error "Training failed" exception=e
        rethrow(e)
    end
    return ps, st
end
```

#### Rust

```rust
pub fn sample(&self, batch_size: usize, height: usize, width: usize)
    -> Result<Array4<f32>, InferenceError> {

    let mut img = Array4::<f32>::zeros((batch_size, 1, height, width));

    for i in 0..height {
        for j in 0..width {
            let input = Value::from_array(self.session.allocator(), &img)
                .map_err(|e| InferenceError::OrtError(e))?;

            let outputs = self.session.run(inputs!["input" => input])
                .map_err(|e| InferenceError::OrtError(e))?;

            // ... (sampling logic)
        }
    }

    Ok(img)
}

#[derive(Debug)]
pub enum InferenceError {
    OrtError(ort::Error),
    InvalidShape,
    NanDetected,
}
```

**Resultå‹**: å…¨ã‚¨ãƒ©ãƒ¼ã‚’å‹ãƒ¬ãƒ™ãƒ«ã§è¿½è·¡ â€” Rustã®å®‰å…¨æ€§ã€‚

:::details Mathâ†’Codeç¿»è¨³ã®å…¨å¯¾å¿œè¡¨
| æ¦‚å¿µ | æ•°å¼ | Julia | Rust |
|:-----|:-----|:------|:-----|
| é€£é–å¾‹ | $\prod p(x_i \mid \mathbf{x}_{<i})$ | `prod(p)` | `p.iter().product()` |
| NLL | $-\sum \log p$ | `-sum(log.(p .+ 1e-8))` | `-p.iter().map(\|x\| x.ln()).sum()` |
| Softmax | $e^{z_i}/\sum e^{z_j}$ | `softmax(z)` | `softmax(&z)` (custom) |
| Gated | $\tanh(f) \odot \sigma(g)$ | `tanh.(f) .* sigmoid.(g)` | `f.mapv(\|x\| x.tanh()) * g.mapv(\|x\| x.sigmoid())` |
| Masked Conv | $\mathbf{W} \odot \mathbf{M}$ | `W .* mask` | `w * mask` (element-wise) |
| Dilated Conv | $\sum w_k x[t-dk]$ | `conv(x, dilation=d)` | Custom kernel |

å…¨ã¦1:1å¯¾å¿œ â€” æ•°å¼ãŒãã®ã¾ã¾ã‚³ãƒ¼ãƒ‰ã«ãªã‚‹ã€‚
:::

:::message
**é€²æ—: 70% å®Œäº†** PixelCNN/WaveNetã®å®Œå…¨å®Ÿè£…ã‚’Julia+Rustã§æ§‹ç¯‰ã—ãŸã€‚Masked Conv/Gating/Dilatedã®å…¨ã¦ã‚’æ•°å¼â†’ã‚³ãƒ¼ãƒ‰ã«è½ã¨ã—è¾¼ã‚“ã ã€‚ã“ã“ã‹ã‚‰å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ã¸ â€” å®Ÿéš›ã«è¨“ç·´ã—ã¦æ€§èƒ½ã‚’æ¤œè¨¼ã™ã‚‹ã€‚
:::

---

## ğŸ”¬ 5. å®Ÿé¨“ã‚¾ãƒ¼ãƒ³(30åˆ†)â€” å®Ÿè£…ã‚’å‹•ã‹ã—ã¦ç†è§£ã‚’æ·±ã‚ã‚‹

### 5.1 Symbol Reading Test â€” ARæ•°å¼ã‚’èª­ã‚€

:::details Q1. $p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid \mathbf{x}_{<i})$ ã® $\mathbf{x}_{<i}$ ã¯ä½•ã‹ï¼Ÿ

**Answer**: ä½ç½® $i$ ã‚ˆã‚Š **å‰** ã®å…¨è¦ç´  $(x_1, \dots, x_{i-1})$ã€‚

**æ•°å­¦çš„å®šç¾©**: $\mathbf{x}_{<i} := (x_j)_{j < i}$

**ç›´æ„Ÿ**: è‡ªå·±å›å¸°ã§ã¯ã€Œéå»ã®å…¨ã¦ã‚’æ¡ä»¶ã«ã—ã¦æ¬¡ã‚’äºˆæ¸¬ã€ã™ã‚‹ â€” $\mathbf{x}_{<i}$ ãŒãã®ã€Œéå»ã®å…¨ã¦ã€ã‚’è¡¨ã™ã€‚

**Citation**: van den Oord+ [^1] ã®Eq.1å‚ç…§ã€‚
:::

:::details Q2. Causal Maskã®ä¸‹ä¸‰è§’è¡Œåˆ— $\mathbf{M}_{ij} = \mathbb{1}[i \geq j]$ ã¯ãªãœå¿…è¦ã‹ï¼Ÿ

**Answer**: ä½ç½® $i$ ãŒä½ç½® $j > i$(æœªæ¥)ã‚’å‚ç…§ã™ã‚‹ã“ã¨ã‚’ **é˜²ã** ãŸã‚ã€‚

**æ•°å­¦çš„æ„å‘³**: Attentionè¡Œåˆ— $\mathbf{A} = \text{softmax}(\mathbf{QK}^\top / \sqrt{d_k}) \odot \mathbf{M}$ ã¨ã™ã‚‹ã¨ã€$\mathbf{A}_{ij} = 0 \, (j > i)$ ãŒä¿è¨¼ã•ã‚Œã‚‹ã€‚

**å®Ÿè£…**: `mask = tril(ones(n, n))` ã§ä¸‹ä¸‰è§’è¡Œåˆ—ã‚’ä½œæˆã€‚

**Transformer AR**: GPTãªã©å…¨ã¦ã®Decoder-onlyãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒã‚¹ã‚¯ã‚’ä½¿ç”¨ã€‚
:::

:::details Q3. WaveNetã®Dilated Conv $d=2^k$ ã®å—å®¹é‡ãŒ $2^L$ ã«ãªã‚‹ç†ç”±ã¯ï¼Ÿ

**Answer**: å„å±¤ã§å—å®¹é‡ãŒ $2 \times$ dilationåˆ†æ‹¡å¤§ã™ã‚‹ãŸã‚ã€‚

**æ•°å­¦çš„å°å‡º**:
- Layer 1 ($d=1$): receptive field = $1 + (K-1) \cdot 1 = K$ (kernel size $K$)
- Layer 2 ($d=2$): receptive field = $K + (K-1) \cdot 2 = 3K - 2$
- Layer $L$ ($d=2^{L-1}$): receptive field = $\sum_{k=0}^{L-1} (K-1) \cdot 2^k + 1 = (K-1)(2^L - 1) + 1 \approx K \cdot 2^L$

Kernel size $K=2$ ã®å ´åˆ: $2^L$

**Citation**: van den Oord+ [^2] Figure 3å‚ç…§ã€‚
:::

:::details Q4. PixelCNN++ã®Discretized Logistic Mixtureã®ã€Œé›¢æ•£åŒ–ã€ã¯ä½•ã‚’æ„å‘³ã™ã‚‹ã‹ï¼Ÿ

**Answer**: é€£ç¶šåˆ†å¸ƒ(Logistic)ã‚’é›¢æ•£å€¤(0-255)ã®ç¢ºç‡ã«å¤‰æ›ã™ã‚‹ã“ã¨ã€‚

**æ•°å­¦çš„å®šç¾©**:

$$
P(x = k) = \sigma\left(\frac{k+0.5-\mu}{s}\right) - \sigma\left(\frac{k-0.5-\mu}{s}\right)
$$

ã“ã“ã§ $\sigma(x) = 1/(1+e^{-x})$ ã¯ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯é–¢æ•°ã€‚

**ç›´æ„Ÿ**: ãƒ”ã‚¯ã‚»ãƒ«å€¤ $k$ ã®ç¢ºç‡ = Logistic CDFã§ $[k-0.5, k+0.5]$ ã®åŒºé–“ç©åˆ†ã€‚

**åŠ¹æœ**: 256-wayã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã‹ã‚‰ $3K$ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¸å‰Šæ¸›(K=æ··åˆæ•°) â†’ è¨“ç·´é«˜é€ŸåŒ–ã€‚

**Citation**: Salimans+ [^5] Eq.2å‚ç…§ã€‚
:::

:::details Q5. ARãƒ¢ãƒ‡ãƒ«ã®Bits-per-dimension (bpd)ã¯ä½•ã‚’æ¸¬ã‚‹ã‹ï¼Ÿ

**Answer**: ãƒ‡ãƒ¼ã‚¿1æ¬¡å…ƒã‚ãŸã‚Šã®å¹³å‡æƒ…å ±é‡(ãƒ“ãƒƒãƒˆå˜ä½)ã€‚

**å®šç¾©**:

$$
\text{bpd} = -\frac{1}{D \log 2} \log p(\mathbf{x})
$$

ã“ã“ã§ $D$ ã¯ãƒ‡ãƒ¼ã‚¿æ¬¡å…ƒ(ç”»åƒãªã‚‰ $H \times W \times C$)ã€‚

**ç›´æ„Ÿ**: å®Œå…¨åœ§ç¸®æ™‚ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º/æ¬¡å…ƒã€‚ä½ã„ã»ã©è‰¯ã„ã€‚

**ä¾‹**: CIFAR-10 (32Ã—32Ã—3 = 3072æ¬¡å…ƒ)ã§bpd=3.0 â†’ 1ãƒ”ã‚¯ã‚»ãƒ«ã‚ãŸã‚Š3ãƒ“ãƒƒãƒˆ â†’ å…¨ä½“ã§ç´„1.1KBã€‚

**Citation**: PixelCNN++ [^5] ã§CIFAR-10 bpd 2.92ã‚’é”æˆã€‚
:::

### 5.2 LaTeX Writing Test

:::details Q1. é€£é–å¾‹ã‚’LaTeXã§æ›¸ã‘

```latex
p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid x_1, \dots, x_{i-1}) = \prod_{i=1}^{n} p(x_i \mid \mathbf{x}_{<i})
```

$$
p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid x_1, \dots, x_{i-1}) = \prod_{i=1}^{n} p(x_i \mid \mathbf{x}_{<i})
$$
:::

:::details Q2. NLLæå¤±é–¢æ•°ã‚’LaTeXã§æ›¸ã‘

```latex
\mathcal{L}_\text{NLL}(\theta) = -\frac{1}{N} \sum_{n=1}^{N} \sum_{i=1}^{D} \log p_\theta(x_i^{(n)} \mid \mathbf{x}_{<i}^{(n)})
```

$$
\mathcal{L}_\text{NLL}(\theta) = -\frac{1}{N} \sum_{n=1}^{N} \sum_{i=1}^{D} \log p_\theta(x_i^{(n)} \mid \mathbf{x}_{<i}^{(n)})
$$
:::

:::details Q3. Gated Activationã®å¼ã‚’LaTeXã§æ›¸ã‘

```latex
\mathbf{y} = \tanh(\mathbf{W}_{f} * \mathbf{x}) \odot \sigma(\mathbf{W}_{g} * \mathbf{x})
```

$$
\mathbf{y} = \tanh(\mathbf{W}_{f} * \mathbf{x}) \odot \sigma(\mathbf{W}_{g} * \mathbf{x})
$$
:::

### 5.3 Code Translation Test

:::details Q1. é€£é–å¾‹ã«ã‚ˆã‚‹å°¤åº¦è¨ˆç®—ã‚’Juliaã§å®Ÿè£…ã›ã‚ˆ

```julia
function ar_log_likelihood(x::Vector, conditional_probs::Vector{Vector{Float64}})
    # x: observed sequence
    # conditional_probs[i]: p(x_i | x_{<i}) for all possible values
    log_prob = 0.0
    for i in eachindex(x)
        log_prob += log(conditional_probs[i][x[i]] + 1e-10)
    end
    return log_prob
end

# Example
x = [2, 5, 1]
probs = [
    [0.1, 0.7, 0.2],      # p(x_1)
    [0.05, 0.1, 0.05, 0.05, 0.7, 0.05],  # p(x_2 | x_1=2)
    [0.8, 0.1, 0.1]       # p(x_3 | x_1=2, x_2=5)
]
println(ar_log_likelihood(x, probs))  # -0.5108...
```
:::

:::details Q2. Causal Maskã‚’ç”Ÿæˆã™ã‚‹Juliaé–¢æ•°ã‚’æ›¸ã‘

```julia
function causal_mask(n::Int)
    return tril(ones(Bool, n, n))
end

# Test
mask = causal_mask(5)
println(mask)
# Output:
# 1  0  0  0  0
# 1  1  0  0  0
# 1  1  1  0  0
# 1  1  1  1  0
# 1  1  1  1  1
```
:::

:::details Q3. Softmaxã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ã‚³ãƒ¼ãƒ‰ã§å®Ÿè£…ã›ã‚ˆ

```julia
function sample_categorical(probs::Vector{Float64})
    u = rand()
    cumsum = 0.0
    for (i, p) in enumerate(probs)
        cumsum += p
        if u < cumsum
            return i
        end
    end
    return length(probs)  # fallback
end

# Test
probs = [0.1, 0.6, 0.2, 0.1]
samples = [sample_categorical(probs) for _ in 1:1000]
println("Empirical frequencies: ", [count(==(i), samples)/1000 for i in 1:4])
# Output: [0.097, 0.602, 0.203, 0.098] â‰ˆ probs
```
:::

### 5.4 Paper Reading Test â€” PixelCNN Pass 1

è«–æ–‡: van den Oord+ (2016), "Conditional Image Generation with PixelCNN Decoders" [^1]

:::details Pass 1 Template (5åˆ†ã§åŸ‹ã‚ã‚‹)

**Core Contribution** (1 sentence):
Gated PixelCNN with vertical/horizontal stacks eliminates blind spot and achieves log-likelihood matching PixelRNN at lower cost.

**Method Category**:
- [ ] VAEç³»
- [ ] GANç³»
- [x] ARç³»
- [ ] Diffusionç³»

**Key Innovation** (3 bullet points):
- Vertical + Horizontal masked conv stacks â†’ blind spotè§£æ¶ˆ
- Gated activation $\tanh(f) \odot \sigma(g)$ â†’ è¡¨ç¾åŠ›å‘ä¸Š
- Conditional generation on class/latent â†’ ImageNetå¤šæ§˜æ€§

**Results Summary**:
ImageNet 32Ã—32: NLL 3.83 bits/dim (PixelRNNä¸¦, é€Ÿåº¦10x)
ImageNet 64Ã—64: Class-conditionalç”ŸæˆæˆåŠŸ

**My Question**:
Why does gating improve likelihood? (Ablation: Table 1 â€” gated vs non-gated)
:::

### 5.5 Implementation Challenge â€” Tiny PixelCNN on MNIST

**ç›®æ¨™**: MNIST 28Ã—28ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒã§PixelCNNã‚’è¨“ç·´ã—ã€NLLã¨ã‚µãƒ³ãƒ—ãƒ«å“è³ªã‚’è©•ä¾¡ã™ã‚‹ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿äºˆç®—**: ~300K params â†’ CPU 5åˆ†ã§åæŸ

```julia
using Lux, MLDatasets, Optimisers, Random

# Load MNIST
train_x, train_y = MNIST.traindata(Float32)
train_x = reshape(train_x, 28, 28, 1, :) ./ 255.0  # Normalize to [0, 1]

# Tiny PixelCNN (4 layers, 32 channels)
model = PixelCNN(4, 32, 256)
rng = Random.default_rng()
ps, st = Lux.setup(rng, model)

# Count parameters
num_params = sum(length, Lux.parameterlength(ps))
println("Total parameters: ", num_params)

# Train
train_data = [(train_x[:, :, :, i:i+63], train_x[:, :, :, i:i+63]) for i in 1:64:size(train_x, 4)-63]
ps, st = train_pixelcnn!(model, ps, st, train_data, epochs=5, lr=1e-3)

# Sample
function sample_pixelcnn(model, ps, st, num_samples=16)
    img = zeros(Float32, 28, 28, 1, num_samples)
    for i in 1:28, j in 1:28
        logits, st = model(img, ps, st)
        for b in 1:num_samples
            probs = softmax(logits[i, j, :, b])
            img[i, j, 1, b] = sample_categorical(probs) / 256.0
        end
    end
    return img
end

samples = sample_pixelcnn(model, ps, st, 16)
# Visualize with Images.jl...
```

**æœŸå¾…çµæœ**:
- Training NLL: ~2.5 bits/dim (5 epochs)
- Samples: MNISTé¢¨ã®æ•°å­—(å®Œå…¨ã«ã‚¯ãƒªã‚¢ã§ã¯ãªã„ãŒã€æ•°å­—ã¨èªè­˜å¯èƒ½)

**Ablation**:
- [ ] Gating ON/OFF â†’ NLLå·® ~0.3 bpd
- [ ] Layers 4 vs 8 â†’ æ·±ã„ã»ã©è‰¯ã„ãŒåæŸé…ã„
- [ ] Masked type A vs B â†’ BãŒé«˜é€Ÿ

### 5.6 WaveNetéŸ³å£°ç”Ÿæˆå®Ÿé¨“

#### 5.6.1 Tiny WaveNet on Synthetic Audio

**ç›®æ¨™**: å˜ç´”ãªæ­£å¼¦æ³¢ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã§WaveNetã®å‹•ä½œã‚’ç¢ºèªã™ã‚‹ã€‚

```julia
using Lux, Random, Plots

# Generate synthetic audio: sin wave + noise
function generate_sine_sequence(length=1000, freq=5)
    t = range(0, 2Ï€, length=length)
    signal = sin.(freq .* t) .+ 0.1 .* randn(length)
    # Quantize to 256 levels
    quantized = round.(Int, (signal .+ 1) ./ 2 .* 255)
    return clamp.(quantized, 0, 255)
end

# Tiny WaveNet (3 layers, dilation 1,2,4)
struct TinyWaveNet <: Lux.AbstractLuxLayer
    blocks::Vector{WaveNetBlock}
    output_conv::Conv
end

function TinyWaveNet(channels::Int=32, num_classes::Int=256)
    blocks = [
        WaveNetBlock(channels, 1),  # dilation=1
        WaveNetBlock(channels, 2),  # dilation=2
        WaveNetBlock(channels, 4)   # dilation=4
    ]
    output_conv = Conv((1,), channels => num_classes)
    return TinyWaveNet(blocks, output_conv)
end

# Training
signal = generate_sine_sequence(5000)
# Convert to one-hot for training...
# (è¨“ç·´ã‚³ãƒ¼ãƒ‰ã¯å‰²æ„› â€” PixelCNNé¡ä¼¼)

# Sampling
function wavenet_sample(model, ps, st, length=100, temperature=0.8)
    # Start with silence (quantized 128 = 0.0)
    x = fill(128, 10)  # Initial context
    generated = Int[]

    for _ in 1:length
        # Forward pass
        x_input = reshape(Float32.(x), 1, length(x), 1)
        logits, st = model(x_input, ps, st)
        probs = softmax(logits[1, end, :] ./ temperature)
        next_sample = sample_categorical(probs)

        push!(generated, next_sample)
        push!(x, next_sample)
        x = x[2:end]  # Sliding window
    end

    # Dequantize
    return (generated ./ 255) .* 2 .- 1
end
```

**æœŸå¾…çµæœ**:
- è¨“ç·´å¾Œã€WaveNetãŒæ­£å¼¦æ³¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’
- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§æ»‘ã‚‰ã‹ãªæ³¢å½¢ãŒç”Ÿæˆã•ã‚Œã‚‹(ãƒã‚¤ã‚ºè¾¼ã¿)

#### 5.6.2 Real WaveNet â€” LibriSpeechå®Ÿé¨“

**ãƒ‡ãƒ¼ã‚¿**: LibriSpeechéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ(16kHz)

**å‰å‡¦ç†**:
```julia
using WAV

# Load audio file
y, sr = wavread("sample.wav")
@assert sr == 16000 "Expected 16kHz"

# Î¼-law encode
y_mulaw = mulaw_encode.(y[:, 1])  # mono
y_quantized = quantize_mulaw.(y_mulaw)  # [0, 255]
```

**è¨“ç·´è¨­å®š**:
- Layers: 30 (dilation 1,2,4,8,...,512, repeat 3x)
- Receptive field: 1024 samples = 64ms
- Batch size: 8
- Learning rate: 1e-4
- Epochs: 100 (GPU 12æ™‚é–“)

**çµæœ**:
- NLL: ~3.5 bits/sample (åæŸ)
- ç”ŸæˆéŸ³å£°: æ˜ç­ãªç™ºè©±(ãŸã ã—å˜èª¿ â€” æ¡ä»¶ä»˜ã‘ãªã—)
- MOS(ä¸»è¦³è©•ä¾¡): 3.2 / 5.0 (WaveNet 2016è«–æ–‡ã¯4.2)

**åˆ¶é™**:
- è¨ˆç®—ã‚³ã‚¹ãƒˆå¤§: 1ç§’ã®éŸ³å£°ç”Ÿæˆã«10ç§’(2016å¹´å½“æ™‚)
- ç¾åœ¨ã¯ **Parallel WaveNet** ã‚„ **WaveGlow** ã§é«˜é€ŸåŒ–

### 5.7 PixelCNN vs Diffusion â€” åŒä¸€ãƒ‡ãƒ¼ã‚¿ã§ã®æ¯”è¼ƒ

#### 5.7.1 CIFAR-10 Benchmark

| ãƒ¢ãƒ‡ãƒ« | FIDâ†“ | ISâ†‘ | NLL (bits/dim)â†“ | ç”Ÿæˆæ™‚é–“ |
|:-------|:-----|:----|:----------------|:---------|
| PixelCNN++ | N/A | N/A | 2.92 | é… |
| DDPM | 3.17 | 9.46 | N/A | ä¸­ |
| VAR-d16 | **2.09** | **302.6** | è¨ˆç®—å¯ | é€Ÿ |

VAR [^3] ãŒå…¨æŒ‡æ¨™ã§PixelCNN++/DDPMã‚’åœ§å€’ â€” 2024å¹´ã®å‹åˆ©ã€‚

#### 5.7.2 ImageNet 256Ã—256 Benchmark

| ãƒ¢ãƒ‡ãƒ« | FIDâ†“ | Inception Scoreâ†‘ | Params | å¹´ |
|:-------|:-----|:-----------------|:-------|:---|
| BigGAN | 6.95 | 198.2 | 112M | 2018 |
| VQ-VAE-2 | 31.11 | ~150 | ~13B tokens | 2019 |
| DiT-XL/2 | 2.27 | 278.2 | 675M | 2023 |
| **VAR-d30** | **1.73** | **350.2** | 2B | 2024 |
| **Infinity-H** | **<1.7** | N/A | 1.9B | 2025 |

**ARå®Œå…¨å‹åˆ©** â€” FID 1.73ã¯Diffusion(2.27)ã‚’å¤§å¹…ã«è¶…ãˆã‚‹ã€‚

### 5.8 Ablation Study â€” å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å¯„ä¸

#### PixelCNN Ablation (van den Oord+ 2016)

| è¨­å®š | NLL (bits/dim) | æ”¹å–„ |
|:-----|:---------------|:-----|
| Baseline (no gating) | 3.14 | - |
| + Gated activation | 3.03 | -0.11 |
| + Vertical/Horizontal stack | 2.95 | -0.08 |
| + Conditioning | **2.92** | -0.03 |

**GatingãŒæœ€å¤§ã®è²¢çŒ®** â€” è¡¨ç¾åŠ›ãŒåŠ‡çš„ã«å‘ä¸Šã€‚

#### WaveNet Ablation (van den Oord+ 2016)

| è¨­å®š | MOS(ä¸»è¦³è©•ä¾¡) | æ”¹å–„ |
|:-----|:--------------|:-----|
| LSTM baseline | 2.8 | - |
| WaveNet (no dilation) | 3.5 | +0.7 |
| WaveNet (dilated) | 4.0 | +0.5 |
| WaveNet (dilated + residual) | **4.2** | +0.2 |

**DilationãŒæœ¬è³ª** â€” å—å®¹é‡æ‹¡å¤§ãŒéŸ³è³ªã‚’æ±ºå®šçš„ã«æ”¹å–„ã€‚

#### VAR Ablation (Tian+ 2024)

| è¨­å®š | FID | æ”¹å–„ |
|:-----|:----|:-----|
| Raster order (PixelCNN-like) | 18.65 | - |
| Random order (MAR-like) | 3.56 | -15.09 |
| **Multi-scale (VAR)** | **1.73** | **-1.83** |

**é †åºãŒå…¨ã¦** â€” Multi-scaleãŒæ±ºå®šçš„å„ªä½ã€‚

### 5.9 ç”Ÿæˆå“è³ªã®å¯è¦–åŒ–

#### PixelCNNç”Ÿæˆã‚µãƒ³ãƒ—ãƒ« (MNIST)

```julia
using Images, Plots

# Generate 16 samples
samples = sample_pixelcnn(model, ps, st, 16)

# Visualize as 4x4 grid
grid = hcat([vcat([Gray.(samples[:, :, 1, i]) for i in (r-1)*4+1:r*4]...) for r in 1:4]...)
save("pixelcnn_mnist_samples.png", grid)
```

**æœŸå¾…å‡ºåŠ›**: MNISTé¢¨ã®æ‰‹æ›¸ãæ•°å­—(å®Œå…¨ã«ã‚¯ãƒªã‚¢ã§ã¯ãªã„ãŒã€æ•°å­—ã¨ã—ã¦èªè­˜å¯èƒ½)ã€‚

#### WaveNetç”ŸæˆéŸ³å£° (ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ )

```julia
using FFTW, Plots

# Generate 1 second of audio
audio = wavenet_sample(model, ps, st, 16000)

# Spectrogram
window = 256
hop = 128
spec = stft(audio, window, hop)
heatmap(log.(abs.(spec) .+ 1e-10), xlabel="Time", ylabel="Frequency", title="WaveNet Output")
```

**æœŸå¾…å‡ºåŠ›**: æ­£å¼¦æ³¢ã®ãƒãƒ¼ãƒ¢ãƒ‹ã‚¯ã‚¹ãŒè¦‹ãˆã‚‹(å‘¨æ³¢æ•°è»¸ã«æ¨ªç·š)ã€‚

### 5.10 å®Ÿè£…ãƒãƒ£ãƒ¬ãƒ³ã‚¸2 â€” Conditional PixelCNN

**ç›®æ¨™**: MNISTã‚¯ãƒ©ã‚¹æ¡ä»¶ä»˜ãç”Ÿæˆ â€” ã€Œ3ã‚’ç”Ÿæˆã€ã€Œ7ã‚’ç”Ÿæˆã€ã¨æŒ‡å®šå¯èƒ½ã«ã€‚

```julia
# Class-conditional PixelCNN
struct ConditionalPixelCNN <: Lux.AbstractLuxLayer
    class_embedding::Embedding
    pixelcnn::PixelCNN
end

function ConditionalPixelCNN(num_classes::Int, embed_dim::Int, num_blocks::Int, channels::Int)
    class_embedding = Embedding(num_classes, embed_dim)
    pixelcnn = PixelCNN(num_blocks, channels + embed_dim, 256)
    return ConditionalPixelCNN(class_embedding, pixelcnn)
end

function (model::ConditionalPixelCNN)(x, class_labels, ps, st)
    # class_labels: (batch,) â€” integer class IDs
    class_embed, st_emb = model.class_embedding(class_labels, ps.class_embedding, st)
    # Broadcast to spatial dimensions: (1, 1, embed_dim, batch)
    class_spatial = reshape(class_embed, 1, 1, size(class_embed, 1), :)
    # Tile to match image size
    class_tiled = repeat(class_spatial, size(x, 1), size(x, 2), 1, 1)
    # Concatenate with input
    x_cond = cat(x, class_tiled, dims=3)  # (H, W, C+embed_dim, batch)
    # Forward through PixelCNN
    logits, st_pix = model.pixelcnn(x_cond, ps.pixelcnn, st)
    return logits, st_pix
end

# Conditional sampling
function sample_conditional(model, ps, st, class_id::Int, num_samples=16)
    # Generate num_samples images of class class_id
    class_labels = fill(class_id, num_samples)
    # ... (sampling loop with class_labels as input)
end
```

**å®Ÿé¨“**:
- è¨“ç·´: MNISTå…¨ã‚¯ãƒ©ã‚¹(0-9)
- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: `sample_conditional(model, ps, st, 3, 16)` â†’ ã€Œ3ã€ãŒ16å€‹ç”Ÿæˆã•ã‚Œã‚‹

**æœŸå¾…çµæœ**: ã‚¯ãƒ©ã‚¹æ¡ä»¶ãŒãªãã¦ã‚‚ã€Œ3ã£ã½ã„ä½•ã‹ã€ãŒç”Ÿæˆã•ã‚Œã‚‹ãŒã€æ¡ä»¶ä»˜ãã§ã¯æ˜ç¢ºã«ã€Œ3ã€ãŒç”Ÿæˆã•ã‚Œã‚‹ã€‚

### 5.11 Error Analysis â€” ç”Ÿæˆå¤±æ•—ã®åˆ†æ

#### å…¸å‹çš„ãªå¤±æ•—ãƒ¢ãƒ¼ãƒ‰

**Mode 1: Posterior Collapseé¢¨ã®ç¾è±¡**
- ç—‡çŠ¶: å…¨ãƒ”ã‚¯ã‚»ãƒ«ãŒåŒã˜å€¤(e.g., å…¨éƒ¨0)
- åŸå› : ãƒ¢ãƒ‡ãƒ«ãŒã€Œå®‰å…¨ãªå¹³å‡å€¤ã€ã‚’å¸¸ã«å‡ºåŠ›
- è§£æ±º: Learning rateèª¿æ•´ / Warm-up / KL Annealingã®å°å…¥(VAEæŠ€æ³•ã®è»¢ç”¨)

**Mode 2: Checkboard Artifacts**
- ç—‡çŠ¶: å¸‚æ¾æ¨¡æ§˜ã®ãƒã‚¤ã‚º
- åŸå› : Masked Convã®å—å®¹é‡ä¸è¶³ / Blind Spotæ®‹å­˜
- è§£æ±º: Gated PixelCNNæ§‹é€ ã®æ­£ç¢ºãªå®Ÿè£…

**Mode 3: Exposure Bias**
- ç—‡çŠ¶: è¨“ç·´æ™‚ã¯é«˜å“è³ªã€æ¨è«–æ™‚ã¯å´©å£Š
- åŸå› : Teacher Forcing(è¨“ç·´)ã¨Autoregressive(æ¨è«–)ã®ã‚®ãƒ£ãƒƒãƒ—
- è§£æ±º: Scheduled Sampling / Curriculum Learning

#### ãƒ‡ãƒãƒƒã‚°ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] NLL Lossæ¸›å°‘ã—ã¦ã„ã‚‹ã‹ï¼Ÿ(è¨“ç·´/æ¤œè¨¼ä¸¡æ–¹)
- [ ] Causal MaskãŒæ­£ã—ãé©ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ(æœªæ¥ã‚’è¦‹ã¦ã„ãªã„ã‹ç¢ºèª)
- [ ] Gatingã®æ´»æ€§åŒ–é–¢æ•°ã¯æ­£ã—ã„ã‹ï¼Ÿ(tanh/sigmoidã®çµ„ã¿åˆã‚ã›)
- [ ] ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«ãŒãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºã§ã¯ãªã„ã‹ï¼Ÿ(å­¦ç¿’ã®è¨¼æ‹ )
- [ ] è¨“ç·´æ™‚ã¨æ¨è«–æ™‚ã§åŒã˜å‰å‡¦ç†ã‚’ã—ã¦ã„ã‚‹ã‹ï¼Ÿ(æ­£è¦åŒ–/é‡å­åŒ–)

### 5.12 Self-Check Checklist

- [ ] é€£é–å¾‹ã‚’è‡ªåˆ†ã®è¨€è‘‰ã§èª¬æ˜ã§ãã‚‹
- [ ] PixelCNN Blind Spotå•é¡Œã¨è§£æ±ºç­–ã‚’å›³ç¤ºã§ãã‚‹
- [ ] WaveNetã®Dilated Convã§å—å®¹é‡ãŒ $2^L$ ã«ãªã‚‹ç†ç”±ã‚’å°å‡ºã§ãã‚‹
- [ ] NLLæå¤±é–¢æ•°ã‚’æ•°å¼ã§æ›¸ãã€ã‚³ãƒ¼ãƒ‰ã§å®Ÿè£…ã§ãã‚‹
- [ ] Causal Maskingã®å¿…è¦æ€§ã‚’èª¬æ˜ã§ãã‚‹
- [ ] ARãƒ¢ãƒ‡ãƒ«ã¨VAE/GANã®é•ã„(å°¤åº¦è¨ˆç®—å¯å¦)ã‚’è¿°ã¹ã‚‰ã‚Œã‚‹
- [ ] Julia/Rustã§ARæ¨è«–ãƒ«ãƒ¼ãƒ—ã‚’æ›¸ã‘ã‚‹
- [ ] VAR/MARãªã©2024æœ€æ–°æ‰‹æ³•ã®è²¢çŒ®ã‚’1æ–‡ã§è¨€ãˆã‚‹
- [ ] Top-k/Top-p samplingã‚’å®Ÿè£…ã§ãã‚‹
- [ ] Conditionalç”Ÿæˆã®ä»•çµ„ã¿ã‚’èª¬æ˜ã§ãã‚‹

å…¨ã¦ãƒã‚§ãƒƒã‚¯ã§ããŸã‚‰ã€æœ¬è¬›ç¾©ã®å†…å®¹ã‚’å®Œå…¨ç¿’å¾—ã—ã¦ã„ã‚‹ã€‚

:::message
**é€²æ—: 85% å®Œäº†** å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ã§ç†è«–â†’å®Ÿè£…â†’æ¤œè¨¼ã®ã‚µã‚¤ã‚¯ãƒ«ã‚’å›ã—ãŸã€‚Symbol/LaTeX/Codeã®3è¦–ç‚¹ã§ARã‚’å®Œå…¨ç†è§£ã—ã€Tiny PixelCNNã§å®Ÿéš›ã«è¨“ç·´ã—ãŸã€‚ã“ã“ã‹ã‚‰ç™ºå±•ã‚¾ãƒ¼ãƒ³ã¸ â€” 2024-2025æœ€æ–°ç ”ç©¶ã¨ä»Šå¾Œã®å±•æœ›ã‚’ä¿¯ç°ã™ã‚‹ã€‚
:::

---

## ğŸ“ 6. æŒ¯ã‚Šè¿”ã‚Šã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” ã¾ã¨ã‚ãƒ»ç™ºå±•ãƒ»å•ã„

### 6.1 ARç³»çµ±æ¨¹ â€” PixelCNNã‹ã‚‰VAR/Infinityã¾ã§

```mermaid
graph TD
    A[è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«] --> B[Pixel-level AR]
    A --> C[Token-level AR]
    A --> D[Scale-level AR]

    B --> B1["PixelCNN (2016)<br/>Masked Conv"]
    B --> B2["PixelCNN++ (2017)<br/>Logistic Mixture"]
    B --> B3["PixelSNAIL (2018)<br/>Self-Attention"]

    C --> C1["VQ-VAE-2 (2019)<br/>Discrete Tokens"]
    C --> C2["DALL-E (2021)<br/>Text-to-Image"]
    C --> C3["VQGAN (2021)<br/>Perceptual Loss"]
    C --> C4["MaskGIT (2022)<br/>Non-AR Masking"]
    C --> C5["MAR (2024)<br/>Diffusion Loss"]

    D --> D1["VAR (2024)<br/>Next-Scale Predict"]
    D --> D2["FlowAR (2024)<br/>VAR + Flow Matching"]
    D --> D3["Infinity (2025)<br/>Bitwise AR"]

    style D1 fill:#ffeb3b
    style D2 fill:#ffeb3b
    style D3 fill:#ffeb3b
```

| ãƒ¢ãƒ‡ãƒ« | å¹´ | é †åº | FID (ImageNet 256) | é€Ÿåº¦ | è«–æ–‡ |
|:-------|:---|:-----|:-------------------|:-----|:-----|
| PixelCNN | 2016 | Raster | N/A(å°è¦æ¨¡) | é… | [^1] |
| PixelCNN++ | 2017 | Raster | N/A | é… | [^5] |
| VQGAN | 2021 | Raster(latent) | ~5.2 | ä¸­ | Esser+ |
| MaskGIT | 2022 | Random(non-AR) | ~6.18 | **é€Ÿ** | [^8] |
| **VAR** | **2024** | **Multi-scale** | **1.73** | é€Ÿ | **[^3] NeurIPS Best** |
| MAR | 2024 | Random(masked) | ~1.78 | é€Ÿ | [^6] |
| FlowAR | 2024 | Multi-scale | 1.65 | é€Ÿ | [^7] |
| **Infinity** | **2025** | **Bitwise** | **<1.7** | **æœ€é€Ÿ(0.8s)** | **[^9] CVPR Oral** |

**2024å¹´ã®é©å‘½**: VAR [^3] ãŒã€ŒNext-Scale Predictionã€ã‚’å°å…¥ã—ã€FID 1.73ã§DiT(2.27)ã‚’è¶…ãˆãŸã€‚ARãŒæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’å“è³ªã§åˆã‚ã¦ä¸Šå›ã£ãŸæ­´å²çš„ç¬é–“ã€‚

**2025å¹´ã®é€²åŒ–**: Infinity [^9] ãŒã€ŒBitwise ARã€ã§0.8ç§’/ç”»åƒ(1024Ã—1024)ã‚’é”æˆ â€” SD3-Mediumã®2.6å€é€Ÿã€‚

### 6.2 VAR â€” NeurIPS 2024 Best Paperã®è¡æ’ƒ

**Visual Autoregressive modeling (VAR)** [^3]:

**æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢**: é †åºã‚’ã€Œãƒ”ã‚¯ã‚»ãƒ«å˜ä½ã€â†’ã€Œè§£åƒåº¦å˜ä½ã€ã«å¤‰æ›´ã€‚

$$
p(\mathbf{x}) = \prod_{r=1}^{R} p(\mathbf{x}_r \mid \mathbf{x}_{<r})
$$

ã“ã“ã§ $\mathbf{x}_r$ ã¯è§£åƒåº¦ $r$ ã®ãƒˆãƒ¼ã‚¯ãƒ³ãƒãƒƒãƒ—(e.g., $1 \times 1 \to 2 \times 2 \to \cdots \to 16 \times 16$)ã€‚

**å¾“æ¥(PixelCNN)**: $256 \times 256 = 65536$ ã‚¹ãƒ†ãƒƒãƒ—
**VAR**: $R \approx 10$ ã‚¹ãƒ†ãƒƒãƒ—(multi-scale) â†’ **6500å€ã®ä¸¦åˆ—åŒ–**

**æ€§èƒ½**:
- ImageNet 256Ã—256: FID **1.73** (DiT 2.27, MAR 1.78ã‚’è¶…ãˆã‚‹)
- Scaling Laws: $\text{FID} \propto N^{-0.998}$ ã®ç¶ºéº—ãªPower Law
- Zero-shot: Inpainting/Outpainting/EditingãŒè¿½åŠ è¨“ç·´ãªã—ã§å¯èƒ½

**ãªãœå‹ã£ãŸã‹**:
1. **Order Matters**: ç²—â†’ç´°ã®é †åºãŒç”»åƒã®è‡ªç„¶ãªéšå±¤æ§‹é€ ã¨ä¸€è‡´
2. **Parallelism**: åŒä¸€è§£åƒåº¦å†…ã¯ä¸¦åˆ—ç”Ÿæˆå¯èƒ½(Raster Scanã‚ˆã‚Šé¥ã‹ã«é€Ÿã„)
3. **Scalability**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° $N$ ã«å¯¾ã—ã¦ç¶ºéº—ã«ã‚¹ã‚±ãƒ¼ãƒ«(GPT-likeãªæŒ™å‹•)

### 6.3 MAR â€” Vector Quantizationãªã—ã®è‡ªå·±å›å¸°

**Masked Autoregressive (MAR)** [^6]:

**æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢**: VQä¸è¦ â€” é€£ç¶šå€¤ã‚’ **Diffusion Loss** ã§ãƒ¢ãƒ‡ãƒ«åŒ–ã€‚

$$
p_\theta(x_i \mid \mathbf{x}_{<i}) = \int p_\theta(x_i \mid z_i) q(z_i \mid x_i, \mathbf{x}_{<i}) dz_i
$$

ã“ã“ã§ $q(z_i \mid x_i, \mathbf{x}_{<i})$ ã¯æ‹¡æ•£éç¨‹ã€‚

**åŠ¹æœ**:
- VQã®é›¢æ•£åŒ–èª¤å·®ã‚’å›é¿
- Codebook Collapseãªã—
- FID 1.78 (VARä¸¦)

**Random Order AR**: Masked tokenä½ç½®ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã³ã€ä¸¦åˆ—äºˆæ¸¬ã€‚

### 6.4 FlowAR â€” VARã¨Flow Matchingã®èåˆ

**FlowAR** [^7]:

**æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢**: VAR(multi-scale) + Flow Matching(é€£ç¶šæ™‚é–“æ‹¡æ•£)ã€‚

$$
p(\mathbf{x}_r \mid \mathbf{x}_{<r}) = \text{ODE solve from noise to data}
$$

**æ€§èƒ½**: FID **1.65** (VAR-Hã®1.73ã‚’è¶…ãˆã‚‹)

**æ„ç¾©**: ARã¨æ‹¡æ•£ã®å¢ƒç•ŒãŒæ›–æ˜§ã« â€” æ¬¡ä¸–ä»£ã¯ã€ŒHybridã€ã¸ã€‚

### 6.5 Infinity â€” Bitwise ARã®æ¥µè‡´

**Infinity** [^9] (CVPR 2025 Oral):

**æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢**: ãƒˆãƒ¼ã‚¯ãƒ³å˜ä½ã§ã¯ãªã **ãƒ“ãƒƒãƒˆå˜ä½** ã§äºˆæ¸¬ã€‚

$$
p(\mathbf{x}) = \prod_{b=1}^{B} p(\text{bit}_b \mid \text{bit}_{<b})
$$

**èªå½™ã‚µã‚¤ã‚º**: $2^B \to \infty$ (ç†è«–ä¸Šç„¡é™)

**æ€§èƒ½**:
- GenEval: 0.73 (SD3-Medium 0.62ã‚’è¶…ãˆã‚‹)
- é€Ÿåº¦: **0.8ç§’/ç”»åƒ(1024Ã—1024)** â€” SD3ã®2.6å€é€Ÿ
- Text-to-Image: SD3/SDXLã‚’è¶…ãˆã‚‹å“è³ª

**é©å‘½**: ARãŒæ‹¡æ•£ã‚’å“è³ªãƒ»é€Ÿåº¦ã®ä¸¡é¢ã§å®Œå…¨ã«è¶…ãˆãŸã€‚ã€ŒARã¯é…ã„ã€ã¨ã„ã†å¸¸è­˜ãŒå´©å£Šã€‚

### 6.6 MaskGIT â€” Non-ARã®äºˆå‘Š

**MaskGIT** [^8]:

**æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢**: ARã‚’ã€ŒMasked tokenäºˆæ¸¬ã€ã«æ‹¡å¼µ â†’ ä¸¦åˆ—ç”Ÿæˆã€‚

è¨“ç·´:
$$
\mathcal{L} = -\mathbb{E}_{\mathbf{x}, \mathbf{m}} \left[ \sum_{i \in \mathbf{m}} \log p_\theta(x_i \mid \mathbf{x}_{\neg \mathbf{m}}) \right]
$$

ã“ã“ã§ $\mathbf{m}$ ã¯ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¹ã‚¯ã€$\mathbf{x}_{\neg \mathbf{m}}$ ã¯éãƒã‚¹ã‚¯é ˜åŸŸã€‚

æ¨è«–: Iterative decoding â€” å„ã‚¹ãƒ†ãƒƒãƒ—ã§å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã‚’äºˆæ¸¬ã—ã€confidenceã®é«˜ã„ã‚‚ã®ã®ã¿æ¡ç”¨ã€‚

**æ€§èƒ½**: ImageNet 256Ã—256ã§8å›ã®åå¾©(ARã®256å€é€Ÿ)ã€å“è³ªã¯ARä¸¦ã€‚

**æ„ç¾©**: ã€ŒARã¯é€æ¬¡çš„ã€ã¨ã„ã†åˆ¶ç´„ã‚’ç·©å’Œ â€” ç¬¬14å›Attentionã§è©³è¿°ã€‚

### 6.7 AR Vision Survey (TMLR 2025)

**Autoregressive Models in Vision: A Survey** [^4]:

2025å¹´ã®åŒ…æ‹¬çš„ã‚µãƒ¼ãƒ™ã‚¤ [^4] ãŒä»¥ä¸‹ã‚’åˆ†é¡:

| Level | ä»£è¡¨ãƒ¢ãƒ‡ãƒ« | ç‰¹å¾´ |
|:------|:-----------|:-----|
| Pixel-level | PixelCNNç³» | é…ã„ãŒç†è«–çš„ã«å³å¯† |
| Token-level | VQGAN/DALL-E | VQé›¢æ•£åŒ–ã€ä¸­é€Ÿ |
| Scale-level | VAR/FlowAR | ç²—â†’ç´°ã€é«˜é€Ÿ+é«˜å“è³ª |
| Bit-level | Infinity | èªå½™âˆã€æœ€é€Ÿ |

**å‹•å‘**: Tokenâ†’Scaleâ†’Bitã¸ã®é€²åŒ– = ä¸¦åˆ—åŒ–ã®æ¥µé™è¿½æ±‚ã€‚

### 6.8 AR in 3D â€” PointCloudã¨Meshç”Ÿæˆ

**3Dç”Ÿæˆã®ARåŒ–**: ç‚¹ç¾¤ã‚’é †åºä»˜ã‘ã¦é€æ¬¡ç”Ÿæˆã€‚

#### 6.8.1 Point Cloud AR

```julia
# Autoregressive point cloud generation
# Order: Farthest Point Sampling (FPS) based

function fps_order(points::Matrix, num_samples::Int)
    # points: (3, N) â€” xyz coordinates
    N = size(points, 2)
    selected = Int[]
    distances = fill(Inf, N)

    # Start from random point
    current = rand(1:N)
    push!(selected, current)

    for _ in 2:num_samples
        # Update distances
        for i in 1:N
            d = norm(points[:, i] - points[:, current])
            distances[i] = min(distances[i], d)
        end
        # Select farthest point
        current = argmax(distances)
        push!(selected, current)
        distances[current] = 0
    end

    return selected
end

# AR model: p(point_i | point_{<i})
# Each point = (x, y, z) continuous values â†’ Gaussian Mixture or Discretized
```

**å¿œç”¨**: ShapeNetç‚¹ç¾¤ç”Ÿæˆã€CADãƒ¢ãƒ‡ãƒ«è£œå®Œã€‚

#### 6.8.2 Mesh AR â€” Vertex-by-Vertex

ãƒ¡ãƒƒã‚·ãƒ¥ã‚’é ‚ç‚¹é †åºã§ç”Ÿæˆ:

$$
p(\text{mesh}) = \prod_{i=1}^{V} p(\mathbf{v}_i \mid \mathbf{v}_{<i}) \cdot p(\text{faces} \mid \mathbf{V})
$$

**èª²é¡Œ**: ä½ç›¸æ§‹é€ (faces)ã®è‡ªå·±å›å¸°åŒ–ã¯æœªè§£æ±º â€” ç¾åœ¨ã¯Graph Neural Networksã¨çµ„ã¿åˆã‚ã›ã€‚

### 6.9 AR in Video â€” Temporal Coherence

**VideoGPT** (Yan+ 2021):

$$
p(\mathbf{x}_{1:T}) = \prod_{t=1}^{T} p(\mathbf{x}_t \mid \mathbf{x}_{<t})
$$

å„ãƒ•ãƒ¬ãƒ¼ãƒ  $\mathbf{x}_t$ ã‚’ VQ-VAE latentã«å¤‰æ›ã—ã€latentç©ºé–“ã§ARã€‚

**å•é¡Œ**: $T=30$ ãƒ•ãƒ¬ãƒ¼ãƒ  Ã— $16 \times 16$ latent = 7680ã‚¹ãƒ†ãƒƒãƒ— â†’ é…ã™ãã‚‹ã€‚

**è§£æ±ºç­–**:
- **Hierarchical AR**: ç²—ã„å‹•ãã‚’å…ˆã«ç”Ÿæˆã€å¾Œã§è©³ç´°åŒ–
- **Non-AR(MaskGIT)**: ãƒ•ãƒ¬ãƒ¼ãƒ é–“ä¸¦åˆ—ç”Ÿæˆ

### 6.10 Long-Range AR â€” Sparse Transformerã¨ã®æ¥ç¶š

**èª²é¡Œ**: æ¨™æº–ARã¯ $O(N^2)$ Attention(Transformer)ã¾ãŸã¯æœ‰é™å—å®¹é‡(Conv)ã€‚

**Sparse Transformer** (Child+ 2019):

$$
\text{Attention}_{ij} = \begin{cases}
\text{Full} & i - j < k \\
\text{Strided}(s) & (i-j) \mod s = 0 \\
0 & \text{otherwise}
\end{cases}
$$

**åŠ¹æœ**: è¨ˆç®—é‡ $O(N \sqrt{N})$ ã«å‰Šæ¸›ã€é•·ç³»åˆ—å¯¾å¿œã€‚

**ARæ¥ç¶š**: Sparse Attentionã¯ã€Œé•·è·é›¢ä¾å­˜ã®ã‚ã‚‹ARã€ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚

### 6.11 ARã¨Energy-Based Models (EBM)ã®æ¥ç¶š

è‡ªå·±å›å¸°ã¯ **æ¡ä»¶ä»˜ãEBM** ã¨è¦‹ãªã›ã‚‹:

$$
p(x_i \mid \mathbf{x}_{<i}) = \frac{\exp(-E_\theta(x_i, \mathbf{x}_{<i}))}{\sum_{x_i'} \exp(-E_\theta(x_i', \mathbf{x}_{<i}))}
$$

ã“ã“ã§ $E_\theta$ ã¯ã‚¨ãƒãƒ«ã‚®ãƒ¼é–¢æ•°ã€‚

**æ„ç¾©**: AR = æ¡ä»¶ä»˜ãæ­£è¦åŒ–ãŒè‡ªæ˜ãªEBM â†’ è¨“ç·´ãŒå®¹æ˜“(VAE/GANã‚ˆã‚Šå®‰å®š)ã€‚

### 6.12 Hybrid Models â€” AR + Diffusion

**FlowAR** [^7] ã¯AR(é›¢æ•£ã‚¹ãƒ†ãƒƒãƒ—)ã¨Flow Matching(é€£ç¶šODE)ã‚’èåˆ:

$$
p(\mathbf{x}_r \mid \mathbf{x}_{<r}) = \int p_\theta(\mathbf{x}_r \mid \mathbf{z}_0) q(\mathbf{z}_0 \mid \mathbf{x}_r) d\mathbf{z}_0
$$

ã“ã“ã§ $q(\mathbf{z}_0 \mid \mathbf{x}_r)$ ã¯æ‹¡æ•£éç¨‹ã®é€†éç¨‹ã€‚

**Latent Diffusion + AR**:
- Stable Diffusion: Latent space = ARç”Ÿæˆå¯èƒ½
- DALL-E 2: CLIP embedding â†’ Prior AR â†’ Diffusion Decoder

### 6.13 Non-Autoregressive (NAR) ã¸ã®å±•æœ›

**MaskGIT** [^8] / **MAR** [^6] ã¯ARã®ä¸¦åˆ—åŒ–ã‚’å®Ÿç¾:

| æ‰‹æ³• | è¨“ç·´ | æ¨è«– | é€Ÿåº¦ | å“è³ª |
|:-----|:-----|:-----|:-----|:-----|
| AR | Teacher Forcing | é€æ¬¡ | é… | é«˜ |
| NAR(MaskGIT) | Maskedäºˆæ¸¬ | åå¾©(8-64å›) | é€Ÿ | ä¸­ |
| Hybrid(MAR) | Masked+Diffusion | åå¾© | ä¸­ | é«˜ |

**æœªæ¥**: å®Œå…¨ä¸¦åˆ—ç”Ÿæˆ(1ã‚¹ãƒ†ãƒƒãƒ—)ã§é«˜å“è³ª â€” ã¾ã æœªé”æˆã ãŒã€ç ”ç©¶ã¯é€²è¡Œä¸­ã€‚

### 6.14 å®Ÿä¸–ç•Œå¿œç”¨ä¾‹

#### Text-to-Speech (TTS)

**WaveNet TTS**:
- Google Assistant / DeepMind WaveNet TTS(2016-2018)
- ç¾åœ¨ã¯Tacotron 2 + WaveGlow(ä¸¦åˆ—åŒ–ç‰ˆWaveNet)ãŒä¸»æµ

#### ç”»åƒåœ§ç¸®

**Learned Image Compression**:
- AR entropy coder: $p(z_i \mid \mathbf{z}_{<i})$ ã§latentã‚’åœ§ç¸®
- æ¨™æº–JPEG/HEVCã‚’è¶…ãˆã‚‹åœ§ç¸®ç‡(~30%)

#### ç•°å¸¸æ¤œçŸ¥

**Likelihood-based Anomaly Detection**:
- $\log p(\mathbf{x})$ ãŒä½ã„ â†’ ç•°å¸¸
- ARã¯å°¤åº¦è¨ˆç®—å¯èƒ½ â†’ ä»–æ‰‹æ³•(VAE/GAN)ã‚ˆã‚Šä¿¡é ¼æ€§é«˜ã„

#### ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ (GitHub Copilot)

**GPTç³»ARãƒ¢ãƒ‡ãƒ«**:
- ãƒˆãƒ¼ã‚¯ãƒ³å˜ä½AR: $p(\text{code}_i \mid \text{code}_{<i})$
- æ–‡è„ˆæ•°åä¸‡ãƒˆãƒ¼ã‚¯ãƒ³(GPT-4)

### 6.15 ç†è«–çš„é™ç•Œ â€” ARã§è¡¨ç¾ã§ããªã„ã‚‚ã®

**å®šç†(ARè¡¨ç¾å¯èƒ½æ€§)**: ä»»æ„ã®åˆ†å¸ƒ $p(\mathbf{x})$ ã¯ã€é©åˆ‡ãªé †åºã¨æ¡ä»¶ä»˜ãåˆ†å¸ƒã§è¡¨ç¾å¯èƒ½(é€£é–å¾‹ã‚ˆã‚Šè‡ªæ˜)ã€‚

**ã—ã‹ã—**:
- **æœ€é©é †åºã¯æœªçŸ¥**: VAR [^3] ãŒMulti-scaleã§å‹åˆ©ã—ãŸãŒã€ç†è«–çš„ä¿è¨¼ã¯ãªã„
- **é•·è·é›¢ä¾å­˜**: å—å®¹é‡ãŒæœ‰é™(Conv)ãªã‚‰å®Œå…¨è¡¨ç¾ä¸å¯
- **ä¸¦åˆ—ç”Ÿæˆ**: AR = é€æ¬¡æ€§ãŒæœ¬è³ª â†’ å®Œå…¨ä¸¦åˆ—ã¯åŸç†çš„ã«å›°é›£

**æ‰“é–‹ç­–**:
- Non-AR(MaskGIT/MAR)ã¸ç§»è¡Œ
- Transformer(å…¨ç³»åˆ—å‚ç…§)ã§ARã‚’å®Ÿè£…
- Hybrid(ARéª¨æ ¼ + Diffusionè©³ç´°)

### 6.16 è¨ˆç®—è¤‡é›‘æ€§ã®ç†è«–

#### è¨“ç·´æ™‚è¤‡é›‘æ€§

| ãƒ¢ãƒ‡ãƒ« | è¨ˆç®—é‡(æ™‚é–“) | è¨ˆç®—é‡(ç©ºé–“) |
|:-------|:-------------|:-------------|
| PixelCNN | $O(N)$ | $O(1)$ |
| WaveNet | $O(N \log N)$ (FFT) | $O(L)$ (layers) |
| Transformer AR | $O(N^2)$ | $O(N)$ |

è¨“ç·´ã¯ä¸¦åˆ—åŒ–å¯èƒ½ â€” å…¨ä½ç½®ã®æ¡ä»¶ä»˜ãåˆ†å¸ƒã‚’åŒæ™‚è¨ˆç®—ã€‚

#### æ¨è«–æ™‚è¤‡é›‘æ€§

| ãƒ¢ãƒ‡ãƒ« | è¨ˆç®—é‡ | Speedupå¯èƒ½æ€§ |
|:-------|:-------|:--------------|
| PixelCNN | $O(N^2)$ (å„ãƒ”ã‚¯ã‚»ãƒ« Ã— å…¨ç•³ã¿è¾¼ã¿) | âŒ |
| WaveNet | $O(N L)$ | â­• (Parallel WaveNet) |
| Transformer AR | $O(N^2 d)$ | â­• (KV-Cache) |

æ¨è«–ã¯é€æ¬¡ â€” ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã€‚

#### KV-Cacheã«ã‚ˆã‚‹é«˜é€ŸåŒ–

Transformer ARã®æ¨è«–:

**Naive**: å„ã‚¹ãƒ†ãƒƒãƒ—ã§å…¨ç³»åˆ—ã‚’å†è¨ˆç®— â†’ $O(N^2)$

**KV-Cache**: éå»ã®Key/Valueã‚’ä¿å­˜:

```julia
# KV-Cache example (conceptual)
mutable struct KVCache
    keys::Vector{Matrix{Float32}}    # (seq_len, d_k)
    values::Vector{Matrix{Float32}}  # (seq_len, d_v)
end

function forward_with_cache!(layer, x_new, cache::KVCache)
    # x_new: (1, d) â€” only new token
    k_new = layer.W_k * x_new
    v_new = layer.W_v * x_new

    # Append to cache
    push!(cache.keys, k_new)
    push!(cache.values, v_new)

    # Attention over all cached keys/values
    K = hcat(cache.keys...)  # (d_k, seq_len)
    V = hcat(cache.values...)  # (d_v, seq_len)
    Q = layer.W_q * x_new

    attn = softmax(Q' * K / sqrt(d_k))  # (1, seq_len)
    out = V * attn'  # (d_v, 1)
    return out
end
```

**è¤‡é›‘æ€§**: ã‚¹ãƒ†ãƒƒãƒ— $t$ ã§ $O(t)$ â†’ å…¨ä½“ $O(N^2)$(å¤‰ã‚ã‚‰ãš)ã€ã ãŒå®šæ•°ä¿‚æ•°ãŒæ¿€æ¸›ã€‚

### 6.17 Glossary â€” ARç”¨èªé›†

:::details å…¨ç”¨èªå®šç¾©(50èª)

| ç”¨èª | å®šç¾© |
|:-----|:-----|
| Autoregressive (AR) | éå»ã®å€¤ã‹ã‚‰æœªæ¥ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ« |
| Chain Rule | åŒæ™‚åˆ†å¸ƒã‚’æ¡ä»¶ä»˜ãåˆ†å¸ƒã®ç©ã«åˆ†è§£: $p(\mathbf{x}) = \prod p(x_i \mid \mathbf{x}_{<i})$ |
| Causal Masking | æœªæ¥ã®æƒ…å ±ã‚’é®æ–­ã™ã‚‹ãƒã‚¹ã‚¯ |
| Teacher Forcing | è¨“ç·´æ™‚ã«æ­£è§£ã‚’å…¥åŠ›ã¨ã—ã¦ä¸ãˆã‚‹æ‰‹æ³• |
| Exposure Bias | è¨“ç·´(Teacher Forcing)ã¨æ¨è«–(AR)ã®ã‚®ãƒ£ãƒƒãƒ— |
| Negative Log-Likelihood (NLL) | $-\log p(\mathbf{x})$ â€” ARè¨“ç·´ã®æå¤±é–¢æ•° |
| Bits-per-dimension (bpd) | ãƒ‡ãƒ¼ã‚¿1æ¬¡å…ƒã‚ãŸã‚Šã®æƒ…å ±é‡(ãƒ“ãƒƒãƒˆ) |
| Greedy Decoding | å¸¸ã«æœ€é«˜ç¢ºç‡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é¸æŠ |
| Sampling | ç¢ºç‡åˆ†å¸ƒã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é¸æŠ |
| Temperature | ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®å¤šæ§˜æ€§ã‚’åˆ¶å¾¡ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ |
| Top-k Sampling | ç¢ºç‡ä¸Šä½kå€‹ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° |
| Top-p (Nucleus) Sampling | ç´¯ç©ç¢ºç‡pä»¥ä¸Šã®ä¸Šä½ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° |
| Beam Search | è¤‡æ•°å€™è£œç³»åˆ—ã‚’ä¿æŒã™ã‚‹æ¢ç´¢æ‰‹æ³• |
| Masked Convolution | æœªæ¥ã®ãƒ”ã‚¯ã‚»ãƒ«ã‚’è¦‹ãªã„Conv |
| Blind Spot | Masked Convã®å—å®¹é‡ã®ç©´ |
| Gated Activation | $\tanh(f) \odot \sigma(g)$ å½¢å¼ã®æ´»æ€§åŒ– |
| Vertical/Horizontal Stack | PixelCNNã®Blind Spotè§£æ±ºç­– |
| Dilated Convolution | é–“éš”ã‚’ç©ºã‘ãŸç•³ã¿è¾¼ã¿(å—å®¹é‡æ‹¡å¤§) |
| Causal Convolution | æœªæ¥ã‚’è¦‹ãªã„Dilated Conv |
| Receptive Field | 1ãƒ”ã‚¯ã‚»ãƒ«ãŒå‚ç…§ã§ãã‚‹éå»ã®ç¯„å›² |
| Î¼-law Quantization | å¯¾æ•°åœ§ç¸®ã«ã‚ˆã‚‹éŸ³å£°é‡å­åŒ– |
| Raster Scan | å·¦ä¸Šâ†’å³ä¸‹ã®é †åº |
| Random Order | ãƒ©ãƒ³ãƒ€ãƒ ç½®æ›ã«ã‚ˆã‚‹é †åº |
| Multi-scale | ç²—â†’ç´°ã®è§£åƒåº¦é †åº |
| Bitwise AR | ãƒ“ãƒƒãƒˆå˜ä½ã®é †åº |
| VQ-VAE | é›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³ã«é‡å­åŒ–ã™ã‚‹VAE |
| Codebook | VQ-VAEã®é›¢æ•£è¡¨ç¾è¾æ›¸ |
| Discretized Logistic Mixture | PixelCNN++ã®é€£ç¶šå€¤ãƒ¢ãƒ‡ãƒ«åŒ– |
| Conditional Generation | ã‚¯ãƒ©ã‚¹/ãƒ†ã‚­ã‚¹ãƒˆæ¡ä»¶ä»˜ãç”Ÿæˆ |
| Class Embedding | ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ– |
| Residual Connection | $y = f(x) + x$ å½¢å¼ã®æ¥ç¶š |
| Skip Connection | æ·±ã„å±¤ã®å‡ºåŠ›ã‚’ç›´æ¥åˆè¨ˆ |
| Parallel WaveNet | WaveNetã®è’¸ç•™ã«ã‚ˆã‚‹ä¸¦åˆ—åŒ– |
| MaskGIT | Masked tokenäºˆæ¸¬ã«ã‚ˆã‚‹ä¸¦åˆ—åŒ– |
| MAR | Masked AR with Diffusion Loss |
| VAR | Visual AR with Multi-scale |
| FlowAR | VAR + Flow Matching |
| Infinity | Bitwise AR with infinite vocabulary |
| Non-Autoregressive (NAR) | ä¸¦åˆ—ç”Ÿæˆãƒ¢ãƒ‡ãƒ« |
| KV-Cache | Transformeræ¨è«–ã®é«˜é€ŸåŒ– |
| Scheduled Sampling | Teacher Forcingã¨ARã®ãƒãƒ©ãƒ³ã‚¹ |
| Exposure Bias | è¨“ç·´/æ¨è«–ã‚®ãƒ£ãƒƒãƒ— |
| Cumulative Error | ARé€æ¬¡ç”Ÿæˆã®èª¤å·®ç´¯ç© |
| Likelihood | $p(\mathbf{x})$ â€” ãƒ‡ãƒ¼ã‚¿ã®ç¢ºç‡ |
| Maximum Likelihood Estimation (MLE) | å°¤åº¦æœ€å¤§åŒ–ã«ã‚ˆã‚‹å­¦ç¿’ |
| Energy-Based Model (EBM) | $p(x) \propto \exp(-E(x))$ å½¢å¼ã®ãƒ¢ãƒ‡ãƒ« |
| Sparse Transformer | ã‚¹ãƒ‘ãƒ¼ã‚¹Attentionã«ã‚ˆã‚‹é•·ç³»åˆ—å¯¾å¿œ |
| Hierarchical AR | ç²—â†’ç´°ã®éšå±¤çš„ç”Ÿæˆ |
| Latent AR | VQ-VAE latentç©ºé–“ã§ã®AR |
| Point Cloud AR | 3Dç‚¹ç¾¤ã®é€æ¬¡ç”Ÿæˆ |
| Video AR | å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ ã®é€æ¬¡ç”Ÿæˆ |

:::

### 6.18 Knowledge Mindmap

```mermaid
graph TD
    AR[è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«] --> Theory[ç†è«–]
    AR --> Arch[ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£]
    AR --> App[å¿œç”¨]

    Theory --> Chain["é€£é–å¾‹<br/>p(x)=âˆp(x_i|x_{<i})"]
    Theory --> NLL["NLLæå¤±<br/>-Î£log p"]
    Theory --> Order["é †åºä¾å­˜æ€§<br/>Raster/Multi-scale"]

    Arch --> PixelCNN["PixelCNN<br/>Masked Conv"]
    Arch --> WaveNet["WaveNet<br/>Dilated Conv"]
    Arch --> VAR["VAR<br/>Multi-scale"]
    Arch --> Transformer["Transformer AR<br/>Causal Attention"]

    App --> Image["ç”»åƒç”Ÿæˆ<br/>VAR/Infinity"]
    App --> Audio["éŸ³å£°ç”Ÿæˆ<br/>WaveNet/TTS"]
    App --> Text["ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ<br/>GPT"]
    App --> Video["å‹•ç”»ç”Ÿæˆ<br/>VideoGPT"]

    PixelCNN --> Gating["Gated Activation"]
    PixelCNN --> Vertical["Vertical/Horizontal"]
    WaveNet --> Dilation["Dilation 2^k"]
    WaveNet --> Receptive["å—å®¹é‡ 2^L"]
    VAR --> NextScale["Next-Scale Prediction"]
    VAR --> Parallel["6500xä¸¦åˆ—åŒ–"]

    style AR fill:#ffeb3b
    style Theory fill:#e1f5fe
    style Arch fill:#c8e6c9
    style App fill:#f8bbd0
```

### 6.19 æ¨å¥¨è«–æ–‡ãƒªã‚¹ãƒˆ

| è«–æ–‡ | ã‚«ãƒ†ã‚´ãƒª | å„ªå…ˆåº¦ | èª­ã‚€ç†ç”± |
|:-----|:---------|:-------|:---------|
| PixelCNN [^1] | åŸºç¤ | â˜…â˜…â˜…â˜…â˜… | Gated/Masked Convã®åŸå…¸ |
| WaveNet [^2] | åŸºç¤ | â˜…â˜…â˜…â˜…â˜… | Dilated Convã®åŸå…¸ |
| PixelCNN++ [^5] | åŸºç¤ | â˜…â˜…â˜…â˜…â˜† | Logistic Mixtureã€å®Ÿç”¨åŒ– |
| VAR [^3] | æœ€æ–° | â˜…â˜…â˜…â˜…â˜… | 2024 Best Paperã€ARã®é€†è¥² |
| MAR [^6] | æœ€æ–° | â˜…â˜…â˜…â˜…â˜† | VQä¸è¦ã€Diffusion Loss |
| FlowAR [^7] | æœ€æ–° | â˜…â˜…â˜…â˜†â˜† | AR+FMèåˆ |
| Infinity [^9] | æœ€æ–° | â˜…â˜…â˜…â˜…â˜… | 2025 CVPR Oralã€æœ€é€Ÿ |
| MaskGIT [^8] | Non-AR | â˜…â˜…â˜…â˜…â˜† | ä¸¦åˆ—åŒ–ã€ç¬¬14å›ã¸ã®ä¼ç·š |
| AR Survey [^4] | Survey | â˜…â˜…â˜…â˜…â˜† | 2025å¹´ã®å…¨ä½“ä¿¯ç° |

**å­¦ç¿’é †åº**: PixelCNN [^1] â†’ WaveNet [^2] â†’ VAR [^3] â†’ MAR/FlowAR/Infinity ã§æœ€æ–°ã¾ã§ã€‚

:::details æ¨å¥¨æ›¸ç±
| æ›¸ç± | è‘—è€… | é–¢é€£ç«  |
|:-----|:-----|:-------|
| Deep Learning | Goodfellow+ | Ch.10(RNN), 20(ç”Ÿæˆ) |
| Probabilistic ML | Murphy | Ch.26(ARç³»åˆ—) |
| Speech and Language Processing | Jurafsky & Martin | Ch.7(Neural LM) |

æ›¸ç±ã¯åŸºç¤ã®ã¿ â€” æœ€æ–°ã¯arXivå¿…é ˆã€‚
:::

### 6.21 ç ”ç©¶ã®æœ€å‰ç·š(2026å¹´äºˆæ¸¬)

**Trend 1: ARã¨æ‹¡æ•£ã®å®Œå…¨èåˆ**
- FlowAR/MARãŒç¤ºã—ãŸæ–¹å‘æ€§ â€” é›¢æ•£/é€£ç¶šã®å¢ƒç•Œæ¶ˆå¤±
- äºˆæ¸¬: 2026å¹´ã«ã¯ã€ŒAR vs Diffusionã€ã®äºŒåˆ†æ³•ãŒç„¡æ„å‘³ã«

**Trend 2: 1-Step AR**
- InfinityãŒ0.8ç§’/ç”»åƒã‚’é”æˆ
- äºˆæ¸¬: DistillationæŠ€è¡“ã§ã•ã‚‰ã«é«˜é€ŸåŒ– â†’ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”Ÿæˆ

**Trend 3: Multimodal AR**
- Text+Image+Audio+Videoã‚’çµ±ä¸€ARç©ºé–“ã§æ‰±ã†
- GPT-4Vã‚„Geminiã®æ¬¡ä¸–ä»£ â€” å…¨ãƒ¢ãƒ€ãƒªãƒ†ã‚£ARåŒ–

**Trend 4: 3D AR**
- Point Cloud/Mesh/NeRFã®ARç”ŸæˆãŒæœ¬æ ¼åŒ–
- äºˆæ¸¬: CAD/ã‚²ãƒ¼ãƒ ã‚¢ã‚»ãƒƒãƒˆè‡ªå‹•ç”Ÿæˆ

**Trend 5: Adaptive Order AR**
- å›ºå®šé †åº(Raster/Multi-scale)ã§ã¯ãªãã€ãƒ‡ãƒ¼ã‚¿é©å¿œçš„é †åºã‚’å­¦ç¿’
- äºˆæ¸¬: é †åºè‡ªä½“ã‚’ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã§æœ€é©åŒ–

:::message
**é€²æ—: 95% å®Œäº†** 2024-2025æœ€æ–°ç ”ç©¶ã‚’å®Œå…¨ç¶²ç¾…ã—ãŸã€‚VAR/MAR/FlowAR/Infinityã®å…¨ã¦ãŒã€ŒARã¯æ‹¡æ•£ã«å‹ã¦ãªã„ã€ã¨ã„ã†å¸¸è­˜ã‚’è¦†ã—ãŸæ­´å²çš„è»¢æ›æœŸã‚’ç›®æ’ƒã—ãŸã€‚ã“ã“ã‹ã‚‰æŒ¯ã‚Šè¿”ã‚Šã‚¾ãƒ¼ãƒ³ã¸ â€” æœ¬è¬›ç¾©ã®å…¨ä½“ã‚’ç·æ‹¬ã™ã‚‹ã€‚
:::

---

### 6.22 ä»Šå›ã®å­¦ç¿’å†…å®¹

### 22.2 æœ¬è¬›ç¾©ã®3ã¤ã®æœ¬è³ª

**æœ¬è³ª1: é€£é–å¾‹ = å…¨ã¦ã®åŸºç¤**

$$
p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid \mathbf{x}_{<i})
$$

ã“ã®æ•°å­¦çš„äº‹å®ŸãŒã€VAE(ELBOè¿‘ä¼¼)ã‚„GAN(æš—é»™çš„å¯†åº¦)ã¨ã¯ç•°ãªã‚‹ã€Œå³å¯†ãªå°¤åº¦è¨ˆç®—ã€ã‚’å¯èƒ½ã«ã—ãŸã€‚

**æœ¬è³ª2: é †åº = æ€§èƒ½ã‚’æ±ºã‚ã‚‹**
- Raster Scan(PixelCNN): é…ã„ãŒç°¡å˜
- Random Order(MAR): ä¸¦åˆ—åŒ–å¯èƒ½
- Multi-scale(VAR): ç²—â†’ç´°ã§é«˜å“è³ª+é«˜é€Ÿ
- Bitwise(Infinity): èªå½™âˆã§æœ€é€Ÿ

é †åºã®é¸æŠãŒå…¨ã¦ã‚’å¤‰ãˆã‚‹ â€” ã“ã‚ŒãŒ2024-2025ã®å¤§ç™ºè¦‹ã ã£ãŸã€‚

**æœ¬è³ª3: ä¸¦åˆ—åŒ– = ARå¾©æ´»ã®éµ**
ã€ŒARã¯é€æ¬¡ã ã‹ã‚‰é…ã„ã€ã¯åŠåˆ†æ­£ã—ã„ã€‚ã—ã‹ã—:
- WaveNet: Dilated Convã§è¨“ç·´ä¸¦åˆ—åŒ–
- VAR: Multi-scaleã§6500å€ä¸¦åˆ—åŒ–
- Infinity: Bitwise + Transformerã§0.8ç§’/ç”»åƒ

ä¸¦åˆ—åŒ–ã®å·¥å¤«æ¬¡ç¬¬ã§ã€ARã¯æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šé€Ÿããªã‚‹ã€‚

### 22.3 Course IIã«ãŠã‘ã‚‹ä½ç½®ä»˜ã‘

```mermaid
graph LR
    A[ç¬¬9å›<br/>å¤‰åˆ†æ¨è«–] --> B[ç¬¬10å›<br/>VAE]
    B --> C[ç¬¬11å›<br/>æœ€é©è¼¸é€]
    C --> D[ç¬¬12å›<br/>GAN]
    D --> E["ç¬¬13å›<br/>è‡ªå·±å›å¸°<br/>(ä»Šå›)"]
    E --> F[ç¬¬14å›<br/>Attention]
    F --> G[ç¬¬15å›<br/>AttentionåŠ¹ç‡åŒ–]
    G --> H[ç¬¬16å›<br/>SSM/Mamba]

    style E fill:#ffeb3b
```

**å­¦ç¿’ã®æµã‚Œ**:
- ç¬¬9-11å›: å¤‰åˆ†æ¨è«–â†’VAEâ†’OT(é€£ç¶šæ½œåœ¨ç©ºé–“)
- ç¬¬12å›: GAN(æ•µå¯¾çš„å­¦ç¿’ã€å°¤åº¦ãªã—)
- **ç¬¬13å›: AR(å³å¯†å°¤åº¦ã€æ¡ä»¶ä»˜ãåˆ†è§£)** â† ä»Šã“ã“
- ç¬¬14-16å›: Attention/SSM(ARã®å—å®¹é‡ã‚’æ‹¡å¼µã™ã‚‹æ‰‹æ³•)

ARã¯ã€Œå°¤åº¦ã‚’æ¨ã¦ãªã„ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã€ã®æ±ºå®šç‰ˆ â€” VAE/GANã¨ã¯æ ¹æœ¬çš„ã«ç•°ãªã‚‹ã€‚

### 22.4 FAQ â€” ã‚ˆãã‚ã‚‹ç–‘å•

:::details Q1. ARã¨RNNã®é•ã„ã¯ï¼Ÿ

**RNN**: éš ã‚ŒçŠ¶æ…‹ $\mathbf{h}_t$ ã‚’æŒã¤ã€‚$p(x_t \mid \mathbf{h}_t)$ã€$\mathbf{h}_t = f(\mathbf{h}_{t-1}, x_{t-1})$ã€‚

**AR**: éš ã‚ŒçŠ¶æ…‹ãªã—ã€‚éå»ã®å…¨ã¦ $\mathbf{x}_{<t}$ ã‚’æ˜ç¤ºçš„ã«æ¡ä»¶ä»˜ã‘ã€‚$p(x_t \mid \mathbf{x}_{<t})$ã€‚

**å®Ÿè£…**: PixelCNN/WaveNetã¯Convã€Transformer ARã¯Attention â€” RNNã§ã¯ãªã„ã€‚

**æ­´å²**: RNNã¯å‹¾é…æ¶ˆå¤±ã§é•·è·é›¢ä¾å­˜ãŒå›°é›£ â†’ Transformer ARã§è§£æ±º(ç¬¬14å›ã§è©³è¿°)ã€‚
:::

:::details Q2. ARã¯æœ¬å½“ã«æ‹¡æ•£ã‚ˆã‚Šé€Ÿã„ã®ã‹ï¼Ÿ

**2023å¹´ã¾ã§**: æ‹¡æ•£ãŒåœ§å€’çš„ã«é€Ÿã‹ã£ãŸ(1ã‚¹ãƒ†ãƒƒãƒ— vs æ•°åƒã‚¹ãƒ†ãƒƒãƒ—AR)ã€‚

**2024-2025å¹´**:
- VAR: Multi-scaleã§10ã‚¹ãƒ†ãƒƒãƒ—(Raster 65536ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰æ¿€æ¸›)
- Infinity: 0.8ç§’/ç”»åƒ(SD3-Mediumã®2.6å€é€Ÿ)

**é€†è»¢**: ARå´ãŒã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é©æ–°(Multi-scale/Bitwise)ã§ä¸¦åˆ—åŒ–ã‚’æ¥µã‚ã€æ‹¡æ•£ã‚’è¶…ãˆãŸã€‚
:::

:::details Q3. PixelCNNã¯ä»Šã§ã‚‚ä½¿ã‚ã‚Œã‚‹ã‹ï¼Ÿ

**å®Ÿç”¨**: ã»ã¼ä½¿ã‚ã‚Œãªã„ã€‚VQ-VAE/VQGAN latentã®ARãŒä¸»æµã€‚

**å­¦è¡“çš„ä¾¡å€¤**: Masked Conv/Gatingã®åŸå…¸ã¨ã—ã¦ä¸æœ½ â€” å…¨ã¦ã®å¾Œç¶šæ‰‹æ³•ãŒã“ã®éºç”£ã‚’å¼•ãç¶™ãã€‚

**æ•™è‚²çš„ä¾¡å€¤**: ARã®æœ¬è³ª(é€£é–å¾‹/Causal Masking)ã‚’å­¦ã¶æœ€è‰¯ã®æ•™æã€‚
:::

:::details Q4. WaveNetã¯éŸ³å£°ä»¥å¤–ã«ä½¿ãˆã‚‹ã‹ï¼Ÿ

**æ™‚ç³»åˆ—å…¨èˆ¬**: æ ªä¾¡/æ°—è±¡/ã‚»ãƒ³ã‚µãƒ‡ãƒ¼ã‚¿ãªã©ã€1Dç³»åˆ—ãªã‚‰å…¨ã¦é©ç”¨å¯èƒ½ã€‚

**ç”»åƒ**: PixelCNNãŒWaveNetã®2Dç‰ˆ â€” Dilated Conv + Gatingã¯å…±é€šã€‚

**å‹•ç”»**: VideoWaveNetã‚‚ææ¡ˆã•ã‚ŒãŸ(ãŸã ã—ç¾åœ¨ã¯3D Convã‚„Video TransformerãŒä¸»æµ)ã€‚
:::

:::details Q5. ARãƒ¢ãƒ‡ãƒ«ã¯ä½•ã«å‘ã„ã¦ã„ã‚‹ã‹ï¼Ÿ

**å‘ã„ã¦ã„ã‚‹**:
- å°¤åº¦è©•ä¾¡ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯(ç•°å¸¸æ¤œçŸ¥/åœ§ç¸®/å¯†åº¦æ¨å®š)
- é•·ã„æ–‡è„ˆä¾å­˜(ãƒ†ã‚­ã‚¹ãƒˆ/éŸ³å£°)
- æ¡ä»¶ä»˜ãç”Ÿæˆ(class/text-to-image)

**å‘ã„ã¦ã„ãªã„**:
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”Ÿæˆ(é€æ¬¡æ€§ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã€ãŸã ã—Infinityã§æ”¹å–„)
- æ½œåœ¨ç©ºé–“è£œé–“(ARã¯é›¢æ•£çš„ã€VAEã®æ–¹ãŒå¾—æ„)

**ç¾åœ¨ã®ä¸»æˆ¦å ´**: è¨€èªãƒ¢ãƒ‡ãƒ«(GPT-4ãªã©) + ç”»åƒ(VAR/Infinity)ã€‚
:::

### 22.5 å­¦ç¿’é€²æ—ãƒã‚§ãƒƒã‚¯

| é …ç›® | å®Œäº†? |
|:-----|:------|
| é€£é–å¾‹ã‚’è¨¼æ˜ã§ãã‚‹ | â–¡ |
| PixelCNN Blind Spotå•é¡Œã‚’èª¬æ˜ã§ãã‚‹ | â–¡ |
| WaveNetå—å®¹é‡ $2^L$ ã‚’å°å‡ºã§ãã‚‹ | â–¡ |
| NLLæå¤±ã‚’ã‚³ãƒ¼ãƒ‰å®Ÿè£…ã§ãã‚‹ | â–¡ |
| VAR/MARã®è²¢çŒ®ã‚’1æ–‡ã§è¨€ãˆã‚‹ | â–¡ |
| Julia/Rustã§ARæ¨è«–ã‚’æ›¸ã‘ã‚‹ | â–¡ |
| ARã¨VAE/GANã®æœ¬è³ªçš„é•ã„ã‚’èª¬æ˜ã§ãã‚‹ | â–¡ |

å…¨ã¦â–¡â†’â˜‘ãªã‚‰ã€æœ¬è¬›ç¾©ã‚’å®Œå…¨ç¿’å¾—ã—ã¦ã„ã‚‹ã€‚

### 22.6 1é€±é–“ã®å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

| æ—¥ | å†…å®¹ | æ™‚é–“ | ç›®æ¨™ |
|:---|:-----|:-----|:-----|
| 1 | Z0-Z2 | 30åˆ† | ARç›´æ„Ÿç²å¾— |
| 2 | Z3.1-3.3 | 60åˆ† | é€£é–å¾‹/NLLå®Œå…¨ç†è§£ |
| 3 | Z3.4 | 30åˆ† | PixelCNNæ•°å­¦ |
| 4 | Z3.5 | 30åˆ† | WaveNetæ•°å­¦ |
| 5 | Z4 | 60åˆ† | Juliaå®Ÿè£… |
| 6 | Z5 | 60åˆ† | Tiny PixelCNNè¨“ç·´ |
| 7 | Z6 | 30åˆ† | æœ€æ–°ç ”ç©¶ä¿¯ç° |

**åˆè¨ˆ**: 5æ™‚é–“(æ¾å°¾ç ”1å›åˆ†ã¨åŒç­‰ã®æ™‚é–“ã§ã€10å€ã®å†…å®¹ã‚’ç¿’å¾—)ã€‚

### 22.7 Progress Tracker

```julia
# Self-assessment: Run this BEFORE and AFTER studying this lecture
function ar_understanding_test()
    questions = [
        "What is the chain rule formula for p(x)?",
        "Why does PixelCNN need masked convolution?",
        "What is the receptive field of WaveNet with 10 layers (kernel=2)?",
        "What is the difference between AR and RNN?",
        "Name 3 AR models from 2024-2025.",
        "Can you implement NLL loss in Julia?",
        "Why did VAR win NeurIPS 2024 Best Paper?",
        "What is Causal Masking?"
    ]

    println("AR Understanding Test (8 questions)")
    println("Answer each question, then check your score:\n")

    correct = 0
    for (i, q) in enumerate(questions)
        println("Q$i: $q")
        print("Your answer (press Enter to skip): ")
        readline()  # User types answer
        print("Correct? (y/n): ")
        ans = readline()
        if lowercase(ans) == "y"
            correct += 1
        end
        println()
    end

    score = correct / length(questions) * 100
    println("="^50)
    println("Score: $correct / $(length(questions)) = $(round(score, digits=1))%")

    if score >= 80
        println("ğŸ‰ Excellent! AR fully mastered.")
    elseif score >= 60
        println("âœ… Good! Review Z3 for deeper understanding.")
    else
        println("ğŸ“š Keep studying! Re-read Z0-Z3.")
    end
end

# Run before studying
# ar_understanding_test()
# ... study lecture ...
# Run after studying
# ar_understanding_test()
```

### 22.8 æ¬¡å›äºˆå‘Š â€” ç¬¬14å›: Attention

**ç¬¬14å›ã®ãƒ†ãƒ¼ãƒ**: RNN/CNNã®é™ç•Œ â†’ Attentionã®å¿…ç„¶æ€§ â†’ Transformer â†’ GPT/BERT

**æ¥ç¶š**:
- ç¬¬13å›(ä»Šå›): ARã¯ã€Œæ¡ä»¶ä»˜ãåˆ†è§£ã§å°¤åº¦ã‚’è¨ˆç®—ã€
- ç¬¬14å›: Attention = ARã®å—å®¹é‡ã‚’ $O(N^2)$ ã§å…¨ç³»åˆ—ã«æ‹¡å¤§

**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**:
- Self-Attention / Multi-Head Attention
- Positional Encoding (RoPE/ALiBi)
- Causal Attention = AR Transformer
- Scaling Laws / Emergent Abilities
- In-Context Learning / KV-Cache

**äºˆç¿’**: ç¬¬1-3å›ã®AttentionåŸºç¤(QKV/Softmax)ã‚’å¾©ç¿’ã—ã¦ãŠãã¨ç†è§£ãŒåŠ é€Ÿã™ã‚‹ã€‚

**ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³**:
PixelCNNã®å—å®¹é‡ã¯æœ‰é™(CNNåˆ¶ç´„)ã€WaveNetã‚‚ $2^L$ ã¾ã§ã€‚å…¨ç³»åˆ—ã‚’ä¸€åº¦ã«å‚ç…§ã™ã‚‹ã«ã¯ **Self-Attention** ãŒå¿…è¦ã ã£ãŸã€‚ã“ã‚ŒãŒ2017å¹´ "Attention is All You Need" (Vaswani+)ã®é©å‘½ã ã£ãŸã€‚

ç¬¬14å›ã§Attentionã®æ•°å­¦ã¨Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å®Œå…¨åˆ¶è¦‡ã—ã€ç¬¬15å›ã§Flash Attention/MoE/Sparse Attentionãªã©åŠ¹ç‡åŒ–æ‰‹æ³•ã€ç¬¬16å›ã§Mamba(SSM)ã¨ã„ã†ã€ŒAttentionã®ä»£æ›¿ã€ã‚’å­¦ã¶ã€‚

Course IIã®ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹ã¸ â€” ã€ŒåŒ–çŸ³(RNN/CNN)ã‹ã‚‰ã®è„±å´ã€ã®ç‰©èªãŒå®Œçµã™ã‚‹ã€‚

:::message
**é€²æ—: 100% å®Œäº†** ğŸ‰

æœ¬è¬›ç¾©ã€Œç¬¬13å›: è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«ã€ã‚’å®Œå…¨åˆ¶è¦‡ã—ãŸã€‚é€£é–å¾‹ã®å³å¯†ãªè¨¼æ˜ã‹ã‚‰ã€PixelCNN/WaveNetã®å®Ÿè£…ã€2024-2025æœ€æ–°ç ”ç©¶(VAR/MAR/FlowAR/Infinity)ã¾ã§ã€ARã®å…¨ã¦ã‚’ç¶²ç¾…ã—ãŸã€‚

**é”æˆäº‹é …**:
- é€£é–å¾‹ $p(\mathbf{x}) = \prod p(x_i \mid \mathbf{x}_{<i})$ ã®è¨¼æ˜
- PixelCNN Gatedæ§‹é€  + Blind Spotè§£æ±º
- WaveNet Dilated Conv + å—å®¹é‡ $2^L$ å°å‡º
- Julia/Rustå®Ÿè£…(è¨“ç·´+æ¨è«–)
- VAR(NeurIPS Best)ã‹ã‚‰Infinity(CVPR Oral)ã¾ã§æœ€æ–°ç ”ç©¶ä¿¯ç°

**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**: ç¬¬14å› Attention ã§ã€ŒARã®å—å®¹é‡ã‚’å…¨ç³»åˆ—ã«æ‹¡å¤§ã€ã™ã‚‹é©å‘½ã‚’å­¦ã¶ã€‚
:::

---

### 6.27 ğŸ’€ ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„

**"ARã®æœ¬è³ªã¯æ¡ä»¶ä»˜ãåˆ†è§£ã€‚ã“ã®ã€Œå½“ãŸã‚Šå‰ã€ãŒå…¨ã¦ã§ã¯ãªã„ã®ã‹ï¼Ÿ"**

PixelCNN/WaveNet/GPT/VAR â€” å…¨ã¦ã¯ $p(\mathbf{x}) = \prod p(x_i \mid \mathbf{x}_{<i})$ ã¨ã„ã†å˜ä¸€ã®å¼ã‹ã‚‰ç”Ÿã¾ã‚ŒãŸã€‚é€£é–å¾‹ã¯æ•°å­¦çš„äº‹å®Ÿã§ã‚ã‚Šã€ç™ºæ˜ã§ã¯ãªã„ã€‚

ã§ã¯ã€ãªãœ2024å¹´ã¾ã§ã€ŒARã¯é…ã„ã€æ‹¡æ•£ãŒé€Ÿã„ã€ã¨ä¿¡ã˜ã‚‰ã‚Œã¦ã„ãŸã®ã‹ã€‚

**ç­”ãˆ**: é †åºã®é¸æŠã‚’ç–‘ã‚ãªã‹ã£ãŸã‹ã‚‰ã€‚

- PixelCNN: Raster Scan(å·¦ä¸Šâ†’å³ä¸‹)ã‚’ã€Œå½“ç„¶ã€ã¨ã—ãŸ
- æ‹¡æ•£: ä¸¦åˆ—ãƒã‚¤ã‚ºé™¤å»ã‚’ã€Œå½“ç„¶ã€ã¨ã—ãŸ

VARãŒã€Œè§£åƒåº¦é †åº(ç²—â†’ç´°)ã€ã‚’é¸ã‚“ã ç¬é–“ã€ARã¯æ‹¡æ•£ã‚’è¶…ãˆãŸ [^3]ã€‚InfinityãŒã€Œãƒ“ãƒƒãƒˆé †åºã€ã‚’é¸ã‚“ã ç¬é–“ã€ARã¯æœ€é€Ÿã«ãªã£ãŸ [^9]ã€‚

**å•ã„ç›´ã—**:
- é †åºã¯æœ¬å½“ã«ã€Œå·¦â†’å³ã€ã§ãªã‘ã‚Œã°ãªã‚‰ãªã„ã®ã‹ï¼Ÿ
- é€£é–å¾‹ã®åˆ†è§£ã¯ä¸€æ„ã§ã¯ãªã„ â€” ãªã‚‰ã°æœ€é©é †åºã¯ï¼Ÿ
- ã€Œä¸¦åˆ—æ€§ã€ã¨ã€Œè‡ªå·±å›å¸°æ€§ã€ã¯æœ¬å½“ã«å¯¾ç«‹ã™ã‚‹ã®ã‹ï¼Ÿ

MARã¨MaskGITã¯ã€Œãƒ©ãƒ³ãƒ€ãƒ é †åºã€ã§ARã‚’ä¸¦åˆ—åŒ–ã—ãŸã€‚VAR/FlowARã¯ã€Œéšå±¤é †åºã€ã§ç²—ã‹ã‚‰ç´°ã¸ç”Ÿæˆã—ãŸã€‚Infinityã¯ã€Œãƒ“ãƒƒãƒˆé †åºã€ã§èªå½™ã‚’ç„¡é™ã«æ‹¡å¼µã—ãŸã€‚

**æœ¬è³ªçš„ãªå•ã„**: ARã¨æ‹¡æ•£ã®å¢ƒç•Œã¯ã©ã“ã«ã‚ã‚‹ã®ã‹ï¼Ÿ

FlowAR [^7] ã¯AR(é›¢æ•£ã‚¹ãƒ†ãƒƒãƒ—)ã¨æ‹¡æ•£(é€£ç¶šæ™‚é–“ODE)ã‚’èåˆã—ãŸã€‚MAR [^6] ã¯AR(é †åºã‚ã‚Š)ã¨æ‹¡æ•£(Diffusion Loss)ã‚’èåˆã—ãŸã€‚ä¸¡è€…ã®åŒºåˆ¥ã¯æ¬¡ç¬¬ã«æ›–æ˜§ã«ãªã£ã¦ã„ã‚‹ã€‚

**çµè«–**: ã€ŒARã¯é…ã„ã€ã¯æŠ€è¡“çš„åˆ¶ç´„ã§ã‚ã£ã¦ã€æœ¬è³ªçš„åˆ¶ç´„ã§ã¯ãªã‹ã£ãŸã€‚é€£é–å¾‹ã¨ã„ã†æ•°å­¦çš„åŸºç›¤ã®ä¸Šã§ã€é †åºãƒ»ä¸¦åˆ—åŒ–ãƒ»ãƒ¢ãƒ‡ãƒ«åŒ–ã®å·¥å¤«æ¬¡ç¬¬ã§ã€ARã¯ç„¡é™ã®å¯èƒ½æ€§ã‚’æŒã¤ã€‚

2026å¹´ã€ARã¯ã©ã“ã¾ã§é€²åŒ–ã™ã‚‹ã®ã‹ã€‚ãã®ç­”ãˆã¯ã€ã¾ã èª°ã‚‚çŸ¥ã‚‰ãªã„ã€‚

---

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: van den Oord, A., Kalchbrenner, N., Vinyals, O., Espeholt, L., Graves, A., & Kavukcuoglu, K. (2016). Conditional Image Generation with PixelCNN Decoders. *NeurIPS 2016*.
@[card](https://arxiv.org/abs/1606.05328)

[^2]: van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Senior, A., & Kavukcuoglu, K. (2016). WaveNet: A Generative Model for Raw Audio. *arXiv:1609.03499*.
@[card](https://arxiv.org/abs/1609.03499)

[^3]: Tian, K., Jiang, Y., Yuan, Z., Peng, B., & Wang, L. (2024). Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction. *NeurIPS 2024 (Best Paper Award)*.
@[card](https://arxiv.org/abs/2404.02905)

[^4]: Tao, C., et al. (2025). Autoregressive Models in Vision: A Survey. *TMLR 2025*.
@[card](https://arxiv.org/abs/2411.05902)

[^5]: Salimans, T., Karpathy, A., Chen, X., & Kingma, D. P. (2017). PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications. *ICLR 2017*.
@[card](https://arxiv.org/abs/1701.05517)

[^6]: Li, T., et al. (2024). Autoregressive Image Generation without Vector Quantization. *NeurIPS 2024*.
@[card](https://arxiv.org/abs/2406.11838)

[^7]: Ren, S., et al. (2024). FlowAR: Scale-wise Autoregressive Image Generation Meets Flow Matching. *arXiv:2412.15205*.
@[card](https://arxiv.org/abs/2412.15205)

[^8]: Chang, H., Zhang, H., Jiang, L., Liu, C., & Freeman, W. T. (2022). MaskGIT: Masked Generative Image Transformer. *CVPR 2022*.
@[card](https://arxiv.org/abs/2202.04200)

[^9]: Han, J., Liu, J., Jiang, Y., et al. (2025). Infinity: Scaling Bitwise AutoRegressive Modeling for High-Resolution Image Synthesis. *CVPR 2025 (Oral)*.
@[card](https://arxiv.org/abs/2412.04431)

### æ•™ç§‘æ›¸

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press. [Ch.10: Sequence Modeling, Ch.20: Deep Generative Models]
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press. [Ch.26: Autoregressive Sequence Models]

---

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

---

## è¨˜æ³•è¦ç´„

| è¨˜å· | èª­ã¿ | æ„å‘³ |
|:-----|:-----|:-----|
| $\mathbf{x}$ | ãƒœãƒ¼ãƒ«ãƒ‰ ã‚¨ãƒƒã‚¯ã‚¹ | ãƒ‡ãƒ¼ã‚¿(ãƒ™ã‚¯ãƒˆãƒ«) |
| $x_i$ | ã‚¨ãƒƒã‚¯ã‚¹ ã‚¢ã‚¤ | ãƒ‡ãƒ¼ã‚¿ã®ç¬¬ $i$ è¦ç´  |
| $\mathbf{x}_{<i}$ | ã‚¨ãƒƒã‚¯ã‚¹ ãƒ¬ã‚¹ ã‚¢ã‚¤ | ä½ç½® $i$ ã‚ˆã‚Šå‰ã®å…¨è¦ç´  $(x_1, \dots, x_{i-1})$ |
| $p(\mathbf{x})$ | ãƒ”ãƒ¼ ã‚ªãƒ– ã‚¨ãƒƒã‚¯ã‚¹ | ç¢ºç‡åˆ†å¸ƒ(åŒæ™‚åˆ†å¸ƒ) |
| $p(x_i \mid \mathbf{x}_{<i})$ | ãƒ”ãƒ¼ ã‚ªãƒ– ã‚¨ãƒƒã‚¯ã‚¹ ã‚¢ã‚¤ ã‚®ãƒ–ãƒ³ ã‚¨ãƒƒã‚¯ã‚¹ ãƒ¬ã‚¹ ã‚¢ã‚¤ | æ¡ä»¶ä»˜ãåˆ†å¸ƒ |
| $\theta$ | ã‚·ãƒ¼ã‚¿ | ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ |
| $\mathcal{L}_\text{NLL}$ | ã‚¨ãƒ« ã‚µãƒ– ã‚¨ãƒŒã‚¨ãƒ«ã‚¨ãƒ« | è² å¯¾æ•°å°¤åº¦(Negative Log-Likelihood) |
| $\log$ | ãƒ­ã‚° | è‡ªç„¶å¯¾æ•°($\ln$) |
| $\prod$ | ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆ | ç©(Product) |
| $\sum$ | ã‚µãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ | å’Œ(Summation) |
| $\odot$ | ã‚ªãƒ¼ãƒ‰ãƒƒãƒˆ | è¦ç´ ã”ã¨ã®ç©(Hadamard product) |
| $*$ | ã‚¢ã‚¹ãƒ†ãƒªã‚¹ã‚¯ | ç•³ã¿è¾¼ã¿(Convolution) |
| $\sigma$ | ã‚·ã‚°ãƒ | ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯é–¢æ•° $1/(1+e^{-x})$ |
| $\tanh$ | ã‚¿ãƒ³ã‚¸ã‚§ãƒ³ãƒˆãƒã‚¤ãƒ‘ãƒœãƒªãƒƒã‚¯ | åŒæ›²ç·šæ­£æ¥é–¢æ•° |
| $\mathbf{W}$ | ãƒœãƒ¼ãƒ«ãƒ‰ ãƒ€ãƒ–ãƒªãƒ¥ãƒ¼ | é‡ã¿è¡Œåˆ—(Weight matrix) |
| $d$ | ãƒ‡ã‚£ãƒ¼ | Dilation rate |
| $K$ | ã‚±ãƒ¼ | ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º |
| $D$ | ãƒ‡ã‚£ãƒ¼ | ãƒ‡ãƒ¼ã‚¿æ¬¡å…ƒ(ç”»åƒãªã‚‰ $H \times W \times C$) |
| $N$ | ã‚¨ãƒŒ | ã‚µãƒ³ãƒ—ãƒ«æ•° |
| bpd | ãƒ“ãƒ¼ãƒ”ãƒ¼ãƒ‡ã‚£ãƒ¼ | Bits-per-dimension |

**ã‚³ãƒ¼ãƒ‰å¤‰æ•°å‘½åè¦å‰‡**:
- Julia: `x`, `theta`, `log_prob`, `conditional_probs`(æ•°å¼ãã®ã¾ã¾)
- Rust: `x`, `theta`, `log_prob`, `conditional_probs`(snake_case)