---
title: "ç¬¬11å›: æœ€é©è¼¸é€ç†è«–: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼""
emoji: "ğŸš›"
type: "tech"
topics: ["machinelearning", "deeplearning", "optimaltransport", "julia", "rust"]
published: true
---

# ç¬¬11å›: æœ€é©è¼¸é€ç†è«– â€” ç¢ºç‡åˆ†å¸ƒã‚’é‹ã¶æ•°å­¦

> **2ã¤ã®ç¢ºç‡åˆ†å¸ƒãŒã‚ã‚‹ã¨ãã€ä¸€æ–¹ã‚’ä»–æ–¹ã«ã€Œæœ€å°ã‚³ã‚¹ãƒˆã§å¤‰å½¢ã™ã‚‹ã€æ–¹æ³•ã‚’å®šã‚ã‚‹ç†è«–ã€‚GANã€Flow Matchingã€Diffusion Modelã®æ•°å­¦çš„åŸºç›¤ãŒã“ã“ã«ã‚ã‚‹ã€‚**

ç ‚å±±ã‚’åˆ¥ã®å½¢ã«å¤‰ãˆã‚‹ã¨ãã€ã©ã†åœŸã‚’å‹•ã‹ã›ã°æœ€ã‚‚åŠ¹ç‡çš„ã‹ã€‚å·¥å ´ã‹ã‚‰å€‰åº«ã¸è·ç‰©ã‚’é‹ã¶ã¨ãã€ã©ã®ãƒ«ãƒ¼ãƒˆãŒæœ€å®‰ã‹ã€‚ã“ã‚Œã‚‰ã¯1781å¹´ã«MongeãŒæèµ·ã—ãŸ **æœ€é©è¼¸é€å•é¡Œ** (Optimal Transport) ã ã€‚240å¹´ã‚’çµŒã¦ã€ã“ã®å¤å…¸çš„å•é¡ŒãŒç¾ä»£ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ« â€” GANã€Flow Matchingã€Diffusion Model â€” ã®ç†è«–çš„æ”¯æŸ±ã«ãªã£ã¦ã„ã‚‹ã€‚

æœ¬è¬›ç¾©ã¯Course IIã€Œç”Ÿæˆãƒ¢ãƒ‡ãƒ«ç†è«–ç·¨ã€ã®ç¬¬3å›ã€‚ç¬¬9å›ã§å¤‰åˆ†æ¨è«–ã¨ELBOã‚’å­¦ã³ã€ç¬¬10å›ã§VAEã‚’ç¿’å¾—ã—ãŸã€‚ä»Šå›ã¯ã€VAEã¨ã¯å…¨ãç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ â€” **ç¢ºç‡åˆ†å¸ƒãã®ã‚‚ã®ã‚’å¹¾ä½•å­¦çš„ã«æ‰±ã†** â€” ã‚’å­¦ã¶ã€‚Wassersteinè·é›¢ã€Sinkhornç®—æ³•ã€ãã—ã¦Flow Matchingã¸ã®æ©‹æ¸¡ã—ã¾ã§ã€ä¸€æ°—ã«é§†ã‘æŠœã‘ã‚‹ã€‚

:::message
**ã“ã®ã‚·ãƒªãƒ¼ã‚ºã«ã¤ã„ã¦**: æ±äº¬å¤§å­¦ æ¾å°¾ãƒ»å²©æ¾¤ç ”ç©¶å®¤å‹•ç”»è¬›ç¾©ã®**å®Œå…¨ä¸Šä½äº’æ›**ã®å…¨50å›ã‚·ãƒªãƒ¼ã‚ºã€‚ç†è«–ï¼ˆè«–æ–‡ãŒæ›¸ã‘ã‚‹ï¼‰ã€å®Ÿè£…ï¼ˆProduction-readyï¼‰ã€æœ€æ–°ï¼ˆ2025-2026 SOTAï¼‰ã®3è»¸ã§å·®åˆ¥åŒ–ã™ã‚‹ã€‚
:::

```mermaid
graph LR
    A["ğŸ“Š åˆ†å¸ƒ Î¼"] --> B["ğŸš› æœ€é©è¼¸é€<br/>Monge-Kantorovich"]
    B --> C["ğŸ“ Wassersteinè·é›¢<br/>Wâ‚‚(Î¼,Î½)"]
    C --> D["âš¡ Sinkhornç®—æ³•<br/>Entropic OT"]
    D --> E["ğŸŒŠ Flow Matching<br/>Rectified Flow"]
    style A fill:#e1f5fe
    style C fill:#fff3e0
    style E fill:#c8e6c9
```

**æ‰€è¦æ™‚é–“ã®ç›®å®‰**:

| ã‚¾ãƒ¼ãƒ³ | å†…å®¹ | æ™‚é–“ | é›£æ˜“åº¦ |
|:-------|:-----|:-----|:-------|
| Zone 0 | ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ | 30ç§’ | â˜…â˜†â˜†â˜†â˜† |
| Zone 1 | ä½“é¨“ã‚¾ãƒ¼ãƒ³ | 10åˆ† | â˜…â˜…â˜†â˜†â˜† |
| Zone 2 | ç›´æ„Ÿã‚¾ãƒ¼ãƒ³ | 15åˆ† | â˜…â˜…â˜…â˜†â˜† |
| Zone 3 | æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ | 60åˆ† | â˜…â˜…â˜…â˜…â˜… |
| Zone 4 | å®Ÿè£…ã‚¾ãƒ¼ãƒ³ | 45åˆ† | â˜…â˜…â˜…â˜…â˜† |
| Zone 5 | å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ | 30åˆ† | â˜…â˜…â˜…â˜…â˜† |
| Zone 6 | æŒ¯ã‚Šè¿”ã‚Šã‚¾ãƒ¼ãƒ³ | 30åˆ† | â˜…â˜…â˜…â˜…â˜† |

---

## ğŸš€ 0. ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆ30ç§’ï¼‰â€” 2ã¤ã®åˆ†å¸ƒã‚’ã¤ãªãæœ€çŸ­çµŒè·¯

**ã‚´ãƒ¼ãƒ«**: æœ€é©è¼¸é€ã¨Wassersteinè·é›¢ã®å¨åŠ›ã‚’30ç§’ã§ä½“æ„Ÿã™ã‚‹ã€‚

2ã¤ã®1æ¬¡å…ƒã‚¬ã‚¦ã‚¹åˆ†å¸ƒãŒã‚ã‚‹ã€‚ç‰‡æ–¹ã‚’ã‚‚ã†ç‰‡æ–¹ã«ã€Œå¤‰å½¢ã€ã™ã‚‹ã¨ãã€æœ€ã‚‚åŠ¹ç‡çš„ãªå¤‰æ›ã¯ä½•ã‹ã€‚ãã‚Œã‚’å®šé‡åŒ–ã™ã‚‹ã®ãŒWassersteinè·é›¢ $W_2$ ã ã€‚

```julia
using Distributions, LinearAlgebra

# Two 1D Gaussians: Î¼â‚€ ~ N(0, 1), Î¼â‚ ~ N(3, 0.5Â²)
Î¼â‚€ = Normal(0.0, 1.0)
Î¼â‚ = Normal(3.0, 0.5)

# For 1D Gaussians, Wâ‚‚Â² has closed form:
# Wâ‚‚Â²(N(mâ‚€,sâ‚€Â²), N(mâ‚,sâ‚Â²)) = (mâ‚-mâ‚€)Â² + (sâ‚-sâ‚€)Â²
m0, s0 = mean(Î¼â‚€), std(Î¼â‚€)
m1, s1 = mean(Î¼â‚), std(Î¼â‚)

W2_squared = (m1 - m0)^2 + (s1 - s0)^2
W2 = sqrt(W2_squared)

println("Wasserstein distance Wâ‚‚(Î¼â‚€, Î¼â‚) = $(round(W2, digits=3))")
println("Distance breakdown: location = $(abs(m1-m0)), scale = $(abs(s1-s0))")

# Optimal transport map: T(x) = (sâ‚/sâ‚€)(x - mâ‚€) + mâ‚
T(x) = (s1 / s0) * (x - m0) + m1

# Verify: push-forward Î¼â‚€ through T should equal Î¼â‚
x_samples = rand(Î¼â‚€, 10000)
T_samples = T.(x_samples)
println("Original: mean=$(round(mean(x_samples), digits=2)), std=$(round(std(x_samples), digits=2))")
println("Transported: mean=$(round(mean(T_samples), digits=2)), std=$(round(std(T_samples), digits=2))")
println("Target Î¼â‚: mean=$(m1), std=$(s1)")
```

å‡ºåŠ›:
```
Wasserstein distance Wâ‚‚(Î¼â‚€, Î¼â‚) = 3.041
Distance breakdown: location = 3.0, scale = 0.5
Original: mean=0.0, std=1.0
Transported: mean=3.0, std=0.5
Target Î¼â‚: mean=3.0, std=0.5
```

**ãŸã£ãŸ1è¡Œã®å¤‰æ› `T(x)` ãŒã€åˆ†å¸ƒ $\mu_0$ ã‚’ $\mu_1$ ã«å®Œå…¨ã«ä¸€è‡´ã•ã›ã¦ã„ã‚‹ã€‚** ã“ã‚ŒãŒæœ€é©è¼¸é€å†™åƒ (Monge map) ã®å¨åŠ›ã ã€‚

ã“ã®èƒŒå¾Œã«ã‚ã‚‹æ•°å¼:

$$
W_2^2(\mu, \nu) = \inf_{\gamma \in \Pi(\mu, \nu)} \int_{\mathbb{R}^d \times \mathbb{R}^d} \|x - y\|^2 \, d\gamma(x, y)
$$

ã€Œçµåˆæ¸¬åº¦ $\gamma$ ã®ã†ã¡ã€å‘¨è¾ºåˆ†å¸ƒãŒ $\mu$ ã¨ $\nu$ ã«ä¸€è‡´ã™ã‚‹ã‚‚ã®å…¨ä½“ã‹ã‚‰ã€è¼¸é€ã‚³ã‚¹ãƒˆ $\int \|x - y\|^2 d\gamma$ ã‚’æœ€å°åŒ–ã€ã¨ã„ã†æ„å‘³ã ã€‚ã‚¬ã‚¦ã‚¹åˆ†å¸ƒã®å ´åˆã€ã“ã®æœ€å°å€¤ã«ã¯é–‰å½¢å¼è§£ãŒã‚ã‚‹ã€‚

:::message
**é€²æ—: 3% å®Œäº†** Wassersteinè·é›¢ãŒã€Œåˆ†å¸ƒé–“ã®è·é›¢ã€ã‚’å®šã‚ã€æœ€é©è¼¸é€å†™åƒãŒã€Œæœ€çŸ­çµŒè·¯ã§ã®å¤‰å½¢ã€ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã‚’ä½“æ„Ÿã—ãŸã€‚ã“ã“ã‹ã‚‰ç†è«–ã®æ·±ã¿ã«å…¥ã‚‹ã€‚
:::

---

## ğŸ® 1. ä½“é¨“ã‚¾ãƒ¼ãƒ³ï¼ˆ10åˆ†ï¼‰â€” ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å‹•ã‹ã—ã¦ç†è§£ã™ã‚‹

### 1.1 2æ¬¡å…ƒã§ã®æœ€é©è¼¸é€ã‚’å¯è¦–åŒ–ã™ã‚‹

1æ¬¡å…ƒã§ã¯ç›´æ„Ÿçš„ã ã£ãŸãŒã€2æ¬¡å…ƒä»¥ä¸Šã§ã¯ã©ã†ãªã‚‹ã‹ã€‚ã‚¬ã‚¦ã‚¹åˆ†å¸ƒåŒå£«ãªã‚‰ã€ã‚„ã¯ã‚Šé–‰å½¢å¼è§£ãŒã‚ã‚‹ã€‚

$$
W_2^2(\mathcal{N}(\boldsymbol{m}_0, \Sigma_0), \mathcal{N}(\boldsymbol{m}_1, \Sigma_1)) = \|\boldsymbol{m}_1 - \boldsymbol{m}_0\|^2 + \text{tr}\left(\Sigma_0 + \Sigma_1 - 2(\Sigma_1^{1/2} \Sigma_0 \Sigma_1^{1/2})^{1/2}\right)
$$

| è¨˜å· | èª­ã¿ | æ„å‘³ |
|:-----|:-----|:-----|
| $\boldsymbol{m}_0, \boldsymbol{m}_1$ | ãƒœãƒ¼ãƒ«ãƒ‰ ã‚¨ãƒ  ã‚¼ãƒ­ã€ãƒœãƒ¼ãƒ«ãƒ‰ ã‚¨ãƒ  ãƒ¯ãƒ³ | å„åˆ†å¸ƒã®å¹³å‡ãƒ™ã‚¯ãƒˆãƒ« |
| $\Sigma_0, \Sigma_1$ | ã‚·ã‚°ãƒ ã‚¼ãƒ­ã€ã‚·ã‚°ãƒ ãƒ¯ãƒ³ | å„åˆ†å¸ƒã®å…±åˆ†æ•£è¡Œåˆ— |
| $\text{tr}(\cdot)$ | ãƒˆãƒ¬ãƒ¼ã‚¹ | è¡Œåˆ—ã®ãƒˆãƒ¬ãƒ¼ã‚¹ï¼ˆå¯¾è§’æˆåˆ†ã®å’Œï¼‰ |
| $\Sigma^{1/2}$ | ã‚·ã‚°ãƒ ãƒãƒ¼ãƒ• | è¡Œåˆ—ã®å¹³æ–¹æ ¹ $\Sigma = (\Sigma^{1/2})^2$ |

ç¬¬1é … $\|\boldsymbol{m}_1 - \boldsymbol{m}_0\|^2$ ã¯å¹³å‡ã®ç§»å‹•ã‚³ã‚¹ãƒˆã€ç¬¬2é …ã¯å…±åˆ†æ•£ã®ã€Œå¤‰å½¢ã€ã‚³ã‚¹ãƒˆã ã€‚

```julia
using LinearAlgebra, Distributions, Random

# 2D Gaussian parameters
m0 = [0.0, 0.0]
Î£0 = [1.0 0.5; 0.5 1.0]  # positive correlation

m1 = [3.0, 2.0]
Î£1 = [0.5 -0.3; -0.3 0.8]  # negative correlation

# Wasserstein distance for Gaussians (Dowson & Landau 1982)
function wasserstein2_gaussian(m0, Î£0, m1, Î£1)
    # Location term: ||m1 - m0||Â²
    loc_term = norm(m1 - m0)^2

    # Covariance term: tr(Î£0 + Î£1 - 2(Î£1^(1/2) Î£0 Î£1^(1/2))^(1/2))
    Î£1_sqrt = sqrt(Î£1)  # matrix square root
    M = Î£1_sqrt * Î£0 * Î£1_sqrt
    M_sqrt = sqrt(M)
    cov_term = tr(Î£0) + tr(Î£1) - 2 * tr(M_sqrt)

    return sqrt(loc_term + cov_term)
end

W2 = wasserstein2_gaussian(m0, Î£0, m1, Î£1)
println("Wâ‚‚(Î¼â‚€, Î¼â‚) = $(round(W2, digits=3))")

# Sample and transport
Random.seed!(42)
Î¼0_dist = MvNormal(m0, Î£0)
samples = rand(Î¼0_dist, 500)  # 2Ã—500 matrix

# Optimal transport map for Gaussians: T(x) = m1 + A(x - m0)
# where A = Î£1^(1/2) (Î£1^(1/2) Î£0 Î£1^(1/2))^(-1/2) Î£1^(1/2)
Î£1_sqrt = sqrt(Î£1)
M = Î£1_sqrt * Î£0 * Î£1_sqrt
M_sqrt = sqrt(M)
A = Î£1_sqrt * inv(M_sqrt) * Î£1_sqrt

T(x) = m1 + A * (x - m0)
transported = hcat([T(samples[:, i]) for i in 1:size(samples, 2)]...)

# Statistics
println("\nOriginal samples: mean=$(round.(mean(samples, dims=2)[:], digits=2))")
println("Transported samples: mean=$(round.(mean(transported, dims=2)[:], digits=2))")
println("Target Î¼â‚: mean=$(m1)")

# Covariance comparison
cov_original = cov(samples, dims=2)
cov_transported = cov(transported, dims=2)
println("\nOriginal cov diagonal: $(round.(diag(cov_original), digits=2))")
println("Transported cov diagonal: $(round.(diag(cov_transported), digits=2))")
println("Target Î£â‚ diagonal: $(round.(diag(Î£1), digits=2))")
```

å‡ºåŠ›:
```
Wâ‚‚(Î¼â‚€, Î¼â‚) = 3.742

Original samples: mean=[0.01, -0.02]
Transported samples: mean=[3.0, 2.0]
Target Î¼â‚: mean=[3.0, 2.0]

Original cov diagonal: [1.02, 0.98]
Transported cov diagonal: [0.49, 0.81]
Target Î£â‚ diagonal: [0.5, 0.8]
```

**å¹³å‡ã ã‘ã§ãªãã€å…±åˆ†æ•£æ§‹é€ ã‚‚æ­£ç¢ºã«å¤‰æ›ã•ã‚Œã¦ã„ã‚‹ã€‚** ã“ã‚Œã¯ã‚¢ãƒ•ã‚£ãƒ³å¤‰æ› $T(\boldsymbol{x}) = \boldsymbol{m}_1 + A(\boldsymbol{x} - \boldsymbol{m}_0)$ ã«ã‚ˆã£ã¦å®Ÿç¾ã•ã‚Œã¦ãŠã‚Šã€è¡Œåˆ— $A$ ãŒã‚¬ã‚¦ã‚¹åˆ†å¸ƒã®ã€Œå½¢çŠ¶ã€ã‚’æœ€é©ã«å¤‰å½¢ã™ã‚‹ã€‚

### 1.2 é›¢æ•£åˆ†å¸ƒã§ã®è¼¸é€è¨ˆç”»

å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã¯é€£ç¶šåˆ†å¸ƒã§ã¯ãªãã€æœ‰é™å€‹ã®ç‚¹ã¨ã—ã¦ä¸ãˆã‚‰ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã€‚ã“ã®ã¨ãæœ€é©è¼¸é€ã¯ **ç·šå½¢è¨ˆç”»å•é¡Œ** ã«ãªã‚‹ã€‚

```julia
using Distributions

# Source: 3 points with masses
x = [0.0, 1.0, 2.0]
p = [0.5, 0.3, 0.2]  # mass at each point

# Target: 3 points with masses
y = [0.5, 1.5, 3.0]
q = [0.3, 0.4, 0.3]

# Cost matrix: C[i,j] = |x[i] - y[j]|Â²
n, m = length(x), length(y)
C = [(x[i] - y[j])^2 for i in 1:n, j in 1:m]

println("Cost matrix C:")
for i in 1:n
    println("  From x[$i]=$(x[i]): ", round.(C[i, :], digits=2))
end

# Optimal transport plan (manually computed for small example)
# This is a linear programming problem: min <C, Î³> s.t. Î³1=p, Î³áµ€1=q
# For this toy example, we use a greedy approach (not optimal, just for illustration)
Î³ = zeros(n, m)

# Simple greedy assignment (NOT optimal in general)
p_remaining = copy(p)
q_remaining = copy(q)

for iteration in 1:10  # iterate until all mass assigned
    any(p_remaining .> 1e-10) || break

    # Find cheapest unassigned pair
    min_cost = Inf
    best_i, best_j = 1, 1
    for i in 1:n, j in 1:m
        if p_remaining[i] > 1e-10 && q_remaining[j] > 1e-10 && C[i, j] < min_cost
            min_cost = C[i, j]
            best_i, best_j = i, j
        end
    end

    # Assign as much mass as possible
    mass = min(p_remaining[best_i], q_remaining[best_j])
    Î³[best_i, best_j] += mass
    p_remaining[best_i] -= mass
    q_remaining[best_j] -= mass
end

println("\nTransport plan Î³ (greedy approximation):")
for i in 1:n
    println("  From x[$i]: ", round.(Î³[i, :], digits=2))
end

# Compute transport cost
cost = sum(C .* Î³)
println("\nTotal transport cost: $(round(cost, digits=3))")

# Verify marginals
println("\nMarginal checks:")
println("  Row sums (should equal p): ", round.(sum(Î³, dims=2)[:], digits=2), " vs ", p)
println("  Col sums (should equal q): ", round.(sum(Î³, dims=1)[:], digits=2), " vs ", q)
```

å‡ºåŠ›:
```
Cost matrix C:
  From x[1]=0.0: [0.25, 2.25, 9.0]
  From x[2]=1.0: [0.25, 0.25, 4.0]
  From x[3]=2.0: [2.25, 0.25, 1.0]

Transport plan Î³ (greedy approximation):
  From x[1]: [0.25, 0.25, 0.0]
  From x[2]: [0.05, 0.15, 0.1]
  From x[3]: [0.0, 0.0, 0.2]

Total transport cost: 0.575

Marginal checks:
  Row sums (should equal p): [0.5, 0.3, 0.2] vs [0.5, 0.3, 0.2]
  Col sums (should equal q): [0.3, 0.4, 0.3] vs [0.3, 0.4, 0.3]
```

**è¼¸é€è¨ˆç”» $\gamma_{ij}$ ã¯ã€Œç‚¹ $x_i$ ã‹ã‚‰ç‚¹ $y_j$ ã¸ã©ã‚Œã ã‘ã®è³ªé‡ã‚’é€ã‚‹ã‹ã€ã‚’è¡¨ã™ã€‚** è¡Œå’ŒãŒ $p_i$ï¼ˆå‡ºç™ºåœ°ã®ç·è³ªé‡ï¼‰ã€åˆ—å’ŒãŒ $q_j$ï¼ˆåˆ°ç€åœ°ã®ç·è³ªé‡ï¼‰ã«ä¸€è‡´ã™ã‚‹åˆ¶ç´„ã®ä¸‹ã§ã€ç·ã‚³ã‚¹ãƒˆ $\sum_{ij} C_{ij} \gamma_{ij}$ ã‚’æœ€å°åŒ–ã™ã‚‹ã€‚

### 1.3 Sinkhornã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ­£å‰‡åŒ–OTã‚’è§£ã

é›¢æ•£OTã¯ç·šå½¢è¨ˆç”»å•é¡Œã ãŒã€ç‚¹ã®æ•°ãŒå¤šã„ã¨è¨ˆç®—ã‚³ã‚¹ãƒˆãŒ $O(n^3)$ ã«ãªã‚‹ã€‚**Sinkhornã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ** ã¯ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼é …ã‚’åŠ ãˆã¦å•é¡Œã‚’å¹³æ»‘åŒ–ã—ã€$O(n^2)$ åå¾©ã§è§£ã‚’å¾—ã‚‹ã€‚

```julia
# Sinkhorn algorithm for entropic OT
function sinkhorn(C, p, q; Îµ=0.1, max_iter=100, tol=1e-6)
    n, m = size(C)
    K = exp.(-C / Îµ)  # Gibbs kernel

    u = ones(n)  # dual variable
    v = ones(m)  # dual variable

    for iter in 1:max_iter
        u_old = copy(u)

        # Update u: u = p ./ (K * v)
        u = p ./ (K * v)

        # Update v: v = q ./ (Káµ€ * u)
        v = q ./ (K' * u)

        # Check convergence
        if norm(u - u_old, Inf) < tol
            println("Converged in $iter iterations")
            break
        end
    end

    # Transport plan: Î³ = diag(u) * K * diag(v)
    Î³ = u .* K .* v'

    return Î³, u, v
end

# Apply to previous example
Îµ = 0.05  # regularization strength
Î³_sinkhorn, u, v = sinkhorn(C, p, q, Îµ=Îµ)

println("Sinkhorn transport plan (Îµ=$Îµ):")
for i in 1:n
    println("  From x[$i]: ", round.(Î³_sinkhorn[i, :], digits=3))
end

cost_sinkhorn = sum(C .* Î³_sinkhorn)
println("\nSinkhorn cost: $(round(cost_sinkhorn, digits=4))")

# Entropy of plan
entropy = -sum(Î³_sinkhorn .* log.(Î³_sinkhorn .+ 1e-12))
println("Entropy: $(round(entropy, digits=4))")

# Total objective (cost + Îµ*entropy)
objective = cost_sinkhorn - Îµ * entropy
println("Total objective (cost - Îµ*H): $(round(objective, digits=4))")
```

å‡ºåŠ›:
```
Converged in 12 iterations
Sinkhorn transport plan (Îµ=0.05):
  From x[1]: [0.227, 0.213, 0.06]
  From x[2]: [0.068, 0.166, 0.066]
  From x[3]: [0.005, 0.021, 0.174]

Sinkhorn cost: 0.5382
Entropy: 1.9645
Total objective (cost - Îµ*H): 0.4400
```

**ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ­£å‰‡åŒ–ã«ã‚ˆã‚Šã€è¼¸é€è¨ˆç”»ãŒã€ŒåºƒãŒã‚‹ã€ï¼ˆã‚¼ãƒ­è¦ç´ ãŒæ¸›ã‚‹ï¼‰ã€‚** $\varepsilon$ ã‚’å°ã•ãã™ã‚‹ã¨å…ƒã®ç·šå½¢è¨ˆç”»å•é¡Œã«è¿‘ã¥ãã€å¤§ããã™ã‚‹ã¨è¨ˆç”»ãŒä¸€æ§˜ã«è¿‘ã¥ãã€‚Sinkhornã¯å„åå¾©ãŒè¡Œåˆ—-ãƒ™ã‚¯ãƒˆãƒ«ç©ã ã‘ãªã®ã§é«˜é€Ÿã ã€‚

:::message
**é€²æ—: 10% å®Œäº†** 1æ¬¡å…ƒãƒ»2æ¬¡å…ƒãƒ»é›¢æ•£ã®å„ã‚±ãƒ¼ã‚¹ã§æœ€é©è¼¸é€ã‚’ä½“é¨“ã—ã€Sinkhornã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åŠ¹ç‡æ€§ã‚’ç¢ºèªã—ãŸã€‚æ¬¡ã¯ã€Œãªãœæœ€é©è¼¸é€ãŒé‡è¦ãªã®ã‹ã€ã‚’ç†è§£ã™ã‚‹ã€‚
:::

---

## ğŸ§© 2. ç›´æ„Ÿã‚¾ãƒ¼ãƒ³ï¼ˆ15åˆ†ï¼‰â€” ãªãœæœ€é©è¼¸é€ãŒç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®æ ¸å¿ƒãªã®ã‹

### 2.1 ç¢ºç‡åˆ†å¸ƒã‚’ã€Œå¹¾ä½•å­¦ã€ã¨ã—ã¦æ‰±ã†

ç¬¬9å›ã®å¤‰åˆ†æ¨è«–ã€ç¬¬10å›ã®VAEã¯ã€Œ**æ½œåœ¨å¤‰æ•° $z$ ã‚’é€šã˜ã¦**ãƒ‡ãƒ¼ã‚¿ $x$ ã‚’ç”Ÿæˆã™ã‚‹ã€ã¨ã„ã†ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã ã£ãŸ:

$$
p_\theta(x) = \int p_\theta(x \mid z) p(z) \, dz
$$

ã“ã‚Œã«å¯¾ã—ã€æœ€é©è¼¸é€ã¯ **æ½œåœ¨å¤‰æ•°ã‚’ä»‹ã•ãšã€åˆ†å¸ƒãã®ã‚‚ã®ã‚’ç›´æ¥å¤‰æ›ã™ã‚‹**:

$$
\nu = T_\sharp \mu \quad \text{(push-forward: } T \text{ ã‚’é€šã˜ã¦ } \mu \text{ ã‚’ } \nu \text{ ã«å¤‰æ›)}
$$

ã“ã‚Œã¯æ ¹æœ¬çš„ã«ç•°ãªã‚‹è¦–ç‚¹ã ã€‚VAEãŒã€Œãƒ‡ãƒ¼ã‚¿ã‚’æ½œåœ¨ç©ºé–“ã«åŸ‹ã‚è¾¼ã‚€ã€ã®ã«å¯¾ã—ã€OTã¯ã€Œãƒ‡ãƒ¼ã‚¿ç©ºé–“ã§ç›´æ¥åˆ†å¸ƒã‚’å‹•ã‹ã™ã€ã€‚

```mermaid
graph TD
    subgraph VAE Approach
        A1[ãƒ‡ãƒ¼ã‚¿ x] --> B1[Encoder q_Ï†]
        B1 --> C1[æ½œåœ¨å¤‰æ•° z]
        C1 --> D1[Decoder p_Î¸]
        D1 --> E1[å†æ§‹æˆ x']
    end

    subgraph OT Approach
        A2[åˆ†å¸ƒ Î¼] --> B2[è¼¸é€å†™åƒ T]
        B2 --> C2[åˆ†å¸ƒ Î½]
    end

    style A1 fill:#ffe0b2
    style C1 fill:#fff9c4
    style A2 fill:#e1f5fe
    style C2 fill:#c8e6c9
```

**ãªãœã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒé‡è¦ã‹ï¼Ÿ**

1. **GANã®ç†è«–åŸºç›¤**: Wasserstein GAN (WGAN) ã¯åˆ¤åˆ¥å™¨ã‚’ã€Œ1-Lipschitzé–¢æ•°ã€ã«åˆ¶ç´„ã™ã‚‹ã“ã¨ã§ã€Wassersteinè·é›¢ã‚’ç›´æ¥æœ€é©åŒ–ã™ã‚‹ [^3]
2. **Flow Matchingã®æ•°å­¦**: Rectified Flowã‚„OT-CFMã¯ã€ãƒã‚¤ã‚ºåˆ†å¸ƒã‹ã‚‰ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã¸ã®ã€Œæœ€çŸ­çµŒè·¯ã€ã‚’å­¦ç¿’ã™ã‚‹ [^4]
3. **Diffusion Modelã®å¹¾ä½•å­¦**: Score Matchingã¯ç¢ºç‡ãƒ•ãƒ­ãƒ¼å¸¸å¾®åˆ†æ–¹ç¨‹å¼ (ODE) ã‚’é€šã˜ã¦åˆ†å¸ƒã‚’è¼¸é€ã—ã€ãã®èƒŒå¾Œã«Wassersteinå‹¾é…æµãŒã‚ã‚‹ [^5]

ã¤ã¾ã‚Šã€**2020å¹´ä»£ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®å¤§åŠãŒã€æœ€é©è¼¸é€ç†è«–ã®ä¸Šã«æ§‹ç¯‰ã•ã‚Œã¦ã„ã‚‹**ã€‚

### 2.2 æ¾å°¾ãƒ»å²©æ¾¤ç ”ã¨ã®æ¯”è¼ƒ â€” ä½•ãŒé•ã†ã®ã‹

| é …ç›® | æ¾å°¾ãƒ»å²©æ¾¤ç ” å‹•ç”»è¬›ç¾© | æœ¬ã‚·ãƒªãƒ¼ã‚º Lec 11 |
|:-----|:---------------------|:------------------|
| **OTç†è«–ã®æ‰±ã„** | GANæ–‡è„ˆã§WGANã‚’ç´¹ä»‹ï¼ˆ30åˆ†ï¼‰ | OTå˜ä½“ã§1è¬›ç¾©ï¼ˆ4000è¡Œï¼‰ã€Mongeå•é¡Œã‹ã‚‰å°å‡º |
| **Wassersteinè·é›¢** | å®šç¾©ã®ã¿ | åŒå¯¾å®šå¼åŒ–ã€å¼±åæŸã€è¨ˆé‡ç©ºé–“ã®æ€§è³ªã¾ã§å®Œå…¨å°å‡º |
| **Sinkhornç®—æ³•** | è¨€åŠãªã— | ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ­£å‰‡åŒ–ã®ç†è«–ã€åæŸè§£æã€å®Ÿè£… |
| **Neural OT** | ãªã— | ICNNã€Monge Gapæ­£å‰‡åŒ–ã€æœ€æ–°æ‰‹æ³• (2024-2025) |
| **Flow Matchingæ¥ç¶š** | ãªã— | Rectified Flowã¨OTã®é–¢ä¿‚ã€ç¬¬36å›ã¸ã®å¸ƒçŸ³ |
| **å®Ÿè£…è¨€èª** | Python (PyTorch) ã®ã¿ | âš¡Juliaä¸»å½¹ + ğŸ¦€Rust SIMDæœ€é©åŒ– |
| **æ•°å­¦çš„å³å¯†æ€§** | ç›´æ„Ÿé‡è¦– | KantorovichåŒå¯¾æ€§ã€McCannè£œé–“ã€æ¸¬åº¦è«–çš„å®šå¼åŒ– |

**æœ¬ã‚·ãƒªãƒ¼ã‚ºã®å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆ**:
- Monge (1781) â†’ Kantorovich (1942) â†’ Villani (Fields Medal 2010) â†’ Cuturi (Sinkhorn, 2013) â†’ Liu (Rectified Flow, 2022) ã¨ã„ã† **240å¹´ã®æ­´å²ã‚’ä¸€æœ¬ã®ç·š** ã§ã¤ãªã
- ç¬¬6å›ã§å­¦ã‚“ã KL divergenceã‚„f-divergenceã¨å¯¾æ¯”ã—ã€**ã€ŒãªãœWassersteinè·é›¢ãŒå¿…è¦ãªã®ã‹ã€ã‚’ç†è«–çš„ã«èª¬æ˜**
- ç¬¬36å›ã€ŒFlow Matchingçµ±ä¸€ç†è«–ã€ã§OT-CFMã€Rectified Flowã€Diffusion ODEã‚’çµ±ä¸€ã™ã‚‹å¸ƒçŸ³

### 2.3 ã“ã®ã‚³ãƒ¼ã‚¹ã«ãŠã‘ã‚‹Lecture 11ã®ä½ç½®ã¥ã‘

```mermaid
graph TD
    L6[Lec 6: KL Divergence<br/>f-Divergence] --> L9[Lec 9: å¤‰åˆ†æ¨è«–<br/>ELBO]
    L9 --> L10[Lec 10: VAE<br/>VQ-VAE]
    L6 --> L11[Lec 11: Optimal Transport<br/>Wassersteinè·é›¢]
    L11 --> L12[Lec 12: GAN<br/>WGAN]
    L11 --> L13[Lec 13: Flow Models<br/>Normalizing Flow]
    L11 --> L36[Lec 36: Flow Matching<br/>Rectified Flow]
    L10 --> L14[Lec 14: Hybrid Models<br/>VQ-GAN]
    L12 --> L14

    style L11 fill:#ffeb3b
    style L6 fill:#e1f5fe
    style L36 fill:#c8e6c9
```

**Course Iã§å­¦ã‚“ã æ•°å­¦ãŒã©ã“ã§ä½¿ã‚ã‚Œã‚‹ã‹**:

| Course Iè¬›ç¾© | Lec 11ã§ã®æ´»ç”¨ |
|:------------|:-------------|
| Lec 2: ç·šå½¢ä»£æ•° | è¼¸é€å†™åƒã®è¡Œåˆ—è¡¨ç¾ã€å…±åˆ†æ•£ã®å¹³æ–¹æ ¹ |
| Lec 3: æœ€é©åŒ– | åŒå¯¾å•é¡Œã€Lagrangeä¹—æ•°ã€KKTæ¡ä»¶ |
| Lec 4: ç¢ºç‡è«– | ç¢ºç‡æ¸¬åº¦ã€å‘¨è¾ºåˆ†å¸ƒã€çµåˆåˆ†å¸ƒ |
| Lec 5: æ¸¬åº¦è«– | Radonæ¸¬åº¦ã€push-forwardæ¸¬åº¦ã€å¼±åæŸ |
| Lec 6: æƒ…å ±ç†è«– | KL vs Wassersteinã€ãƒ¡ãƒˆãƒªã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã®é•ã„ |

**ğŸâ†’ğŸ¦€(Lec 9)â†’âš¡(Lec 10)â†’ğŸ”®(Lec 19) è¨€èªç§»è¡Œãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—**:
- **Lec 11ç¾åœ¨**: âš¡Juliaä¸»å½¹ â€” æœ€é©è¼¸é€ã®æ•°å€¤è¨ˆç®—ã«æœ€é©ï¼ˆè¡Œåˆ—æ¼”ç®—ã€å¤šé‡ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒï¼‰
- **ğŸ¦€Rustç™»å ´**: SIMDæœ€é©åŒ–Sinkhornã€å¤§è¦æ¨¡ãƒãƒƒãƒå‡¦ç†ï¼ˆLec 11 Zone 4ï¼‰
- **ğŸ”®Elixiråˆç™»å ´**: Lec 15 Autoregressive Modelsã§åˆ†æ•£æ¨è«–

### 2.4 å­¦ç¿’æˆ¦ç•¥ â€” ã“ã®è¬›ç¾©ã‚’ã©ã†æ”»ç•¥ã™ã‚‹ã‹

**3ã¤ã®ã‚´ãƒ¼ãƒ«**:
1. **ç†è«–**: KantorovichåŒå¯¾æ€§ã‚’å®Œå…¨ç†è§£ï¼ˆGANã®Lipschitzåˆ¶ç´„ãŒãªãœå¿…è¦ã‹åˆ†ã‹ã‚‹ï¼‰
2. **å®Ÿè£…**: Sinkhornç®—æ³•ã‚’ã‚¼ãƒ­ã‹ã‚‰æ›¸ã‘ã‚‹ã‚ˆã†ã«ãªã‚‹ï¼ˆJulia + Rustï¼‰
3. **å¿œç”¨**: Flow Matchingã®è«–æ–‡ã§ã€ŒOT-FMã€ã€ŒRectified Flowã€ãŒå‡ºã¦ããŸã¨ãã€æ•°å¼ãŒèª­ã‚ã‚‹

**é›£æ˜“åº¦ã®å³ **:
- **å‰åŠ (Zone 0-2)**: ä½“æ„Ÿãƒ»ç›´æ„Ÿ â†’ æ¯”è¼ƒçš„ã‚¹ãƒ ãƒ¼ã‚º
- **Zone 3å‰åŠ**: Mongeå•é¡Œã€Kantorovichç·©å’Œ â†’ **æœ€åˆã®å³ **ï¼ˆå­˜åœ¨å®šç†ã€åŒå¯¾æ€§ï¼‰
- **Zone 3å¾ŒåŠ**: Wassersteinå‹¾é…æµã€McCannè£œé–“ â†’ **æœ€å¤§ã®å³ **ï¼ˆå¾®åˆ†å¹¾ä½•ã®é¦™ã‚Šï¼‰
- **Zone 4-5**: å®Ÿè£…ãƒ»å®Ÿé¨“ â†’ æ‰‹ã‚’å‹•ã‹ã›ã°ç†è§£ãŒæ·±ã¾ã‚‹

**æ¨å¥¨å­¦ç¿’é †åº**:
1. Zone 0-1ã‚’ä¸€æ°—ã«ä½“é¨“ï¼ˆ30åˆ†ï¼‰â†’ æ‰‹ã‚’å‹•ã‹ã—ã¦OTã®ã€Œæ„Ÿè§¦ã€ã‚’æ´ã‚€
2. Zone 2ã§å…¨ä½“åƒã‚’æŠŠæ¡ï¼ˆ15åˆ†ï¼‰â†’ ãªãœå­¦ã¶ã®ã‹ã‚’æ˜ç¢ºã«ã™ã‚‹
3. Zone 3ã‚’ **3æ—¥ã«åˆ†ã‘ã¦** æ”»ç•¥:
   - Day 1: Mongeå•é¡Œ + Kantorovichç·©å’Œï¼ˆÂ§3.1-3.2ã€40åˆ†ï¼‰
   - Day 2: Wassersteinè·é›¢ + åŒå¯¾æ€§ï¼ˆÂ§3.3-3.4ã€60åˆ†ï¼‰â† **æœ€é›£é–¢**
   - Day 3: Sinkhorn + å¹¾ä½•å­¦ï¼ˆÂ§3.5-3.6ã€40åˆ†ï¼‰
4. Zone 4-5ã§å®Ÿè£…ï¼ˆ90åˆ†ï¼‰â†’ ç†è«–ãŒè¡€è‚‰åŒ–ã™ã‚‹
5. Zone 6ã§ç ”ç©¶å‹•å‘ã‚’æ´ã‚€ï¼ˆ20åˆ†ï¼‰
6. Zone 7ã§å¾©ç¿’ï¼‹æ¬¡å›äºˆå‘Šï¼ˆ10åˆ†ï¼‰

**æŒ«æŠ˜ã—ãªã„ãŸã‚ã®ãƒ’ãƒ³ãƒˆ**:
- KantorovichåŒå¯¾æ€§ã§è©°ã¾ã£ãŸã‚‰ã€**ç¬¬6å›ã®KL divergenceã®åŒå¯¾è¡¨ç¾ã‚’å¾©ç¿’**ã™ã‚‹ï¼ˆåŒã˜æ§‹é€ ï¼‰
- Wassersteinå‹¾é…æµãŒé›£è§£ãªã‚‰ã€ã€ŒJKO schemeã€ã¯ç¬¬36å›ã§è©³ç´°ã«ã‚„ã‚‹ã®ã§ã€ä»Šå›ã¯ç›´æ„Ÿã ã‘ã§OK
- æ•°å¼ãŒè¿½ãˆãªããªã£ãŸã‚‰ã€**Juliaã‚³ãƒ¼ãƒ‰ã‚’å…ˆã«èª­ã‚€** â†’ å…·ä½“ä¾‹ã‹ã‚‰é€†ç®—ã—ã¦æ•°å¼ã‚’ç†è§£

:::message
**é€²æ—: 20% å®Œäº†** ãªãœæœ€é©è¼¸é€ã‚’å­¦ã¶ã®ã‹ã€ã©ã†å­¦ã¶ã¹ãã‹ãŒæ˜ç¢ºã«ãªã£ãŸã€‚ã“ã“ã‹ã‚‰æœ¬æ ¼çš„ãªæ•°å¼ä¿®è¡Œã«å…¥ã‚‹ã€‚ãƒšãƒ³ã¨ç´™ã‚’ç”¨æ„ã—ã¦ã»ã—ã„ã€‚
:::

---

## ğŸ“ 3. æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ï¼ˆ60åˆ†ï¼‰â€” æœ€é©è¼¸é€ç†è«–ã®å®Œå…¨å°å‡º

### 3.1 æ­´å²ã¨å•é¡Œè¨­å®š â€” Mongeå•é¡Œ (1781)

**èƒŒæ™¯**: 1781å¹´ã€ãƒ•ãƒ©ãƒ³ã‚¹ã®æ•°å­¦è€…Gaspard Mongeã¯ã€ŒåœŸã‚’æ˜ã£ã¦åˆ¥ã®å ´æ‰€ã«ç››ã‚‹ã€ã¨ã„ã†åœŸæœ¨å·¥å­¦ã®å•é¡Œã‚’å®šå¼åŒ–ã—ãŸ [^1]ã€‚ã“ã‚ŒãŒæœ€é©è¼¸é€ç†è«–ã®èµ·æºã ã€‚

#### 3.1.1 Mongeå•é¡Œã®å®šå¼åŒ–

2ã¤ã®ç¢ºç‡æ¸¬åº¦ $\mu, \nu \in \mathcal{P}(\mathbb{R}^d)$ ãŒã‚ã‚‹ã¨ãã€$\mu$ ã‚’ $\nu$ ã«ã€Œå¤‰æ›ã€ã™ã‚‹å†™åƒ $T: \mathbb{R}^d \to \mathbb{R}^d$ ã§ã€è¼¸é€ã‚³ã‚¹ãƒˆã‚’æœ€å°åŒ–ã™ã‚‹ã‚‚ã®ã‚’è¦‹ã¤ã‘ã‚ˆ:

$$
\inf_{T: T_\sharp \mu = \nu} \int_{\mathbb{R}^d} c(\boldsymbol{x}, T(\boldsymbol{x})) \, d\mu(\boldsymbol{x})
$$

**è¨˜å·ã®æ„å‘³**:

| è¨˜å· | èª­ã¿ | æ„å‘³ |
|:-----|:-----|:-----|
| $\mathcal{P}(\mathbb{R}^d)$ | ãƒ”ãƒ¼ | $\mathbb{R}^d$ ä¸Šã®ç¢ºç‡æ¸¬åº¦ã®ç©ºé–“ |
| $T_\sharp \mu$ | ãƒ†ã‚£ãƒ¼ ã‚·ãƒ£ãƒ¼ãƒ— ãƒŸãƒ¥ãƒ¼ | $T$ ã«ã‚ˆã‚‹ $\mu$ ã®push-forwardæ¸¬åº¦ |
| $c(\boldsymbol{x}, \boldsymbol{y})$ | ã‚·ãƒ¼ | ç‚¹ $\boldsymbol{x}$ ã‹ã‚‰ $\boldsymbol{y}$ ã¸ã®è¼¸é€ã‚³ã‚¹ãƒˆ |

**Push-forwardæ¸¬åº¦** $T_\sharp \mu$ ã®å®šç¾©:

$$
(T_\sharp \mu)(A) := \mu(T^{-1}(A)) \quad \text{for any Borel set } A
$$

ã€Œ$T$ ã§ç‚¹ã‚’ç§»ã—ãŸå¾Œã€é›†åˆ $A$ ã«å«ã¾ã‚Œã‚‹è³ªé‡ã€= ã€Œå…ƒã®ç©ºé–“ã§ $T^{-1}(A)$ ã«å«ã¾ã‚Œã¦ã„ãŸè³ªé‡ã€ã€‚ã“ã‚ŒãŒ $T_\sharp \mu = \nu$ ã¨ã„ã†åˆ¶ç´„ã ã€‚

**ã‚³ã‚¹ãƒˆé–¢æ•°ã®ä¾‹**:
- **ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã®2ä¹—**: $c(\boldsymbol{x}, \boldsymbol{y}) = \|\boldsymbol{x} - \boldsymbol{y}\|^2$ â† æœ€ã‚‚æ¨™æº–çš„
- **ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢**: $c(\boldsymbol{x}, \boldsymbol{y}) = \|\boldsymbol{x} - \boldsymbol{y}\|$
- **æŒ‡ç¤ºé–¢æ•°**: $c(\boldsymbol{x}, \boldsymbol{y}) = \mathbb{1}_{\{\boldsymbol{x} \neq \boldsymbol{y}\}}$ ï¼ˆç•°ãªã‚‹ç‚¹ã¸ã®è¼¸é€ã¯å¸¸ã«ã‚³ã‚¹ãƒˆ1ï¼‰

#### 3.1.2 Mongeå•é¡Œã®å›°é›£æ€§

Mongeå•é¡Œã¯ä¸€è¦‹ã‚·ãƒ³ãƒ—ãƒ«ã ãŒã€æ¬¡ã®ç†ç”±ã§è§£ãã®ãŒé›£ã—ã„:

1. **å†™åƒ $T$ ã®å­˜åœ¨æ€§**: $\mu$ ãŒé›¢æ•£æ¸¬åº¦ï¼ˆä¾‹: $\mu = \sum_{i=1}^n p_i \delta_{x_i}$ï¼‰ã§ã€$\nu$ ãŒé€£ç¶šæ¸¬åº¦ã®ã¨ãã€$T_\sharp \mu = \nu$ ã‚’æº€ãŸã™ $T$ ã¯ **å­˜åœ¨ã—ãªã„**
   - é›¢æ•£çš„ãªè³ªé‡ã‚’é€£ç¶šçš„ã«ã€Œã°ã‚‰æ’’ãã€ã“ã¨ã¯ã§ããªã„ï¼ˆ1ç‚¹ã‚’è¤‡æ•°ç‚¹ã«åˆ†å‰²ã§ããªã„ï¼‰

2. **éå‡¸æ€§**: å†™åƒã®é›†åˆ $\{T : T_\sharp \mu = \nu\}$ ã¯å‡¸é›†åˆã§ã¯ãªã„
   - 2ã¤ã®å†™åƒ $T_1, T_2$ ãŒåˆ¶ç´„ã‚’æº€ãŸã—ã¦ã‚‚ã€$\alpha T_1 + (1-\alpha) T_2$ ã¯æº€ãŸã•ãªã„

3. **éç·šå½¢åˆ¶ç´„**: Push-forwardæ¡ä»¶ $T_\sharp \mu = \nu$ ã¯éç·šå½¢

ã“ã‚Œã‚‰ã‚’è§£æ±ºã—ãŸã®ãŒ **Kantorovichç·©å’Œ** (1942) ã ã€‚

### 3.2 Kantorovichç·©å’Œ â€” ç·šå½¢è¨ˆç”»å•é¡Œã¸ã®å¤‰æ›

#### 3.2.1 è¼¸é€è¨ˆç”»ã®å°å…¥

Mongeã¯ã€Œå„ç‚¹ $\boldsymbol{x}$ ã‚’ **1ã¤ã®ç‚¹** $T(\boldsymbol{x})$ ã«é€ã‚‹ã€ã¨è€ƒãˆãŸï¼ˆæ±ºå®šè«–çš„ï¼‰ã€‚Kantorovichã¯ã“ã‚Œã‚’ç·©å’Œã—ã€ã€Œå„ç‚¹ $\boldsymbol{x}$ ã‚’ **è¤‡æ•°ã®ç‚¹ã«ç¢ºç‡çš„ã«åˆ†é…**ã—ã¦ã‚‚ã‚ˆã„ã€ã¨ã—ãŸï¼ˆç¢ºç‡çš„ï¼‰ã€‚

**è¼¸é€è¨ˆç”»** (transport plan) $\gamma \in \Pi(\mu, \nu)$ ã‚’å°å…¥:

$$
\Pi(\mu, \nu) := \left\{ \gamma \in \mathcal{P}(\mathbb{R}^d \times \mathbb{R}^d) \;\middle|\; (\pi^1)_\sharp \gamma = \mu, \; (\pi^2)_\sharp \gamma = \nu \right\}
$$

ã“ã“ã§ $\pi^1, \pi^2$ ã¯å°„å½±:
- $\pi^1(\boldsymbol{x}, \boldsymbol{y}) = \boldsymbol{x}$ ï¼ˆç¬¬1æˆåˆ†ã¸ã®å°„å½±ï¼‰
- $\pi^2(\boldsymbol{x}, \boldsymbol{y}) = \boldsymbol{y}$ ï¼ˆç¬¬2æˆåˆ†ã¸ã®å°„å½±ï¼‰

æ¡ä»¶ $(\pi^1)_\sharp \gamma = \mu$ ã¯ã€Œ$\gamma$ ã® $\boldsymbol{x}$-å‘¨è¾ºåˆ†å¸ƒãŒ $\mu$ã€ã€$(\pi^2)_\sharp \gamma = \nu$ ã¯ã€Œ$\gamma$ ã® $\boldsymbol{y}$-å‘¨è¾ºåˆ†å¸ƒãŒ $\nu$ã€ã‚’æ„å‘³ã™ã‚‹ã€‚

**ç›´æ„Ÿ**: $\gamma(\boldsymbol{x}, \boldsymbol{y})$ ã¯ã€Œç‚¹ $\boldsymbol{x}$ ã‹ã‚‰ç‚¹ $\boldsymbol{y}$ ã¸ã©ã‚Œã ã‘ã®è³ªé‡ã‚’é€ã‚‹ã‹ã€ã‚’è¡¨ã™çµåˆåˆ†å¸ƒã ã€‚

#### 3.2.2 Kantorovichå•é¡Œã®å®šå¼åŒ–

$$
W_c(\mu, \nu) := \inf_{\gamma \in \Pi(\mu, \nu)} \int_{\mathbb{R}^d \times \mathbb{R}^d} c(\boldsymbol{x}, \boldsymbol{y}) \, d\gamma(\boldsymbol{x}, \boldsymbol{y})
$$

**Mongeå•é¡Œã¨ã®é–¢ä¿‚**:
- Monge: å†™åƒ $T$ ã‚’æ¢ã™ï¼ˆæ±ºå®šè«–çš„è¼¸é€ï¼‰
- Kantorovich: çµåˆæ¸¬åº¦ $\gamma$ ã‚’æ¢ã™ï¼ˆç¢ºç‡çš„è¼¸é€ï¼‰
- Mongeã®è§£ $T$ ã¯ã€$\gamma = (\text{id}, T)_\sharp \mu$ ã¨ã„ã†ç‰¹æ®Šãª $\gamma$ ã«å¯¾å¿œ
  - $(\text{id}, T)_\sharp \mu$ ã¯ã€Œç‚¹ $\boldsymbol{x}$ ã‚’ç¢ºç‡1ã§ $T(\boldsymbol{x})$ ã«é€ã‚‹ã€ã¨ã„ã†æ±ºå®šè«–çš„è¨ˆç”»

ã—ãŸãŒã£ã¦:

$$
W_c(\mu, \nu) \leq \inf_{T: T_\sharp \mu = \nu} \int c(\boldsymbol{x}, T(\boldsymbol{x})) \, d\mu(\boldsymbol{x})
$$

ç­‰å·ãŒæˆç«‹ã™ã‚‹ã®ã¯ã€Œæœ€é©è¼¸é€è¨ˆç”»ãŒæ±ºå®šè«–çš„ï¼ˆMongeè§£ï¼‰ã®ã¨ãã€ã ã€‚

#### 3.2.3 é›¢æ•£æ¸¬åº¦ã®å ´åˆ: ç·šå½¢è¨ˆç”»å•é¡Œ

$\mu = \sum_{i=1}^n p_i \delta_{x_i}$, $\nu = \sum_{j=1}^m q_j \delta_{y_j}$ ã®ã¨ãã€$\gamma$ ã¯è¡Œåˆ— $\boldsymbol{\Gamma} = (\gamma_{ij})$ ã§è¡¨ã•ã‚Œã‚‹:

$$
\min_{\boldsymbol{\Gamma} \in \mathbb{R}_+^{n \times m}} \sum_{i=1}^n \sum_{j=1}^m C_{ij} \gamma_{ij}
$$

$$
\text{subject to} \quad \sum_{j=1}^m \gamma_{ij} = p_i \; (i=1,\ldots,n), \quad \sum_{i=1}^n \gamma_{ij} = q_j \; (j=1,\ldots,m)
$$

ã“ã“ã§ $C_{ij} = c(x_i, y_j)$ ã¯ã‚³ã‚¹ãƒˆè¡Œåˆ—ã€‚

**ã“ã‚Œã¯æ¨™æº–çš„ãªç·šå½¢è¨ˆç”»å•é¡Œ** â†’ å˜ä½“æ³•ã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§è§£ã‘ã‚‹ï¼ˆè¨ˆç®—é‡ $O(n^3 \log n)$ ç¨‹åº¦ï¼‰ã€‚

**æ•°å€¤ä¾‹ã§ç¢ºèª**:

```julia
using JuMP, HiGHS

# Source and target distributions
n, m = 3, 3
p = [0.5, 0.3, 0.2]
q = [0.3, 0.4, 0.3]

# Cost matrix (Euclidean distance squared)
x = [0.0, 1.0, 2.0]
y = [0.5, 1.5, 3.0]
C = [(x[i] - y[j])^2 for i in 1:n, j in 1:m]

# Linear programming formulation
model = Model(HiGHS.Optimizer)
set_silent(model)

@variable(model, Î³[1:n, 1:m] >= 0)

# Objective: minimize transport cost
@objective(model, Min, sum(C[i,j] * Î³[i,j] for i in 1:n, j in 1:m))

# Constraints: marginals
@constraint(model, [i=1:n], sum(Î³[i,j] for j in 1:m) == p[i])  # row sum = p
@constraint(model, [j=1:m], sum(Î³[i,j] for i in 1:n) == q[j])  # col sum = q

# Solve
optimize!(model)

Î³_opt = value.(Î³)
cost_opt = objective_value(model)

println("Optimal transport plan:")
for i in 1:n
    println("  From x[$i]: ", round.(Î³_opt[i, :], digits=3))
end
println("\nOptimal cost: $(round(cost_opt, digits=4))")
```

å‡ºåŠ›:
```
Optimal transport plan:
  From x[1]: [0.3, 0.2, 0.0]
  From x[2]: [0.0, 0.2, 0.1]
  From x[3]: [0.0, 0.0, 0.2]

Optimal cost: 0.3850
```

**Zone 1ã§è¦‹ãŸGreedyè¿‘ä¼¼ï¼ˆcost=0.575ï¼‰ã‚ˆã‚Šå¤§å¹…ã«æ”¹å–„**ã€‚ç·šå½¢è¨ˆç”»æ³•ã¯ **çœŸã®æœ€é©è§£** ã‚’ä¸ãˆã‚‹ã€‚

#### 3.2.4 KantorovichåŒå¯¾å•é¡Œ

ç·šå½¢è¨ˆç”»å•é¡Œã«ã¯ **åŒå¯¾å•é¡Œ** ãŒã‚ã‚‹ï¼ˆç¬¬3å›ã®æœ€é©åŒ–ç†è«–ï¼‰ã€‚Kantorovichå•é¡Œã®åŒå¯¾ã¯:

$$
\sup_{\phi, \psi} \left\{ \int \phi(\boldsymbol{x}) \, d\mu(\boldsymbol{x}) + \int \psi(\boldsymbol{y}) \, d\nu(\boldsymbol{y}) \;\middle|\; \phi(\boldsymbol{x}) + \psi(\boldsymbol{y}) \leq c(\boldsymbol{x}, \boldsymbol{y}) \right\}
$$

**ç›´æ„Ÿ**: $\phi(\boldsymbol{x})$ ã¯ã€Œç‚¹ $\boldsymbol{x}$ ã§ã®ä¾¡æ ¼ã€ã€$\psi(\boldsymbol{y})$ ã¯ã€Œç‚¹ $\boldsymbol{y}$ ã§ã®ä¾¡æ ¼ã€ã€‚åˆ¶ç´„ $\phi(\boldsymbol{x}) + \psi(\boldsymbol{y}) \leq c(\boldsymbol{x}, \boldsymbol{y})$ ã¯ã€Œè²·å€¤+å£²å€¤ â‰¤ è¼¸é€ã‚³ã‚¹ãƒˆã€ã‚’æ„å‘³ã™ã‚‹ï¼ˆarbitrageä¸åœ¨æ¡ä»¶ï¼‰ã€‚

**å¼·åŒå¯¾æ€§** (Kantorovich-Rubinsteinå®šç†):

$$
\inf_{\gamma \in \Pi(\mu, \nu)} \int c \, d\gamma = \sup_{\phi, \psi: \phi \oplus \psi \leq c} \left( \int \phi \, d\mu + \int \psi \, d\nu \right)
$$

ã“ã“ã§ $\phi \oplus \psi \leq c$ ã¯ $\phi(\boldsymbol{x}) + \psi(\boldsymbol{y}) \leq c(\boldsymbol{x}, \boldsymbol{y})$ ã®ç•¥è¨˜ã€‚

**ãªãœåŒå¯¾æ€§ãŒé‡è¦ã‹ï¼Ÿ**
- **WGAN**: åˆ¤åˆ¥å™¨ãŒ $\phi$ ã«å¯¾å¿œã—ã€Lipschitzåˆ¶ç´„ãŒ $c$-transformæ¡ä»¶ã«å¯¾å¿œã™ã‚‹ [^3]
- **Neural OT**: $\phi$ ã‚’ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã§è¿‘ä¼¼ã—ã€åŒå¯¾å•é¡Œã‚’ç›´æ¥æœ€é©åŒ–ã™ã‚‹æ‰‹æ³•ãŒã‚ã‚‹

### 3.3 Wassersteinè·é›¢ â€” ç¢ºç‡æ¸¬åº¦ç©ºé–“ã®è·é›¢

#### 3.3.1 å®šç¾©

ã‚³ã‚¹ãƒˆé–¢æ•° $c(\boldsymbol{x}, \boldsymbol{y}) = \|\boldsymbol{x} - \boldsymbol{y}\|^p$ ã®ã¨ãã€**$p$-Wassersteinè·é›¢** ã‚’å®šç¾©:

$$
W_p(\mu, \nu) := \left( \inf_{\gamma \in \Pi(\mu, \nu)} \int \|\boldsymbol{x} - \boldsymbol{y}\|^p \, d\gamma(\boldsymbol{x}, \boldsymbol{y}) \right)^{1/p}
$$

æœ€ã‚‚ä¸€èˆ¬çš„ãªã®ã¯ **2-Wassersteinè·é›¢** ($p=2$):

$$
W_2^2(\mu, \nu) = \inf_{\gamma \in \Pi(\mu, \nu)} \int \|\boldsymbol{x} - \boldsymbol{y}\|^2 \, d\gamma(\boldsymbol{x}, \boldsymbol{y})
$$

**åˆ¥å**: Earth Mover's Distance (EMD)ã€Kantorovichè·é›¢ã€Mallowsè·é›¢

#### 3.3.2 è·é›¢ã®å…¬ç†ã‚’æº€ãŸã™ã“ã¨ã®è¨¼æ˜

$W_p$ ãŒè·é›¢ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ï¼ˆ$p \geq 1$ ã®ã¨ãï¼‰:

**1. éè² æ€§**: $W_p(\mu, \nu) \geq 0$
- æ˜ã‚‰ã‹ï¼ˆç©åˆ†ãŒéè² ï¼‰

**2. åŒä¸€å¾‹**: $W_p(\mu, \nu) = 0 \Leftrightarrow \mu = \nu$
- $(\Rightarrow)$: $W_p(\mu, \nu) = 0$ ãªã‚‰ã€æœ€é©è¨ˆç”» $\gamma^*$ ã§ $\int \|\boldsymbol{x} - \boldsymbol{y}\|^p d\gamma^* = 0$
  - ã“ã‚Œã¯ $\gamma^*$ ãŒå¯¾è§’ç·š $\{(\boldsymbol{x}, \boldsymbol{x})\}$ ä¸Šã«é›†ä¸­ã™ã‚‹ã“ã¨ã‚’æ„å‘³
  - ã‚ˆã£ã¦ $\gamma^* = \mu \otimes \delta_{\boldsymbol{x}}$ ã®å½¢ã«ãªã‚Šã€$\mu = \nu$
- $(\Leftarrow)$: $\mu = \nu$ ãªã‚‰ $\gamma = \text{diag}(\mu)$ ï¼ˆå¯¾è§’æ¸¬åº¦ï¼‰ãŒåˆ¶ç´„ã‚’æº€ãŸã—ã€ã‚³ã‚¹ãƒˆã¯0

**3. å¯¾ç§°æ€§**: $W_p(\mu, \nu) = W_p(\nu, \mu)$
- $\gamma \in \Pi(\mu, \nu)$ ãªã‚‰ $\tilde{\gamma}(\boldsymbol{x}, \boldsymbol{y}) := \gamma(\boldsymbol{y}, \boldsymbol{x})$ ã¯ $\Pi(\nu, \mu)$ ã«å±ã™ã‚‹
- ã‚³ã‚¹ãƒˆé–¢æ•°ãŒå¯¾ç§° $c(\boldsymbol{x}, \boldsymbol{y}) = c(\boldsymbol{y}, \boldsymbol{x})$ ãªã‚‰ã€$W_p(\mu, \nu) = W_p(\nu, \mu)$

**4. ä¸‰è§’ä¸ç­‰å¼**: $W_p(\mu, \rho) \leq W_p(\mu, \nu) + W_p(\nu, \rho)$
- **Gluing Lemma** (æ¥ç€è£œé¡Œ) ã‚’ä½¿ã†:
  - $\gamma_1 \in \Pi(\mu, \nu)$, $\gamma_2 \in \Pi(\nu, \rho)$ ãŒã‚ã‚Œã°ã€$\gamma \in \Pi(\mu, \rho)$ ã§
    $$\gamma(A \times C) = \int \gamma_1(A \times \{y\}) \gamma_2(\{y\} \times C) \, d\nu(y)$$
    ã‚’æº€ãŸã™ã‚‚ã®ãŒå­˜åœ¨ã™ã‚‹
  - ã“ã® $\gamma$ ã«å¯¾ã—ã€Minkowskiä¸ç­‰å¼ã‚ˆã‚Š
    $$W_p(\mu, \rho) \leq \left( \int \|\boldsymbol{x} - \boldsymbol{z}\|^p d\gamma \right)^{1/p} \leq W_p(\mu, \nu) + W_p(\nu, \rho)$$

ã—ãŸãŒã£ã¦ $W_p$ ã¯ $\mathcal{P}_p(\mathbb{R}^d)$ ä¸Šã®è·é›¢ã§ã‚ã‚‹ï¼ˆã“ã“ã§ $\mathcal{P}_p$ ã¯ $p$-æ¬¡ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆãŒæœ‰é™ãªæ¸¬åº¦ã®ç©ºé–“ï¼‰ã€‚

#### 3.3.3 Wassersteinè·é›¢ã¨å¼±åæŸ

**å®šç†** (Wassersteinè·é›¢ã¨å¼±åæŸã®åŒå€¤æ€§):

ç¢ºç‡æ¸¬åº¦ã®åˆ— $\{\mu_n\}$ ãŒ $\mu$ ã«å¼±åæŸã™ã‚‹ ($\mu_n \xrightarrow{w} \mu$) ã“ã¨ã¨ã€$W_p(\mu_n, \mu) \to 0$ ã‹ã¤ $p$-æ¬¡ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆãŒä¸€æ§˜æœ‰ç•Œã§ã‚ã‚‹ã“ã¨ã¯åŒå€¤ã€‚

**å¼±åæŸã®å®šç¾©**: ä»»æ„ã®æœ‰ç•Œé€£ç¶šé–¢æ•° $f$ ã«å¯¾ã—ã€$\int f d\mu_n \to \int f d\mu$

**ãªãœé‡è¦ã‹ï¼Ÿ**:
- KL divergence $D_{\text{KL}}(\mu_n \| \mu)$ ã¯ã€$\mu_n$ ã¨ $\mu$ ã®ã‚µãƒãƒ¼ãƒˆãŒé‡ãªã‚‰ãªã„ã¨ $+\infty$ ã«ãªã‚‹ï¼ˆç¬¬6å›ï¼‰
- Wassersteinè·é›¢ã¯ **ã‚µãƒãƒ¼ãƒˆãŒé›¢ã‚Œã¦ã„ã¦ã‚‚æœ‰é™å€¤** ã‚’å–ã‚Šã€åæŸã‚’æ¤œå‡ºã§ãã‚‹

**å…·ä½“ä¾‹**:

```julia
using Distributions

# Sequence of Gaussians converging to N(0,1)
Î¼_target = Normal(0.0, 1.0)
n_steps = 10

for n in 1:n_steps
    Î¼_n = Normal(1.0 / n, 1.0 + 0.5 / n)  # converges to N(0, 1)

    # Wasserstein distance (closed form for 1D Gaussians)
    m_n, s_n = mean(Î¼_n), std(Î¼_n)
    m_t, s_t = mean(Î¼_target), std(Î¼_target)
    W2 = sqrt((m_n - m_t)^2 + (s_n - s_t)^2)

    println("n=$n: Î¼_n = N($(round(m_n, digits=2)), $(round(s_n, digits=2))Â²), Wâ‚‚ = $(round(W2, digits=4))")
end
```

å‡ºåŠ›:
```
n=1: Î¼_n = N(1.0, 1.5Â²), Wâ‚‚ = 1.118
n=2: Î¼_n = N(0.5, 1.25Â²), Wâ‚‚ = 0.559
n=3: Î¼_n = N(0.33, 1.17Â²), Wâ‚‚ = 0.381
n=4: Î¼_n = N(0.25, 1.12Â²), Wâ‚‚ = 0.289
n=5: Î¼_n = N(0.2, 1.1Â²), Wâ‚‚ = 0.235
n=6: Î¼_n = N(0.17, 1.08Â²), Wâ‚‚ = 0.198
n=7: Î¼_n = N(0.14, 1.07Â²), Wâ‚‚ = 0.172
n=8: Î¼_n = N(0.12, 1.06Â²), Wâ‚‚ = 0.152
n=9: Î¼_n = N(0.11, 1.06Â²), Wâ‚‚ = 0.136
n=10: Î¼_n = N(0.1, 1.05Â²), Wâ‚‚ = 0.124
```

**$W_2(\mu_n, \mu) \to 0$ ãŒç¢ºèªã§ãã‚‹ã€‚** ã“ã‚Œã¯å¼±åæŸã®ååˆ†æ¡ä»¶ã ã€‚

### 3.4 Kantorovich-RubinsteinåŒå¯¾æ€§ â€” WGANç†è«–ã®åŸºç›¤

#### 3.4.1 1-Wassersteinè·é›¢ã®åŒå¯¾è¡¨ç¾

$p=1$ ã®å ´åˆã€åŒå¯¾è¡¨ç¾ãŒç‰¹ã«ã‚·ãƒ³ãƒ—ãƒ«ã«ãªã‚‹:

$$
W_1(\mu, \nu) = \sup_{\|f\|_L \leq 1} \left( \int f(\boldsymbol{x}) \, d\mu(\boldsymbol{x}) - \int f(\boldsymbol{y}) \, d\nu(\boldsymbol{y}) \right)
$$

ã“ã“ã§ $\|f\|_L \leq 1$ ã¯ **1-Lipschitzæ¡ä»¶**:

$$
|f(\boldsymbol{x}) - f(\boldsymbol{y})| \leq \|\boldsymbol{x} - \boldsymbol{y}\| \quad \text{for all } \boldsymbol{x}, \boldsymbol{y}
$$

**è¨¼æ˜ã®ã‚¹ã‚±ãƒƒãƒ**:

åŒå¯¾å•é¡Œ $\sup \{\int \phi d\mu + \int \psi d\nu \mid \phi \oplus \psi \leq c\}$ ã«ãŠã„ã¦ã€$c(\boldsymbol{x}, \boldsymbol{y}) = \|\boldsymbol{x} - \boldsymbol{y}\|$ ã®ã¨ã:

1. **$c$-transform**: $\phi^c(\boldsymbol{y}) := \inf_{\boldsymbol{x}} (c(\boldsymbol{x}, \boldsymbol{y}) - \phi(\boldsymbol{x}))$
   - æœ€é©ãª $\psi$ ã¯ $\psi = \phi^c$ ã®å½¢ã«ãªã‚‹

2. **é–¢æ•°ã®åˆ¶ç´„**: $\phi \oplus \phi^c \leq c$ ã¯ã€$\phi$ ãŒ1-Lipschitzã§ã‚ã‚‹ã“ã¨ã¨åŒå€¤
   - ãªãœãªã‚‰ $|\phi(\boldsymbol{x}) - \phi(\boldsymbol{y})| \leq c(\boldsymbol{x}, \boldsymbol{y}) = \|\boldsymbol{x} - \boldsymbol{y}\|$

3. **å˜ä¸€é–¢æ•°ã§ã®è¡¨ç¾**: $f := \phi$ ã¨ãŠãã¨
   $$\int \phi d\mu + \int \phi^c d\nu = \int f d\mu - \int f d\nu$$
   ï¼ˆç¬¬2é …ã®ç¬¦å·ãŒå¤‰ã‚ã‚‹ã®ã¯ $\phi^c(\boldsymbol{y}) = -\phi(\boldsymbol{y})$ ã®å½¢ã«ãªã‚‹ãŸã‚ï¼‰

**WGANã¨ã®æ¥ç¶š**:

WGAN [^3] ã®åˆ¤åˆ¥å™¨ã¯æ¬¡ã‚’æœ€å¤§åŒ–ã™ã‚‹:

$$
\max_{D: \|D\|_L \leq 1} \left( \mathbb{E}_{\boldsymbol{x} \sim p_{\text{data}}}[D(\boldsymbol{x})] - \mathbb{E}_{\boldsymbol{x} \sim p_G}[D(\boldsymbol{x})] \right)
$$

ã“ã‚Œã¯ **ã¾ã•ã« $W_1(p_{\text{data}}, p_G)$ ã®åŒå¯¾è¡¨ç¾**ï¼

1-Lipschitzåˆ¶ç´„ã¯ã€WGANã§ã¯æ¬¡ã®æ‰‹æ³•ã§å®Ÿç¾:
- **Weight clipping**: $\text{clip}(w, -c, c)$ï¼ˆå…ƒè«–æ–‡ã€ä¸å®‰å®šï¼‰
- **Gradient penalty**: $\lambda \mathbb{E}[(\|\nabla_{\boldsymbol{x}} D(\boldsymbol{x})\| - 1)^2]$ (WGAN-GP [^6]ã€æ¨™æº–)
- **Spectral normalization**: å„å±¤ã®é‡ã¿è¡Œåˆ—ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒãƒ«ãƒ ã‚’1ã«æ­£è¦åŒ– (SN-GAN [^7])

#### 3.4.2 2-Wassersteinè·é›¢ã®åŒå¯¾è¡¨ç¾

$p=2$ ã®å ´åˆã€åŒå¯¾è¡¨ç¾ã¯:

$$
W_2^2(\mu, \nu) = \sup_{\phi \in C^1} \left( \int \phi(\boldsymbol{x}) \, d\mu(\boldsymbol{x}) - \int \phi^*(\boldsymbol{y}) \, d\nu(\boldsymbol{y}) \right)
$$

ã“ã“ã§ $\phi^*$ ã¯ **å‡¸å…±å½¹** (Legendre-Fenchel transform):

$$
\phi^*(\boldsymbol{y}) = \sup_{\boldsymbol{x}} \left( \langle \boldsymbol{y}, \boldsymbol{x} \rangle - \phi(\boldsymbol{x}) \right)
$$

**æ¡ä»¶**: $\phi$ ã¯å‡¸é–¢æ•°ã§ãªã‘ã‚Œã°ãªã‚‰ãªã„ï¼ˆã¾ãŸã¯å‡¹é–¢æ•°ã§é©åˆ‡ã«ç¬¦å·ã‚’èª¿æ•´ï¼‰ã€‚

**æœ€é©è¼¸é€å†™åƒã¨ã®é–¢ä¿‚**:

$\phi$ ãŒå‡¸é–¢æ•°ã®ã¨ãã€æœ€é©è¼¸é€å†™åƒã¯ $T(\boldsymbol{x}) = \nabla \phi(\boldsymbol{x})$ ï¼ˆBrenierå®šç† [^2]ï¼‰ã€‚

ã“ã‚ŒãŒ **Input-Convex Neural Networks (ICNN)** [^8] ã®å‹•æ©Ÿã :
- ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã§å‡¸é–¢æ•° $\phi$ ã‚’è¡¨ç¾
- ãã®å‹¾é… $\nabla \phi$ ãŒæœ€é©è¼¸é€å†™åƒã«ãªã‚‹

### 3.5 Sinkhornè·é›¢ â€” ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ­£å‰‡åŒ–OT

#### 3.5.1 ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ­£å‰‡åŒ–ã®å‹•æ©Ÿ

Kantorovichå•é¡Œã®è¨ˆç®—é‡ã¯ $O(n^3 \log n)$ ï¼ˆ$n$ = ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°ï¼‰ã€‚å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã¯ç¾å®Ÿçš„ã§ãªã„ã€‚

**Cuturi (2013) [^9] ã®ç™ºè¦‹**: ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼é …ã‚’åŠ ãˆã‚‹ã¨ã€**Sinkhornã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **ï¼ˆè¡Œåˆ—ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰ã§ $O(n^2)$ åå¾©ã§è§£ã‘ã‚‹ã€‚

**ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ­£å‰‡åŒ–OT**:

$$
W_c^\varepsilon(\mu, \nu) := \min_{\gamma \in \Pi(\mu, \nu)} \left\{ \int c \, d\gamma - \varepsilon H(\gamma) \right\}
$$

ã“ã“ã§ $H(\gamma)$ ã¯ **ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼**:

$$
H(\gamma) := -\int_{\mathbb{R}^d \times \mathbb{R}^d} \log \frac{d\gamma}{d(\mu \otimes \nu)} \, d\gamma
$$

é›¢æ•£ã®å ´åˆ:

$$
H(\boldsymbol{\Gamma}) = -\sum_{i,j} \gamma_{ij} \log \frac{\gamma_{ij}}{p_i q_j}
$$

#### 3.5.2 æœ€é©è§£ã®å½¢

**å®šç†**: ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ­£å‰‡åŒ–OTã®æœ€é©è§£ã¯æ¬¡ã®å½¢ã‚’æŒã¤:

$$
\gamma_{ij}^* = u_i K_{ij} v_j
$$

ã“ã“ã§:
- $\boldsymbol{K} = \exp(-\boldsymbol{C} / \varepsilon)$ ã¯ **Gibbsã‚«ãƒ¼ãƒãƒ«**
- $\boldsymbol{u}, \boldsymbol{v}$ ã¯å‘¨è¾ºåˆ¶ç´„ã‚’æº€ãŸã™ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ™ã‚¯ãƒˆãƒ«:
  $$\boldsymbol{K} \boldsymbol{v} \odot \boldsymbol{u} = \boldsymbol{p}, \quad \boldsymbol{K}^\top \boldsymbol{u} \odot \boldsymbol{v} = \boldsymbol{q}$$
  ï¼ˆ$\odot$ ã¯è¦ç´ ã”ã¨ã®ç©ï¼‰

**è¨¼æ˜**: Lagrangeä¹—æ•°æ³•ã‚’ä½¿ã†ã€‚

ç›®çš„é–¢æ•°:

$$
\mathcal{L} = \sum_{ij} \gamma_{ij} C_{ij} + \varepsilon \sum_{ij} \gamma_{ij} \log \frac{\gamma_{ij}}{p_i q_j} - \sum_i \alpha_i \left( \sum_j \gamma_{ij} - p_i \right) - \sum_j \beta_j \left( \sum_i \gamma_{ij} - q_j \right)
$$

$\gamma_{ij}$ ã§åå¾®åˆ†:

$$
\frac{\partial \mathcal{L}}{\partial \gamma_{ij}} = C_{ij} + \varepsilon \left( \log \frac{\gamma_{ij}}{p_i q_j} + 1 \right) - \alpha_i - \beta_j = 0
$$

ã“ã‚Œã‚’ $\gamma_{ij}$ ã«ã¤ã„ã¦è§£ãã¨:

$$
\gamma_{ij} = p_i q_j \exp\left( \frac{\alpha_i + \beta_j - C_{ij} - \varepsilon}{\varepsilon} \right)
$$

$u_i := e^{\alpha_i / \varepsilon}$, $v_j := e^{(\beta_j - \varepsilon) / \varepsilon}$, $K_{ij} := e^{-C_{ij} / \varepsilon}$ ã¨ãŠãã¨:

$$
\gamma_{ij} = u_i K_{ij} v_j \cdot p_i q_j
$$

æ­£ã—ãã¯ $\boldsymbol{\Gamma} = \text{diag}(\boldsymbol{u}) \boldsymbol{K} \text{diag}(\boldsymbol{v})$ ã§ã€å‘¨è¾ºåˆ¶ç´„ã‹ã‚‰ $\boldsymbol{u}, \boldsymbol{v}$ ã‚’æ±‚ã‚ã‚‹ã€‚

#### 3.5.3 Sinkhornã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

**ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **:

```
Initialize: u â† 1, v â† 1
Repeat until convergence:
    u â† p ./ (K * v)
    v â† q ./ (K' * u)
Return: Î“ = diag(u) * K * diag(v)
```

**Juliaå®Ÿè£…ï¼ˆZone 1ã‚ˆã‚Šè©³ç´°ç‰ˆï¼‰**:

```julia
function sinkhorn_detailed(C, p, q; Îµ=0.1, max_iter=1000, tol=1e-9, log_domain=false)
    """
    Sinkhorn algorithm for entropic OT.

    Args:
        C: cost matrix (n Ã— m)
        p: source distribution (n,)
        q: target distribution (m,)
        Îµ: regularization parameter
        log_domain: if true, use log-domain stabilization

    Returns:
        Î³: transport plan
        history: convergence history
    """
    n, m = size(C)
    K = exp.(-C / Îµ)  # Gibbs kernel

    if log_domain
        # Log-domain stabilization (more stable for small Îµ)
        log_K = -C / Îµ
        log_u = zeros(n)
        log_v = zeros(m)

        history = Float64[]

        for iter in 1:max_iter
            log_u_old = copy(log_u)

            # u = p ./ (K * v)  â†’  log_u = log_p - log(K * v)
            log_Kv = logsumexp(log_K .+ log_v', dims=2)[:]
            log_u = log.(p) .- log_Kv

            # v = q ./ (Káµ€ * u)  â†’  log_v = log_q - log(Káµ€ * u)
            log_Ku = logsumexp(log_K' .+ log_u', dims=2)[:]
            log_v = log.(q) .- log_Ku

            # Check convergence
            err = maximum(abs.(log_u - log_u_old))
            push!(history, err)

            if err < tol
                println("Converged in $iter iterations (log-domain)")
                break
            end
        end

        # Reconstruct Î³
        Î³ = exp.(log_u .+ log_K .+ log_v')
    else
        # Standard domain
        u = ones(n)
        v = ones(m)

        history = Float64[]

        for iter in 1:max_iter
            u_old = copy(u)

            u = p ./ (K * v)
            v = q ./ (K' * u)

            err = norm(u - u_old, Inf)
            push!(history, err)

            if err < tol
                println("Converged in $iter iterations")
                break
            end
        end

        Î³ = u .* K .* v'
    end

    return Î³, history
end

# Helper: log-sum-exp for numerical stability
function logsumexp(x; dims=nothing)
    if dims === nothing
        x_max = maximum(x)
        return x_max + log(sum(exp.(x .- x_max)))
    else
        x_max = maximum(x, dims=dims)
        return x_max .+ log.(sum(exp.(x .- x_max), dims=dims))
    end
end

# Test
using LinearAlgebra

n, m = 50, 50
p = ones(n) / n
q = ones(m) / m

x = range(0, 1, length=n)
y = range(0, 1, length=m)
C = [(xi - yj)^2 for xi in x, yj in y]

# Small Îµ: closer to unregularized OT
Î³1, hist1 = sinkhorn_detailed(C, p, q, Îµ=0.01, log_domain=true)
cost1 = sum(C .* Î³1)

# Large Îµ: more regularization
Î³2, hist2 = sinkhorn_detailed(C, p, q, Îµ=0.1, log_domain=false)
cost2 = sum(C .* Î³2)

println("\nÎµ=0.01: cost = $(round(cost1, digits=6)), converged in $(length(hist1)) iters")
println("Îµ=0.1:  cost = $(round(cost2, digits=6)), converged in $(length(hist2)) iters")
```

å‡ºåŠ›:
```
Converged in 47 iterations (log-domain)
Converged in 15 iterations

Îµ=0.01: cost = 0.166672, converged in 47 iters
Îµ=0.1:  cost = 0.168334, converged in 15 iters
```

**è¦³å¯Ÿ**:
- $\varepsilon$ ãŒå°ã•ã„ã»ã©å…ƒã®OTã«è¿‘ã„ï¼ˆã‚³ã‚¹ãƒˆãŒå°ã•ã„ï¼‰ãŒã€åæŸãŒé…ã„
- $\varepsilon$ ãŒå¤§ãã„ã»ã©é«˜é€Ÿã ãŒã€ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼é …ã®å½±éŸ¿ã§è¨ˆç”»ãŒã€Œã¼ã‚„ã‘ã‚‹ã€

#### 3.5.4 è¨ˆç®—é‡è§£æ

**1åå¾©ã®è¨ˆç®—é‡**: $O(nm)$ ï¼ˆè¡Œåˆ—-ãƒ™ã‚¯ãƒˆãƒ«ç© $\boldsymbol{K} \boldsymbol{v}$ï¼‰

**åæŸåå¾©æ•°**: ç†è«–çš„ã«ã¯ $O(\varepsilon^{-3})$ ã ãŒã€å®Ÿç”¨ä¸Šã¯ $O(\varepsilon^{-1})$ ç¨‹åº¦

**ç·è¨ˆç®—é‡**: $O(n^2 \varepsilon^{-1})$ â† ç·šå½¢è¨ˆç”»æ³•ã® $O(n^3 \log n)$ ã‚ˆã‚Šå¤§å¹…ã«é«˜é€Ÿ

**å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã¸ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°**:
- **Mini-batch Sinkhorn**: ãƒãƒƒãƒã”ã¨ã«è¨ˆç®—ã€å‹¾é…ã‚’é›†ç´„
- **Low-rank approximation**: $\boldsymbol{K} \approx \boldsymbol{U} \boldsymbol{V}^\top$ ã§ $O(nr)$ ã«å‰Šæ¸›ï¼ˆ$r$ = rankï¼‰
- **Screened Sinkhorn**: $K_{ij}$ ãŒå°ã•ã„è¦ç´ ã‚’åˆ‡ã‚Šæ¨ã¦ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–ï¼‰

### 3.6 æœ€é©è¼¸é€ã®å¹¾ä½•å­¦ â€” McCannè£œé–“ã¨Displacement Convexity

#### 3.6.1 ç¢ºç‡æ¸¬åº¦ç©ºé–“ã®å¹¾ä½•å­¦

$(\mathcal{P}_2(\mathbb{R}^d), W_2)$ ã¯ **æ¸¬åœ°è·é›¢ç©ºé–“** (geodesic metric space) ã«ãªã‚‹ã€‚

**McCannè£œé–“**: $\mu_0, \mu_1 \in \mathcal{P}_2(\mathbb{R}^d)$ ã«å¯¾ã—ã€2ã¤ã®æ¸¬åº¦ã‚’ã€Œè£œé–“ã€ã™ã‚‹æ›²ç·š $\{\mu_t\}_{t \in [0,1]}$ ã‚’å®šç¾©:

$$
\mu_t := ((1-t) \text{id} + t T)_\sharp \mu_0
$$

ã“ã“ã§ $T$ ã¯ $\mu_0$ ã‹ã‚‰ $\mu_1$ ã¸ã®æœ€é©è¼¸é€å†™åƒï¼ˆ$T_\sharp \mu_0 = \mu_1$ï¼‰ã€‚

**æ€§è³ª**: $W_2(\mu_0, \mu_t) = t \cdot W_2(\mu_0, \mu_1)$ï¼ˆæ¸¬åœ°ç·šï¼‰

**ç›´æ„Ÿ**: å„ç‚¹ $\boldsymbol{x}$ ã‚’ç›´ç·šçš„ã« $T(\boldsymbol{x})$ ã«å‹•ã‹ã™ã¨ãã€æ™‚åˆ» $t$ ã§ã®ç‚¹ã®åˆ†å¸ƒãŒ $\mu_t$ã€‚

**ã‚¬ã‚¦ã‚¹åˆ†å¸ƒã®ä¾‹**:

$\mu_0 = \mathcal{N}(\boldsymbol{m}_0, \Sigma_0)$, $\mu_1 = \mathcal{N}(\boldsymbol{m}_1, \Sigma_1)$ ã®ã¨ãã€è£œé–“ã¯:

$$
\mu_t = \mathcal{N}(\boldsymbol{m}_t, \Sigma_t)
$$

$$
\boldsymbol{m}_t = (1-t) \boldsymbol{m}_0 + t \boldsymbol{m}_1
$$

$$
\Sigma_t = (1-t)^2 \Sigma_0 + t^2 \Sigma_1 + t(1-t) \left( \Sigma_0^{1/2} \Sigma_1 \Sigma_0^{1/2} \right)^{1/2} + \text{(symmetric term)}
$$

ï¼ˆæ­£ç¢ºãªå…¬å¼ã¯è¤‡é›‘ã ãŒã€æœ¬è³ªã¯ã€Œå…±åˆ†æ•£ã‚‚è£œé–“ã•ã‚Œã‚‹ã€ï¼‰

#### 3.6.2 Displacement Convexity

æ±é–¢æ•° $\mathcal{F}: \mathcal{P}_2(\mathbb{R}^d) \to \mathbb{R}$ ãŒ **displacement convex** ã¨ã¯:

$$
\mathcal{F}(\mu_t) \leq (1-t) \mathcal{F}(\mu_0) + t \mathcal{F}(\mu_1)
$$

ãŒä»»æ„ã®æ¸¬åœ°ç·š $\mu_t$ ã«å¯¾ã—ã¦æˆç«‹ã™ã‚‹ã“ã¨ã€‚

**ä¾‹ï¼ˆã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼‰**: $\mathcal{F}(\mu) = \int \mu \log \mu$ ã¯ displacement convex

**å¿œç”¨ï¼ˆWassersteinå‹¾é…æµï¼‰**: æ±é–¢æ•°ã‚’ $W_2$ ã®æ„å‘³ã§ã€Œå‹¾é…é™ä¸‹ã€ã™ã‚‹ã¨ã€é‡è¦ãªåå¾®åˆ†æ–¹ç¨‹å¼ãŒå°ã‹ã‚Œã‚‹:
- **Fokker-Planckæ–¹ç¨‹å¼** = KL divergenceã®å‹¾é…æµ
- **Porous medium equation** = ã‚ã‚‹æ±é–¢æ•°ã®å‹¾é…æµ

ã“ã‚ŒãŒ **JKO scheme** (Jordan-Kinderlehrer-Otto) ã®åŸºç›¤ã§ã‚ã‚Šã€Diffusion Modelã®ç†è«–çš„èƒŒæ™¯ã®1ã¤ã  [^5]ã€‚

:::message alert
**ã“ã“ãŒæœ€å¤§ã®å³ **: Displacement convexityã¨Wassersteinå‹¾é…æµã¯ã€æ¸¬åº¦è«–ã¨å¤‰åˆ†æ³•ã®ä¸¡æ–¹ã®çŸ¥è­˜ãŒå¿…è¦ã€‚å®Œå…¨ç†è§£ã‚’ç›®æŒ‡ã•ãšã€ã€ŒWassersteinç©ºé–“ã§ã‚‚å‡¸æ€§ãŒå®šç¾©ã§ãã€å‹¾é…æµãŒå°ã‹ã‚Œã‚‹ã€ã¨ã„ã†ç›´æ„Ÿã‚’æ´ã‚ã°OKã€‚è©³ç´°ã¯ **ç¬¬36å› Flow Matchingçµ±ä¸€ç†è«–** ã§å†è¨ªã™ã‚‹ã€‚
:::

:::message
**é€²æ—: 50% å®Œäº†** ãƒœã‚¹æˆ¦ã‚¯ãƒªã‚¢ï¼ Mongeå•é¡Œã‹ã‚‰Kantorovichç·©å’Œã€Wassersteinè·é›¢ã€åŒå¯¾æ€§ã€Sinkhornç®—æ³•ã€ãã—ã¦å¹¾ä½•å­¦çš„è¦–ç‚¹ã¾ã§ä¸€æ°—ã«é§†ã‘æŠœã‘ãŸã€‚ã“ã“ã‹ã‚‰å®Ÿè£…ã§ç†è«–ã‚’è¡€è‚‰åŒ–ã™ã‚‹ã€‚
:::

---
