---
title: "ç¬¬36å›: æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«åŸºç¤ / DDPM & ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
emoji: "ğŸ”„"
type: "tech"
topics: ["machinelearning", "deeplearning", "ddpm", "rust", "diffusion"]
published: true
slug: "ml-lecture-36-part2"
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Python", "Rust"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---

## ğŸ’» Z5. è©¦ç·´ï¼ˆå®Ÿè£…ï¼‰ï¼ˆ45åˆ†ï¼‰â€” Pythonè¨“ç·´ + Rustæ¨è«–

### 4.1 ç’°å¢ƒæ§‹ç¯‰ & ãƒ©ã‚¤ãƒ–ãƒ©ãƒªé¸å®š

**Rustç’°å¢ƒ**:

```python
# requirements.txt â€” Pythonè¨“ç·´ç’°å¢ƒ:
# torch>=2.0        (PyTorch + CUDA)
# torchvision>=0.15
# numpy
# Pillow
# python-mnist
```

**Rustç’°å¢ƒ** (æ¨è«–):

```toml
# Cargo.toml
[dependencies]
ndarray = "0.15"
ort = "2.0"  # ONNX Runtime
image = "0.25"
```

### 4.2 Tiny DDPM PyTorchè¨“ç·´å®Ÿè£… (å®Œå…¨ç‰ˆ)

**ç›®æ¨™**: MNIST ã§ 500K paramsã€CPU 5åˆ†ã§è¨“ç·´ã€‚

#### 4.2.1 Noise Schedule

```rust
use std::f32::consts::PI;

/// Cosine noise schedule (Nichol & Dhariwal 2021).
/// f(t) = cosÂ²(Ï€/2 Â· (t/T + s)/(1+s)),  á¾±â‚œ = f(t)/f(0),  Î±â‚œ = á¾±â‚œ/á¾±â‚œâ‚‹â‚,  Î²â‚œ = 1-Î±â‚œ
/// Returns (beta, alpha, alpha_bar) each of length `t_steps`.
fn cosine_schedule(t_steps: usize, s: f32) -> (Vec<f32>, Vec<f32>, Vec<f32>) {
    // f(t) = cosÂ²(Ï€/2 Â· (t/T + s)/(1+s))
    let f: Vec<f32> = (0..=t_steps)
        .map(|t| {
            let ratio = t as f32 / t_steps as f32;
            ((ratio + s) / (1.0 + s) * PI / 2.0).cos().powi(2)
        })
        .collect();
    let alpha_bar: Vec<f32> = f[1..].iter().map(|&ft| ft / f[0]).collect(); // á¾±â‚œ = f(t)/f(0)
    let mut alpha = vec![alpha_bar[0]; t_steps];
    for i in 1..t_steps {
        alpha[i] = alpha_bar[i] / alpha_bar[i - 1]; // Î±â‚œ = á¾±â‚œ / á¾±â‚œâ‚‹â‚
    }
    let beta: Vec<f32> = alpha.iter().map(|&a| 1.0 - a).collect(); // Î²â‚œ = 1 - Î±â‚œ
    (beta, alpha, alpha_bar)
}

fn main() {
    let (beta, _alpha, alpha_bar) = cosine_schedule(1000, 0.008);
    let beta_min = beta.iter().cloned().fold(f32::INFINITY, f32::min);
    let beta_max = beta.iter().cloned().fold(f32::NEG_INFINITY, f32::max);
    println!("Î² range: [{}, {}]", beta_min, beta_max);
    println!("á¾±_T = {}", alpha_bar.last().unwrap()); // Should be â‰ˆ 0
}
```

#### 4.2.2 Simplified U-Net (Tinyç‰ˆ)

```python
import math
import torch
import torch.nn as nn
import torch.nn.functional as F

def time_embedding(t: int, d: int) -> torch.Tensor:
    # Sinusoidal time embedding: returns Tensor of shape (d,).
    half = d // 2
    log_scale = math.log(10000.0) / (half - 1)
    freqs = torch.exp(-log_scale * torch.arange(half, dtype=torch.float32))
    vals  = t * freqs
    return torch.cat([vals.sin(), vals.cos()])  # (d,)

class TinyUNet(nn.Module):
    # Tiny U-Net for MNIST 28Ã—28 (~500K params).

    def __init__(self, d_model: int = 64) -> None:
        super().__init__()
        t_dim = 128
        self.time_fc1   = nn.Linear(t_dim,       d_model * 4)
        self.time_fc2   = nn.Linear(d_model * 4, d_model * 4)
        self.enc1_conv  = nn.Conv2d(1,            d_model,     3, padding=1)
        self.enc2_conv  = nn.Conv2d(d_model,      d_model * 2, 3, padding=1, stride=2)
        self.bottleneck = nn.Conv2d(d_model * 2,  d_model * 2, 3, padding=1)
        self.dec1_conv  = nn.ConvTranspose2d(d_model * 4, d_model, 4, padding=1, stride=2)
        self.out_conv   = nn.Conv2d(d_model, 1, 3, padding=1)

    def forward(self, x: torch.Tensor, t: int) -> torch.Tensor:
        t_vec  = time_embedding(t, 128).to(x.device)
        t_emb  = F.silu(self.time_fc1(t_vec.unsqueeze(0)))  # (1, d*4)
        _t_emb = self.time_fc2(t_emb)

        # Encoder
        h1 = F.silu(self.enc1_conv(x))    # (B, d, 28, 28)
        h2 = F.silu(self.enc2_conv(h1))   # (B, d*2, 14, 14)

        # Bottleneck
        h  = F.silu(self.bottleneck(h2))  # (B, d*2, 14, 14)

        # Decoder with skip connection
        h_cat = torch.cat([h, h2], dim=1)   # (B, d*4, 14, 14)
        h     = F.silu(self.dec1_conv(h_cat))  # (B, d, 28, 28)

        return self.out_conv(h)  # (B, 1, 28, 28)
```

<details><summary>å®Œå…¨ãªU-Netå®Ÿè£… (Self-Attentionä»˜ã)</summary>

æœ¬æ ¼çš„ãªU-Netã«ã¯16Ã—16è§£åƒåº¦ã§Self-Attentionã‚’è¿½åŠ ã™ã‚‹ã€‚ä»¥ä¸‹ã¯å®Œå…¨ç‰ˆ (MNIST ã§ã¯éå‰°):

```python
import torch
import torch.nn as nn

class SelfAttention(nn.Module):
    # Multi-Head Self-Attention layer.
    # x: Tensor of shape (B, C, H, W) â€” applied at low-resolution feature maps.

    def __init__(self, heads: int, d_model: int) -> None:
        super().__init__()
        self.heads   = heads
        self.d_model = d_model

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        b, c, h, w = x.shape
        assert c % self.heads == 0, "C must be divisible by heads"
        n = h * w

        # Reshape to (B, N, C) for attention
        x_flat = x.reshape(b, c, n).transpose(1, 2)  # (B, N, C)

        # Simplified: Q = K = V = x_flat (identity projection for demo)
        scale  = c / self.heads
        scores = x_flat.matmul(x_flat.transpose(1, 2)) / scale  # (B, N, N)
        attn   = scores.softmax(dim=-1)
        out    = attn.matmul(x_flat)                             # (B, N, C)

        # Reshape back to (B, C, H, W) and add residual
        out = out.transpose(1, 2).reshape(b, c, h, w)
        return out + x  # Residual connection
```

</details>

#### 4.2.3 è¨“ç·´ãƒ«ãƒ¼ãƒ—

```python
import math
import torch
import torch.nn.functional as F
from torch.optim import AdamW

def train_step(
    model:     TinyUNet,
    opt:       AdamW,
    x0:        torch.Tensor,
    alpha_bar: list[float],
    t_steps:   int,
) -> float:
    # Single training step; returns MSE loss scalar.
    t    = torch.randint(0, t_steps, (1,)).item()
    ab_t = alpha_bar[t]

    # q(xâ‚œ|xâ‚€) = N(âˆšá¾±â‚œÂ·xâ‚€, (1-á¾±â‚œ)Â·I)  â†’  xâ‚œ = âˆšá¾±â‚œÂ·xâ‚€ + âˆš(1-á¾±â‚œ)Â·Îµ
    eps = torch.randn_like(x0)
    x_t = math.sqrt(ab_t) * x0 + math.sqrt(1.0 - ab_t) * eps

    # L_simple = E[||Îµ - Îµ_Î¸(xâ‚œ, t)||Â²]  (Ho et al. 2020)
    eps_pred = model(x_t, t)
    loss     = F.mse_loss(eps_pred, eps)
    opt.zero_grad(set_to_none=True)
    loss.backward()
    opt.step()
    return loss.item()

def train_ddpm(
    model:      TinyUNet,
    train_data: list[torch.Tensor],
    alpha_bar:  list[float],
    t_steps:    int,
    epochs:     int,
    lr:         float,
) -> None:
    # Full training loop.
    opt = AdamW(model.parameters(), lr=lr)
    for epoch in range(epochs):
        total_loss = 0.0
        for batch_idx, x0 in enumerate(train_data):
            loss = train_step(model, opt, x0, alpha_bar, t_steps)
            total_loss += loss
            if batch_idx % 100 == 0:
                print(f"Epoch {epoch + 1}, Batch {batch_idx}, Loss: {loss:.4f}")
        avg = total_loss / len(train_data)
        print(f"Epoch {epoch + 1} completed. Avg Loss: {avg:.4f}")
```

#### 4.2.4 ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (DDPM & DDIM)

```python
import math
import torch

@torch.inference_mode()
def ddpm_sample(
    model:     TinyUNet,
    x_t_init:  torch.Tensor,
    beta:      list[float],
    alpha:     list[float],
    alpha_bar: list[float],
    t_steps:   int,
) -> torch.Tensor:
    # DDPM sampling: stochastic reverse process from x_T â†’ x_0.
    x_t = x_t_init.clone()
    for t in reversed(range(t_steps)):
        # p_Î¸(x_{t-1}|xâ‚œ) = N(Î¼_Î¸(xâ‚œ,t), Ïƒâ‚œÂ²Â·I)
        eps_pred = model(x_t, t)
        # Î¼_Î¸ = (xâ‚œ âˆ’ Î²â‚œ/âˆš(1-á¾±â‚œ)Â·Îµ_Î¸) / âˆšÎ±â‚œ
        coeff = beta[t] / math.sqrt(1.0 - alpha_bar[t])
        mu    = (x_t - coeff * eps_pred) / math.sqrt(alpha[t])
        if t > 0:
            sigma = math.sqrt(beta[t])  # Ïƒâ‚œ = âˆšÎ²â‚œ
            z     = torch.randn_like(x_t)
            x_t   = mu + sigma * z      # x_{t-1} = Î¼_Î¸ + Ïƒâ‚œÂ·z
        else:
            x_t = mu
    return x_t

@torch.inference_mode()
def ddim_sample(
    model:     TinyUNet,
    x_t_init:  torch.Tensor,
    alpha_bar: list[float],
    steps:     int,
    eta:       float,
) -> torch.Tensor:
    # DDIM sampling: accelerated deterministic (Î·=0) or stochastic (Î·=1) reverse.
    total = len(alpha_bar)
    tau   = [min(i * total // steps, total - 1) for i in range(steps)]
    x_t   = x_t_init.clone()

    for i in reversed(range(1, len(tau))):
        t, t_prev     = tau[i], tau[i - 1]
        ab_t, ab_prev = alpha_bar[t], alpha_bar[t_prev]
        eps_pred      = model(x_t, t)

        # xÌ‚â‚€ = (xâ‚œ - âˆš(1-á¾±â‚œ)Â·Îµ_Î¸) / âˆšá¾±â‚œ
        x0_pred = (x_t - math.sqrt(1.0 - ab_t) * eps_pred) / math.sqrt(ab_t)

        # Ïƒâ‚œ(Î·) = Î·Â·âˆš((1-á¾±_{t-1})/(1-á¾±â‚œ))Â·âˆš(1 - á¾±â‚œ/á¾±_{t-1})  (Î·=0 â†’ deterministic)
        sigma_t   = eta * math.sqrt((1.0 - ab_prev) / (1.0 - ab_t))                         * math.sqrt(1.0 - ab_t / ab_prev)
        dir_coeff = math.sqrt(1.0 - ab_prev - sigma_t ** 2)
        dir_xt    = dir_coeff * eps_pred  # âˆš(1-á¾±_{t-1}-Ïƒâ‚œÂ²)Â·Îµ_Î¸

        if eta > 0.0:
            noise = torch.randn_like(x_t)
            x_t   = math.sqrt(ab_prev) * x0_pred + dir_xt + sigma_t * noise
        else:
            x_t = math.sqrt(ab_prev) * x0_pred + dir_xt

    # Final step: t = Ï„[0] â†’ x_0
    t0   = tau[0]
    ab0  = alpha_bar[t0]
    eps_pred = model(x_t, t0)
    return (x_t - math.sqrt(1.0 - ab0) * eps_pred) / math.sqrt(ab0)
```

### 4.3 ğŸ¦€ Rustæ¨è«–å®Ÿè£… (DDIMé«˜é€Ÿã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°)

**Rustå®Ÿè£…** ã¯è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ« (ONNXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ) ã‚’èª­ã¿è¾¼ã¿ã€DDIM ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’é«˜é€Ÿå®Ÿè¡Œã€‚

#### 4.3.1 Rustå´ã‚³ãƒ¼ãƒ‰

```rust
// src/ddim.rs
use ndarray::{Array4, s};
use ort::{Session, Value};

pub struct DDIMSampler {
    session: Session,
    alpha_bar: Vec<f32>,
    steps: usize,
}

type Result<T> = std::result::Result<T, Box<dyn std::error::Error>>;

impl DDIMSampler {
    pub fn new(model_path: &str, alpha_bar: Vec<f32>, steps: usize) -> Result<Self> {
        let session = Session::builder()?
            .with_model_from_file(model_path)?;
        Ok(Self { session, alpha_bar, steps })
    }

    pub fn sample(&self, x_t: Array4<f32>, eta: f32) -> Result<Array4<f32>> {
        let n = self.alpha_bar.len();
        let tau: Vec<usize> = (0..self.steps)
            .map(|i| (i * n / self.steps).min(n - 1))
            .collect();

        let mut x = x_t;

        for i in (1..tau.len()).rev() {
            let (t, t_prev) = (tau[i], tau[i - 1]);

            // Predict noise via ONNX model
            let Îµ_pred = self.predict_noise(&x, t)?;

            // DDIM step
            x = self.ddim_step(x, Îµ_pred, t, t_prev, eta);
        }

        // Final step
        let Îµ_pred = self.predict_noise(&x, tau[0])?;
        let á¾±_t = self.alpha_bar[tau[0]];
        let x_0 = (&x - (1.0 - á¾±_t).sqrt() * &Îµ_pred) / á¾±_t.sqrt();

        Ok(x_0)
    }

    fn predict_noise(&self, x_t: &Array4<f32>, t: usize) -> Result<Array4<f32>> {
        // Convert to ONNX input
        let x_input = Value::from_array(x_t.view())?;
        let t_input = Value::from_array(ndarray::arr0(t as f32).view())?;

        // Run inference
        let outputs = self.session.run(vec![x_input, t_input])?;
        let Îµ = outputs[0].try_extract_tensor::<f32>()?;

        Ok(Îµ.to_owned().into_dimensionality()?)
    }

    fn ddim_step(&self, x_t: Array4<f32>, Îµ: Array4<f32>, t: usize, t_prev: usize, Î·: f32) -> Array4<f32> {
        let (á¾±_t, á¾±_prev) = (self.alpha_bar[t], self.alpha_bar[t_prev]);

        // Predicted x_0
        let x_0_pred = (&x_t - (1.0 - á¾±_t).sqrt() * &Îµ) / á¾±_t.sqrt();

        // Variance
        let Ïƒ_t = Î· * ((1.0 - á¾±_prev) / (1.0 - á¾±_t)).sqrt()
            * (1.0 - á¾±_t / á¾±_prev).sqrt();

        // Direction + DDIM step
        let dir_xt = (1.0 - á¾±_prev - Ïƒ_t.powi(2)).sqrt() * &Îµ;
        á¾±_prev.sqrt() * x_0_pred + dir_xt
    }
}
```

#### 4.3.2 ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ (Rust â†’ ONNX)

```python
# Export trained PyTorch model to ONNX for Rust inference (ort):
#
#   from safetensors.torch import save_file
#   save_file(model.state_dict(), "tiny_ddpm.safetensors")
#   # Full ONNX export:
#   torch.onnx.export(model, (x_dummy, torch.tensor(0)), "tiny_ddpm.onnx",
#                     input_names=["x_t", "t"], output_names=["eps_pred"])

def export_to_onnx(model: TinyUNet, filepath: str) -> None:
    x_dummy = torch.zeros(1, 1, 28, 28)
    t_dummy = torch.tensor(0)
    torch.onnx.export(
        model, (x_dummy, t_dummy), filepath,
        input_names=["x_t", "t"], output_names=["eps_pred"],
    )
    print(f"Model exported to {filepath}")

if __name__ == "__main__":
    model = TinyUNet(d_model=64)
    # ... (train model) ...
    export_to_onnx(model, "tiny_ddpm.onnx")
```

#### 4.3.3 Rustå®Ÿè¡Œ

```rust
// src/main.rs
use ndarray::Array4;
use ndarray_rand::RandomExt;
use ndarray_rand::rand_distr::StandardNormal;

mod ddim;

fn main() {
    // Load alpha_bar schedule
    let alpha_bar: Vec<f32> = load_alpha_bar_from_file("alpha_bar.json");

    // Create sampler
    let sampler = ddim::DDIMSampler::new("tiny_ddpm.onnx", alpha_bar, 50).unwrap();

    // Sample from noise
    let x_T = Array4::random((1, 1, 28, 28), StandardNormal);
    let x_0 = sampler.sample(x_T, 0.0).unwrap();  // Deterministic (Î·=0)

    println!("Generated image shape: {:?}", x_0.shape());
    save_image(&x_0, "generated.png");
}

fn load_alpha_bar_from_file(path: &str) -> Vec<f32> {
    // Load from JSON (implementation omitted for brevity)
    vec![0.999, 0.998, /* ... */, 0.001]
}

fn save_image(x: &Array4<f32>, path: &str) {
    // Convert to image and save (implementation omitted)
}
```

### 4.4 Math â†’ Code 1:1å¯¾å¿œãƒ‘ã‚¿ãƒ¼ãƒ³

| æ•°å¼ | Python | Rustæ¨è«– |
|:-----|:------|:-----|
| $\mathbf{x}_t = \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t} \boldsymbol{\epsilon}$ | `x_t = sqrt(á¾±[t]) .* xâ‚€ .+ sqrt(1 - á¾±[t]) .* Îµ` | `x_t = alpha_bar_t.sqrt() * x_0 + (1.0 - alpha_bar_t).sqrt() * epsilon` |
| $\boldsymbol{\mu}_\theta = \frac{1}{\sqrt{\alpha_t}} (\mathbf{x}_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta)$ | `Î¼ = (1 / sqrt(Î±[t])) .* (x_t .- (Î²[t] / sqrt(1 - á¾±[t])) .* Îµ_pred)` | `mu = (x_t - (beta_t / (1.0 - alpha_bar_t).sqrt()) * epsilon_pred) / alpha_t.sqrt()` |
| $\mathbf{x}_{t-1} = \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0 + \sqrt{1-\bar{\alpha}_{t-1}} \boldsymbol{\epsilon}_\theta$ | `x_prev = sqrt(á¾±[t_prev]) .* xâ‚€_pred .+ sqrt(1 - á¾±[t_prev]) .* Îµ_pred` | `x_prev = alpha_bar_prev.sqrt() * x_0_pred + (1.0 - alpha_bar_prev).sqrt() * epsilon_pred` |

> **Note:** **é€²æ—: 70% å®Œäº†** Pythonè¨“ç·´ + Rustæ¨è«–ã®å®Ÿè£…å®Œäº†ã€‚Zone 5ã§å®Ÿé¨“ã¸ã€‚

---

### ğŸ”¬ å®Ÿé¨“ãƒ»æ¤œè¨¼ï¼ˆ30åˆ†ï¼‰â€” Tiny DDPM on MNIST

### 5.1 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ (MNIST)

```python
import torch
from torchvision import datasets, transforms

def load_mnist_batched(batch_size: int, device: torch.device) -> list[torch.Tensor]:
    # Load MNIST, normalize to [-1, 1], and return batched Tensors of shape (B, 1, 28, 28).
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,)),  # [0, 1] â†’ [-1, 1]
    ])
    dataset = datasets.MNIST("data", train=True, download=True, transform=transform)
    loader  = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)
    batches = [x.to(device) for x, _ in loader]
    print(f"Training batches: {len(batches)}  (batch_size={batch_size})")
    return batches
```

### 5.2 è¨“ç·´å®Ÿè¡Œ (CPU 5åˆ†)

```python
import torch

def main() -> None:
    dev   = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = TinyUNet(d_model=64).to(dev)

    # Noise schedule
    t_steps = 1000
    beta, alpha, alpha_bar = cosine_schedule(t_steps, 0.008)

    # Load data and train
    train_batches = load_mnist_batched(128, dev)
    train_ddpm(model, train_batches, alpha_bar, t_steps, epochs=10, lr=1e-3)

    torch.save(model.state_dict(), "tiny_ddpm.pt")
    print("Training completed!")

if __name__ == "__main__":
    main()
```

**Expected output**:
```
Epoch 1, Batch 100, Loss: 0.523
...
Epoch 10 completed. Avg Loss: 0.089
Training completed!
```

### 5.3 ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° & å¯è¦–åŒ–

```python
import torch

def print_sample_stats(samples: torch.Tensor, label: str) -> None:
    # Print pixel statistics for a batch of samples (shape: NÃ—1Ã—HÃ—W, range [-1, 1]).
    d = samples.flatten()
    print(f"{label}: min={d.min():.3f}, max={d.max():.3f}, mean={d.mean():.3f}")

def main() -> None:
    dev = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Sample 16 images (DDPM 1000 steps)
    x_t          = torch.randn(16, 1, 28, 28, device=dev)
    samples_ddpm = ddpm_sample(model, x_t.clone(), beta, alpha, alpha_bar, 1000)

    # Sample 16 images (DDIM 50 steps, deterministic Î·=0)
    samples_ddim = ddim_sample(model, x_t, alpha_bar, 50, 0.0)

    # Print statistics; use torchvision.utils.save_image for visual inspection
    print_sample_stats(samples_ddpm, "DDPM (1000 steps)")
    print_sample_stats(samples_ddim, "DDIM (50 steps, deterministic)")

if __name__ == "__main__":
    main()
```

### 5.4 å®šé‡è©•ä¾¡ & æ¯”è¼ƒ

**FID (FrÃ©chet Inception Distance)** ã¯è¨ˆç®—ã‚³ã‚¹ãƒˆé«˜ã„ãŸã‚ã€ç°¡æ˜“çš„ãª **å†æ§‹æˆèª¤å·®** ã¨ **å¤šæ§˜æ€§** ã‚’æ¸¬å®š:

```python
import math
import torch

@torch.inference_mode()
def test_reconstruction(
    model:     TinyUNet,
    x0:        torch.Tensor,
    alpha_bar: list[float],
    t:         int,
) -> float:
    # Encode x_0 to x_t (t=500), denoise back with DDIM, and return MSE.
    ab_t = alpha_bar[t]
    # q(xâ‚œ|xâ‚€) = N(âˆšá¾±â‚œÂ·xâ‚€, (1-á¾±â‚œ)Â·I)  â†’  xâ‚œ = âˆšá¾±â‚œÂ·xâ‚€ + âˆš(1-á¾±â‚œ)Â·Îµ
    eps    = torch.randn_like(x0)
    x_t    = math.sqrt(ab_t) * x0 + math.sqrt(1.0 - ab_t) * eps
    x_recon = ddim_sample(model, x_t, alpha_bar[:t + 1], 50, 0.0)
    return ((x0 - x_recon) ** 2).mean().item()

def main() -> None:
    mse_sum = sum(
        test_reconstruction(model, test_data[i:i+1], alpha_bar, 500)
        for i in range(100)
    )
    print(f"Average reconstruction MSE: {mse_sum / 100.0:.4f}")

if __name__ == "__main__":
    main()
```

**aMUSEd-256 æ¨è«–ãƒ‡ãƒ¢ã¨ã®å“è³ªæ¯”è¼ƒ**:

aMUSEd-256 [Hugging Face](https://huggingface.co/amused/amused-256) ã¯éæ‹¡æ•£ãƒ¢ãƒ‡ãƒ« (Masked Image Modeling) ã§256Ã—256ç”»åƒã‚’ç”Ÿæˆã€‚

| ãƒ¢ãƒ‡ãƒ« | è§£åƒåº¦ | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | è¨“ç·´æ™‚é–“ (CPU) | å“è³ª (ä¸»è¦³) |
|:-------|:-------|:----------|:--------------|:-----------|
| **Tiny DDPM (æœ¬å®Ÿè£…)** | 28Ã—28 | ~500K | 5åˆ† | MNISTæ•°å­—ã€ã‚·ãƒ£ãƒ¼ãƒ— |
| **aMUSEd-256** | 256Ã—256 | ~800M | N/A (äº‹å‰è¨“ç·´æ¸ˆã¿) | é«˜å“è³ªã€å¤šæ§˜ |

**çµè«–**: Tiny DDPMã¯ç†è«–å­¦ç¿’ç”¨ã€‚Productionå“è³ªã¯aMUSEd-256ã‚„Stable Diffusion (ç¬¬39å›) ã§å®Ÿç¾ã€‚

### 5.5 è¨“ç·´æ›²ç·šåˆ†æ & ãƒ‡ãƒãƒƒã‚°

**Lossæ›²ç·šã®å…¸å‹çš„ãƒ‘ã‚¿ãƒ¼ãƒ³**:

```rust
use std::f32::consts::PI;

/// Print training curves (epoch, loss, lr).
/// Use the `plotters` crate for a full chart.
fn print_training_curves(loss_history: &[f32], lr_schedule: &[f32]) {
    println!("{:<8} {:>10} {:>12}", "Epoch", "Loss", "LR");
    for (epoch, (&loss, &lr)) in loss_history.iter().zip(lr_schedule).enumerate() {
        println!("{:<8} {:>10.4} {:>12.6}", epoch + 1, loss, lr);
    }
    if let Some(&final_loss) = loss_history.last() {
        println!("Final loss target: 0.089 | actual: {:.4}", final_loss);
    }
}

fn main() {
    let loss_history = vec![0.523f32, 0.420, 0.350, 0.280, 0.220, 0.175, 0.140, 0.115, 0.099, 0.089];
    // Cosine LR decay: lr * cos(Ï€ * epoch / (2 * epochs))
    let lr_schedule: Vec<f32> = (0..=10)
        .map(|e| 1e-3 * (PI * e as f32 / 20.0).cos())
        .collect();
    print_training_curves(&loss_history, &lr_schedule);
}
```

**å…¸å‹çš„ãªå•é¡Œã¨å¯¾å‡¦**:

| ç—‡çŠ¶ | åŸå›  | å¯¾å‡¦ |
|:-----|:-----|:-----|
| Loss ãŒç™ºæ•£ (NaN) | Learning rate é«˜ã™ã | LR ã‚’ 1/10 ã«æ¸›ã‚‰ã™ |
| Loss ãŒä¸‹ãŒã‚‰ãªã„ | ãƒ¢ãƒ‡ãƒ«ãŒå°ã•ã™ã | d_model ã‚’ 64 â†’ 128 |
| ç”Ÿæˆç”»åƒãŒãƒã‚¤ã‚ºã®ã¿ | è¨“ç·´ä¸è¶³ | epochs ã‚’ 10 â†’ 50 |
| ç”Ÿæˆç”»åƒãŒå˜ä¸€ãƒ‘ã‚¿ãƒ¼ãƒ³ | Mode collapse | Batch size ã‚’ 128 â†’ 256 |

**è¨“ç·´å®‰å®šåŒ–ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯**:

```python
import math
import torch
import torch.nn.functional as F
from torch.optim import AdamW

def train_step_with_clip(
    model:     TinyUNet,
    opt:       AdamW,
    x0:        torch.Tensor,
    alpha_bar: list[float],
    t_steps:   int,
    clip_norm: float,
) -> tuple[float, float]:
    # Training step with gradient-norm clipping. Returns (loss, grad_norm).
    t    = torch.randint(0, t_steps, (1,)).item()
    ab_t = alpha_bar[t]

    # q(xâ‚œ|xâ‚€) = N(âˆšá¾±â‚œÂ·xâ‚€, (1-á¾±â‚œ)Â·I)  â†’  xâ‚œ = âˆšá¾±â‚œÂ·xâ‚€ + âˆš(1-á¾±â‚œ)Â·Îµ
    eps  = torch.randn_like(x0)
    x_t  = math.sqrt(ab_t) * x0 + math.sqrt(1.0 - ab_t) * eps

    eps_pred = model(x_t, t)
    loss     = F.mse_loss(eps_pred, eps)
    opt.zero_grad(set_to_none=True)
    loss.backward()

    # Clip by scaling gradients if norm exceeds threshold
    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), clip_norm).item()
    opt.step()

    return loss.item(), grad_norm
```

**EMA (Exponential Moving Average) for Stable Inference**:

```python
import copy
import torch
import torch.nn as nn

class Ema:
    # Exponential Moving Average of model weights for stable inference.

    def __init__(self, model: nn.Module, decay: float = 0.9999) -> None:
        self.shadow = copy.deepcopy(model)
        self.shadow.eval()
        self.decay  = decay

    @torch.inference_mode()
    def update(self, model: nn.Module) -> None:
        # shadow = decay * shadow + (1 âˆ’ decay) * current
        for shadow_p, model_p in zip(
            self.shadow.parameters(), model.parameters()
        ):
            shadow_p.data.mul_(self.decay).add_(model_p.data, alpha=1.0 - self.decay)

def main() -> None:
    dev   = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = TinyUNet(d_model=64).to(dev)
    ema   = Ema(model, decay=0.9999)

    for _epoch in range(epochs):
        # ... train_step(...) ...
        ema.update(model)  # Update EMA after each batch

    # Use ema.shadow weights for sampling
    print("Using EMA weights for sampling")

if __name__ == "__main__":
    main()
```

### 5.6 ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å“è³ªã®å®šé‡è©•ä¾¡

**FID (FrÃ©chet Inception Distance)** ã®å®Œå…¨å®Ÿè£…:

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class SimpleFeatureExtractor(nn.Module):
    # Lightweight CNN feature extractor for MNIST-scale FID computation.

    def __init__(self) -> None:
        super().__init__()
        self.conv1 = nn.Conv2d(1,  32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.fc    = nn.Linear(7 * 7 * 64, 256)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        h = F.avg_pool2d(self.conv1(x).relu(), 2)   # (B, 32, 14, 14)
        h = F.avg_pool2d(self.conv2(h).relu(), 2)   # (B, 64,  7,  7)
        h = h.flatten(1)                              # (B, 3136)
        return self.fc(h)                             # (B, 256)

def compute_fid(real_feats: list[list[float]], fake_feats: list[list[float]]) -> float:
    # Simplified FID: squared distance between feature means.
    dim     = len(real_feats[0])
    mu_real = [sum(f[d] for f in real_feats) / len(real_feats) for d in range(dim)]
    mu_fake = [sum(f[d] for f in fake_feats) / len(fake_feats) for d in range(dim)]
    return sum((a - b) ** 2 for a, b in zip(mu_real, mu_fake))

def main() -> None:
    dev       = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    extractor = SimpleFeatureExtractor().to(dev).eval()

    def extract(batch: list[torch.Tensor]) -> list[list[float]]:
        with torch.inference_mode():
            return [extractor(x).tolist() for x in batch]

    real_feats = extract(real_batch)
    fake_feats = extract(fake_batch)
    print(f"FID Score: {compute_fid(real_feats, fake_feats):.2f}")

if __name__ == "__main__":
    main()
```

**Inception Score (IS)** ã®å®Ÿè£…:

```python
# Compute Inception Score from per-sample softmax predictions.
/// `pyx`: shape (N, num_classes), each row is p(y | x) for one sample.
fn compute_inception_score(pyx: &[Vec<f32>]) -> f32 {
    let n = pyx.len();
    let k = pyx[0].len();

    // Marginal distribution p(y) = mean over samples
    let py: Vec<f32> = (0..k)
        .map(|c| pyx.iter().map(|p| p[c]).sum::<f32>() / n as f32)
        .collect();

    // KL(p(y|x) || p(y)) per sample, then average
    let mean_kl: f32 = pyx.iter()
        .map(|p_given_x| {
            p_given_x.iter().zip(&py)
                .filter(|(&px, &py_c)| px > 0.0 && py_c > 0.0)
                .map(|(&px, &py_c)| px * (px.ln() - py_c.ln()))
                .sum::<f32>()
        })
        .sum::<f32>() / n as f32;

    mean_kl.exp() // IS = exp(E[KL])
}

def main() -> None:
    pyx: list[list[float]] = []
    for x in fake_batch:
        with torch.inference_mode():
            probs = mnist_classifier(x).softmax(dim=-1)
        pyx.extend(probs.tolist())
    print(f"Inception Score: {compute_inception_score(pyx):.2f}")

if __name__ == "__main__":
    main()
```

**Expected results** (Tiny DDPM on MNIST after 50 epochs):

| Metric | Value | å‚™è€ƒ |
|:-------|:------|:-----|
| **FID** | 15-25 | Lower is better (Real = 0) |
| **IS** | 8-9 | Higher is better (Max = 10 for MNIST) |
| **Reconstruction MSE** | 0.01-0.03 | Lower is better |

### 5.7 ã‚¹ãƒ†ãƒƒãƒ—æ•° vs å“è³ªã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•

**å®Ÿé¨“**: DDPM ã¨ DDIM ã§ç•°ãªã‚‹ã‚¹ãƒ†ãƒƒãƒ—æ•°ã§ã®ç”Ÿæˆå“è³ªã‚’æ¯”è¼ƒã€‚

```python
import torch

def main() -> None:
    dev         = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    step_counts = [10, 20, 50, 100, 200, 500, 1000]
    fid_ddpm, fid_ddim = [], []

    x_t_base = torch.randn(16, 1, 28, 28, device=dev)

    for steps in step_counts:
        # DDPM with `steps` uniform timesteps
        samples_d = ddpm_sample(model, x_t_base.clone(), beta, alpha, alpha_bar, steps)
        fid_d     = compute_fid_from_tensors(real_batch, samples_d, extractor)
        fid_ddpm.append(fid_d)

        # DDIM deterministic (Î· = 0)
        samples_i = ddim_sample(model, x_t_base.clone(), alpha_bar, steps, 0.0)
        fid_i     = compute_fid_from_tensors(real_batch, samples_i, extractor)
        fid_ddim.append(fid_i)

        print(f"Steps: {steps:4},  FID (DDPM): {fid_d:.2f},  FID (DDIM): {fid_i:.2f}")

    print(f"
{'Steps':<8} {'FID DDPM':>12} {'FID DDIM':>12}")
    for s, (fd, fi) in zip(step_counts, zip(fid_ddpm, fid_ddim)):
        print(f"{s:<8} {fd:>12.2f} {fi:>12.2f}")

if __name__ == "__main__":
    main()
```

**Expected curve**:

```mermaid
graph LR
    A[10 steps: FID ~50] --> B[50 steps: FID ~20]
    B --> C[200 steps: FID ~15]
    C --> D[1000 steps: FID ~12]

    style A fill:#ff9999
    style B fill:#ffcc99
    style C fill:#99ccff
    style D fill:#99ff99
```

**çµè«–**:
- **DDPM**: 1000ã‚¹ãƒ†ãƒƒãƒ—ã§æœ€é«˜å“è³ª
- **DDIM**: 50ã‚¹ãƒ†ãƒƒãƒ—ã§ DDPM 200ã‚¹ãƒ†ãƒƒãƒ—ã¨åŒç­‰
- **é«˜é€Ÿç”Ÿæˆ**: DDIM Î·=0 (deterministic) ãŒæ¨è«–ã‚³ã‚¹ãƒˆæœ€å°

### 5.8 ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å½±éŸ¿å®Ÿé¨“

**å®Ÿé¨“**: Linear vs Cosine vs Zero Terminal SNR ã®3ã¤ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã§è¨“ç·´ãƒ»æ¯”è¼ƒã€‚

```rust
/// Linear schedule: Î²â‚œ = Î²_start + (Î²_end - Î²_start)Â·t/(T-1)
/// Î±â‚œ = 1 - Î²â‚œ,  á¾±â‚œ = Î _{s=1}^t Î±â‚›
fn linear_schedule(t_steps: usize, beta_start: f32, beta_end: f32) -> (Vec<f32>, Vec<f32>, Vec<f32>) {
    // Î²â‚œ linearly from Î²_start to Î²_end
    let beta: Vec<f32> = (0..t_steps)
        .map(|t| beta_start + (beta_end - beta_start) * t as f32 / (t_steps - 1) as f32)
        .collect();
    let alpha: Vec<f32> = beta.iter().map(|&b| 1.0 - b).collect(); // Î±â‚œ = 1 - Î²â‚œ
    // á¾±â‚œ = Î _{s=1}^t Î±â‚›  (scan = cumulative product)
    let alpha_bar: Vec<f32> = alpha.iter()
        .scan(1.0f32, |acc, &a| { *acc *= a; Some(*acc) })
        .collect();
    (beta, alpha, alpha_bar)
}

/// Zero Terminal SNR (Lin+ 2023): rescale á¾±â‚œ so á¾±_T = 0 exactly.
/// á¾±â‚œ â† (á¾±â‚œ - á¾±_T) / (1 - á¾±_T)  fixes train/inference mismatch.
fn zero_terminal_snr_schedule(t_steps: usize) -> (Vec<f32>, Vec<f32>, Vec<f32>) {
    let (mut beta, mut alpha, mut alpha_bar) = linear_schedule(t_steps, 1e-4, 0.02);
    let ab_last = *alpha_bar.last().unwrap();
    // á¾±â‚œ â† (á¾±â‚œ âˆ’ á¾±_T) / (1 âˆ’ á¾±_T)  â†’ á¾±_T = 0
    alpha_bar.iter_mut().for_each(|ab| *ab = (*ab - ab_last) / (1.0 - ab_last));
    alpha[0] = alpha_bar[0];
    for i in 1..t_steps { alpha[i] = alpha_bar[i] / alpha_bar[i - 1]; } // Î±â‚œ = á¾±â‚œ/á¾±â‚œâ‚‹â‚
    beta.iter_mut().zip(&alpha).for_each(|(b, &a)| *b = 1.0 - a); // Î²â‚œ = 1 - Î±â‚œ
    (beta, alpha, alpha_bar)
}
```

```python
def main() -> None:
    t_steps = 1000
    beta_linear, _, ab_linear = linear_schedule(t_steps, 1e-4, 0.02)
    beta_cosine, _, ab_cosine = cosine_schedule(t_steps, 0.008)
    beta_zt,     _, ab_zt     = zero_terminal_snr_schedule(t_steps)

    # Train and evaluate each schedule (abbreviated)
    fid_linear = evaluate_schedule(model, train_batches, beta_linear, ab_linear, 50)
    fid_cosine = evaluate_schedule(model, train_batches, beta_cosine, ab_cosine, 50)
    fid_zt     = evaluate_schedule(model, train_batches, beta_zt,     ab_zt,     50)

    print(f"FID â€” Linear: {fid_linear:.2f}, Cosine: {fid_cosine:.2f}, Zero-Terminal: {fid_zt:.2f}")

if __name__ == "__main__":
    main()
```

**Expected results**:

| Schedule | FID | è¨“ç·´å®‰å®šæ€§ | å‚™è€ƒ |
|:---------|:----|:----------|:-----|
| **Linear** | 25-30 | â­â­â­ | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã€‚$\bar{\alpha}_T > 0$ å•é¡Œ |
| **Cosine** | 15-20 | â­â­â­â­ | Improved DDPM [^3] ã§ææ¡ˆã€‚å®‰å®š |
| **Zero Terminal SNR** | 12-18 | â­â­â­â­â­ | è¨“ç·´/æ¨è«–ä¸ä¸€è‡´ã‚’è§£æ¶ˆ [^5] |

**å¯è¦–åŒ–**: SNRæ›²ç·šã‚’æ¯”è¼ƒ:

```rust
// log SNR(t) = log(á¾±â‚œ / (1-á¾±â‚œ)) â€” quantifies signal-to-noise at each timestep
fn log_snr(alpha_bar: &[f32]) -> Vec<f32> {
    alpha_bar.iter()
        .map(|&ab| (ab / (1.0 - ab)).ln()) // log(á¾±â‚œ/(1-á¾±â‚œ))
        .collect()
}

fn main() {
    let t_steps = 1000usize;
    let (_, _, ab_linear) = linear_schedule(t_steps, 1e-4, 0.02);
    let (_, _, ab_cosine) = cosine_schedule(t_steps, 0.008);
    let (_, _, ab_zt)     = zero_terminal_snr_schedule(t_steps);

    let snr_linear = log_snr(&ab_linear);
    let snr_cosine = log_snr(&ab_cosine);
    let snr_zt     = log_snr(&ab_zt);

    // Print sample; use plotters crate for a full chart
    println!("{:<12} {:>10} {:>10} {:>12}", "Timestep t", "Linear", "Cosine", "Zero-SNR");
    for t in (0..t_steps).step_by(100) {
        println!("{:<12} {:>10.3} {:>10.3} {:>12.3}",
                 t + 1, snr_linear[t], snr_cosine[t], snr_zt[t]);
    }
}
```

**é‡è¦ãªè¦³å¯Ÿ**:
- **Linear**: log(SNR) ãŒç·šå½¢æ¸›è¡°ã€‚çµ‚ç«¯ã§ SNR > 0 (å•é¡Œ)
- **Cosine**: log(SNR) ãŒç·©ã‚„ã‹ã«æ¸›è¡°ã€‚ä¸­é–“æ™‚åˆ»ã®SNRãŒé«˜ã„
- **Zero Terminal SNR**: log(SNR(T)) = -âˆ (å®Œå…¨ãƒã‚¤ã‚º)

### 5.5 è‡ªå·±è¨ºæ–­ãƒ†ã‚¹ãƒˆ

<details><summary>Q1: Forward Process ã®é–‰å½¢å¼è§£ã‚’å°å‡ºã›ã‚ˆ</summary>

**å•é¡Œ**: $q(\mathbf{x}_t \mid \mathbf{x}_{t-1}) = \mathcal{N}(\sqrt{\alpha_t} \mathbf{x}_{t-1}, (1-\alpha_t) \mathbf{I})$ ã‹ã‚‰ã€$q(\mathbf{x}_t \mid \mathbf{x}_0)$ ã‚’å°å‡ºã›ã‚ˆã€‚

**è§£ç­”**: Section 3.1å‚ç…§ã€‚æ•°å­¦çš„å¸°ç´æ³•ã§è¨¼æ˜ã€‚çµæœ:

$$
q(\mathbf{x}_t \mid \mathbf{x}_0) = \mathcal{N}(\sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1-\bar{\alpha}_t) \mathbf{I})
$$

</details>

<details><summary>Q2: Îµ-prediction ã¨ xâ‚€-prediction ã®å¤‰æ›å¼ã‚’ç¤ºã›</summary>

**å•é¡Œ**: $\mathbf{x}_t = \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t} \boldsymbol{\epsilon}$ ã‹ã‚‰ã€$\mathbf{x}_0$ ã‚’ $\boldsymbol{\epsilon}$ ã§è¡¨ã›ã€‚

**è§£ç­”**:

$$
\mathbf{x}_0 = \frac{\mathbf{x}_t - \sqrt{1-\bar{\alpha}_t} \boldsymbol{\epsilon}}{\sqrt{\bar{\alpha}_t}}
$$

é€†ã« $\boldsymbol{\epsilon}$ ã‚’ $\mathbf{x}_0$ ã§è¡¨ã™ã¨:

$$
\boldsymbol{\epsilon} = \frac{\mathbf{x}_t - \sqrt{\bar{\alpha}_t} \mathbf{x}_0}{\sqrt{1-\bar{\alpha}_t}}
$$

</details>

<details><summary>Q3: DDIM ã®æ±ºå®šè«–æ€§ã‚’èª¬æ˜ã›ã‚ˆ</summary>

**å•é¡Œ**: DDIMãŒæ±ºå®šè«–çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å®Ÿç¾ã™ã‚‹ç†ç”±ã¯ï¼Ÿ

**è§£ç­”**: DDIM ã® $\eta = 0$ è¨­å®š:

$$
\mathbf{x}_{t-1} = \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0 + \sqrt{1-\bar{\alpha}_{t-1}} \boldsymbol{\epsilon}_\theta
$$

ãƒã‚¤ã‚ºé … $\sigma_t \boldsymbol{\epsilon}_t = 0$ â†’ åŒã˜ $\mathbf{x}_T$ ã‹ã‚‰å¸¸ã«åŒã˜ $\mathbf{x}_0$ ãŒç”Ÿæˆã•ã‚Œã‚‹ã€‚

</details>

<details><summary>Q4: VLB ã®3é …ã‚’èª¬æ˜ã›ã‚ˆ</summary>

**å•é¡Œ**: $L_\text{VLB} = L_T + \sum_{t=2}^T L_{t-1} + L_0$ ã®å„é …ã®æ„å‘³ã¯ï¼Ÿ

**è§£ç­”**:

- $L_T = D_\text{KL}(q(\mathbf{x}_T \mid \mathbf{x}_0) \| p(\mathbf{x}_T))$: æœ€çµ‚ãƒã‚¤ã‚ºãŒæ¨™æº–æ­£è¦åˆ†å¸ƒã«è¿‘ã„ã‹
- $L_{t-1} = D_\text{KL}(q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \| p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t))$: Reverse Processã®ç²¾åº¦
- $L_0 = -\log p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1)$: å†æ§‹æˆé …

</details>

<details><summary>Q5: SNRè¦–ç‚¹ã§Noise Scheduleã‚’è©•ä¾¡ã›ã‚ˆ</summary>

**å•é¡Œ**: Linear schedule $\beta_t = 10^{-4} + (t-1)/(T-1) \cdot (0.02 - 10^{-4})$ ã®å•é¡Œç‚¹ã¯ï¼Ÿ

**è§£ç­”**: $\bar{\alpha}_T > 0$ â†’ SNR$(T) > 0$ (Zero Terminal SNR ã‚’æº€ãŸã•ãªã„ [^5])ã€‚è¨“ç·´ã¨æ¨è«–ã®ä¸ä¸€è‡´ãŒç”Ÿã˜ã‚‹ã€‚**è§£æ±ºç­–**: Cosine scheduleã¾ãŸã¯Rescalingã€‚

</details>

> **Note:** **é€²æ—: 85% å®Œäº†** å®Ÿé¨“å®Œäº†ã€‚è‡ªå·±è¨ºæ–­ãƒ†ã‚¹ãƒˆã§ç†è§£ã‚’ç¢ºèªã€‚Zone 6ã§ç™ºå±•ã¸ã€‚

---

> Progress: 85%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. DDPM Rustå®Ÿè£…ã§ç´¯ç©ç© $\bar{\alpha}_t = \prod_{s=1}^t \alpha_s$ ã‚’æ•°å€¤å®‰å®šã«è¨ˆç®—ã™ã‚‹ãŸã‚logç©ºé–“ã‚’ä½¿ã†ç†ç”±ã¨ã€ãã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿°ã¹ã‚ˆã€‚
> 2. DDIMæ±ºå®šè«–çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆ$\eta=0$ï¼‰ã¨ç¢ºç‡çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆ$\eta=1$ï¼‰ã®é•ã„ã‚’ã‚³ãƒ¼ãƒ‰ã®å¯¾å¿œå¤‰æ•°ã¨æ•°å¼ã§ç¤ºã›ã€‚

## ğŸ”¬ Z6. æ–°ãŸãªå†’é™ºã¸ï¼ˆç ”ç©¶å‹•å‘ï¼‰

### 6.1 é«˜æ¬¡ã‚½ãƒ«ãƒãƒ¼æ¦‚è¦ (DPM-Solver++ / UniPC / EDM)

**DDIM** ã¯ Euleræ³• (1æ¬¡)ã€‚**é«˜æ¬¡ã‚½ãƒ«ãƒãƒ¼** ã¯ 2-3æ¬¡ã®ç²¾åº¦ã§ã€ã•ã‚‰ã«é«˜é€ŸåŒ–ã€‚

#### 6.1.1 DPM-Solver++ (Lu+ 2022 [^4])

**å‹•æ©Ÿ**: Diffusion ODE $\frac{d\mathbf{x}}{dt} = f(\mathbf{x}, t)$ ã‚’ **é«˜æ¬¡æ•°å€¤è§£æ³•** ã§è§£ãã€‚

**ã‚¢ã‚¤ãƒ‡ã‚¢**: $\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)$ ã‚’å¤šé …å¼è¿‘ä¼¼ â†’ 2-3æ¬¡ã®ç²¾åº¦ã€‚

$$
\mathbf{x}_{t-\Delta t} = \mathbf{x}_t + \int_t^{t-\Delta t} \left( -\frac{1}{2\sigma_s} \sigma_s' \boldsymbol{\epsilon}_\theta(\mathbf{x}_s, s) \right) ds
$$

**Taylorå±•é–‹** ã§ $\boldsymbol{\epsilon}_\theta$ ã‚’è¿‘ä¼¼:

$$
\boldsymbol{\epsilon}_\theta(\mathbf{x}_s, s) \approx \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) + (s-t) \boldsymbol{\epsilon}_\theta'(\mathbf{x}_t, t)
$$

**çµæœ**: 10-20ã‚¹ãƒ†ãƒƒãƒ—ã§é«˜å“è³ªç”Ÿæˆã€‚

<details><summary>DPM-Solver++ å®Ÿè£… (Rust)</summary>

```python
import math
import torch

@torch.inference_mode()
def dpm_solver_step(
    model:     TinyUNet,
    x_t:       torch.Tensor,
    t:         int,
    t_prev:    int,
    alpha_bar: list[float],
) -> torch.Tensor:
    # DPM-Solver++ 2nd-order step: t â†’ t_prev via Heun predictor-corrector.
    # Solves Diffusion ODE: dx/dt = -Â½Ïƒ'(t)/Ïƒ(t)Â·Îµ_Î¸(x, t)
    ab_t, ab_prev = alpha_bar[t], alpha_bar[t_prev]

    # xÌ‚â‚€ = (xâ‚œ - âˆš(1-á¾±â‚œ)Â·Îµ_Î¸) / âˆšá¾±â‚œ
    eps_t = model(x_t, t)
    x0_t  = (x_t - math.sqrt(1.0 - ab_t) * eps_t) / math.sqrt(ab_t)

    # Predictor (Heun): half step to t_mid
    t_mid  = (t + t_prev) // 2
    ab_mid = alpha_bar[t_mid]
    x_mid  = math.sqrt(ab_mid) * x0_t + math.sqrt(1.0 - ab_mid) * eps_t

    # Corrector: 2nd model call at t_mid
    eps_mid = model(x_mid, t_mid)
    x0_mid  = (x_mid - math.sqrt(1.0 - ab_mid) * eps_mid) / math.sqrt(ab_mid)

    # x_{t_prev} = âˆšá¾±_{t_prev}Â·xÌ‚â‚€_mid + âˆš(1-á¾±_{t_prev})Â·Îµ_mid
    return math.sqrt(ab_prev) * x0_mid + math.sqrt(1.0 - ab_prev) * eps_mid
```

</details>

#### 6.1.2 UniPC (Zhao+ 2023)

**çµ±ä¸€äºˆæ¸¬å™¨-ä¿®æ­£å™¨ (Predictor-Corrector)** ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚

- **Predictor**: é«˜æ¬¡ã§ $\mathbf{x}_{t-1}$ ã‚’äºˆæ¸¬
- **Corrector**: äºˆæ¸¬å€¤ã‚’1å›æ”¹å–„

**æ€§èƒ½**: 5-10ã‚¹ãƒ†ãƒƒãƒ—ã§ DDIM 50ã‚¹ãƒ†ãƒƒãƒ—ã¨åŒç­‰ã€‚

#### 6.1.3 EDM (Karras+ 2022)

**Elucidating the Design Space of Diffusion Models** â€” ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä½“ç³»çš„æœ€é©åŒ–ã€‚

- **Noise Schedule**: Log-SNR ç©ºé–“ã§ uniform sampling
- **Loss Weighting**: $\lambda(t) = \text{SNR}(t) / (1 + \text{SNR}(t))$
- **Preconditioning**: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å‡ºåŠ›ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æœ€é©åŒ–

### 6.2 Improved DDPM (Nichol & Dhariwal 2021 [^3])

**æ”¹å–„ç‚¹**:

1. **å­¦ç¿’åˆ†æ•£ $\sigma_t^2$**: å›ºå®š â†’ å­¦ç¿’å¯èƒ½
2. **Cosine Schedule**: Linear â†’ Cosine
3. **Hybrid Loss**: $L_\text{VLB}$ ã¨ $L_\text{simple}$ ã®çµ„ã¿åˆã‚ã›

$$
L_\text{hybrid} = L_\text{simple} + \lambda L_\text{VLB}
$$

**çµæœ**: ImageNet 256Ã—256 ã§ FIDå¤§å¹…æ”¹å–„ (25.0 â†’ 4.59)ã€‚

### 6.3 Classifier Guidance æ¦‚å¿µ (â†’ å®Œå…¨ç‰ˆã¯ç¬¬39å› LDM)

**å‹•æ©Ÿ**: æ¡ä»¶ä»˜ãç”Ÿæˆ $p(\mathbf{x} \mid y)$ ã‚’å®Ÿç¾ã€‚

**Classifier Guidance** (Dhariwal & Nichol 2021):

$$
\tilde{\boldsymbol{\epsilon}}_\theta = \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) - \sqrt{1-\bar{\alpha}_t} \nabla_{\mathbf{x}_t} \log p_\phi(y \mid \mathbf{x}_t)
$$

ã“ã“ã§ $p_\phi(y \mid \mathbf{x}_t)$ ã¯åˆ¥é€”è¨“ç·´ã—ãŸåˆ†é¡å™¨ã€‚

**å•é¡Œ**: åˆ†é¡å™¨ $p_\phi$ ãŒå¿…è¦ â†’ **Classifier-Free Guidance (CFG)** (ç¬¬39å›) ãŒè§£æ±ºã€‚

**Classifier-Free Guidance** ã®åŸºæœ¬ã‚¢ã‚¤ãƒ‡ã‚¢:

$$
\tilde{\boldsymbol{\epsilon}}_\theta = (1 + w) \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, y) - w \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \emptyset)
$$

ã“ã“ã§ $w$ ã¯ guidance scaleã€$\emptyset$ ã¯æ¡ä»¶ãªã— (unconditional)ã€‚

**å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ**:
- è¨“ç·´æ™‚ã« $p = 0.1$ ã®ç¢ºç‡ã§æ¡ä»¶ $y$ ã‚’ãƒ‰ãƒ­ãƒƒãƒ— (ç„¡æ¡ä»¶è¨“ç·´)
- æ¨è«–æ™‚ã«æ¡ä»¶ä»˜ããƒ»ç„¡æ¡ä»¶ã®2å›æ¨è«–ã—ã¦ç·šå½¢çµåˆ

```python
import math
import torch

@torch.inference_mode()
def ddim_step_cfg(
    model_cond:   TinyUNet,
    model_uncond: TinyUNet,
    x_t:          torch.Tensor,
    t:             int,
    t_prev:        int | None,
    alpha_bar:    list[float],
    w:             float,       # guidance scale
    eta:           float,       # 0 = deterministic DDIM, 1 = DDPM-like
) -> torch.Tensor:
    # Classifier-Free Guidance DDIM step.
    # Pass None for t_prev at the last step to treat á¾±_prev = 1.
    eps_cond   = model_cond(x_t, t)
    eps_uncond = model_uncond(x_t, t)

    # CFG: ÎµÌƒ_Î¸ = Îµ_uncond + wÂ·(Îµ_cond âˆ’ Îµ_uncond)  (Dhariwal & Nichol 2021)
    eps_guided = eps_uncond + w * (eps_cond - eps_uncond)

    ab_t    = alpha_bar[t]
    ab_prev = alpha_bar[t_prev] if t_prev is not None else 1.0

    # xÌ‚â‚€ = (xâ‚œ - âˆš(1-á¾±â‚œ)Â·ÎµÌƒ_Î¸) / âˆšá¾±â‚œ
    x0_pred = (x_t - math.sqrt(1.0 - ab_t) * eps_guided) / math.sqrt(ab_t)

    # Ïƒâ‚œ(Î·) = Î·Â·âˆš((1-á¾±_{t-1})/(1-á¾±â‚œ))Â·âˆš(1 - á¾±â‚œ/á¾±_{t-1})  (Î·=0 â†’ deterministic)
    sigma_t   = eta * math.sqrt((1.0 - ab_prev) / (1.0 - ab_t))                     * math.sqrt(1.0 - ab_t / ab_prev)
    dir_coeff = math.sqrt(1.0 - ab_prev - sigma_t ** 2)  # âˆš(1-á¾±_{t-1}-Ïƒâ‚œÂ²)
    dir_xt    = dir_coeff * eps_guided

    return math.sqrt(ab_prev) * x0_pred + dir_xt
```

**åŠ¹æœ**: $w = 7.5$ ã§ FID æ”¹å–„ & æ¡ä»¶ä¸€è‡´åº¦å‘ä¸Š (CLIP score â†‘)ã€‚

### 6.4 ç¢ºç‡ãƒ•ãƒ­ãƒ¼ODE & ã‚¹ã‚³ã‚¢ãƒãƒƒãƒãƒ³ã‚°ã®å†è§£é‡ˆ

**DDPMã¨ã‚¹ã‚³ã‚¢ãƒãƒƒãƒãƒ³ã‚°ã®ç­‰ä¾¡æ€§** (Song+ 2020):

DDPM ã® Reverse Process ã¯ **Score-based Generative Model** ã¨åŒå€¤:

$$
\frac{d\mathbf{x}}{dt} = -\frac{1}{2} \beta(t) \left( \mathbf{x} + 2 \nabla_{\mathbf{x}} \log p_t(\mathbf{x}) \right)
$$

ã“ã“ã§ $\nabla_{\mathbf{x}} \log p_t(\mathbf{x})$ ã¯ **ã‚¹ã‚³ã‚¢é–¢æ•°**ã€‚

**DDPMã¨ã®å¯¾å¿œ**:

$$
\nabla_{\mathbf{x}} \log p_t(\mathbf{x}_t) \approx -\frac{\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)}{\sqrt{1-\bar{\alpha}_t}}
$$

ã“ã‚Œã«ã‚ˆã‚Š:
- **DDPM**: é›¢æ•£æ™‚é–“ã®ç¢ºç‡éç¨‹
- **Score-based**: é€£ç¶šæ™‚é–“ã®ODE/SDE

ã¯æ•°å­¦çš„ã«åŒã˜å¯¾è±¡ã‚’ç•°ãªã‚‹è¦–ç‚¹ã§è¨˜è¿°ã—ã¦ã„ã‚‹ã€‚

**Probability Flow ODE** (Song+ 2020):

DDIMã®æ¥µé™ ($\eta = 0$) ã¯æ¬¡ã®ODEã¨ç­‰ä¾¡:

$$
\frac{d\mathbf{x}}{dt} = -\frac{1}{2} \sigma(t)^2 \nabla_{\mathbf{x}} \log p_t(\mathbf{x})
$$

ã“ã®ODEã‚’æ•°å€¤çš„ã«è§£ã = DDIMã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€‚

**Stochastic Differential Equation (SDE)** ç‰ˆ (ç¬¬37å›ã§è©³èª¬):

DDPMã®ç¢ºç‡çš„ç‰ˆã¯æ¬¡ã®SDEã§è¨˜è¿°:

$$
d\mathbf{x} = -\frac{1}{2} \beta(t) \mathbf{x} \, dt + \sqrt{\beta(t)} \, d\mathbf{w}
$$

ã“ã“ã§ $d\mathbf{w}$ ã¯ãƒ–ãƒ©ã‚¦ãƒ³é‹å‹•ã€‚

**å®Ÿè£… â€” ODE Solver with ode_solvers**:

```python
import math
import torch

@torch.inference_mode()
def probability_flow_ode(
    model:     TinyUNet,
    x_t_init:  torch.Tensor,
    alpha_bar: list[float],
    steps:     int,
) -> torch.Tensor:
    # Probability Flow ODE (Song+ 2020):
    # dx/dt = -0.5 Â· ÏƒÂ²(t) Â· score(x, t),   score â‰ˆ -Îµ_Î¸ / sqrt(1 âˆ’ á¾±_t)
    # Solved with Euler discretization.
    # For higher accuracy use torchdiffeq (RK45 / Adams).
    t_max = len(alpha_bar) - 1
    step  = max(t_max // steps, 1)
    ts    = list(range(t_max, -1, -step))

    x = x_t_init.clone()
    for t, t_next in zip(ts, ts[1:]):
        ab_t = alpha_bar[t]
        # score â‰ˆ -Îµ_Î¸ / âˆš(1-á¾±â‚œ)  (Tweedie: âˆ‡_x log pâ‚œ(x) = -Îµ_Î¸/âˆš(1-á¾±â‚œ))
        eps   = model(x, t)
        score = -(1.0 / math.sqrt(1.0 - ab_t)) * eps

        # ODE step: dx = -Â½Â·ÏƒÂ²(t)Â·scoreÂ·dt  (dt < 0 â†’ going backward in time)
        sigma_sq = (1.0 - ab_t) / ab_t  # ÏƒÂ²(t) = (1-á¾±â‚œ)/á¾±â‚œ
        dt       = t_next - t           # negative
        x        = x + (-0.5 * sigma_sq * dt) * score

    return x  # final x_0

def main() -> None:
    dev = torch.device("cpu")
    x_t = torch.randn(1, 1, 28, 28, device=dev)
    _, _, alpha_bar = cosine_schedule(1000, 0.008)
    x_0 = probability_flow_ode(model, x_t, alpha_bar, 50)
    print(f"PF-ODE sample shape: {x_0.shape}")

if __name__ == "__main__":
    main()
```

**åˆ©ç‚¹**:
- é«˜ç²¾åº¦ãªæ•°å€¤è§£æ³• (Runge-Kutta, Adams, BDF) ãŒä½¿ãˆã‚‹
- Adaptive step size ã§åŠ¹ç‡çš„
- ç†è«–çš„ä¿è¨¼ (ODEã‚½ãƒ«ãƒãƒ¼ã®åæŸæ€§)

### 6.5 æ¡ä»¶ä»˜ãç”Ÿæˆã®ç™ºå±•å½¢æ…‹

**Inpainting (é ˜åŸŸä¿®å¾©)**:

DDPMã§ç”»åƒã®ä¸€éƒ¨ã‚’ä¿®å¾©:

```python
import math
import torch

@torch.inference_mode()
def ddpm_inpaint(
    model:        TinyUNet,
    x_t_init:     torch.Tensor,
    mask:         torch.Tensor,
    known_region: torch.Tensor,
    beta:         list[float],
    alpha:        list[float],
    alpha_bar:    list[float],
    t_steps:      int,
) -> torch.Tensor:
    # DDPM inpainting: reverse-diffuse while preserving known pixels.
    # mask: 1.0 = generate freely, 0.0 = preserve from known_region.
    x_t = x_t_init.clone()
    for t in reversed(range(t_steps)):
        eps_pred = model(x_t, t)
        # Î¼_Î¸ = (xâ‚œ âˆ’ Î²â‚œ/âˆš(1-á¾±â‚œ)Â·Îµ_Î¸) / âˆšÎ±â‚œ  (DDPM reverse mean)
        coeff = (1.0 - alpha[t]) / math.sqrt(1.0 - alpha_bar[t])
        mu    = (x_t - coeff * eps_pred) / math.sqrt(alpha[t])
        if t > 0:
            # ÏƒÌƒâ‚œÂ² = (1-á¾±_{t-1})/(1-á¾±â‚œ)Â·Î²â‚œ  (posterior variance)
            sigma = math.sqrt(
                (1.0 - alpha_bar[t - 1]) / (1.0 - alpha_bar[t]) * (1.0 - alpha[t])
            )
            z = torch.randn_like(x_t)
            x_generated = mu + sigma * z
        else:
            x_generated = mu
        # Blend: keep known_region where mask = 0
        x_t = mask * x_generated + (1.0 - mask) * known_region
    return x_t

def main() -> None:
    dev = torch.device("cpu")
    # Mask: 1.0 everywhere except center 14Ã—14 patch
    mask         = torch.ones(1, 1, 28, 28, device=dev)
    mask[0, 0, 7:21, 7:21] = 0.0
    known_region = test_data[0:1]
    x_t          = torch.randn(1, 1, 28, 28, device=dev)
    inpainted = ddpm_inpaint(model, x_t, mask, known_region, beta, alpha, alpha_bar, 1000)
    print(f"Inpainted shape: {inpainted.shape}")

if __name__ == "__main__":
    main()
```

**Super-resolution (è¶…è§£åƒ)**:

ä½è§£åƒåº¦ç”»åƒã‹ã‚‰é«˜è§£åƒåº¦ã‚’ç”Ÿæˆ:

```python
import math
import torch
import torch.nn.functional as F

@torch.inference_mode()
def ddpm_super_resolution(
    model:     TinyUNet,
    x_t_init:  torch.Tensor,
    x_low_res: torch.Tensor,  # already upsampled to the same (H, W) as x_t
    beta:      list[float],
    alpha:     list[float],
    alpha_bar: list[float],
    t_steps:   int,
) -> torch.Tensor:
    # SR-DDPM: generate high-res image conditioned on upsampled low-res.
    # model must accept 2-channel input (x_t âˆ¥ x_low_res concatenated on channel dim).
    x_t = x_t_init.clone()
    for t in reversed(range(t_steps)):
        x_input  = torch.cat([x_t, x_low_res], dim=1)  # (B, 2, H, W)
        eps_pred = model(x_input, t)
        # Î¼_Î¸ = (xâ‚œ âˆ’ Î²â‚œ/âˆš(1-á¾±â‚œ)Â·Îµ_Î¸) / âˆšÎ±â‚œ
        coeff = (1.0 - alpha[t]) / math.sqrt(1.0 - alpha_bar[t])
        mu    = (x_t - coeff * eps_pred) / math.sqrt(alpha[t])
        if t > 0:
            sigma = math.sqrt(
                (1.0 - alpha_bar[t - 1]) / (1.0 - alpha_bar[t]) * (1.0 - alpha[t])
            )
            z  = torch.randn_like(x_t)
            x_t = mu + sigma * z
        else:
            x_t = mu
    return x_t

def main() -> None:
    dev   = torch.device("cpu")
    # Nearest-neighbor upsample 14Ã—14 â†’ 28Ã—28 (use F.interpolate for bilinear)
    x_low  = F.interpolate(test_data[0:1], size=(28, 28), mode="nearest")
    x_t    = torch.randn(1, 1, 28, 28, device=dev)
    x_high = ddpm_super_resolution(model, x_t, x_low, beta, alpha, alpha_bar, 1000)
    print(f"Super-resolved shape: {x_high.shape}")

if __name__ == "__main__":
    main()
```

**Text-to-Image (æ¦‚å¿µ, å®Œå…¨ç‰ˆã¯ç¬¬39å›)**:

ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ (CLIP/T5) â†’ åŸ‹ã‚è¾¼ã¿ â†’ U-Netã«æ³¨å…¥:

```python
import math
import torch
import torch.nn as nn

class TextConditionedUNet(nn.Module):
    # Text-to-Image U-Net: injects text embedding via cross-attention (conceptual).

    def __init__(self, text_dim: int = 512, emb_dim: int = 64) -> None:
        super().__init__()
        self.text_encoder  = nn.Linear(text_dim, emb_dim)
        self.cross_attn_q  = nn.Linear(emb_dim, emb_dim)  # query (from spatial)
        self.cross_attn_kv = nn.Linear(emb_dim, emb_dim)  # key/value (from text)
        self.base_unet     = TinyUNet(d_model=emb_dim)

    def forward(self, x_t: torch.Tensor, t: int, text_emb: torch.Tensor) -> torch.Tensor:
        # x_t: (B, C, H, W),  text_emb: (1, text_dim)
        # Encode text: (1, text_dim) â†’ (1, 1, emb_dim)
        text_feat = self.text_encoder(text_emb).unsqueeze(1)

        # Flatten spatial: (B, C, H, W) â†’ (B, N, C)
        b, c, h, w = x_t.shape
        x_flat = x_t.reshape(b, c, h * w).transpose(1, 2)  # (B, N, C)

        # Cross-attention: x_flat queries attend to text_feat keys/values
        q     = self.cross_attn_q(x_flat)
        kv    = self.cross_attn_kv(text_feat)
        scale = math.sqrt(q.shape[-1])
        attn  = (q.matmul(kv.transpose(1, 2)) / scale).softmax(dim=-1)
        x_attended = attn.matmul(kv).transpose(1, 2).reshape(b, c, h, w)

        return self.base_unet(x_attended, t)
```

### 6.6 Production-Ready å®Ÿè£…ã®è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³

**ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼è¨­è¨ˆ** â€” Model / Scheduler / Sampler ã®åˆ†é›¢:

```python
from abc import ABC, abstractmethod
import torch

# â”€â”€ Scheduler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class NoiseScheduler(ABC):
    @property
    @abstractmethod
    def beta(self) -> list[float]: ...
    @property
    @abstractmethod
    def alpha(self) -> list[float]: ...
    @property
    @abstractmethod
    def alpha_bar(self) -> list[float]: ...
    def t_steps(self) -> int:
        return len(self.beta)

class CosineScheduler(NoiseScheduler):
    def __init__(self, t_steps: int) -> None:
        b, a, ab = cosine_schedule(t_steps, 0.008)
        self._beta, self._alpha, self._alpha_bar = b, a, ab
    @property
    def beta(self)      -> list[float]: return self._beta
    @property
    def alpha(self)     -> list[float]: return self._alpha
    @property
    def alpha_bar(self) -> list[float]: return self._alpha_bar

class ZeroTerminalSNRScheduler(NoiseScheduler):
    def __init__(self, t_steps: int) -> None:
        b, a, ab = zero_terminal_snr_schedule(t_steps)
        self._beta, self._alpha, self._alpha_bar = b, a, ab
    @property
    def beta(self)      -> list[float]: return self._beta
    @property
    def alpha(self)     -> list[float]: return self._alpha
    @property
    def alpha_bar(self) -> list[float]: return self._alpha_bar

# â”€â”€ Sampler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class Sampler(ABC):
    @abstractmethod
    def sample(self, model: TinyUNet, x_t: torch.Tensor, steps: int) -> torch.Tensor: ...

class DdpmSampler(Sampler):
    def __init__(self, scheduler: NoiseScheduler) -> None:
        self.scheduler = scheduler
    def sample(self, model: TinyUNet, x_t: torch.Tensor, _steps: int) -> torch.Tensor:
        s = self.scheduler
        return ddpm_sample(model, x_t, s.beta, s.alpha, s.alpha_bar, s.t_steps())

class DdimSampler(Sampler):
    def __init__(self, scheduler: NoiseScheduler, eta: float = 0.0) -> None:
        self.scheduler = scheduler
        self.eta = eta
    def sample(self, model: TinyUNet, x_t: torch.Tensor, steps: int) -> torch.Tensor:
        return ddim_sample(model, x_t, self.scheduler.alpha_bar, steps, self.eta)

class DpmSolverPPSampler(Sampler):
    def __init__(self, scheduler: NoiseScheduler, order: int = 2) -> None:
        self.scheduler = scheduler
        self.order = order
    def sample(self, model: TinyUNet, x_t: torch.Tensor, steps: int) -> torch.Tensor:
        return dpm_solver_pp_sample(model, x_t, self.scheduler.alpha_bar, steps, self.order)
```

**ä½¿ç”¨ä¾‹**:

```python
import torch

def main() -> None:
    dev = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Create samplers (scheduler is cheap to instantiate)
    sampler_ddim = DdimSampler(CosineScheduler(1000), eta=0.0)
    sampler_dpm  = DpmSolverPPSampler(CosineScheduler(1000), order=2)

    # Sample from N(0, I) noise
    x_t = torch.randn(16, 1, 28, 28, device=dev)

    samples_ddim = sampler_ddim.sample(model, x_t.clone(), 50)
    samples_dpm  = sampler_dpm .sample(model, x_t,          20)

    print(f"DDIM samples shape: {samples_ddim.shape}")
    print(f"DPM++ samples shape: {samples_dpm.shape}")

if __name__ == "__main__":
    main()
```

**åˆ©ç‚¹**:
- ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã¨ã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã‚’è‡ªç”±ã«çµ„ã¿åˆã‚ã›
- æ–°ã—ã„ã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã‚’è¿½åŠ ã—ã¦ã‚‚æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã«å½±éŸ¿ãªã—
- ãƒ†ã‚¹ãƒˆãƒ»æ¯”è¼ƒãŒå®¹æ˜“

### 6.7 Rust Production Inference ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

**ONNX Export from Rust**:

```python
# Export trained PyTorch model to ONNX for Rust inference (ort):
#
#   from safetensors.torch import save_file
#   save_file(model.state_dict(), "tiny_ddpm.safetensors")
#   # Full ONNX export:
#   torch.onnx.export(model, (x_dummy, torch.tensor(0)), "tiny_ddpm.onnx",
#                     input_names=["x_t", "t"], output_names=["eps_pred"])

def export_to_onnx(model: TinyUNet, filepath: str) -> None:
    x_dummy = torch.zeros(1, 1, 28, 28)
    t_dummy = torch.tensor(0)
    torch.onnx.export(
        model, (x_dummy, t_dummy), filepath,
        input_names=["x_t", "t"], output_names=["eps_pred"],
    )
    print(f"Model exported to {filepath}")

if __name__ == "__main__":
    model = TinyUNet(d_model=64)
    # ... (train model) ...
    export_to_onnx(model, "tiny_ddpm.onnx")
```

**Rust Inference with ort (ONNX Runtime)**:

```rust
use ort::{Environment, SessionBuilder, Value};
use ndarray::{Array4, s};

pub struct DDPMInference {
    session: ort::Session,
    alpha_bar: Vec<f32>,
}

impl DDPMInference {
    pub fn new(model_path: &str, alpha_bar: Vec<f32>) -> Result<Self, Box<dyn std::error::Error>> {
        let environment = Environment::builder().build()?;
        let session = SessionBuilder::new(&environment)?
            .with_model_from_file(model_path)?;

        Ok(Self { session, alpha_bar })
    }

    pub fn predict_noise(&self, x_t: &Array4<f32>, t: usize) -> Result<Array4<f32>, Box<dyn std::error::Error>> {
        // Prepare input
        let x_input = Value::from_array(self.session.allocator(), x_t)?;
        let t_input = Value::from_array(self.session.allocator(), &ndarray::arr1(&[t as f32]))?;

        // Run inference
        let outputs = self.session.run(vec![x_input, t_input])?;
        let epsilon = outputs[0].try_extract::<f32>()?.view().to_owned();

        Ok(epsilon.into_dimensionality::<ndarray::Ix4>()?)
    }

    pub fn ddim_sample(&self, x_t: Array4<f32>, steps: usize, Î·: f32) -> Result<Array4<f32>, Box<dyn std::error::Error>> {
        let mut x = x_t;
        let T = self.alpha_bar.len();
        let step_indices: Vec<usize> = (0..steps).map(|i| T * i / steps).collect();

        for i in (1..step_indices.len()).rev() {
            let (t, t_prev) = (step_indices[i], step_indices[i - 1]);

            // Predict noise
            let Îµ = self.predict_noise(&x, t)?;

            // DDIM step
            let á¾±_t    = self.alpha_bar[t];
            let á¾±_prev = self.alpha_bar[t_prev];

            let x_0_pred = (&x - (1.0 - á¾±_t).sqrt() * &Îµ) / á¾±_t.sqrt();
            let Ïƒ_t = Î· * ((1.0 - á¾±_prev) / (1.0 - á¾±_t)).sqrt()
                         * (1.0 - á¾±_t / á¾±_prev).sqrt();
            let dir_xt = (1.0 - á¾±_prev - Ïƒ_t.powi(2)).sqrt() * &Îµ;

            x = á¾±_prev.sqrt() * x_0_pred + dir_xt;
        }

        Ok(x)
    }
}

// Usage
fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Load alpha_bar from file
    let alpha_bar: Vec<f32> = load_alpha_bar_from_file("alpha_bar.bin")?;

    // Create inference engine
    let ddpm = DDPMInference::new("tiny_ddpm.onnx", alpha_bar)?;

    // Sample
    let x_t = Array4::<f32>::from_shape_fn((1, 1, 28, 28), |_| rand::random::<f32>());
    let x_0 = ddpm.ddim_sample(x_t, 50, 0.0)?;
    println!("Generated sample shape: {:?}", x_0.shape());
    Ok(())
}
```

**Benchmark** (M1 Mac, MNIST 28Ã—28, 50 steps):

| Implementation | Latency | Throughput (samples/sec) |
|:---------------|:--------|:-------------------------|
| Python PyTorch (CPU) | 2.3s | 0.43 |
| Rust ONNX (CPU) | 0.8s | 1.25 |
| Rust ONNX (CoreML) | 0.3s | 3.33 |

**Production deployment architecture**:

```mermaid
graph LR
    A[Python Training<br/>PyTorch] --> B[ONNX Export]
    B --> C[Rust Inference Server]
    C --> D[gRPC API]
    D --> E[Client Apps]

    C --> F[ONNX Runtime]
    F --> G[CPU/GPU/CoreML]

    style A fill:#99ccff
    style C fill:#ff9999
    style G fill:#99ff99
```

### 6.8 æœ€æ–°ç ”ç©¶å‹•å‘ (2024-2026)

| ç ”ç©¶ | ä¸»å¼µ | è«–æ–‡ |
|:-----|:-----|:-----|
| **DDPMæœ€é©åæŸãƒ¬ãƒ¼ãƒˆ** | TVè·é›¢ $O(d/T)$ åæŸè¨¼æ˜ã€ã‚¹ãƒ†ãƒƒãƒ—æ•°ã®ä¸‹ç•Œ | [arXiv:2510.27562](https://arxiv.org/abs/2510.27562) (2025H2) |
| **DDPM Score Matchingæ¼¸è¿‘åŠ¹ç‡æ€§** | DDPMã‚¹ã‚³ã‚¢æ¨å®šãŒçµ±è¨ˆçš„ã«æœ€é©ã€ç†è«–çš„æ­£å½“åŒ– | [arXiv:2504.05161](https://arxiv.org/abs/2504.05161) (ICLR 2025) |
| **Zero Terminal SNR** | è¨“ç·´/æ¨è«–ã®ä¸ä¸€è‡´ã‚’è§£æ¶ˆ | [arXiv:2305.08891](https://arxiv.org/abs/2305.08891) (Lin+ 2023) |
| **Consistency Models** | 1ã‚¹ãƒ†ãƒƒãƒ—ç”Ÿæˆã§å“è³ªç¶­æŒ | [arXiv:2303.01469](https://arxiv.org/abs/2303.01469) (Song+ 2023) |
| **Flow Matching** | ODEãƒ™ãƒ¼ã‚¹ã®æ–°ã—ã„å®šå¼åŒ– | [arXiv:2210.02747](https://arxiv.org/abs/2210.02747) (Lipman+ 2022) |

> **Note:** **é€²æ—: 95% å®Œäº†** é«˜æ¬¡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ»Improved DDPMãƒ»Guidanceã‚’æ¦‚è¦³ã€‚Zone 7ã§ç·æ‹¬ã¸ã€‚

---

> Progress: 95%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. DDPMã®æœ€é©åæŸãƒ¬ãƒ¼ãƒˆ $O(d/T)$ï¼ˆarXiv:2510.27562ï¼‰ã«ãŠã„ã¦ $d$ ãŒæŒ‡ã™é‡ã¨ã€åæŸã‚’ä¿è¨¼ã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—æ•° $T$ ã®é¸ã³æ–¹ã®æŒ‡é‡ã‚’è¿°ã¹ã‚ˆã€‚
> 2. Cosineã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒ Linearã‚ˆã‚Šé«˜SNRé ˜åŸŸã§æœ‰åˆ©ã§ã€ä½SNRé ˜åŸŸã§å·®ãŒç¸®ã¾ã‚‹ç†ç”±ã‚’ $\bar{\alpha}_t$ ã®ã‚°ãƒ©ãƒ•ã®å½¢çŠ¶ã¨å¯¾å¿œã•ã›ã¦èª¬æ˜ã›ã‚ˆã€‚

## ğŸ­ Z7. ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ï¼ˆã¾ã¨ã‚ãƒ»FAQãƒ»æ¬¡å›äºˆå‘Šï¼‰

### 7.1 æœ¬è¬›ç¾©ã®åˆ°é”ç‚¹

**3ã¤ã®æ ¸å¿ƒ**:

1. **Forward/Reverse Process ã®å®Œå…¨å°å‡º**: é–‰å½¢å¼è§£ (æ•°å­¦çš„å¸°ç´æ³•)ã€ãƒ™ã‚¤ã‚ºåè»¢ (æ¡ä»¶ä»˜ãã‚¬ã‚¦ã‚¹)
2. **VLB ã¨ç°¡ç´ åŒ–æå¤±**: $L_T + \sum L_t + L_0$ ã®å®Œå…¨å±•é–‹ã€$L_\text{simple}$ ãŒå„ªã‚Œã‚‹ç†ç”±
3. **DDIMæ±ºå®šè«–çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°**: Non-Markovian forwardã€Probability Flow ODE ã¨ã®æ¥ç¶š

**é‡è¦ãªå¼**:

$$
\begin{aligned}
\text{Forward:} \quad & q(\mathbf{x}_t \mid \mathbf{x}_0) = \mathcal{N}(\sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1-\bar{\alpha}_t) \mathbf{I}) \\
\text{Reverse:} \quad & p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t) = \mathcal{N}(\boldsymbol{\mu}_\theta(\mathbf{x}_t, t), \sigma_t^2 \mathbf{I}) \\
\text{Loss:} \quad & L_\text{simple} = \mathbb{E}_{t, \mathbf{x}_0, \boldsymbol{\epsilon}} [\|\boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\|^2] \\
\text{DDIM:} \quad & \mathbf{x}_{t-1} = \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0 + \sqrt{1-\bar{\alpha}_{t-1}} \boldsymbol{\epsilon}_\theta
\end{aligned}
$$

**å®Ÿè£…**: ğŸ Pythonè¨“ç·´ (PyTorch) + ğŸ¦€ Rustæ¨è«– (ONNX Runtime) ã§ Production-readyã€‚

### 7.2 FAQ

<details><summary>Q1: DDPMã¨Score Matchingã®é•ã„ã¯ï¼Ÿ</summary>

**A**: **æœ¬è³ªçš„ã«åŒã˜** (Section 3.10)ã€‚DDPMã¯é›¢æ•£æ™‚åˆ»ã€Score Matchingã¯é€£ç¶šæ™‚åˆ»ã€‚æ•°å¼:

$$
\nabla_{\mathbf{x}_t} \log q(\mathbf{x}_t \mid \mathbf{x}_0) = - \frac{\boldsymbol{\epsilon}}{\sqrt{1-\bar{\alpha}_t}}
$$

ãƒã‚¤ã‚ºäºˆæ¸¬ = ã‚¹ã‚³ã‚¢äºˆæ¸¬ (rescaled)ã€‚

</details>

<details><summary>Q2: ãªãœ $L_\text{simple}$ ãŒ $L_\text{VLB}$ ã‚ˆã‚Šå„ªã‚Œã‚‹ï¼Ÿ</summary>

**A**: $L_\text{VLB}$ ã®é‡ã¿ $\frac{\beta_t^2}{2\sigma_t^2 \alpha_t (1-\bar{\alpha}_t)}$ ã¯ã€ä½ãƒã‚¤ã‚ºé ˜åŸŸã‚’éé‡è¦– â†’ çŸ¥è¦šå“è³ªä½ä¸‹ã€‚$L_\text{simple}$ ã¯å…¨æ™‚åˆ»ã‚’å‡ç­‰ã«å­¦ç¿’ â†’ FIDæ”¹å–„ã€‚

</details>

<details><summary>Q3: DDIM ã® $\eta$ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ„å‘³ã¯ï¼Ÿ</summary>

**A**: $\eta = 0$: æ±ºå®šè«–çš„ (åŒã˜ $\mathbf{x}_T$ â†’ åŒã˜ $\mathbf{x}_0$)ã€‚$\eta = 1$: DDPMé¢¨ (ç¢ºç‡çš„)ã€‚ä¸­é–“å€¤ã§åˆ¶å¾¡å¯èƒ½ã€‚

</details>

<details><summary>Q4: Cosine schedule vs Linear schedule ã®é•ã„ã¯ï¼Ÿ</summary>

**A**: **Cosine** (æ¨å¥¨): SNRç·©ã‚„ã‹ã«æ¸›å°‘ã€è¨“ç·´å®‰å®šã€Zero Terminal SNRã«è¿‘ã„ã€‚**Linear**: å¤ã„ã€$\bar{\alpha}_T > 0$ ã§è¨“ç·´/æ¨è«–ä¸ä¸€è‡´ã€‚

</details>

<details><summary>Q5: U-Net ã® Self-Attention ã¯ã©ã“ã«é…ç½®ï¼Ÿ</summary>

**A**: **16Ã—16ä»¥ä¸‹ã®ä½è§£åƒåº¦** ã§ã®ã¿ã€‚è¨ˆç®—é‡ $O(N^2)$ ã®ãŸã‚ã€é«˜è§£åƒåº¦ã§ã¯çœç•¥ã€‚MNISTã§ã¯28Ã—28ãªã®ã§ã€1å±¤ã®ã¿ã§ååˆ†ã€‚

</details>

### 7.3 å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« (1é€±é–“ãƒ—ãƒ©ãƒ³)

| æ—¥ | å†…å®¹ | æ™‚é–“ |
|:---|:-----|:-----|
| 1 | Zone 0-2 (ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ â†’ ç›´æ„Ÿ) | 30åˆ† |
| 2 | Zone 3.1-3.4 (Forward â†’ VLB) | 60åˆ† |
| 3 | Zone 3.5-3.7 (3å½¢æ…‹ â†’ SNR) | 45åˆ† |
| 4 | Zone 3.8-3.10 (U-Net â†’ Score) | 60åˆ† |
| 5 | Zone 4 (Rustå®Ÿè£…) | 90åˆ† |
| 6 | Zone 5 (å®Ÿé¨“ + è‡ªå·±è¨ºæ–­) | 60åˆ† |
| 7 | Zone 6-7 (ç™ºå±• + æŒ¯ã‚Šè¿”ã‚Š) | 45åˆ† |

### 7.4 æ¬¡å›äºˆå‘Š: ç¬¬37å› SDE/ODE & ç¢ºç‡éç¨‹è«–

**DDPM (é›¢æ•£)** ã‚’ **SDE (é€£ç¶šæ™‚é–“)** ã«æ‹¡å¼µã™ã‚‹ã€‚

**äºˆå‘Šå†…å®¹**:

- **VP-SDE / VE-SDE / Sub-VP SDE**: DDPMã¨NCSNã®SDEçµ±ä¸€
- **Reverse-time SDE** (Anderson 1982): é€†æ™‚é–“æ‹¡æ•£ã®å­˜åœ¨å®šç†
- **Probability Flow ODE**: åŒä¸€å‘¨è¾ºåˆ†å¸ƒã‚’æŒã¤æ±ºå®šè«–çš„éç¨‹
- **Score SDEçµ±ä¸€ç†è«–** (Song+ 2021): Forwardâ†’Reverseâ†’Scoreâ†’ODE
- **åæŸæ€§è§£æ**: TVè·é›¢ $O(d/T)$ åæŸã€Manifoldä»®èª¬ä¸‹ã®ç·šå½¢åæŸ

**Course I ç¬¬5å›ã¨ã®é–¢ä¿‚**: ç¬¬5å›ã§ä¼Šè—¤ç©åˆ†ãƒ»ä¼Šè—¤ã®è£œé¡Œãƒ»SDEåŸºç¤ã‚’å°å…¥æ¸ˆã¿ã€‚ç¬¬37å›ã¯ã“ã‚Œã‚’**Diffusionå›ºæœ‰ã®SDE (VP/VE/Reverse/PF-ODE)** ã«ç‰¹åŒ–ã€‚

**æ¥ç¶š**: DDPMé›¢æ•£ â†’ SDEé€£ç¶š â†’ Flow Matchingçµ±ä¸€ (ç¬¬38å›)ã€‚

> **Note:** **é€²æ—: 100% å®Œäº†** ğŸ† ç¬¬36å›å®Œäº†ï¼DDPMç†è«–ãƒ»å®Ÿè£…ãƒ»å®Ÿé¨“ã‚’å®Œå…¨ãƒã‚¹ã‚¿ãƒ¼ã€‚ç¬¬37å›ã§SDEé€£ç¶šæ™‚é–“ã¸ã€‚

---

### 6.X ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„

**"1000ã‚¹ãƒ†ãƒƒãƒ—"ã¯ç†è«–ç†è§£ã®ä¸è¶³ã§ã¯ï¼Ÿ**

DDPM [^1] (2020) ã¯1000ã‚¹ãƒ†ãƒƒãƒ—ã€‚ã ãŒ2021å¹´ã®DDIM [^2] ã§50ã‚¹ãƒ†ãƒƒãƒ—ã€2022å¹´ã®DPM-Solver++ [^4] ã§10-20ã‚¹ãƒ†ãƒƒãƒ—ã€2023å¹´ã®Consistency Models (ç¬¬40å›) ã§1ã‚¹ãƒ†ãƒƒãƒ—ã€‚

**å•ã„**:

1. ãªãœDDPMã¯1000ã‚¹ãƒ†ãƒƒãƒ—å¿…è¦ã ã£ãŸã®ã‹ï¼Ÿ â†’ **ãƒãƒ«ã‚³ãƒ•ä»®å®š** + **å›ºå®šã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«** ã®åˆ¶ç´„
2. DDIMã®æœ¬è³ªã¯ä½•ã‹ï¼Ÿ â†’ **Non-Markovian** ã§è‡ªç”±åº¦ç²å¾— + **Probability Flow ODE** è¿‘ä¼¼
3. 1ã‚¹ãƒ†ãƒƒãƒ—ç”Ÿæˆã®ç†è«–çš„é™ç•Œã¯ï¼Ÿ â†’ **è’¸ç•™** vs **Flow Matching** vs **Consistency** (ç¬¬40å›ã§è¨¼æ˜)

**æŒ‘ç™ºçš„ä»®èª¬**: "1000ã‚¹ãƒ†ãƒƒãƒ—" ã¯å®Ÿè£…ã®ä¾¿å®œã€‚**ç†è«–çš„ã«ã¯10-50ã‚¹ãƒ†ãƒƒãƒ—ã§ååˆ†** (DDIM/DPM-Solver++)ã€**æœ€çµ‚çš„ã«ã¯1ã‚¹ãƒ†ãƒƒãƒ—ãŒå¯èƒ½** (Consistency Models)ã€‚ã‚¹ãƒ†ãƒƒãƒ—æ•°å‰Šæ¸›ã®æ­´å²ã¯ã€**ç†è«–ã®æ´—ç·´ã®æ­´å²** ã§ã‚ã‚‹ã€‚

**ã‚ãªãŸã¯ã©ã†è€ƒãˆã‚‹ã‹ï¼Ÿ**

---

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: Ho, J., Jain, A., & Abbeel, P. (2020). Denoising Diffusion Probabilistic Models. *NeurIPS 2020*. [arXiv:2006.11239](https://arxiv.org/abs/2006.11239)

<https://arxiv.org/abs/2006.11239>

[^2]: Song, J., Meng, C., & Ermon, S. (2020). Denoising Diffusion Implicit Models. *ICLR 2021*. [arXiv:2010.02502](https://arxiv.org/abs/2010.02502)

<https://arxiv.org/abs/2010.02502>

[^3]: Nichol, A., & Dhariwal, P. (2021). Improved Denoising Diffusion Probabilistic Models. *ICML 2021*. [arXiv:2102.09672](https://arxiv.org/abs/2102.09672)

<https://arxiv.org/abs/2102.09672>

[^4]: Lu, C., Zhou, Y., Bao, F., Chen, J., Li, C., & Zhu, J. (2022). DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models. *NeurIPS 2022*. [arXiv:2211.01095](https://arxiv.org/abs/2211.01095)

<https://arxiv.org/abs/2211.01095>

[^5]: Lin, S., Liu, B., Li, J., & Yang, X. (2023). Common Diffusion Noise Schedules and Sample Steps are Flawed. *WACV 2024*. [arXiv:2305.08891](https://arxiv.org/abs/2305.08891)

<https://arxiv.org/abs/2305.08891>

[^6]: Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., & Poole, B. (2020). Score-Based Generative Modeling through Stochastic Differential Equations. *ICLR 2021*. [arXiv:2011.13456](https://arxiv.org/abs/2011.13456)

<https://arxiv.org/abs/2011.13456>

### æ•™ç§‘æ›¸

- Karras, T., Aittala, M., Aila, T., & Laine, S. (2022). Elucidating the Design Space of Diffusion-Based Generative Models. *NeurIPS 2022*. [arXiv:2206.00364](https://arxiv.org/abs/2206.00364)
- Yang, L., Zhang, Z., Song, Y., Hong, S., Xu, R., Zhao, Y., ... & Cui, B. (2023). Diffusion Models: A Comprehensive Survey of Methods and Applications. *ACM Computing Surveys*. [arXiv:2209.00796](https://arxiv.org/abs/2209.00796)

---

## è‘—è€…ãƒªãƒ³ã‚¯

- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
