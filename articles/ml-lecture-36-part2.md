---
title: "ç¬¬36å›: æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«åŸºç¤ / DDPM & ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
emoji: "ğŸ”„"
type: "tech"
topics: ["machinelearning", "deeplearning", "ddpm", "julia", "diffusion"]
published: true
slug: "ml-lecture-36-part2"
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Julia", "Rust"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---

## ğŸ’» 4. å®Ÿè£…ã‚¾ãƒ¼ãƒ³ï¼ˆ45åˆ†ï¼‰â€” Juliaè¨“ç·´ + Rustæ¨è«–

### 4.1 ç’°å¢ƒæ§‹ç¯‰ & ãƒ©ã‚¤ãƒ–ãƒ©ãƒªé¸å®š

**Juliaç’°å¢ƒ**:

```julia
# Project.toml ã«è¿½åŠ 
using Pkg
Pkg.add(["Lux", "Optimisers", "Zygote", "CUDA", "MLUtils", "Images", "Plots"])
```

**Rustç’°å¢ƒ** (æ¨è«–):

```toml
# Cargo.toml
[dependencies]
ndarray = "0.15"
ort = "2.0"  # ONNX Runtime
image = "0.25"
```

### 4.2 Tiny DDPM Juliaå®Ÿè£… (è¨“ç·´ãƒ«ãƒ¼ãƒ—å®Œå…¨ç‰ˆ)

**ç›®æ¨™**: MNIST ã§ 500K paramsã€CPU 5åˆ†ã§è¨“ç·´ã€‚

#### 4.2.1 Noise Schedule

```julia
using LinearAlgebra

# Cosine schedule (Improved DDPM)
function cosine_schedule(T::Int, s::Float64=0.008)
    t_seq = 0:T
    f_t = @. cos((t_seq / T + s) / (1 + s) * Ï€ / 2)^2
    á¾± = f_t[2:end] ./ f_t[1]
    Î± = á¾± ./ [1.0; á¾±[1:end-1]]
    Î² = 1.0 .- Î±
    return Î², Î±, á¾±
end

T = 1000
Î², Î±, á¾± = cosine_schedule(T)
println("Î² range: [$(minimum(Î²)), $(maximum(Î²))]")
println("á¾±_T = $(á¾±[end])")  # Should be â‰ˆ 0
```

#### 4.2.2 Simplified U-Net (Tinyç‰ˆ)

```julia
using Lux, Random

# Simplified U-Net for MNIST (28x28)
function create_tiny_unet(; d_model=64, t_emb_dim=128)
    # Time embedding MLP
    time_mlp = Chain(
        Dense(t_emb_dim, d_model * 4, swish),
        Dense(d_model * 4, d_model * 4)
    )

    # Encoder
    enc1 = Chain(
        Conv((3, 3), 1 => d_model, swish, pad=1),
        GroupNorm(d_model, 8)
    )
    enc2 = Chain(
        Conv((3, 3), d_model => d_model * 2, swish, stride=2, pad=1),
        GroupNorm(d_model * 2, 8)
    )

    # Bottleneck
    bottleneck = Chain(
        Conv((3, 3), d_model * 2 => d_model * 2, swish, pad=1),
        GroupNorm(d_model * 2, 8)
    )

    # Decoder
    dec1 = Chain(
        ConvTranspose((4, 4), d_model * 4 => d_model, swish, stride=2, pad=1),
        GroupNorm(d_model, 8)
    )

    # Output
    out_conv = Conv((3, 3), d_model => 1, pad=1)

    return (time_mlp=time_mlp, enc1=enc1, enc2=enc2, bottleneck=bottleneck,
            dec1=dec1, out_conv=out_conv)
end

# Sinusoidal time embedding
function time_embedding(t::Int, d::Int)
    half_dim = d Ã· 2
    emb = log(10000.0) / (half_dim - 1)
    emb = exp.(-emb * (0:half_dim-1))
    emb = t * emb
    emb = vcat(sin.(emb), cos.(emb))
    return Float32.(emb)
end

# Forward pass
function (model::NamedTuple)(x::AbstractArray, t::Int, ps, st)
    # Time embedding
    t_emb = time_embedding(t, 128)
    t_emb, _ = model.time_mlp(t_emb, ps.time_mlp, st.time_mlp)

    # Encoder
    h1, st1 = model.enc1(x, ps.enc1, st.enc1)
    h1 = h1 .+ reshape(t_emb[1:64], 64, 1, 1, 1)  # Add time embedding

    h2, st2 = model.enc2(h1, ps.enc2, st.enc2)

    # Bottleneck
    h, st_b = model.bottleneck(h2, ps.bottleneck, st.bottleneck)

    # Decoder (with skip connection)
    h_cat = cat(h, h2; dims=3)  # Channel-wise concatenation
    h, st_d = model.dec1(h_cat, ps.dec1, st.dec1)

    # Output
    Îµ_pred, st_o = model.out_conv(h, ps.out_conv, st.out_conv)

    return Îµ_pred, (st1..., st2..., st_b..., st_d..., st_o...)
end
```

<details><summary>å®Œå…¨ãªU-Netå®Ÿè£… (Self-Attentionä»˜ã)</summary>

æœ¬æ ¼çš„ãªU-Netã«ã¯16Ã—16è§£åƒåº¦ã§Self-Attentionã‚’è¿½åŠ ã™ã‚‹ã€‚ä»¥ä¸‹ã¯å®Œå…¨ç‰ˆ (MNIST ã§ã¯éå‰°):

```julia
# Multi-Head Self-Attention layer
struct SelfAttention
    heads::Int
    d_model::Int
end

function (attn::SelfAttention)(x, ps, st)
    # x: (H, W, C, B)
    H, W, C, B = size(x)
    @assert C % attn.heads == 0

    # Reshape to (HW, C, B)
    x_flat = reshape(x, H * W, C, B)

    # QKV projection (simplified: identity for demo)
    q = k = v = x_flat

    # Scaled dot-product attention per head
    d_head = C Ã· attn.heads
    attn_out = similar(x_flat)

    @inbounds for h in 1:attn.heads
        rng = (h-1)*d_head+1 : h*d_head
        @views begin
            q_h = q[:, rng, :]
            k_h = k[:, rng, :]
            v_h = v[:, rng, :]
            scores = batched_mul(q_h, permutedims(k_h, (2, 1, 3))) / sqrt(d_head)
            attn_weights = softmax(scores; dims=2)
            attn_out[:, rng, :] .= batched_mul(attn_weights, v_h)
        end
    end

    # Reshape back
    out = reshape(attn_out, H, W, C, B)
    return out .+ x, st  # Residual connection
end
```

</details>

#### 4.2.3 è¨“ç·´ãƒ«ãƒ¼ãƒ—

```julia
using Optimisers, MLUtils, Zygote

# Training step
function train_step!(model, ps, st, opt_state, xâ‚€, Î², á¾±, T, rng)
    # Sample t uniformly
    t = rand(rng, 1:T)

    # Sample noise Îµ ~ ğ’©(0, I)
    Îµ = randn(rng, Float32, size(xâ‚€))

    # Compute x_t using closed-form
    x_t = sqrt(á¾±[t]) .* xâ‚€ .+ sqrt(1 - á¾±[t]) .* Îµ

    # Compute loss and gradient
    loss, (âˆ‡ps, _) = Zygote.withgradient(ps, st) do p, s
        Îµ_pred, _ = model(x_t, t, p, s)
        sum((Îµ .- Îµ_pred).^2)  # MSE loss
    end

    # Update parameters
    opt_state, ps = Optimisers.update!(opt_state, ps, âˆ‡ps)

    return loss, ps, st, opt_state
end

# Training loop (simplified)
function train_ddpm!(model, ps, st, train_data, Î², á¾±, T; epochs=10, lr=1e-3)
    rng = Random.default_rng()
    opt_state = Optimisers.setup(Adam(lr), ps)

    for epoch in 1:epochs
        total_loss = 0.0
        for (batch_idx, xâ‚€) in enumerate(train_data)
            loss, ps, st, opt_state = train_step!(model, ps, st, opt_state, xâ‚€, Î², á¾±, T, rng)
            total_loss += loss

            if batch_idx % 100 == 0
                println("Epoch $epoch, Batch $batch_idx, Loss: $loss")
            end
        end

        avg_loss = total_loss / length(train_data)
        println("Epoch $epoch completed. Avg Loss: $avg_loss")
    end

    return ps, st
end
```

#### 4.2.4 ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (DDPM & DDIM)

```julia
# DDPM sampling
function ddpm_sample(model, ps, st, x_T, Î², Î±, á¾±, T)
    x_t = x_T

    for t in T:-1:1
        # Predict noise
        Îµ_pred, _ = model(x_t, t, ps, st)

        # Compute mean
        Î¼ = (1 / sqrt(Î±[t])) .* (x_t .- (Î²[t] / sqrt(1 - á¾±[t])) .* Îµ_pred)

        # Sample (no noise at t=1)
        if t > 1
            Ïƒ = sqrt(Î²[t])
            z = randn(Float32, size(x_t))
            x_t = Î¼ .+ Ïƒ .* z
        else
            x_t = Î¼
        end
    end

    return x_t
end

# DDIM sampling (accelerated)
function ddim_sample(model, ps, st, x_T, á¾±, steps; Î·=0.0)
    # Subsequence of timesteps
    Ï„ = Int.(round.(range(1, length(á¾±), length=steps)))
    x_t = x_T

    for i in length(Ï„):-1:2
        t = Ï„[i]
        t_prev = Ï„[i-1]

        # Predict noise
        Îµ_pred, _ = model(x_t, t, ps, st)

        # Predicted xâ‚€
        xâ‚€_pred = (x_t .- sqrt(1 - á¾±[t]) .* Îµ_pred) ./ sqrt(á¾±[t])

        # Variance
        Ïƒ_t = Î· * sqrt((1 - á¾±[t_prev]) / (1 - á¾±[t])) * sqrt(1 - á¾±[t] / á¾±[t_prev])

        # Direction
        dir_xt = sqrt(1 - á¾±[t_prev] - Ïƒ_t^2) .* Îµ_pred

        # Noise
        noise = (Î· > 0) ? randn(Float32, size(x_t)) : zero(x_t)

        # DDIM step
        x_t = sqrt(á¾±[t_prev]) .* xâ‚€_pred .+ dir_xt .+ Ïƒ_t .* noise
    end

    # Final step (t=1 â†’ t=0)
    Îµ_pred, _ = model(x_t, Ï„[1], ps, st)
    xâ‚€ = (x_t .- sqrt(1 - á¾±[Ï„[1]]) .* Îµ_pred) ./ sqrt(á¾±[Ï„[1]])

    return xâ‚€
end
```

### 4.3 ğŸ¦€ Rustæ¨è«–å®Ÿè£… (DDIMé«˜é€Ÿã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°)

**Rustå®Ÿè£…** ã¯è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ« (ONNXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ) ã‚’èª­ã¿è¾¼ã¿ã€DDIM ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’é«˜é€Ÿå®Ÿè¡Œã€‚

#### 4.3.1 Rustå´ã‚³ãƒ¼ãƒ‰

```rust
// src/ddim.rs
use ndarray::{Array4, s};
use ort::{Session, Value};

pub struct DDIMSampler {
    session: Session,
    alpha_bar: Vec<f32>,
    steps: usize,
}

type Result<T> = std::result::Result<T, Box<dyn std::error::Error>>;

impl DDIMSampler {
    pub fn new(model_path: &str, alpha_bar: Vec<f32>, steps: usize) -> Result<Self> {
        let session = Session::builder()?
            .with_model_from_file(model_path)?;
        Ok(Self { session, alpha_bar, steps })
    }

    pub fn sample(&self, x_t: Array4<f32>, eta: f32) -> Result<Array4<f32>> {
        let n = self.alpha_bar.len();
        let tau: Vec<usize> = (0..self.steps)
            .map(|i| (i * n / self.steps).min(n - 1))
            .collect();

        let mut x = x_t;

        for i in (1..tau.len()).rev() {
            let (t, t_prev) = (tau[i], tau[i - 1]);

            // Predict noise via ONNX model
            let Îµ_pred = self.predict_noise(&x, t)?;

            // DDIM step
            x = self.ddim_step(x, Îµ_pred, t, t_prev, eta);
        }

        // Final step
        let Îµ_pred = self.predict_noise(&x, tau[0])?;
        let á¾±_t = self.alpha_bar[tau[0]];
        let x_0 = (&x - (1.0 - á¾±_t).sqrt() * &Îµ_pred) / á¾±_t.sqrt();

        Ok(x_0)
    }

    fn predict_noise(&self, x_t: &Array4<f32>, t: usize) -> Result<Array4<f32>> {
        // Convert to ONNX input
        let x_input = Value::from_array(x_t.view())?;
        let t_input = Value::from_array(ndarray::arr0(t as f32).view())?;

        // Run inference
        let outputs = self.session.run(vec![x_input, t_input])?;
        let Îµ = outputs[0].try_extract_tensor::<f32>()?;

        Ok(Îµ.to_owned().into_dimensionality()?)
    }

    fn ddim_step(&self, x_t: Array4<f32>, Îµ: Array4<f32>, t: usize, t_prev: usize, Î·: f32) -> Array4<f32> {
        let (á¾±_t, á¾±_prev) = (self.alpha_bar[t], self.alpha_bar[t_prev]);

        // Predicted x_0
        let x_0_pred = (&x_t - (1.0 - á¾±_t).sqrt() * &Îµ) / á¾±_t.sqrt();

        // Variance
        let Ïƒ_t = Î· * ((1.0 - á¾±_prev) / (1.0 - á¾±_t)).sqrt()
            * (1.0 - á¾±_t / á¾±_prev).sqrt();

        // Direction + DDIM step
        let dir_xt = (1.0 - á¾±_prev - Ïƒ_t.powi(2)).sqrt() * &Îµ;
        á¾±_prev.sqrt() * x_0_pred + dir_xt
    }
}
```

#### 4.3.2 ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ (Julia â†’ ONNX)

```julia
using Lux, ONNX

# Export trained model to ONNX
function export_to_onnx(model, ps, st, filepath)
    # Dummy input
    x_dummy = randn(Float32, 28, 28, 1, 1)
    t_dummy = 500

    # Trace model
    traced_model = Lux.trace(model, (x_dummy, t_dummy), ps, st)

    # Export
    ONNX.save(filepath, traced_model)
    println("Model exported to $filepath")
end

export_to_onnx(model, ps, st, "tiny_ddpm.onnx")
```

#### 4.3.3 Rustå®Ÿè¡Œ

```rust
// src/main.rs
use ndarray::Array4;
use ndarray_rand::RandomExt;
use ndarray_rand::rand_distr::StandardNormal;

mod ddim;

fn main() {
    // Load alpha_bar schedule
    let alpha_bar: Vec<f32> = load_alpha_bar_from_file("alpha_bar.json");

    // Create sampler
    let sampler = ddim::DDIMSampler::new("tiny_ddpm.onnx", alpha_bar, 50).unwrap();

    // Sample from noise
    let x_T = Array4::random((1, 1, 28, 28), StandardNormal);
    let x_0 = sampler.sample(x_T, 0.0).unwrap();  // Deterministic (Î·=0)

    println!("Generated image shape: {:?}", x_0.shape());
    save_image(&x_0, "generated.png");
}

fn load_alpha_bar_from_file(path: &str) -> Vec<f32> {
    // Load from JSON (implementation omitted for brevity)
    vec![0.999, 0.998, /* ... */, 0.001]
}

fn save_image(x: &Array4<f32>, path: &str) {
    // Convert to image and save (implementation omitted)
}
```

### 4.4 Math â†’ Code 1:1å¯¾å¿œãƒ‘ã‚¿ãƒ¼ãƒ³

| æ•°å¼ | Julia | Rust |
|:-----|:------|:-----|
| $\mathbf{x}_t = \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t} \boldsymbol{\epsilon}$ | `x_t = sqrt(á¾±[t]) .* xâ‚€ .+ sqrt(1 - á¾±[t]) .* Îµ` | `x_t = alpha_bar_t.sqrt() * x_0 + (1.0 - alpha_bar_t).sqrt() * epsilon` |
| $\boldsymbol{\mu}_\theta = \frac{1}{\sqrt{\alpha_t}} (\mathbf{x}_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta)$ | `Î¼ = (1 / sqrt(Î±[t])) .* (x_t .- (Î²[t] / sqrt(1 - á¾±[t])) .* Îµ_pred)` | `mu = (x_t - (beta_t / (1.0 - alpha_bar_t).sqrt()) * epsilon_pred) / alpha_t.sqrt()` |
| $\mathbf{x}_{t-1} = \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0 + \sqrt{1-\bar{\alpha}_{t-1}} \boldsymbol{\epsilon}_\theta$ | `x_prev = sqrt(á¾±[t_prev]) .* xâ‚€_pred .+ sqrt(1 - á¾±[t_prev]) .* Îµ_pred` | `x_prev = alpha_bar_prev.sqrt() * x_0_pred + (1.0 - alpha_bar_prev).sqrt() * epsilon_pred` |

> **Note:** **é€²æ—: 70% å®Œäº†** Juliaè¨“ç·´ + Rustæ¨è«–ã®å®Ÿè£…å®Œäº†ã€‚Zone 5ã§å®Ÿé¨“ã¸ã€‚

---

## ğŸ”¬ 5. å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” Tiny DDPM on MNIST

### 5.1 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ (MNIST)

```julia
using MLDatasets, MLUtils

# Load MNIST
train_data, train_labels = MNIST.traindata(Float32)
test_data, test_labels = MNIST.testdata(Float32)

# Normalize to [-1, 1] in-place
@. train_data = train_data * 2f0 - 1f0
@. test_data  = test_data  * 2f0 - 1f0

# Reshape to (H, W, C, B)
train_data = reshape(train_data, 28, 28, 1, :)
test_data = reshape(test_data, 28, 28, 1, :)

# Create data loader
train_loader = DataLoader((train_data,), batchsize=128, shuffle=true)

println("Training samples: $(size(train_data, 4))")
```

### 5.2 è¨“ç·´å®Ÿè¡Œ (CPU 5åˆ†)

```julia
# Initialize model
model = create_tiny_unet(d_model=64, t_emb_dim=128)
ps, st = Lux.setup(Random.default_rng(), model)

# Noise schedule
T = 1000
Î², Î±, á¾± = cosine_schedule(T)

# Train
ps_trained, st_trained = train_ddpm!(model, ps, st, train_loader, Î², á¾±, T; epochs=10, lr=1e-3)

println("Training completed!")
```

**Expected output**:
```
Epoch 1, Batch 100, Loss: 0.523
...
Epoch 10 completed. Avg Loss: 0.089
Training completed!
```

### 5.3 ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° & å¯è¦–åŒ–

```julia
using Plots

# Sample 16 images (DDPM 1000 steps)
x_T = randn(Float32, 28, 28, 1, 16)
samples_ddpm = ddpm_sample(model, ps_trained, st_trained, x_T, Î², Î±, á¾±, T)

# Sample 16 images (DDIM 50 steps)
samples_ddim = ddim_sample(model, ps_trained, st_trained, x_T, á¾±, 50; Î·=0.0)

# Visualize
function plot_samples(samples, title)
    n = size(samples, 4)
    grid = plot(layout=(4, 4), size=(800, 800), title=title)

    for i in 1:min(n, 16)
        @views img = @. (samples[:, :, 1, i] + 1f0) / 2f0
        plot!(grid, subplot=i, Gray.(img'), axis=false, ticks=false)
    end

    return grid
end

plot_ddpm = plot_samples(samples_ddpm, "DDPM (1000 steps)")
plot_ddim = plot_samples(samples_ddim, "DDIM (50 steps, deterministic)")

display(plot_ddpm)
display(plot_ddim)
```

### 5.4 å®šé‡è©•ä¾¡ & æ¯”è¼ƒ

**FID (FrÃ©chet Inception Distance)** ã¯è¨ˆç®—ã‚³ã‚¹ãƒˆé«˜ã„ãŸã‚ã€ç°¡æ˜“çš„ãª **å†æ§‹æˆèª¤å·®** ã¨ **å¤šæ§˜æ€§** ã‚’æ¸¬å®š:

```julia
# Reconstruction test (encode real image â†’ denoise)
function test_reconstruction(model, ps, st, xâ‚€, Î², á¾±, T)
    # Add noise to t=500
    t = 500
    Îµ = randn(Float32, size(xâ‚€))
    x_t = sqrt(á¾±[t]) .* xâ‚€ .+ sqrt(1 - á¾±[t]) .* Îµ

    # Denoise back
    x_recon = ddim_sample(model, ps, st, x_t, á¾±[1:t], 50; Î·=0.0)

    # MSE
    mse = mean((xâ‚€ .- x_recon).^2)
    return mse
end

# Test on 100 samples
avg_mse = mean(
    test_reconstruction(model, ps_trained, st_trained,
                        @view(test_data[:, :, :, i:i]), Î², á¾±, T)
    for i in 1:100
)
println("Average reconstruction MSE: $avg_mse")
```

**aMUSEd-256 æ¨è«–ãƒ‡ãƒ¢ã¨ã®å“è³ªæ¯”è¼ƒ**:

aMUSEd-256 [Hugging Face](https://huggingface.co/amused/amused-256) ã¯éæ‹¡æ•£ãƒ¢ãƒ‡ãƒ« (Masked Image Modeling) ã§256Ã—256ç”»åƒã‚’ç”Ÿæˆã€‚

| ãƒ¢ãƒ‡ãƒ« | è§£åƒåº¦ | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | è¨“ç·´æ™‚é–“ (CPU) | å“è³ª (ä¸»è¦³) |
|:-------|:-------|:----------|:--------------|:-----------|
| **Tiny DDPM (æœ¬å®Ÿè£…)** | 28Ã—28 | ~500K | 5åˆ† | MNISTæ•°å­—ã€ã‚·ãƒ£ãƒ¼ãƒ— |
| **aMUSEd-256** | 256Ã—256 | ~800M | N/A (äº‹å‰è¨“ç·´æ¸ˆã¿) | é«˜å“è³ªã€å¤šæ§˜ |

**çµè«–**: Tiny DDPMã¯ç†è«–å­¦ç¿’ç”¨ã€‚Productionå“è³ªã¯aMUSEd-256ã‚„Stable Diffusion (ç¬¬39å›) ã§å®Ÿç¾ã€‚

### 5.5 è¨“ç·´æ›²ç·šåˆ†æ & ãƒ‡ãƒãƒƒã‚°

**Lossæ›²ç·šã®å…¸å‹çš„ãƒ‘ã‚¿ãƒ¼ãƒ³**:

```julia
using Plots

# Training history (from train_ddpm!)
function plot_training_curves(loss_history, lr_schedule)
    p1 = plot(loss_history, xlabel="Epoch", ylabel="Loss", label="Training Loss", lw=2, legend=:topright)
    hline!([0.089], label="Final Loss", linestyle=:dash, color=:red)

    p2 = plot(lr_schedule, xlabel="Epoch", ylabel="Learning Rate", label="LR Schedule", lw=2, color=:orange)

    plot(p1, p2, layout=(2, 1), size=(800, 600))
end

# Example: Cosine decay
lr_schedule = @. 1e-3 * cos(Ï€ * (0:10) / 20)
plot_training_curves(loss_history, lr_schedule)
```

**å…¸å‹çš„ãªå•é¡Œã¨å¯¾å‡¦**:

| ç—‡çŠ¶ | åŸå›  | å¯¾å‡¦ |
|:-----|:-----|:-----|
| Loss ãŒç™ºæ•£ (NaN) | Learning rate é«˜ã™ã | LR ã‚’ 1/10 ã«æ¸›ã‚‰ã™ |
| Loss ãŒä¸‹ãŒã‚‰ãªã„ | ãƒ¢ãƒ‡ãƒ«ãŒå°ã•ã™ã | d_model ã‚’ 64 â†’ 128 |
| ç”Ÿæˆç”»åƒãŒãƒã‚¤ã‚ºã®ã¿ | è¨“ç·´ä¸è¶³ | epochs ã‚’ 10 â†’ 50 |
| ç”Ÿæˆç”»åƒãŒå˜ä¸€ãƒ‘ã‚¿ãƒ¼ãƒ³ | Mode collapse | Batch size ã‚’ 128 â†’ 256 |

**è¨“ç·´å®‰å®šåŒ–ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯**:

```julia
# Gradient clipping (Lux.jl with Optimisers.jl)
using Optimisers

function train_step_with_clip!(model, ps, st, opt_state, xâ‚€, Î², á¾±, T, rng; clip_norm=1.0)
    t = rand(rng, 1:T)
    Îµ = randn(rng, Float32, size(xâ‚€))
    x_t = sqrt(á¾±[t]) .* xâ‚€ .+ sqrt(1 - á¾±[t]) .* Îµ

    loss, (âˆ‡ps, _) = Zygote.withgradient(ps, st) do p, s
        Îµ_pred, _ = model(x_t, t, p, s)
        sum((Îµ .- Îµ_pred).^2)
    end

    # Clip gradients
    âˆ‡norm = sqrt(sum(sum(abs2, g) for g in âˆ‡ps))
    if âˆ‡norm > clip_norm
        âˆ‡ps = map(g -> g .* (clip_norm / âˆ‡norm), âˆ‡ps)
    end

    opt_state, ps = Optimisers.update!(opt_state, ps, âˆ‡ps)
    return loss, ps, st, opt_state, âˆ‡norm
end
```

**EMA (Exponential Moving Average) for Stable Inference**:

```julia
# EMA weights for better sample quality
mutable struct EMAWeights
    shadow_ps::Any
    decay::Float64
end

function create_ema(ps, decay=0.9999)
    shadow_ps = deepcopy(ps)
    return EMAWeights(shadow_ps, decay)
end

function update_ema!(ema::EMAWeights, ps)
    for (shadow, current) in zip(ema.shadow_ps, ps)
        @. shadow = ema.decay * shadow + (1 - ema.decay) * current
    end
end

# Use during training
ema = create_ema(ps, 0.9999)
for epoch in 1:epochs
    # ... train_step! ...
    update_ema!(ema, ps)  # Update EMA after each batch
end

# Use EMA weights for sampling
samples = ddpm_sample(model, ema.shadow_ps, st, x_T, Î², Î±, á¾±, T)
```

### 5.6 ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å“è³ªã®å®šé‡è©•ä¾¡

**FID (FrÃ©chet Inception Distance)** ã®å®Œå…¨å®Ÿè£…:

```julia
using Flux, Statistics

# Load pre-trained Inception v3 (or simple CNN for MNIST)
struct SimpleFeatureExtractor
    layers::Chain
end

function create_feature_extractor()
    return Chain(
        Conv((3, 3), 1 => 32, relu, pad=1),
        MaxPool((2, 2)),
        Conv((3, 3), 32 => 64, relu, pad=1),
        MaxPool((2, 2)),
        Flux.flatten,
        Dense(7 * 7 * 64, 256)
    )
end

feature_extractor = create_feature_extractor()

# Extract features
function extract_features(images, extractor)
    features = extractor(images)
    return features
end

# Compute FID
function compute_fid(real_images, fake_images, extractor)
    # Extract features
    real_features = extract_features(real_images, extractor)
    fake_features = extract_features(fake_images, extractor)

    # Compute statistics
    Î¼_real = mean(real_features, dims=2)
    Î¼_fake = mean(fake_features, dims=2)
    Î£_real = cov(real_features, dims=2)
    Î£_fake = cov(fake_features, dims=2)

    # FID formula
    diff = Î¼_real - Î¼_fake
    covmean = sqrt(Î£_real * Î£_fake)

    fid = sum(diff.^2) + tr(Î£_real + Î£_fake - 2 * covmean)
    return fid
end

# Test on 1000 samples
real_batch = test_data[:, :, :, 1:1000]
fake_batch = ddim_sample_batch(model, ps_trained, st_trained, 1000, á¾±, 50)

fid_score = compute_fid(real_batch, fake_batch, feature_extractor)
println("FID Score: $fid_score")
```

**Inception Score (IS)** ã®å®Ÿè£…:

```julia
# Compute Inception Score
function compute_inception_score(images, classifier)
    # Classify each image
    p_y_given_x = classifier(images)  # Shape: (num_classes, num_samples)

    # Marginal distribution p(y)
    p_y = mean(p_y_given_x, dims=2)

    # KL divergence
    kl_div = sum(p_y_given_x .* (log.(p_y_given_x) .- log.(p_y)), dims=1)

    # Inception Score = exp(E[KL(p(y|x) || p(y))])
    is_score = exp(mean(kl_div))
    return is_score
end

# Use pre-trained MNIST classifier
mnist_classifier = load_mnist_classifier()  # Returns softmax probabilities

is_score = compute_inception_score(fake_batch, mnist_classifier)
println("Inception Score: $is_score")
```

**Expected results** (Tiny DDPM on MNIST after 50 epochs):

| Metric | Value | å‚™è€ƒ |
|:-------|:------|:-----|
| **FID** | 15-25 | Lower is better (Real = 0) |
| **IS** | 8-9 | Higher is better (Max = 10 for MNIST) |
| **Reconstruction MSE** | 0.01-0.03 | Lower is better |

### 5.7 ã‚¹ãƒ†ãƒƒãƒ—æ•° vs å“è³ªã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•

**å®Ÿé¨“**: DDPM ã¨ DDIM ã§ç•°ãªã‚‹ã‚¹ãƒ†ãƒƒãƒ—æ•°ã§ã®ç”Ÿæˆå“è³ªã‚’æ¯”è¼ƒã€‚

```julia
using Plots

# Sample with different step counts
step_counts = [10, 20, 50, 100, 200, 500, 1000]
fid_ddpm = Float64[]
fid_ddim = Float64[]

for steps in step_counts
    # DDPM (use subset of T steps)
    step_indices = round.(Int, range(1, T, length=steps))
    samples_ddpm = ddpm_sample_subset(model, ps_trained, st_trained, x_T, Î², Î±, á¾±, step_indices)
    fid = compute_fid(real_batch, samples_ddpm, feature_extractor)
    push!(fid_ddpm, fid)

    # DDIM
    samples_ddim = ddim_sample(model, ps_trained, st_trained, x_T, á¾±, steps; Î·=0.0)
    fid = compute_fid(real_batch, samples_ddim, feature_extractor)
    push!(fid_ddim, fid)

    println("Steps: $steps, FID (DDPM): $(fid_ddpm[end]), FID (DDIM): $(fid_ddim[end])")
end

# Plot
plot(step_counts, fid_ddpm, label="DDPM", marker=:circle, xscale=:log10, xlabel="Sampling Steps", ylabel="FID (lower is better)", lw=2)
plot!(step_counts, fid_ddim, label="DDIM (Î·=0)", marker=:square, lw=2)
```

**Expected curve**:

```mermaid
graph LR
    A[10 steps: FID ~50] --> B[50 steps: FID ~20]
    B --> C[200 steps: FID ~15]
    C --> D[1000 steps: FID ~12]

    style A fill:#ff9999
    style B fill:#ffcc99
    style C fill:#99ccff
    style D fill:#99ff99
```

**çµè«–**:
- **DDPM**: 1000ã‚¹ãƒ†ãƒƒãƒ—ã§æœ€é«˜å“è³ª
- **DDIM**: 50ã‚¹ãƒ†ãƒƒãƒ—ã§ DDPM 200ã‚¹ãƒ†ãƒƒãƒ—ã¨åŒç­‰
- **é«˜é€Ÿç”Ÿæˆ**: DDIM Î·=0 (deterministic) ãŒæ¨è«–ã‚³ã‚¹ãƒˆæœ€å°

### 5.8 ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å½±éŸ¿å®Ÿé¨“

**å®Ÿé¨“**: Linear vs Cosine vs Zero Terminal SNR ã®3ã¤ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã§è¨“ç·´ãƒ»æ¯”è¼ƒã€‚

```julia
# Define 3 schedules
T = 1000

# Linear
Î²_linear = collect(range(1e-4, 0.02, length=T))
Î±_linear = 1.0 .- Î²_linear
á¾±_linear = cumprod(Î±_linear)

# Cosine
Î²_cosine, Î±_cosine, á¾±_cosine = cosine_schedule(T)

# Zero Terminal SNR
Î²_zt, Î±_zt, á¾±_zt = zero_terminal_snr_schedule(T)

# Train 3 models
ps_linear, st_linear = train_ddpm!(model, ps, st, train_loader, Î²_linear, á¾±_linear, T; epochs=50)
ps_cosine, st_cosine = train_ddpm!(model, ps, st, train_loader, Î²_cosine, á¾±_cosine, T; epochs=50)
ps_zt, st_zt = train_ddpm!(model, ps, st, train_loader, Î²_zt, á¾±_zt, T; epochs=50)

# Compare FID
fid_linear = compute_fid(real_batch, ddim_sample_batch(model, ps_linear, st_linear, 1000, á¾±_linear, 50), feature_extractor)
fid_cosine = compute_fid(real_batch, ddim_sample_batch(model, ps_cosine, st_cosine, 1000, á¾±_cosine, 50), feature_extractor)
fid_zt = compute_fid(real_batch, ddim_sample_batch(model, ps_zt, st_zt, 1000, á¾±_zt, 50), feature_extractor)

println("FID â€” Linear: $fid_linear, Cosine: $fid_cosine, Zero-Terminal: $fid_zt")
```

**Expected results**:

| Schedule | FID | è¨“ç·´å®‰å®šæ€§ | å‚™è€ƒ |
|:---------|:----|:----------|:-----|
| **Linear** | 25-30 | â­â­â­ | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã€‚$\bar{\alpha}_T > 0$ å•é¡Œ |
| **Cosine** | 15-20 | â­â­â­â­ | Improved DDPM [^3] ã§ææ¡ˆã€‚å®‰å®š |
| **Zero Terminal SNR** | 12-18 | â­â­â­â­â­ | è¨“ç·´/æ¨è«–ä¸ä¸€è‡´ã‚’è§£æ¶ˆ [^5] |

**å¯è¦–åŒ–**: SNRæ›²ç·šã‚’æ¯”è¼ƒ:

```julia
snr_linear = á¾±_linear ./ (1 .- á¾±_linear)
snr_cosine = á¾±_cosine ./ (1 .- á¾±_cosine)
snr_zt = á¾±_zt ./ (1 .- á¾±_zt)

plot(1:T, log.(snr_linear), label="Linear", lw=2, xlabel="Timestep t", ylabel="log(SNR)", legend=:topright)
plot!(1:T, log.(snr_cosine), label="Cosine", lw=2)
plot!(1:T, log.(snr_zt), label="Zero Terminal SNR", lw=2)
```

**é‡è¦ãªè¦³å¯Ÿ**:
- **Linear**: log(SNR) ãŒç·šå½¢æ¸›è¡°ã€‚çµ‚ç«¯ã§ SNR > 0 (å•é¡Œ)
- **Cosine**: log(SNR) ãŒç·©ã‚„ã‹ã«æ¸›è¡°ã€‚ä¸­é–“æ™‚åˆ»ã®SNRãŒé«˜ã„
- **Zero Terminal SNR**: log(SNR(T)) = -âˆ (å®Œå…¨ãƒã‚¤ã‚º)

### 5.5 è‡ªå·±è¨ºæ–­ãƒ†ã‚¹ãƒˆ

<details><summary>Q1: Forward Process ã®é–‰å½¢å¼è§£ã‚’å°å‡ºã›ã‚ˆ</summary>

**å•é¡Œ**: $q(\mathbf{x}_t \mid \mathbf{x}_{t-1}) = \mathcal{N}(\sqrt{\alpha_t} \mathbf{x}_{t-1}, (1-\alpha_t) \mathbf{I})$ ã‹ã‚‰ã€$q(\mathbf{x}_t \mid \mathbf{x}_0)$ ã‚’å°å‡ºã›ã‚ˆã€‚

**è§£ç­”**: Section 3.1å‚ç…§ã€‚æ•°å­¦çš„å¸°ç´æ³•ã§è¨¼æ˜ã€‚çµæœ:

$$
q(\mathbf{x}_t \mid \mathbf{x}_0) = \mathcal{N}(\sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1-\bar{\alpha}_t) \mathbf{I})
$$

</details>

<details><summary>Q2: Îµ-prediction ã¨ xâ‚€-prediction ã®å¤‰æ›å¼ã‚’ç¤ºã›</summary>

**å•é¡Œ**: $\mathbf{x}_t = \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t} \boldsymbol{\epsilon}$ ã‹ã‚‰ã€$\mathbf{x}_0$ ã‚’ $\boldsymbol{\epsilon}$ ã§è¡¨ã›ã€‚

**è§£ç­”**:

$$
\mathbf{x}_0 = \frac{\mathbf{x}_t - \sqrt{1-\bar{\alpha}_t} \boldsymbol{\epsilon}}{\sqrt{\bar{\alpha}_t}}
$$

é€†ã« $\boldsymbol{\epsilon}$ ã‚’ $\mathbf{x}_0$ ã§è¡¨ã™ã¨:

$$
\boldsymbol{\epsilon} = \frac{\mathbf{x}_t - \sqrt{\bar{\alpha}_t} \mathbf{x}_0}{\sqrt{1-\bar{\alpha}_t}}
$$

</details>

<details><summary>Q3: DDIM ã®æ±ºå®šè«–æ€§ã‚’èª¬æ˜ã›ã‚ˆ</summary>

**å•é¡Œ**: DDIMãŒæ±ºå®šè«–çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å®Ÿç¾ã™ã‚‹ç†ç”±ã¯ï¼Ÿ

**è§£ç­”**: DDIM ã® $\eta = 0$ è¨­å®š:

$$
\mathbf{x}_{t-1} = \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0 + \sqrt{1-\bar{\alpha}_{t-1}} \boldsymbol{\epsilon}_\theta
$$

ãƒã‚¤ã‚ºé … $\sigma_t \boldsymbol{\epsilon}_t = 0$ â†’ åŒã˜ $\mathbf{x}_T$ ã‹ã‚‰å¸¸ã«åŒã˜ $\mathbf{x}_0$ ãŒç”Ÿæˆã•ã‚Œã‚‹ã€‚

</details>

<details><summary>Q4: VLB ã®3é …ã‚’èª¬æ˜ã›ã‚ˆ</summary>

**å•é¡Œ**: $L_\text{VLB} = L_T + \sum_{t=2}^T L_{t-1} + L_0$ ã®å„é …ã®æ„å‘³ã¯ï¼Ÿ

**è§£ç­”**:

- $L_T = D_\text{KL}(q(\mathbf{x}_T \mid \mathbf{x}_0) \| p(\mathbf{x}_T))$: æœ€çµ‚ãƒã‚¤ã‚ºãŒæ¨™æº–æ­£è¦åˆ†å¸ƒã«è¿‘ã„ã‹
- $L_{t-1} = D_\text{KL}(q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \| p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t))$: Reverse Processã®ç²¾åº¦
- $L_0 = -\log p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1)$: å†æ§‹æˆé …

</details>

<details><summary>Q5: SNRè¦–ç‚¹ã§Noise Scheduleã‚’è©•ä¾¡ã›ã‚ˆ</summary>

**å•é¡Œ**: Linear schedule $\beta_t = 10^{-4} + (t-1)/(T-1) \cdot (0.02 - 10^{-4})$ ã®å•é¡Œç‚¹ã¯ï¼Ÿ

**è§£ç­”**: $\bar{\alpha}_T > 0$ â†’ SNR$(T) > 0$ (Zero Terminal SNR ã‚’æº€ãŸã•ãªã„ [^5])ã€‚è¨“ç·´ã¨æ¨è«–ã®ä¸ä¸€è‡´ãŒç”Ÿã˜ã‚‹ã€‚**è§£æ±ºç­–**: Cosine scheduleã¾ãŸã¯Rescalingã€‚

</details>

> **Note:** **é€²æ—: 85% å®Œäº†** å®Ÿé¨“å®Œäº†ã€‚è‡ªå·±è¨ºæ–­ãƒ†ã‚¹ãƒˆã§ç†è§£ã‚’ç¢ºèªã€‚Zone 6ã§ç™ºå±•ã¸ã€‚

---

> Progress: 85%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. DDPM Juliaå®Ÿè£…ã§ç´¯ç©ç© $\bar{\alpha}_t = \prod_{s=1}^t \alpha_s$ ã‚’æ•°å€¤å®‰å®šã«è¨ˆç®—ã™ã‚‹ãŸã‚logç©ºé–“ã‚’ä½¿ã†ç†ç”±ã¨ã€ãã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿°ã¹ã‚ˆã€‚
> 2. DDIMæ±ºå®šè«–çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆ$\eta=0$ï¼‰ã¨ç¢ºç‡çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆ$\eta=1$ï¼‰ã®é•ã„ã‚’ã‚³ãƒ¼ãƒ‰ã®å¯¾å¿œå¤‰æ•°ã¨æ•°å¼ã§ç¤ºã›ã€‚

## ğŸš€ 6. ç™ºå±•ã‚¾ãƒ¼ãƒ³ï¼ˆ20åˆ†ï¼‰â€” é«˜æ¬¡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° & æœ€æ–°ç ”ç©¶

### 6.1 é«˜æ¬¡ã‚½ãƒ«ãƒãƒ¼æ¦‚è¦ (DPM-Solver++ / UniPC / EDM)

**DDIM** ã¯ Euleræ³• (1æ¬¡)ã€‚**é«˜æ¬¡ã‚½ãƒ«ãƒãƒ¼** ã¯ 2-3æ¬¡ã®ç²¾åº¦ã§ã€ã•ã‚‰ã«é«˜é€ŸåŒ–ã€‚

#### 6.1.1 DPM-Solver++ (Lu+ 2022 [^4])

**å‹•æ©Ÿ**: Diffusion ODE $\frac{d\mathbf{x}}{dt} = f(\mathbf{x}, t)$ ã‚’ **é«˜æ¬¡æ•°å€¤è§£æ³•** ã§è§£ãã€‚

**ã‚¢ã‚¤ãƒ‡ã‚¢**: $\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)$ ã‚’å¤šé …å¼è¿‘ä¼¼ â†’ 2-3æ¬¡ã®ç²¾åº¦ã€‚

$$
\mathbf{x}_{t-\Delta t} = \mathbf{x}_t + \int_t^{t-\Delta t} \left( -\frac{1}{2\sigma_s} \sigma_s' \boldsymbol{\epsilon}_\theta(\mathbf{x}_s, s) \right) ds
$$

**Taylorå±•é–‹** ã§ $\boldsymbol{\epsilon}_\theta$ ã‚’è¿‘ä¼¼:

$$
\boldsymbol{\epsilon}_\theta(\mathbf{x}_s, s) \approx \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) + (s-t) \boldsymbol{\epsilon}_\theta'(\mathbf{x}_t, t)
$$

**çµæœ**: 10-20ã‚¹ãƒ†ãƒƒãƒ—ã§é«˜å“è³ªç”Ÿæˆã€‚

<details><summary>DPM-Solver++ å®Ÿè£… (Julia)</summary>

```julia
# DPM-Solver++ (2nd order)
function dpm_solver_step(model, ps, st, x_t, t, t_prev, á¾±)
    # Predict noise at t
    Îµ_t, _ = model(x_t, t, ps, st)

    # Predict xâ‚€
    xâ‚€_t  = @. (x_t - sqrt(1 - á¾±[t]) * Îµ_t) / sqrt(á¾±[t])

    # Half step
    t_mid  = (t + t_prev) Ã· 2
    x_mid  = @. sqrt(á¾±[t_mid]) * xâ‚€_t + sqrt(1 - á¾±[t_mid]) * Îµ_t

    # Predict noise at t_mid
    Îµ_mid, _ = model(x_mid, t_mid, ps, st)

    # Predict xâ‚€ at t_mid
    xâ‚€_mid = @. (x_mid - sqrt(1 - á¾±[t_mid]) * Îµ_mid) / sqrt(á¾±[t_mid])

    # Final step (using xâ‚€_mid as better estimate)
    x_prev = @. sqrt(á¾±[t_prev]) * xâ‚€_mid + sqrt(1 - á¾±[t_prev]) * Îµ_mid

    return x_prev
end
```

</details>

#### 6.1.2 UniPC (Zhao+ 2023)

**çµ±ä¸€äºˆæ¸¬å™¨-ä¿®æ­£å™¨ (Predictor-Corrector)** ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚

- **Predictor**: é«˜æ¬¡ã§ $\mathbf{x}_{t-1}$ ã‚’äºˆæ¸¬
- **Corrector**: äºˆæ¸¬å€¤ã‚’1å›æ”¹å–„

**æ€§èƒ½**: 5-10ã‚¹ãƒ†ãƒƒãƒ—ã§ DDIM 50ã‚¹ãƒ†ãƒƒãƒ—ã¨åŒç­‰ã€‚

#### 6.1.3 EDM (Karras+ 2022)

**Elucidating the Design Space of Diffusion Models** â€” ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä½“ç³»çš„æœ€é©åŒ–ã€‚

- **Noise Schedule**: Log-SNR ç©ºé–“ã§ uniform sampling
- **Loss Weighting**: $\lambda(t) = \text{SNR}(t) / (1 + \text{SNR}(t))$
- **Preconditioning**: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å‡ºåŠ›ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æœ€é©åŒ–

### 6.2 Improved DDPM (Nichol & Dhariwal 2021 [^3])

**æ”¹å–„ç‚¹**:

1. **å­¦ç¿’åˆ†æ•£ $\sigma_t^2$**: å›ºå®š â†’ å­¦ç¿’å¯èƒ½
2. **Cosine Schedule**: Linear â†’ Cosine
3. **Hybrid Loss**: $L_\text{VLB}$ ã¨ $L_\text{simple}$ ã®çµ„ã¿åˆã‚ã›

$$
L_\text{hybrid} = L_\text{simple} + \lambda L_\text{VLB}
$$

**çµæœ**: ImageNet 256Ã—256 ã§ FIDå¤§å¹…æ”¹å–„ (25.0 â†’ 4.59)ã€‚

### 6.3 Classifier Guidance æ¦‚å¿µ (â†’ å®Œå…¨ç‰ˆã¯ç¬¬39å› LDM)

**å‹•æ©Ÿ**: æ¡ä»¶ä»˜ãç”Ÿæˆ $p(\mathbf{x} \mid y)$ ã‚’å®Ÿç¾ã€‚

**Classifier Guidance** (Dhariwal & Nichol 2021):

$$
\tilde{\boldsymbol{\epsilon}}_\theta = \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) - \sqrt{1-\bar{\alpha}_t} \nabla_{\mathbf{x}_t} \log p_\phi(y \mid \mathbf{x}_t)
$$

ã“ã“ã§ $p_\phi(y \mid \mathbf{x}_t)$ ã¯åˆ¥é€”è¨“ç·´ã—ãŸåˆ†é¡å™¨ã€‚

**å•é¡Œ**: åˆ†é¡å™¨ $p_\phi$ ãŒå¿…è¦ â†’ **Classifier-Free Guidance (CFG)** (ç¬¬39å›) ãŒè§£æ±ºã€‚

**Classifier-Free Guidance** ã®åŸºæœ¬ã‚¢ã‚¤ãƒ‡ã‚¢:

$$
\tilde{\boldsymbol{\epsilon}}_\theta = (1 + w) \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, y) - w \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \emptyset)
$$

ã“ã“ã§ $w$ ã¯ guidance scaleã€$\emptyset$ ã¯æ¡ä»¶ãªã— (unconditional)ã€‚

**å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ**:
- è¨“ç·´æ™‚ã« $p = 0.1$ ã®ç¢ºç‡ã§æ¡ä»¶ $y$ ã‚’ãƒ‰ãƒ­ãƒƒãƒ— (ç„¡æ¡ä»¶è¨“ç·´)
- æ¨è«–æ™‚ã«æ¡ä»¶ä»˜ããƒ»ç„¡æ¡ä»¶ã®2å›æ¨è«–ã—ã¦ç·šå½¢çµåˆ

```julia
# Classifier-Free Guidance in DDIM
function ddim_step_cfg(model, ps, st, x_t, t, t_prev, á¾±, y, w; Î·=0.0)
    # Conditional prediction
    Îµ_cond, _ = model(x_t, t, y, ps, st)

    # Unconditional prediction (y = nothing)
    Îµ_uncond, _ = model(x_t, t, nothing, ps, st)

    # CFG formula
    Îµ_guided = @. (1 + w) * Îµ_cond - w * Îµ_uncond

    # DDIM step with guided Îµ
    á¾±_t    = á¾±[t]
    á¾±_prev = (t_prev > 0) ? á¾±[t_prev] : 1.0

    xâ‚€_pred = @. (x_t - sqrt(1 - á¾±_t) * Îµ_guided) / sqrt(á¾±_t)
    Ïƒ_t     = Î· * sqrt((1 - á¾±_prev) / (1 - á¾±_t)) * sqrt(1 - á¾±_t / á¾±_prev)
    dir_xt  = @. sqrt(1 - á¾±_prev - Ïƒ_t^2) * Îµ_guided

    x_prev  = @. sqrt(á¾±_prev) * xâ‚€_pred + dir_xt
    return x_prev
end
```

**åŠ¹æœ**: $w = 7.5$ ã§ FID æ”¹å–„ & æ¡ä»¶ä¸€è‡´åº¦å‘ä¸Š (CLIP score â†‘)ã€‚

### 6.4 ç¢ºç‡ãƒ•ãƒ­ãƒ¼ODE & ã‚¹ã‚³ã‚¢ãƒãƒƒãƒãƒ³ã‚°ã®å†è§£é‡ˆ

**DDPMã¨ã‚¹ã‚³ã‚¢ãƒãƒƒãƒãƒ³ã‚°ã®ç­‰ä¾¡æ€§** (Song+ 2020):

DDPM ã® Reverse Process ã¯ **Score-based Generative Model** ã¨åŒå€¤:

$$
\frac{d\mathbf{x}}{dt} = -\frac{1}{2} \beta(t) \left( \mathbf{x} + 2 \nabla_{\mathbf{x}} \log p_t(\mathbf{x}) \right)
$$

ã“ã“ã§ $\nabla_{\mathbf{x}} \log p_t(\mathbf{x})$ ã¯ **ã‚¹ã‚³ã‚¢é–¢æ•°**ã€‚

**DDPMã¨ã®å¯¾å¿œ**:

$$
\nabla_{\mathbf{x}} \log p_t(\mathbf{x}_t) \approx -\frac{\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)}{\sqrt{1-\bar{\alpha}_t}}
$$

ã“ã‚Œã«ã‚ˆã‚Š:
- **DDPM**: é›¢æ•£æ™‚é–“ã®ç¢ºç‡éç¨‹
- **Score-based**: é€£ç¶šæ™‚é–“ã®ODE/SDE

ã¯æ•°å­¦çš„ã«åŒã˜å¯¾è±¡ã‚’ç•°ãªã‚‹è¦–ç‚¹ã§è¨˜è¿°ã—ã¦ã„ã‚‹ã€‚

**Probability Flow ODE** (Song+ 2020):

DDIMã®æ¥µé™ ($\eta = 0$) ã¯æ¬¡ã®ODEã¨ç­‰ä¾¡:

$$
\frac{d\mathbf{x}}{dt} = -\frac{1}{2} \sigma(t)^2 \nabla_{\mathbf{x}} \log p_t(\mathbf{x})
$$

ã“ã®ODEã‚’æ•°å€¤çš„ã«è§£ã = DDIMã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€‚

**Stochastic Differential Equation (SDE)** ç‰ˆ (ç¬¬37å›ã§è©³èª¬):

DDPMã®ç¢ºç‡çš„ç‰ˆã¯æ¬¡ã®SDEã§è¨˜è¿°:

$$
d\mathbf{x} = -\frac{1}{2} \beta(t) \mathbf{x} \, dt + \sqrt{\beta(t)} \, d\mathbf{w}
$$

ã“ã“ã§ $d\mathbf{w}$ ã¯ãƒ–ãƒ©ã‚¦ãƒ³é‹å‹•ã€‚

**å®Ÿè£… â€” ODE Solver with DifferentialEquations.jl**:

```julia
using DifferentialEquations

# Define ODE
function probability_flow_ode!(du, u, p, t)
    model, ps, st, á¾± = p
    x_t = u

    # Predict noise
    Îµ_Î¸, _ = model(x_t, t, ps, st)

    # Score function: âˆ‡log p(x) â‰ˆ -Îµ / sqrt(1 - á¾±)
    score = -Îµ_Î¸ / sqrt(1 - á¾±[t])

    # ODE: dx/dt = -0.5 * ÏƒÂ² * score
    ÏƒÂ² = (1 - á¾±[t]) / á¾±[t]
    du .= -0.5 * ÏƒÂ² * score
end

# Solve ODE from T â†’ 0
u0 = randn(Float32, 28, 28, 1, 1)  # x_T
tspan = (T, 0)
prob = ODEProblem(probability_flow_ode!, u0, tspan, (model, ps_trained, st_trained, á¾±))
sol = solve(prob, Tsit5(), reltol=1e-3, abstol=1e-3)

# Final sample
x_0 = sol.u[end]
```

**åˆ©ç‚¹**:
- é«˜ç²¾åº¦ãªæ•°å€¤è§£æ³• (Runge-Kutta, Adams, BDF) ãŒä½¿ãˆã‚‹
- Adaptive step size ã§åŠ¹ç‡çš„
- ç†è«–çš„ä¿è¨¼ (ODEã‚½ãƒ«ãƒãƒ¼ã®åæŸæ€§)

### 6.5 æ¡ä»¶ä»˜ãç”Ÿæˆã®ç™ºå±•å½¢æ…‹

**Inpainting (é ˜åŸŸä¿®å¾©)**:

DDPMã§ç”»åƒã®ä¸€éƒ¨ã‚’ä¿®å¾©:

```julia
# Inpainting with DDPM
function ddpm_inpaint(model, ps, st, x_T, mask, known_region, Î², Î±, á¾±, T)
    x_t = x_T

    for t in T:-1:1
        # Predict noise
        Îµ_pred, _ = model(x_t, t, ps, st)

        # DDPM reverse step
        Î¼  = @. (x_t - (1 - Î±[t]) / sqrt(1 - á¾±[t]) * Îµ_pred) / sqrt(Î±[t])
        Ïƒ  = sqrt((1 - á¾±[t-1]) / (1 - á¾±[t]) * (1 - Î±[t]))
        z  = (t > 1) ? randn(Float32, size(x_t)) : zero(x_t)

        # Replace known region (preserve known pixels)
        x_t = @. mask * (Î¼ + Ïƒ * z) + (1 - mask) * known_region
    end

    return x_t
end

# Example: Inpaint center 14Ã—14 region
mask = ones(Float32, 28, 28, 1, 1)
mask[8:21, 8:21, :, :] .= 0.0  # Mask out center
known_region = test_data[:, :, :, 1:1]

inpainted = ddpm_inpaint(model, ps_trained, st_trained, x_T, mask, known_region, Î², Î±, á¾±, T)
```

**Super-resolution (è¶…è§£åƒ)**:

ä½è§£åƒåº¦ç”»åƒã‹ã‚‰é«˜è§£åƒåº¦ã‚’ç”Ÿæˆ:

```julia
# SR-DDPM: Sample high-res conditioned on low-res
function ddpm_super_resolution(model, ps, st, x_T, x_low_res, Î², Î±, á¾±, T)
    x_t = x_T

    for t in T:-1:1
        # Concatenate low-res as condition
        x_input = cat(x_t, x_low_res, dims=3)  # Concat along channel

        # Predict noise
        Îµ_pred, _ = model(x_input, t, ps, st)

        # DDPM step
        Î¼ = @. (x_t - (1 - Î±[t]) / sqrt(1 - á¾±[t]) * Îµ_pred) / sqrt(Î±[t])
        Ïƒ = sqrt((1 - á¾±[t-1]) / (1 - á¾±[t]) * (1 - Î±[t]))
        z = (t > 1) ? randn(Float32, size(x_t)) : zero(x_t)
        x_t = @. Î¼ + Ïƒ * z
    end

    return x_t
end

# Upscale 14Ã—14 â†’ 28Ã—28
x_low = imresize(test_data[:, :, :, 1:1], (14, 14))
x_high = ddpm_super_resolution(model, ps_trained, st_trained, x_T, x_low, Î², Î±, á¾±, T)
```

**Text-to-Image (æ¦‚å¿µ, å®Œå…¨ç‰ˆã¯ç¬¬39å›)**:

ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ (CLIP/T5) â†’ åŸ‹ã‚è¾¼ã¿ â†’ U-Netã«æ³¨å…¥:

```julia
# Text-to-Image U-Net (conceptual)
struct TextConditionedUNet
    text_encoder::Dense  # Text â†’ embedding
    cross_attention::MultiHeadAttention  # Cross-attend to text
    base_unet::TinyUNet
end

function (m::TextConditionedUNet)(x_t, t, text_emb, ps, st)
    # Encode text
    text_feat = m.text_encoder(text_emb)

    # Cross-attention: x_t attends to text_feat
    x_attended = m.cross_attention(x_t, text_feat)

    # Base U-Net
    Îµ_pred = m.base_unet(x_attended, t, ps, st)

    return Îµ_pred, st
end
```

### 6.6 Production-Ready å®Ÿè£…ã®è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³

**ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼è¨­è¨ˆ** â€” Model / Scheduler / Sampler ã®åˆ†é›¢:

```julia
# Abstract interfaces
abstract type NoiseScheduler end
abstract type Sampler end

# Concrete schedulers
struct CosineScheduler <: NoiseScheduler
    T::Int
    Î²::Vector{Float32}
    Î±::Vector{Float32}
    á¾±::Vector{Float32}
end

function CosineScheduler(T::Int)
    Î², Î±, á¾± = cosine_schedule(T)
    return CosineScheduler(T, Î², Î±, á¾±)
end

struct ZeroTerminalSNRScheduler <: NoiseScheduler
    T::Int
    Î²::Vector{Float32}
    Î±::Vector{Float32}
    á¾±::Vector{Float32}
end

function ZeroTerminalSNRScheduler(T::Int)
    Î², Î±, á¾± = zero_terminal_snr_schedule(T)
    return ZeroTerminalSNRScheduler(T, Î², Î±, á¾±)
end

# Samplers
struct DDPMSampler <: Sampler
    scheduler::NoiseScheduler
end

struct DDIMSampler <: Sampler
    scheduler::NoiseScheduler
    Î·::Float64
end

struct DPMSolverPPSampler <: Sampler
    scheduler::NoiseScheduler
    order::Int  # 2 or 3
end

# Generic sample interface
function sample(sampler::Sampler, model, ps, st, x_T, steps::Int)
    # Dispatch to specific sampler
    return _sample_impl(sampler, model, ps, st, x_T, steps)
end

# Implementations
function _sample_impl(sampler::DDPMSampler, model, ps, st, x_T, steps::Int)
    return ddpm_sample(model, ps, st, x_T, sampler.scheduler.Î², sampler.scheduler.Î±, sampler.scheduler.á¾±, sampler.scheduler.T)
end

function _sample_impl(sampler::DDIMSampler, model, ps, st, x_T, steps::Int)
    return ddim_sample(model, ps, st, x_T, sampler.scheduler.á¾±, steps; Î·=sampler.Î·)
end

function _sample_impl(sampler::DPMSolverPPSampler, model, ps, st, x_T, steps::Int)
    return dpm_solver_pp_sample(model, ps, st, x_T, sampler.scheduler.á¾±, steps, sampler.order)
end
```

**ä½¿ç”¨ä¾‹**:

```julia
# Create scheduler
scheduler = CosineScheduler(1000)

# Create sampler
sampler_ddim = DDIMSampler(scheduler, 0.0)
sampler_dpm = DPMSolverPPSampler(scheduler, 2)

# Sample
x_T = randn(Float32, 28, 28, 1, 16)
samples_ddim = sample(sampler_ddim, model, ps_trained, st_trained, x_T, 50)
samples_dpm = sample(sampler_dpm, model, ps_trained, st_trained, x_T, 20)
```

**åˆ©ç‚¹**:
- ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã¨ã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã‚’è‡ªç”±ã«çµ„ã¿åˆã‚ã›
- æ–°ã—ã„ã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã‚’è¿½åŠ ã—ã¦ã‚‚æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã«å½±éŸ¿ãªã—
- ãƒ†ã‚¹ãƒˆãƒ»æ¯”è¼ƒãŒå®¹æ˜“

### 6.7 Rust Production Inference ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

**ONNX Export from Julia**:

```julia
using ONNX

# Export trained model to ONNX
function export_to_onnx(model, ps, st, filepath)
    # Create dummy input
    x_dummy = randn(Float32, 28, 28, 1, 1)
    t_dummy = 500

    # Trace model
    traced = Lux.@trace model(x_dummy, t_dummy, ps, st)

    # Export
    ONNX.export(traced, filepath)
    println("Model exported to $filepath")
end

export_to_onnx(model, ps_trained, st_trained, "tiny_ddpm.onnx")
```

**Rust Inference with ort (ONNX Runtime)**:

```rust
use ort::{Environment, SessionBuilder, Value};
use ndarray::{Array4, s};

pub struct DDPMInference {
    session: ort::Session,
    alpha_bar: Vec<f32>,
}

impl DDPMInference {
    pub fn new(model_path: &str, alpha_bar: Vec<f32>) -> Result<Self, Box<dyn std::error::Error>> {
        let environment = Environment::builder().build()?;
        let session = SessionBuilder::new(&environment)?
            .with_model_from_file(model_path)?;

        Ok(Self { session, alpha_bar })
    }

    pub fn predict_noise(&self, x_t: &Array4<f32>, t: usize) -> Result<Array4<f32>, Box<dyn std::error::Error>> {
        // Prepare input
        let x_input = Value::from_array(self.session.allocator(), x_t)?;
        let t_input = Value::from_array(self.session.allocator(), &ndarray::arr1(&[t as f32]))?;

        // Run inference
        let outputs = self.session.run(vec![x_input, t_input])?;
        let epsilon = outputs[0].try_extract::<f32>()?.view().to_owned();

        Ok(epsilon.into_dimensionality::<ndarray::Ix4>()?)
    }

    pub fn ddim_sample(&self, x_t: Array4<f32>, steps: usize, Î·: f32) -> Result<Array4<f32>, Box<dyn std::error::Error>> {
        let mut x = x_t;
        let T = self.alpha_bar.len();
        let step_indices: Vec<usize> = (0..steps).map(|i| T * i / steps).collect();

        for i in (1..step_indices.len()).rev() {
            let (t, t_prev) = (step_indices[i], step_indices[i - 1]);

            // Predict noise
            let Îµ = self.predict_noise(&x, t)?;

            // DDIM step
            let á¾±_t    = self.alpha_bar[t];
            let á¾±_prev = self.alpha_bar[t_prev];

            let x_0_pred = (&x - (1.0 - á¾±_t).sqrt() * &Îµ) / á¾±_t.sqrt();
            let Ïƒ_t = Î· * ((1.0 - á¾±_prev) / (1.0 - á¾±_t)).sqrt()
                         * (1.0 - á¾±_t / á¾±_prev).sqrt();
            let dir_xt = (1.0 - á¾±_prev - Ïƒ_t.powi(2)).sqrt() * &Îµ;

            x = á¾±_prev.sqrt() * x_0_pred + dir_xt;
        }

        Ok(x)
    }
}

// Usage
fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Load alpha_bar from file
    let alpha_bar: Vec<f32> = load_alpha_bar_from_file("alpha_bar.bin")?;

    // Create inference engine
    let ddpm = DDPMInference::new("tiny_ddpm.onnx", alpha_bar)?;

    // Sample
    let x_t = Array4::<f32>::from_shape_fn((1, 1, 28, 28), |_| rand::random::<f32>());
    let x_0 = ddpm.ddim_sample(x_t, 50, 0.0)?;
    println!("Generated sample shape: {:?}", x_0.shape());
    Ok(())
}
```

**Benchmark** (M1 Mac, MNIST 28Ã—28, 50 steps):

| Implementation | Latency | Throughput (samples/sec) |
|:---------------|:--------|:-------------------------|
| Julia Lux.jl (CPU) | 2.3s | 0.43 |
| Rust ONNX (CPU) | 0.8s | 1.25 |
| Rust ONNX (CoreML) | 0.3s | 3.33 |

**Production deployment architecture**:

```mermaid
graph LR
    A[Julia Training] --> B[ONNX Export]
    B --> C[Rust Inference Server]
    C --> D[gRPC API]
    D --> E[Client Apps]

    C --> F[ONNX Runtime]
    F --> G[CPU/GPU/CoreML]

    style A fill:#99ccff
    style C fill:#ff9999
    style G fill:#99ff99
```

### 6.8 æœ€æ–°ç ”ç©¶å‹•å‘ (2024-2026)

| ç ”ç©¶ | ä¸»å¼µ | è«–æ–‡ |
|:-----|:-----|:-----|
| **DDPMæœ€é©åæŸãƒ¬ãƒ¼ãƒˆ** | TVè·é›¢ $O(d/T)$ åæŸè¨¼æ˜ã€ã‚¹ãƒ†ãƒƒãƒ—æ•°ã®ä¸‹ç•Œ | [arXiv:2510.27562](https://arxiv.org/abs/2510.27562) (2025H2) |
| **DDPM Score Matchingæ¼¸è¿‘åŠ¹ç‡æ€§** | DDPMã‚¹ã‚³ã‚¢æ¨å®šãŒçµ±è¨ˆçš„ã«æœ€é©ã€ç†è«–çš„æ­£å½“åŒ– | [arXiv:2504.05161](https://arxiv.org/abs/2504.05161) (ICLR 2025) |
| **Zero Terminal SNR** | è¨“ç·´/æ¨è«–ã®ä¸ä¸€è‡´ã‚’è§£æ¶ˆ | [arXiv:2305.08891](https://arxiv.org/abs/2305.08891) (Lin+ 2023) |
| **Consistency Models** | 1ã‚¹ãƒ†ãƒƒãƒ—ç”Ÿæˆã§å“è³ªç¶­æŒ | [arXiv:2303.01469](https://arxiv.org/abs/2303.01469) (Song+ 2023) |
| **Flow Matching** | ODEãƒ™ãƒ¼ã‚¹ã®æ–°ã—ã„å®šå¼åŒ– | [arXiv:2210.02747](https://arxiv.org/abs/2210.02747) (Lipman+ 2022) |

> **Note:** **é€²æ—: 95% å®Œäº†** é«˜æ¬¡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ»Improved DDPMãƒ»Guidanceã‚’æ¦‚è¦³ã€‚Zone 7ã§ç·æ‹¬ã¸ã€‚

---

> Progress: 95%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. DDPMã®æœ€é©åæŸãƒ¬ãƒ¼ãƒˆ $O(d/T)$ï¼ˆarXiv:2510.27562ï¼‰ã«ãŠã„ã¦ $d$ ãŒæŒ‡ã™é‡ã¨ã€åæŸã‚’ä¿è¨¼ã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—æ•° $T$ ã®é¸ã³æ–¹ã®æŒ‡é‡ã‚’è¿°ã¹ã‚ˆã€‚
> 2. Cosineã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒ Linearã‚ˆã‚Šé«˜SNRé ˜åŸŸã§æœ‰åˆ©ã§ã€ä½SNRé ˜åŸŸã§å·®ãŒç¸®ã¾ã‚‹ç†ç”±ã‚’ $\bar{\alpha}_t$ ã®ã‚°ãƒ©ãƒ•ã®å½¢çŠ¶ã¨å¯¾å¿œã•ã›ã¦èª¬æ˜ã›ã‚ˆã€‚

## ğŸ“ 6. æŒ¯ã‚Šè¿”ã‚Š + çµ±åˆã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” ã¾ã¨ã‚ & æ¬¡å›äºˆå‘Š

### 7.1 æœ¬è¬›ç¾©ã®åˆ°é”ç‚¹

**3ã¤ã®æ ¸å¿ƒ**:

1. **Forward/Reverse Process ã®å®Œå…¨å°å‡º**: é–‰å½¢å¼è§£ (æ•°å­¦çš„å¸°ç´æ³•)ã€ãƒ™ã‚¤ã‚ºåè»¢ (æ¡ä»¶ä»˜ãã‚¬ã‚¦ã‚¹)
2. **VLB ã¨ç°¡ç´ åŒ–æå¤±**: $L_T + \sum L_t + L_0$ ã®å®Œå…¨å±•é–‹ã€$L_\text{simple}$ ãŒå„ªã‚Œã‚‹ç†ç”±
3. **DDIMæ±ºå®šè«–çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°**: Non-Markovian forwardã€Probability Flow ODE ã¨ã®æ¥ç¶š

**é‡è¦ãªå¼**:

$$
\begin{aligned}
\text{Forward:} \quad & q(\mathbf{x}_t \mid \mathbf{x}_0) = \mathcal{N}(\sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1-\bar{\alpha}_t) \mathbf{I}) \\
\text{Reverse:} \quad & p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t) = \mathcal{N}(\boldsymbol{\mu}_\theta(\mathbf{x}_t, t), \sigma_t^2 \mathbf{I}) \\
\text{Loss:} \quad & L_\text{simple} = \mathbb{E}_{t, \mathbf{x}_0, \boldsymbol{\epsilon}} [\|\boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\|^2] \\
\text{DDIM:} \quad & \mathbf{x}_{t-1} = \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0 + \sqrt{1-\bar{\alpha}_{t-1}} \boldsymbol{\epsilon}_\theta
\end{aligned}
$$

**å®Ÿè£…**: âš¡ Juliaè¨“ç·´ (Lux.jl + Zygote) + ğŸ¦€ Rustæ¨è«– (ONNX Runtime) ã§ Production-readyã€‚

### 7.2 FAQ

<details><summary>Q1: DDPMã¨Score Matchingã®é•ã„ã¯ï¼Ÿ</summary>

**A**: **æœ¬è³ªçš„ã«åŒã˜** (Section 3.10)ã€‚DDPMã¯é›¢æ•£æ™‚åˆ»ã€Score Matchingã¯é€£ç¶šæ™‚åˆ»ã€‚æ•°å¼:

$$
\nabla_{\mathbf{x}_t} \log q(\mathbf{x}_t \mid \mathbf{x}_0) = - \frac{\boldsymbol{\epsilon}}{\sqrt{1-\bar{\alpha}_t}}
$$

ãƒã‚¤ã‚ºäºˆæ¸¬ = ã‚¹ã‚³ã‚¢äºˆæ¸¬ (rescaled)ã€‚

</details>

<details><summary>Q2: ãªãœ $L_\text{simple}$ ãŒ $L_\text{VLB}$ ã‚ˆã‚Šå„ªã‚Œã‚‹ï¼Ÿ</summary>

**A**: $L_\text{VLB}$ ã®é‡ã¿ $\frac{\beta_t^2}{2\sigma_t^2 \alpha_t (1-\bar{\alpha}_t)}$ ã¯ã€ä½ãƒã‚¤ã‚ºé ˜åŸŸã‚’éé‡è¦– â†’ çŸ¥è¦šå“è³ªä½ä¸‹ã€‚$L_\text{simple}$ ã¯å…¨æ™‚åˆ»ã‚’å‡ç­‰ã«å­¦ç¿’ â†’ FIDæ”¹å–„ã€‚

</details>

<details><summary>Q3: DDIM ã® $\eta$ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ„å‘³ã¯ï¼Ÿ</summary>

**A**: $\eta = 0$: æ±ºå®šè«–çš„ (åŒã˜ $\mathbf{x}_T$ â†’ åŒã˜ $\mathbf{x}_0$)ã€‚$\eta = 1$: DDPMé¢¨ (ç¢ºç‡çš„)ã€‚ä¸­é–“å€¤ã§åˆ¶å¾¡å¯èƒ½ã€‚

</details>

<details><summary>Q4: Cosine schedule vs Linear schedule ã®é•ã„ã¯ï¼Ÿ</summary>

**A**: **Cosine** (æ¨å¥¨): SNRç·©ã‚„ã‹ã«æ¸›å°‘ã€è¨“ç·´å®‰å®šã€Zero Terminal SNRã«è¿‘ã„ã€‚**Linear**: å¤ã„ã€$\bar{\alpha}_T > 0$ ã§è¨“ç·´/æ¨è«–ä¸ä¸€è‡´ã€‚

</details>

<details><summary>Q5: U-Net ã® Self-Attention ã¯ã©ã“ã«é…ç½®ï¼Ÿ</summary>

**A**: **16Ã—16ä»¥ä¸‹ã®ä½è§£åƒåº¦** ã§ã®ã¿ã€‚è¨ˆç®—é‡ $O(N^2)$ ã®ãŸã‚ã€é«˜è§£åƒåº¦ã§ã¯çœç•¥ã€‚MNISTã§ã¯28Ã—28ãªã®ã§ã€1å±¤ã®ã¿ã§ååˆ†ã€‚

</details>

### 7.3 å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« (1é€±é–“ãƒ—ãƒ©ãƒ³)

| æ—¥ | å†…å®¹ | æ™‚é–“ |
|:---|:-----|:-----|
| 1 | Zone 0-2 (ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ â†’ ç›´æ„Ÿ) | 30åˆ† |
| 2 | Zone 3.1-3.4 (Forward â†’ VLB) | 60åˆ† |
| 3 | Zone 3.5-3.7 (3å½¢æ…‹ â†’ SNR) | 45åˆ† |
| 4 | Zone 3.8-3.10 (U-Net â†’ Score) | 60åˆ† |
| 5 | Zone 4 (Juliaå®Ÿè£…) | 90åˆ† |
| 6 | Zone 5 (å®Ÿé¨“ + è‡ªå·±è¨ºæ–­) | 60åˆ† |
| 7 | Zone 6-7 (ç™ºå±• + æŒ¯ã‚Šè¿”ã‚Š) | 45åˆ† |

### 7.4 æ¬¡å›äºˆå‘Š: ç¬¬37å› SDE/ODE & ç¢ºç‡éç¨‹è«–

**DDPM (é›¢æ•£)** ã‚’ **SDE (é€£ç¶šæ™‚é–“)** ã«æ‹¡å¼µã™ã‚‹ã€‚

**äºˆå‘Šå†…å®¹**:

- **VP-SDE / VE-SDE / Sub-VP SDE**: DDPMã¨NCSNã®SDEçµ±ä¸€
- **Reverse-time SDE** (Anderson 1982): é€†æ™‚é–“æ‹¡æ•£ã®å­˜åœ¨å®šç†
- **Probability Flow ODE**: åŒä¸€å‘¨è¾ºåˆ†å¸ƒã‚’æŒã¤æ±ºå®šè«–çš„éç¨‹
- **Score SDEçµ±ä¸€ç†è«–** (Song+ 2021): Forwardâ†’Reverseâ†’Scoreâ†’ODE
- **åæŸæ€§è§£æ**: TVè·é›¢ $O(d/T)$ åæŸã€Manifoldä»®èª¬ä¸‹ã®ç·šå½¢åæŸ

**Course I ç¬¬5å›ã¨ã®é–¢ä¿‚**: ç¬¬5å›ã§ä¼Šè—¤ç©åˆ†ãƒ»ä¼Šè—¤ã®è£œé¡Œãƒ»SDEåŸºç¤ã‚’å°å…¥æ¸ˆã¿ã€‚ç¬¬37å›ã¯ã“ã‚Œã‚’**Diffusionå›ºæœ‰ã®SDE (VP/VE/Reverse/PF-ODE)** ã«ç‰¹åŒ–ã€‚

**æ¥ç¶š**: DDPMé›¢æ•£ â†’ SDEé€£ç¶š â†’ Flow Matchingçµ±ä¸€ (ç¬¬38å›)ã€‚

> **Note:** **é€²æ—: 100% å®Œäº†** ğŸ† ç¬¬36å›å®Œäº†ï¼DDPMç†è«–ãƒ»å®Ÿè£…ãƒ»å®Ÿé¨“ã‚’å®Œå…¨ãƒã‚¹ã‚¿ãƒ¼ã€‚ç¬¬37å›ã§SDEé€£ç¶šæ™‚é–“ã¸ã€‚

---

### 6.X ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„

**"1000ã‚¹ãƒ†ãƒƒãƒ—"ã¯ç†è«–ç†è§£ã®ä¸è¶³ã§ã¯ï¼Ÿ**

DDPM [^1] (2020) ã¯1000ã‚¹ãƒ†ãƒƒãƒ—ã€‚ã ãŒ2021å¹´ã®DDIM [^2] ã§50ã‚¹ãƒ†ãƒƒãƒ—ã€2022å¹´ã®DPM-Solver++ [^4] ã§10-20ã‚¹ãƒ†ãƒƒãƒ—ã€2023å¹´ã®Consistency Models (ç¬¬40å›) ã§1ã‚¹ãƒ†ãƒƒãƒ—ã€‚

**å•ã„**:

1. ãªãœDDPMã¯1000ã‚¹ãƒ†ãƒƒãƒ—å¿…è¦ã ã£ãŸã®ã‹ï¼Ÿ â†’ **ãƒãƒ«ã‚³ãƒ•ä»®å®š** + **å›ºå®šã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«** ã®åˆ¶ç´„
2. DDIMã®æœ¬è³ªã¯ä½•ã‹ï¼Ÿ â†’ **Non-Markovian** ã§è‡ªç”±åº¦ç²å¾— + **Probability Flow ODE** è¿‘ä¼¼
3. 1ã‚¹ãƒ†ãƒƒãƒ—ç”Ÿæˆã®ç†è«–çš„é™ç•Œã¯ï¼Ÿ â†’ **è’¸ç•™** vs **Flow Matching** vs **Consistency** (ç¬¬40å›ã§è¨¼æ˜)

**æŒ‘ç™ºçš„ä»®èª¬**: "1000ã‚¹ãƒ†ãƒƒãƒ—" ã¯å®Ÿè£…ã®ä¾¿å®œã€‚**ç†è«–çš„ã«ã¯10-50ã‚¹ãƒ†ãƒƒãƒ—ã§ååˆ†** (DDIM/DPM-Solver++)ã€**æœ€çµ‚çš„ã«ã¯1ã‚¹ãƒ†ãƒƒãƒ—ãŒå¯èƒ½** (Consistency Models)ã€‚ã‚¹ãƒ†ãƒƒãƒ—æ•°å‰Šæ¸›ã®æ­´å²ã¯ã€**ç†è«–ã®æ´—ç·´ã®æ­´å²** ã§ã‚ã‚‹ã€‚

**ã‚ãªãŸã¯ã©ã†è€ƒãˆã‚‹ã‹ï¼Ÿ**

---

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: Ho, J., Jain, A., & Abbeel, P. (2020). Denoising Diffusion Probabilistic Models. *NeurIPS 2020*. [arXiv:2006.11239](https://arxiv.org/abs/2006.11239)

<https://arxiv.org/abs/2006.11239>

[^2]: Song, J., Meng, C., & Ermon, S. (2020). Denoising Diffusion Implicit Models. *ICLR 2021*. [arXiv:2010.02502](https://arxiv.org/abs/2010.02502)

<https://arxiv.org/abs/2010.02502>

[^3]: Nichol, A., & Dhariwal, P. (2021). Improved Denoising Diffusion Probabilistic Models. *ICML 2021*. [arXiv:2102.09672](https://arxiv.org/abs/2102.09672)

<https://arxiv.org/abs/2102.09672>

[^4]: Lu, C., Zhou, Y., Bao, F., Chen, J., Li, C., & Zhu, J. (2022). DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models. *NeurIPS 2022*. [arXiv:2211.01095](https://arxiv.org/abs/2211.01095)

<https://arxiv.org/abs/2211.01095>

[^5]: Lin, S., Liu, B., Li, J., & Yang, X. (2023). Common Diffusion Noise Schedules and Sample Steps are Flawed. *WACV 2024*. [arXiv:2305.08891](https://arxiv.org/abs/2305.08891)

<https://arxiv.org/abs/2305.08891>

[^6]: Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., & Poole, B. (2020). Score-Based Generative Modeling through Stochastic Differential Equations. *ICLR 2021*. [arXiv:2011.13456](https://arxiv.org/abs/2011.13456)

<https://arxiv.org/abs/2011.13456>

### æ•™ç§‘æ›¸

- Karras, T., Aittala, M., Aila, T., & Laine, S. (2022). Elucidating the Design Space of Diffusion-Based Generative Models. *NeurIPS 2022*. [arXiv:2206.00364](https://arxiv.org/abs/2206.00364)
- Yang, L., Zhang, Z., Song, Y., Hong, S., Xu, R., Zhao, Y., ... & Cui, B. (2023). Diffusion Models: A Comprehensive Survey of Methods and Applications. *ACM Computing Surveys*. [arXiv:2209.00796](https://arxiv.org/abs/2209.00796)

---

## è‘—è€…ãƒªãƒ³ã‚¯

- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
