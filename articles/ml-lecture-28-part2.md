---
title: "ç¬¬28å›: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
slug: "ml-lecture-28-part2"
emoji: "ğŸ’¬"
type: "tech"
topics: ["machinelearning", "prompt", "rust", "rust", "llm"]
published: true
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Rust", "Elixir"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---

> **ç¬¬28å›ã€å‰ç·¨ã€‘**: [ç¬¬28å›ã€å‰ç·¨ã€‘](https://zenn.dev/fumishiki/ml-lecture-28-part1)

---
title: "ç¬¬28å›: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
slug: "ml-lecture-28-part2"
emoji: "ğŸ’¬"
type: "tech"
topics: ["machinelearning", "prompt", "rust", "julia", "llm"]
published: true
---

## ğŸ’» Z5. è©¦ç·´ï¼ˆå®Ÿè£…ï¼‰ï¼ˆ45åˆ†ï¼‰â€” Template Engine + Rustå®Ÿé¨“

**ã‚´ãƒ¼ãƒ«**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‹å®‰å…¨ã«ç®¡ç†ã™ã‚‹ğŸ¦€ Rust Template Engineã¨ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåŠ¹æœã‚’å®šé‡æ¸¬å®šã™ã‚‹ğŸ¦€ Rustå®Ÿé¨“ç’°å¢ƒã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

### 4.1 ãªãœTemplate EngineãŒå¿…è¦ãªã®ã‹ï¼Ÿ

Productionç’°å¢ƒã§ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã«ã¯ã€æ¬¡ã®èª²é¡ŒãŒã‚ã‚‹:

| èª²é¡Œ | ä¾‹ | ãƒªã‚¹ã‚¯ |
|:-----|:---|:------|
| **æ–‡å­—åˆ—çµåˆã®è„†å¼±æ€§** | `"Translate: " + user_input` | ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³æ”»æ’ƒ |
| **å‹å®‰å…¨æ€§ã®æ¬ å¦‚** | å¤‰æ•°åã‚¿ã‚¤ãƒã€å‹ãƒŸã‚¹ãƒãƒƒãƒ | å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼ |
| **ãƒ†ã‚¹ãƒˆå›°é›£** | ãƒ™ã‚¿æ›¸ãæ–‡å­—åˆ— | å¤‰æ›´ãŒå£Šã‚Œã‚„ã™ã„ |
| **ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†å›°é›£** | ã‚³ãƒ¼ãƒ‰ã«åŸ‹ã‚è¾¼ã¿ | A/Bãƒ†ã‚¹ãƒˆä¸å¯ |
| **å¤šè¨€èªå¯¾å¿œå›°é›£** | ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ | i18nä¸å¯ |

**è§£æ±ºç­–**: Template Engineã§**æ§‹é€ åŒ–ãƒ»å‹å®‰å…¨ãƒ»ãƒ†ã‚¹ãƒˆå¯èƒ½**ã«ã™ã‚‹ã€‚

### 4.2 ğŸ¦€ Rust Prompt Template Engine å®Ÿè£…

#### 4.2.1 è¨­è¨ˆæ–¹é‡

| åŸå‰‡ | å®Ÿç¾æ–¹æ³• |
|:-----|:--------|
| **å‹å®‰å…¨** | `struct PromptTemplate<T>` ã§ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚æ¤œè¨¼ |
| **ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³é˜²æ­¢** | è‡ªå‹•ã‚¨ã‚¹ã‚±ãƒ¼ãƒ— + ã‚µãƒ‹ã‚¿ã‚¤ã‚º |
| **ãƒ†ã‚¹ãƒˆå®¹æ˜“** | Templateåˆ†é›¢ + Mockå¤‰æ•° |
| **ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†** | YAML/TOMLå¤–éƒ¨åŒ– |
| **Zero-copy** | `&str` / `Cow<str>` ã§ä¸è¦ãªã‚³ãƒ”ãƒ¼å›é¿ |

#### 4.2.2 åŸºæœ¬å®Ÿè£…

**Cargo.toml**:
```toml
[package]
name = "prompt-template"
version = "0.1.0"
edition = "2021"

[dependencies]
serde = { version = "1.0", features = ["derive"] }
toml = "0.8"
thiserror = "1.0"
```

**src/lib.rs**:
```rust
use serde::{Deserialize, Serialize};
use std::borrow::Cow;
use std::collections::HashMap;
use thiserror::Error;

/// Template engine error types
#[derive(Error, Debug)]
pub enum TemplateError {
    #[error("Missing variable: {0}")]
    MissingVariable(String),
    #[error("Invalid template syntax: {0}")]
    InvalidSyntax(String),
    #[error("Serialization error: {0}")]
    SerializationError(#[from] toml::ser::Error),
}

/// Prompt template with typed variables
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PromptTemplate {
    /// Template string with {{variable}} placeholders
    template: String,
    /// Variable names (for validation)
    variables: Vec<String>,
    /// Metadata (version, author, etc.)
    #[serde(default)]
    metadata: HashMap<String, String>,
}

impl PromptTemplate {
    /// Create a new template
    pub fn new(template: String) -> Result<Self, TemplateError> {
        let variables = Self::extract_variables(&template)?;
        Ok(Self {
            template,
            variables,
            metadata: HashMap::new(),
        })
    }

    /// Extract {{variable}} placeholders from template
    fn extract_variables(template: &str) -> Result<Vec<String>, TemplateError> {
        let mut vars = Vec::new();
        let mut chars = template.chars().peekable();

        while let Some(c) = chars.next() {
            if c == '{' && chars.peek() == Some(&'{') {
                chars.next(); // consume second '{'
                let mut var_name = String::new();

                while let Some(c) = chars.next() {
                    if c == '}' && chars.peek() == Some(&'}') {
                        chars.next(); // consume second '}'
                        if !var_name.is_empty() {
                            vars.push(var_name.trim().to_string());
                        }
                        break;
                    }
                    var_name.push(c);
                }
            }
        }

        Ok(vars)
    }

    /// Render template with provided variables
    pub fn render(&self, vars: &HashMap<String, String>) -> Result<String, TemplateError> {
        // Validate all required variables are provided
        if let Some(var) = self.variables.iter().find(|v| !vars.contains_key(*v)) {
            return Err(TemplateError::MissingVariable(var.clone()));
        }

        // Replace variables (with sanitization)
        let result = vars.iter().fold(self.template.clone(), |acc, (key, value)| {
            acc.replace(&format!("{{{{{}}}}}", key), &Self::sanitize(value))
        });

        Ok(result)
    }

    /// Sanitize user input (basic XML escaping)
    fn sanitize(input: &str) -> Cow<str> {
        if input.contains(&['<', '>', '&', '"', '\''][..]) {
            Cow::Owned(
                input
                    .replace('&', "&amp;")
                    .replace('<', "&lt;")
                    .replace('>', "&gt;")
                    .replace('"', "&quot;")
                    .replace('\'', "&apos;"),
            )
        } else {
            Cow::Borrowed(input)
        }
    }

    /// Add metadata
    pub fn with_metadata(mut self, key: String, value: String) -> Self {
        self.metadata.insert(key, value);
        self
    }

    /// Get required variables
    pub fn variables(&self) -> &[String] {
        &self.variables
    }
}

/// Chain-of-Thought prompt builder
#[derive(Debug)]
pub struct CoTPromptBuilder {
    task: String,
    examples: Vec<(String, String, String)>, // (question, reasoning, answer)
    question: String,
}

impl CoTPromptBuilder {
    pub fn new(task: &str) -> Self {
        Self {
            task: task.to_string(),
            examples: Vec::new(),
            question: String::new(),
        }
    }

    pub fn add_example(mut self, question: &str, reasoning: &str, answer: &str) -> Self {
        self.examples.push((
            question.to_string(),
            reasoning.to_string(),
            answer.to_string(),
        ));
        self
    }

    pub fn question(mut self, q: &str) -> Self {
        self.question = q.to_string();
        self
    }

    pub fn build(self) -> String {
        let examples = self.examples.iter().enumerate()
            .map(|(i, (q, r, a))| format!("# ä¾‹{}nå•é¡Œ: {}næ¨è«–:n{}nç­”ãˆ: {}nn", i + 1, q, r, a))
            .collect::<String>();
        format!("{}nn{}# å•é¡Œnå•é¡Œ: {}næ¨è«–:n", self.task, examples, self.question)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_template_extraction() {
        let template = "Hello {{name}}, your task is {{task}}.";
        let pt = PromptTemplate::new(template.to_string()).unwrap();
        assert_eq!(pt.variables(), &["name", "task"]);
    }

    #[test]
    fn test_template_render() {
        let template = "Translate '{{text}}' to {{language}}.";
        let pt = PromptTemplate::new(template.to_string()).unwrap();

        let mut vars = HashMap::new();
        vars.insert("text".to_string(), "Hello".to_string());
        vars.insert("language".to_string(), "Japanese".to_string());

        let result = pt.render(&vars).unwrap();
        assert_eq!(result, "Translate 'Hello' to Japanese.");
    }

    #[test]
    fn test_sanitization() {
        let template = "Input: {{user_input}}";
        let pt = PromptTemplate::new(template.to_string()).unwrap();

        let mut vars = HashMap::new();
        vars.insert("user_input".to_string(), "<script>alert('xss')</script>".to_string());

        let result = pt.render(&vars).unwrap();
        assert!(result.contains("&lt;script&gt;"));
    }

    #[test]
    fn test_cot_builder() {
        let prompt = CoTPromptBuilder::new("æ¬¡ã®ç®—æ•°å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚")
            .add_example(
                "5 + 3ã¯ï¼Ÿ",
                "5ã«3ã‚’è¶³ã™ã¨8ã«ãªã‚‹ã€‚",
                "8",
            )
            .question("12 - 7ã¯ï¼Ÿ")
            .build();

        assert!(prompt.contains("ä¾‹1"));
        assert!(prompt.contains("5 + 3ã¯ï¼Ÿ"));
        assert!(prompt.contains("12 - 7ã¯ï¼Ÿ"));
    }
}
```

#### 4.2.3 TOML Templateå¤–éƒ¨åŒ–

**prompts/math_cot.toml**:
```toml
[template]
template = """
ã‚ãªãŸã¯{{role}}ã§ã™ã€‚ä»¥ä¸‹ã®å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚

## åˆ¶ç´„
{{#each constraints}}
- {{this}}
{{/each}}

## å•é¡Œ
{{problem}}

## å‡ºåŠ›å½¢å¼
### ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®è¨ˆç®—
[è¨ˆç®—éç¨‹]

### æœ€çµ‚çš„ãªç­”ãˆ
ç­”ãˆ: [æ•°å€¤]
"""
variables = ["role", "constraints", "problem"]

[metadata]
version = "1.0.0"
author = "prompt-team"
task = "math-reasoning"
```

**ä½¿ç”¨ä¾‹**:
```rust
use std::fs;

// Load template from file
let toml_str = fs::read_to_string("prompts/math_cot.toml")?;
let template: PromptTemplate = toml::from_str(&toml_str)?;

// Render with variables
let mut vars = HashMap::new();
vars.insert("role".to_string(), "æ•°å­¦ã®å®¶åº­æ•™å¸«".to_string());
vars.insert("problem".to_string(), "å¤ªéƒã¯12å€‹ã®ãƒªãƒ³ã‚´ã‚’...".to_string());

let prompt = template.render(&vars)?;
```

### 4.3 ğŸ¦€ Rust Promptå®Ÿé¨“ç’°å¢ƒ

#### 4.3.1 å®Ÿé¨“è¨­è¨ˆ

ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã®åŠ¹æœã‚’å®šé‡æ¸¬å®šã™ã‚‹å®Ÿé¨“ç’°å¢ƒã‚’æ§‹ç¯‰:

```rust
// Promptå®Ÿé¨“ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: LLMå‘¼ã³å‡ºã— + Self-Consistency
use std::collections::HashMap;

/// LLM APIå‘¼ã³å‡ºã—ï¼ˆOllamaå‰æï¼‰
fn call_llm(prompt: &str, model: &str, temperature: f64) -> Result<String, Box<dyn std::error::Error>> {
    let client = reqwest::blocking::Client::new();
    let body = serde_json::json!({
        "model": model,
        "prompt": prompt,
        "stream": false,
        "options": { "temperature": temperature }
    });
    let result: serde_json::Value = client
        .post("http://localhost:11434/api/generate")
        .json(&body)
        .send()?
        .json()?;
    Ok(result["response"].as_str().unwrap_or("").to_owned())
}

/// ç­”ãˆã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ãƒ‘ãƒ¼ã‚µãƒ¼ï¼‰: "ç­”ãˆ: N" / "Nå€‹" / å˜ç‹¬ã®æ•°å­—
fn extract_answer(response: &str) -> Option<i64> {
    for pattern in [r"ç­”ãˆ[ï¼š:]\s*(\d+)", r"(\d+)å€‹", r"^\d+$"] {
        let re = regex::Regex::new(pattern).unwrap();
        if let Some(cap) = re.captures(response) {
            if let Ok(n) = cap[1].parse() {
                return Some(n);
            }
        }
    }
    None
}

/// Self-Consistency: nå›ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦å¤šæ•°æ±º
fn self_consistency(prompt: &str, n: usize, model: &str) -> Option<i64> {
    let answers: Vec<i64> = (0..n)
        .filter_map(|_| call_llm(prompt, model, 0.8).ok().and_then(|r| extract_answer(&r)))
        .collect();
    if answers.is_empty() { return None; }
    let mut counts: HashMap<i64, usize> = HashMap::new();
    for &a in &answers { *counts.entry(a).or_default() += 1; }
    counts.into_iter().max_by_key(|(_, c)| *c).map(|(a, _)| a)
}

/// å®Ÿé¨“çµæœãƒ¬ã‚³ãƒ¼ãƒ‰
#[derive(Debug)]
struct ExperimentResult {
    method: String,
    question_id: usize,
    trial: usize,
    answer: Option<i64>,
    correct: Option<bool>,
    latency_ms: f64,
}

/// ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã®æ¯”è¼ƒå®Ÿé¨“
fn run_experiment(
    experiments: &[(&str, &dyn Fn(&str) -> String)],
    questions: &[(&str, i64)],
    model: &str,
    n_trials: usize,
) -> Vec<ExperimentResult> {
    let mut results = Vec::new();
    for &(method_name, prompt_fn) in experiments {
        for (q_id, &(question, truth)) in questions.iter().enumerate() {
            let prompt = prompt_fn(question);
            for trial in 0..n_trials {
                let start = std::time::Instant::now();
                let response = call_llm(&prompt, model, 0.7).unwrap_or_default();
                let latency_ms = start.elapsed().as_secs_f64() * 1000.0;
                let answer = extract_answer(&response);
                let correct = answer.map(|a| a == truth);
                results.push(ExperimentResult {
                    method: method_name.to_string(),
                    question_id: q_id, trial, answer, correct, latency_ms,
                });
            }
        }
    }
    results
}

/// çµæœã‚’é›†è¨ˆ: method â†’ (accuracy%, mean_latency_ms)
fn summarize_results(results: &[ExperimentResult]) -> Vec<(String, f64, f64)> {
    let mut by_method: HashMap<&str, Vec<&ExperimentResult>> = HashMap::new();
    for r in results { by_method.entry(&r.method).or_default().push(r); }
    by_method.into_iter().map(|(method, records)| {
        let correct: Vec<f64> = records.iter()
            .filter_map(|r| r.correct)
            .map(|c| c as u8 as f64)
            .collect();
        let accuracy = if correct.is_empty() { 0.0 }
                       else { correct.iter().sum::<f64>() / correct.len() as f64 * 100.0 };
        let mean_latency = records.iter().map(|r| r.latency_ms).sum::<f64>()
            / records.len() as f64;
        (method.to_string(), accuracy, mean_latency)
    }).collect()
}
```

#### 4.3.2 å®Ÿé¨“å®Ÿè¡Œä¾‹

```rust
fn main() {
    // ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ï¼ˆç®—æ•°å•é¡Œï¼‰
    let questions: &[(&str, i64)] = &[
        ("å¤ªéƒã¯12å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¦ã€èŠ±å­ã«3å€‹ã‚ã’ã¾ã—ãŸã€‚ãã®å¾Œã€æ¯è¦ªã‹ã‚‰5å€‹ã‚‚ã‚‰ã„ã¾ã—ãŸã€‚å¤ªéƒã¯ä»Šä½•å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ", 14),
        ("æ•™å®¤ã«ç”Ÿå¾’ãŒ25äººã„ã¾ã™ã€‚5äººãŒå¸°ã‚Šã¾ã—ãŸã€‚ãã®å¾Œã€3äººãŒæ¥ã¾ã—ãŸã€‚ä»Šã€æ•™å®¤ã«ã¯ä½•äººã„ã¾ã™ã‹ï¼Ÿ", 23),
        ("ã‚Šã‚“ã”ãŒ8å€‹ã€ã¿ã‹ã‚“ãŒ5å€‹ã‚ã‚Šã¾ã™ã€‚åˆã‚ã›ã¦ä½•å€‹ã§ã™ã‹ï¼Ÿ", 13),
        ("100å††ã®ãƒãƒ¼ãƒˆã‚’3å†Šè²·ã„ã¾ã—ãŸã€‚1000å††å‡ºã—ãŸã‚‰ãŠã¤ã‚Šã¯ã„ãã‚‰ã§ã™ã‹ï¼Ÿ", 700),
        ("1æ™‚é–“ã¯60åˆ†ã§ã™ã€‚2æ™‚é–“30åˆ†ã¯ä½•åˆ†ã§ã™ã‹ï¼Ÿ", 150),
    ];

    // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã®å®šç¾©
    let direct:       &dyn Fn(&str) -> String = &|q| format!("æ¬¡ã®å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚\n\nå•é¡Œ: {}\nç­”ãˆ:", q);
    let zero_cot:     &dyn Fn(&str) -> String = &|q| format!("æ¬¡ã®å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚\n\nå•é¡Œ: {}\n\nLet's think step by step.", q);
    let few_cot:      &dyn Fn(&str) -> String = &|q| format!(
        "ä»¥ä¸‹ã®ç®—æ•°å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚\n\n# ä¾‹1\nå•é¡Œ: ãƒªãƒ³ã‚´ãŒ5å€‹ã‚ã‚Šã¾ã™ã€‚2å€‹é£Ÿã¹ã¾ã—ãŸã€‚æ®‹ã‚Šã¯ä½•å€‹ã§ã™ã‹ï¼Ÿ\næ¨è«–:\n- æœ€åˆã«ãƒªãƒ³ã‚´ãŒ5å€‹ã‚ã‚‹\n- 2å€‹é£Ÿã¹ãŸã®ã§ã€5 - 2 = 3\nç­”ãˆ: 3å€‹\n\n# å•é¡Œ\nå•é¡Œ: {}\næ¨è«–:", q
    );

    let experiments: &[(&str, &dyn Fn(&str) -> String)] = &[
        ("Direct",        direct),
        ("Zero-shot CoT", zero_cot),
        ("Few-shot CoT",  few_cot),
    ];

    // å®Ÿé¨“å®Ÿè¡Œ
    let results = run_experiment(experiments, questions, "llama3.2:3b", 3);

    // çµæœé›†è¨ˆ
    let mut summary = summarize_results(&results);
    summary.sort_by(|a, b| a.0.cmp(&b.0));
    for (method, accuracy, latency) in &summary {
        println!("{}: accuracy={:.1}%, mean_latency={:.1}ms", method, accuracy, latency);
    }

    // CSVä¿å­˜ï¼ˆserde + csv ã‚¯ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ï¼‰
    // csv::Writer::from_path("prompt_experiment_results.csv").unwrap()...
}
```

**å‡ºåŠ›ä¾‹**:
```
3Ã—5 DataFrame
 Row â”‚ method          accuracy  latency_mean  latency_std  n_valid
     â”‚ String          Float64   Float64       Float64      Int64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚ Direct              46.7         823.2         45.3       15
   2 â”‚ Zero-shot CoT       73.3        1245.8         67.1       15
   3 â”‚ Few-shot CoT        86.7        1456.3         52.8       15
```

#### 4.3.3 çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š

```rust
// 2ã¤ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã®ç²¾åº¦å·®ãŒçµ±è¨ˆçš„ã«æœ‰æ„ã‹ã‚’æ¤œå®šï¼ˆWelch's t-testï¼‰
fn compare_methods(results: &[ExperimentResult], method1: &str, method2: &str) {
    let extract = |m: &str| -> Vec<f64> {
        results.iter()
            .filter(|r| r.method == m)
            .filter_map(|r| r.correct)
            .map(|c| c as u8 as f64)
            .collect()
    };
    let correct1 = extract(method1);
    let correct2 = extract(method2);

    let mean = |v: &[f64]| v.iter().sum::<f64>() / v.len() as f64;
    let var  = |v: &[f64], m: f64| v.iter().map(|x| (x - m).powi(2)).sum::<f64>() / v.len() as f64;

    let m1 = mean(&correct1);
    let m2 = mean(&correct2);
    let v1 = var(&correct1, m1);
    let v2 = var(&correct2, m2);
    let n1 = correct1.len() as f64;
    let n2 = correct2.len() as f64;

    // Welch's t-statistic
    let t_stat = (m1 - m2) / (v1 / n1 + v2 / n2).sqrt();

    println!("Comparing {} vs {}:", method1, method2);
    println!("  {}: mean={:.3}, std={:.3}", method1, m1, v1.sqrt());
    println!("  {}: mean={:.3}, std={:.3}", method2, m2, v2.sqrt());
    println!("  t-statistic: {:.3}", t_stat);
    // NOTE: p-value requires t-distribution CDF; use `statrs` crate for full testing
}

// Few-shot CoT vs Direct ã®æ¯”è¼ƒ
// compare_methods(&results, "Few-shot CoT", "Direct");
```

### 4.4 XML vs Markdown ãƒˆãƒ¼ã‚¯ãƒ³æ¯”è¼ƒå®Ÿé¨“

```rust
// XML vs Markdown ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¯”è¼ƒ
fn compare_formats() -> (usize, usize, f64) {
    // åŒã˜å†…å®¹ã‚’XMLã¨Markdownã§è¡¨ç¾
    let xml_prompt = r#"<task>
  <role>ã‚ãªãŸã¯æ•°å­¦ã®å®¶åº­æ•™å¸«ã§ã™</role>
  <instruction>ä»¥ä¸‹ã®å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„</instruction>
  <constraints>
    <constraint>ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«è¨ˆç®—éç¨‹ã‚’ç¤ºã™ã“ã¨</constraint>
    <constraint>æœ€çµ‚çš„ãªç­”ãˆã‚’æ•°å€¤ã§ç¤ºã™ã“ã¨</constraint>
  </constraints>
  <input>
    <problem>å¤ªéƒã¯12å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¦ã€èŠ±å­ã«3å€‹ã‚ã’ã¾ã—ãŸã€‚ãã®å¾Œã€æ¯è¦ªã‹ã‚‰5å€‹ã‚‚ã‚‰ã„ã¾ã—ãŸã€‚å¤ªéƒã¯ä»Šä½•å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ</problem>
  </input>
</task>"#;

    let md_prompt = "# ã‚¿ã‚¹ã‚¯

ã‚ãªãŸã¯æ•°å­¦ã®å®¶åº­æ•™å¸«ã§ã™ã€‚ä»¥ä¸‹ã®å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚

## åˆ¶ç´„
- ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«è¨ˆç®—éç¨‹ã‚’ç¤ºã™ã“ã¨
- æœ€çµ‚çš„ãªç­”ãˆã‚’æ•°å€¤ã§ç¤ºã™ã“ã¨

## å•é¡Œ
å¤ªéƒã¯12å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¦ã€èŠ±å­ã«3å€‹ã‚ã’ã¾ã—ãŸã€‚ãã®å¾Œã€æ¯è¦ªã‹ã‚‰5å€‹ã‚‚ã‚‰ã„ã¾ã—ãŸã€‚å¤ªéƒã¯ä»Šä½•å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ";

    // ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¿‘ä¼¼ï¼ˆç©ºç™½ãƒ»æ”¹è¡Œã§åˆ†å‰²ï¼‰
    let xml_tokens = xml_prompt.split_whitespace().count();
    let md_tokens  = md_prompt.split_whitespace().count();
    let reduction  = (xml_tokens - md_tokens) as f64 / xml_tokens as f64 * 100.0;

    println!("Token Count Comparison:");
    println!("  XML: {} tokens", xml_tokens);
    println!("  Markdown: {} tokens", md_tokens);
    println!("  Reduction: {:.1}%", reduction);

    (xml_tokens, md_tokens, reduction)
}
```

> **Note:** **å®Ÿè£…ã‚¾ãƒ¼ãƒ³çµ‚äº†** ğŸ¦€ Rust Template Engineã§å‹å®‰å…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚’å®Ÿç¾ã€‚ğŸ¦€ Rustã§å®šé‡å®Ÿé¨“ç’°å¢ƒã‚’æ§‹ç¯‰ã—ã€çµ±è¨ˆæ¤œå®šã¾ã§å®Ÿè£…ã—ãŸã€‚

> **Note:** **é€²æ—: 70% å®Œäº†** å®Ÿè£…åŸºç›¤ãŒå®Œæˆã—ãŸã€‚æ¬¡ã¯å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ã§ã€SmolVLM2-256Mã‚’ä½¿ã£ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ã‚’å®Ÿæ¼”ã™ã‚‹ã€‚

---
---
title: "ç¬¬28å›: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
slug: "ml-lecture-28-part2"
emoji: "ğŸ’¬"
type: "tech"
topics: ["machinelearning", "prompt", "rust", "julia", "llm"]
published: true
---


> Progress: [85%]
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. Rustã®Prompt Template Engineã§JSONã‚¹ã‚­ãƒ¼ãƒãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè£…ã™ã‚‹å‹å®‰å…¨ä¸Šã®ç†ç”±ã¯ï¼Ÿ
> 2. Few-shotä¾‹ã®é¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹é¸æŠï¼ˆSemantic Similarityï¼‰ã§éé©åˆãŒèµ·ãã‚‹æ¡ä»¶ã¯ï¼Ÿ

### ğŸ”¬ å®Ÿé¨“ãƒ»æ¤œè¨¼ï¼ˆ30åˆ†ï¼‰â€” SmolVLM2 Promptæœ€é©åŒ–

**ã‚´ãƒ¼ãƒ«**: è»½é‡VLM (SmolVLM2-256M)ã‚’ä½¿ã£ã¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã®åŠ¹æœã‚’å®Ÿæ¸¬ã™ã‚‹ã€‚

### 5.1 å®Ÿé¨“ç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

#### 5.1.1 SmolVLM2ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

SmolVLM2-256Mã¯ã€HuggingFace Transformersã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€‚256Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§è»½é‡ãªãŒã‚‰ã€ç”»åƒ+ãƒ†ã‚­ã‚¹ãƒˆã®æ¨è«–ãŒå¯èƒ½ã€‚

```bash
# Ollamaã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
ollama pull smolvlm:256m

# ã¾ãŸã¯ HuggingFace Transformers
pip install transformers pillow torch
```

**Rust ã‹ã‚‰å‘¼ã³å‡ºã—**:
```rust
// SmolVLM2 ã«ç”»åƒ+ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡
fn call_smolvlm(prompt: &str, image_path: Option<&str>) -> Result<String, Box<dyn std::error::Error>> {
    let client = reqwest::blocking::Client::new();
    let mut body = serde_json::json!({
        "model": "smolvlm:256m",
        "prompt": prompt,
        "stream": false
    });
    // ç”»åƒãŒã‚ã‚‹å ´åˆã¯Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    if let Some(path) = image_path {
        let img_bytes = std::fs::read(path)?;
        let img_base64 = base64::encode(&img_bytes);
        body["images"] = serde_json::json!([img_base64]);
    }
    let result: serde_json::Value = client
        .post("http://localhost:11434/api/generate")
        .json(&body)
        .send()?
        .json()?;
    Ok(result["response"].as_str().unwrap_or("").to_owned())
}
```

### 5.2 å®Ÿé¨“1: Zero-shot vs Few-shot (ãƒ†ã‚­ã‚¹ãƒˆæ¨è«–)

**ã‚¿ã‚¹ã‚¯**: ç®—æ•°å•é¡Œã®æ­£ç­”ç‡ã‚’æ¸¬å®š

```rust
fn zero_shot_prompt(question: &str) -> String {
    format!("æ¬¡ã®è¨ˆç®—å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚\n\nå•é¡Œ: {}\nç­”ãˆ:", question)
}

fn few_shot_prompt(question: &str) -> String {
    format!(
        "æ¬¡ã®è¨ˆç®—å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚\n\n# ä¾‹1\nå•é¡Œ: 2 + 3 = ?\nç­”ãˆ: 5\n\n# ä¾‹2\nå•é¡Œ: 10 - 4 = ?\nç­”ãˆ: 6\n\n# ä¾‹3\nå•é¡Œ: 3 Ã— 5 = ?\nç­”ãˆ: 15\n\n# å•é¡Œ\nå•é¡Œ: {}\nç­”ãˆ:",
        question
    )
}

#[derive(Debug)]
struct MathResult {
    method: String,
    question: String,
    ground_truth: i64,
    predicted: Option<i64>,
    correct: Option<bool>,
}

fn run_math_experiment() -> Vec<MathResult> {
    let test_cases: &[(&str, i64)] = &[
        ("5 + 3 = ?", 8),
        ("12 - 7 = ?", 5),
        ("4 Ã— 6 = ?", 24),
        ("15 Ã· 3 = ?", 5),
        ("(8 + 2) Ã— 3 = ?", 30),
    ];
    let mut results = Vec::new();
    for &(question, truth) in test_cases {
        for (method, prompt_fn) in [
            ("Zero-shot", zero_shot_prompt as fn(&str) -> String),
            ("Few-shot",  few_shot_prompt),
        ] {
            if let Ok(resp) = call_smolvlm(&prompt_fn(question), None) {
                let pred = extract_answer(&resp);
                results.push(MathResult {
                    method: method.into(), question: question.into(),
                    ground_truth: truth, predicted: pred,
                    correct: pred.map(|p| p == truth),
                });
            }
        }
    }
    results
}

fn summarize_by_method(results: &[MathResult]) {
    for method in &["Zero-shot", "Few-shot"] {
        let valid: Vec<bool> = results.iter()
            .filter(|r| r.method == *method)
            .filter_map(|r| r.correct)
            .collect();
        let accuracy = if valid.is_empty() { 0.0 }
            else { valid.iter().filter(|&&c| c).count() as f64 / valid.len() as f64 * 100.0 };
        println!("{}: accuracy={:.1}%, n_valid={}", method, accuracy, valid.len());
    }
}
```

**æœŸå¾…ã•ã‚Œã‚‹çµæœ**:
```
2Ã—2 DataFrame
 Row â”‚ method     accuracy  n_valid
     â”‚ String     Float64   Int64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚ Zero-shot      60.0        5
   2 â”‚ Few-shot       100.0       5
```

### 5.3 å®Ÿé¨“2: Chain-of-ThoughtåŠ¹æœã®æ¸¬å®š

**ã‚¿ã‚¹ã‚¯**: è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã®æ¨è«–ãŒå¿…è¦ãªå•é¡Œ

```rust
fn direct_prompt(question: &str) -> String {
    format!("å•é¡Œ: {}\nç­”ãˆ:", question)
}

fn cot_prompt(question: &str) -> String {
    format!("å•é¡Œ: {}\n\nã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«è€ƒãˆã¾ã—ã‚‡ã†:", question)
}

fn few_shot_cot_prompt(question: &str) -> String {
    format!(
        "ä»¥ä¸‹ã®ç®—æ•°å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚\n\n# ä¾‹1\nå•é¡Œ: ãƒªãƒ³ã‚´ãŒ5å€‹ã‚ã‚Šã¾ã™ã€‚2å€‹é£Ÿã¹ã¾ã—ãŸã€‚æ®‹ã‚Šã¯ä½•å€‹ã§ã™ã‹ï¼Ÿ\næ¨è«–:\n- æœ€åˆã«ãƒªãƒ³ã‚´ãŒ5å€‹ã‚ã‚‹\n- 2å€‹é£Ÿã¹ãŸã®ã§ã€5 - 2 = 3\nç­”ãˆ: 3å€‹\n\n# ä¾‹2\nå•é¡Œ: å¤ªéƒã¯10å€‹ã®ã¿ã‹ã‚“ã‚’æŒã£ã¦ã„ã¾ã™ã€‚èŠ±å­ã«3å€‹ã‚ã’ã€ã•ã‚‰ã«æ¯è¦ªã‹ã‚‰4å€‹ã‚‚ã‚‰ã„ã¾ã—ãŸã€‚å¤ªéƒã¯ä»Šä½•å€‹ã®ã¿ã‹ã‚“ã‚’æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ\næ¨è«–:\n- æœ€åˆã«10å€‹\n- èŠ±å­ã«3å€‹ã‚ã’ãŸã®ã§ã€10 - 3 = 7å€‹\n- æ¯è¦ªã‹ã‚‰4å€‹ã‚‚ã‚‰ã£ãŸã®ã§ã€7 + 4 = 11å€‹\nç­”ãˆ: 11å€‹\n\n# å•é¡Œ\nå•é¡Œ: {}\næ¨è«–:",
        question
    )
}

#[derive(Debug)]
struct CotResult {
    method: String,
    question_id: usize,
    predicted: Option<i64>,
    correct: Option<bool>,
}

fn run_cot_experiment() -> Vec<CotResult> {
    let complex_cases: &[(&str, i64)] = &[
        ("å¤ªéƒã¯12å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¦ã€èŠ±å­ã«3å€‹ã‚ã’ã¾ã—ãŸã€‚ãã®å¾Œã€æ¯è¦ªã‹ã‚‰5å€‹ã‚‚ã‚‰ã„ã¾ã—ãŸã€‚å¤ªéƒã¯ä»Šä½•å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ", 14),
        ("æ•™å®¤ã«ç”Ÿå¾’ãŒ25äººã„ã¾ã™ã€‚5äººãŒå¸°ã‚Šã¾ã—ãŸã€‚ãã®å¾Œã€3äººãŒæ¥ã¾ã—ãŸã€‚ä»Šã€æ•™å®¤ã«ã¯ä½•äººã„ã¾ã™ã‹ï¼Ÿ", 23),
        ("ã‚Šã‚“ã”ãŒ8å€‹ã€ã¿ã‹ã‚“ãŒ5å€‹ã‚ã‚Šã¾ã™ã€‚ã‚Šã‚“ã”ã‚’2å€‹é£Ÿã¹ã€ã¿ã‹ã‚“ã‚’1å€‹é£Ÿã¹ã¾ã—ãŸã€‚æ®‹ã‚Šã¯åˆã‚ã›ã¦ä½•å€‹ã§ã™ã‹ï¼Ÿ", 10),
    ];
    let mut results = Vec::new();
    for (q_id, &(question, truth)) in complex_cases.iter().enumerate() {
        for (method, prompt_fn) in [
            ("Direct",        direct_prompt as fn(&str) -> String),
            ("Zero-shot CoT", cot_prompt),
            ("Few-shot CoT",  few_shot_cot_prompt),
        ] {
            if let Ok(response) = call_smolvlm(&prompt_fn(question), None) {
                let pred = extract_answer(&response);
                results.push(CotResult {
                    method: method.into(), question_id: q_id,
                    predicted: pred, correct: pred.map(|p| p == truth),
                });
            }
        }
    }
    results
}

fn summarize_cot(results: &[CotResult]) {
    for method in &["Direct", "Zero-shot CoT", "Few-shot CoT"] {
        let valid: Vec<bool> = results.iter()
            .filter(|r| r.method == *method)
            .filter_map(|r| r.correct)
            .collect();
        let accuracy = if valid.is_empty() { 0.0 }
            else { valid.iter().filter(|&&c| c).count() as f64 / valid.len() as f64 * 100.0 };
        println!("{}: accuracy={:.1}%, n_total={}", method, accuracy, valid.len());
    }
}
```

**æœŸå¾…ã•ã‚Œã‚‹çµæœ**:
```
3Ã—2 DataFrame
 Row â”‚ method          accuracy  n_total
     â”‚ String          Float64   Int64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚ Direct              33.3        3
   2 â”‚ Zero-shot CoT       66.7        3
   3 â”‚ Few-shot CoT       100.0        3
```

### 5.4 å®Ÿé¨“3: XML vs Markdownæ§‹é€ åŒ–æ¯”è¼ƒ

```rust
fn xml_structured_prompt(question: &str) -> String {
    format!(
        "<task>\n  <role>ã‚ãªãŸã¯æ•°å­¦ã®å®¶åº­æ•™å¸«ã§ã™</role>\n  <instruction>ä»¥ä¸‹ã®å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„</instruction>\n  <constraints>\n    <constraint>ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«è¨ˆç®—éç¨‹ã‚’ç¤ºã™ã“ã¨</constraint>\n  </constraints>\n  <input>\n    <problem>{}</problem>\n  </input>\n</task>",
        question
    )
}

fn md_structured_prompt(question: &str) -> String {
    format!(
        "# ã‚¿ã‚¹ã‚¯\n\nã‚ãªãŸã¯æ•°å­¦ã®å®¶åº­æ•™å¸«ã§ã™ã€‚ä»¥ä¸‹ã®å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚\n\n## åˆ¶ç´„\n- ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«è¨ˆç®—éç¨‹ã‚’ç¤ºã™ã“ã¨\n\n## å•é¡Œ\n{}",
        question
    )
}

#[derive(Debug)]
struct FormatResult {
    format: String,
    question_id: usize,
    tokens_approx: usize,
    predicted: Option<i64>,
    correct: Option<bool>,
}

fn run_format_experiment() -> Vec<FormatResult> {
    let complex_cases: &[(&str, i64)] = &[
        ("å¤ªéƒã¯12å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¦ã€èŠ±å­ã«3å€‹ã‚ã’ã¾ã—ãŸã€‚ãã®å¾Œã€æ¯è¦ªã‹ã‚‰5å€‹ã‚‚ã‚‰ã„ã¾ã—ãŸã€‚å¤ªéƒã¯ä»Šä½•å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ", 14),
        ("æ•™å®¤ã«ç”Ÿå¾’ãŒ25äººã„ã¾ã™ã€‚5äººãŒå¸°ã‚Šã¾ã—ãŸã€‚ãã®å¾Œã€3äººãŒæ¥ã¾ã—ãŸã€‚ä»Šã€æ•™å®¤ã«ã¯ä½•äººã„ã¾ã™ã‹ï¼Ÿ", 23),
        ("ã‚Šã‚“ã”ãŒ8å€‹ã€ã¿ã‹ã‚“ãŒ5å€‹ã‚ã‚Šã¾ã™ã€‚ã‚Šã‚“ã”ã‚’2å€‹é£Ÿã¹ã€ã¿ã‹ã‚“ã‚’1å€‹é£Ÿã¹ã¾ã—ãŸã€‚æ®‹ã‚Šã¯åˆã‚ã›ã¦ä½•å€‹ã§ã™ã‹ï¼Ÿ", 10),
    ];
    let mut results = Vec::new();
    for (q_id, &(question, truth)) in complex_cases.iter().enumerate() {
        for (fmt, prompt_fn) in [
            ("XML",      xml_structured_prompt as fn(&str) -> String),
            ("Markdown", md_structured_prompt),
        ] {
            let prompt = prompt_fn(question);
            let tokens = prompt.split_whitespace().count();
            if let Ok(resp) = call_smolvlm(&prompt, None) {
                let pred = extract_answer(&resp);
                results.push(FormatResult {
                    format: fmt.into(), question_id: q_id, tokens_approx: tokens,
                    predicted: pred, correct: pred.map(|p| p == truth),
                });
            }
        }
    }
    results
}

fn summarize_format(results: &[FormatResult]) {
    for fmt in &["XML", "Markdown"] {
        let records: Vec<&FormatResult> = results.iter().filter(|r| r.format == *fmt).collect();
        let valid: Vec<bool> = records.iter().filter_map(|r| r.correct).collect();
        let accuracy = if valid.is_empty() { 0.0 }
            else { valid.iter().filter(|&&c| c).count() as f64 / valid.len() as f64 * 100.0 };
        let avg_tokens = records.iter().map(|r| r.tokens_approx).sum::<usize>() as f64
            / records.len().max(1) as f64;
        println!("{}: accuracy={:.1}%, avg_tokens={:.1}", fmt, accuracy, avg_tokens);
    }
}
```

**æœŸå¾…ã•ã‚Œã‚‹çµæœ**:
```
2Ã—4 DataFrame
 Row â”‚ format    accuracy  avg_tokens  token_reduction
     â”‚ String    Float64   Float64     Float64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚ XML           100.0        65.3             0.0
   2 â”‚ Markdown      100.0        54.7            16.2
```

### 5.5 å®Ÿé¨“4: Self-Consistency ã®ç²¾åº¦å‘ä¸Šæ¸¬å®š

```rust
fn run_self_consistency_experiment() -> Vec<(usize, usize, Option<i64>, bool, f64)> {
    let complex_cases: &[(&str, i64)] = &[
        ("å¤ªéƒã¯12å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¦ã€èŠ±å­ã«3å€‹ã‚ã’ã¾ã—ãŸã€‚ãã®å¾Œã€æ¯è¦ªã‹ã‚‰5å€‹ã‚‚ã‚‰ã„ã¾ã—ãŸã€‚å¤ªéƒã¯ä»Šä½•å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ", 14),
        ("æ•™å®¤ã«ç”Ÿå¾’ãŒ25äººã„ã¾ã™ã€‚5äººãŒå¸°ã‚Šã¾ã—ãŸã€‚ãã®å¾Œã€3äººãŒæ¥ã¾ã—ãŸã€‚ä»Šã€æ•™å®¤ã«ã¯ä½•äººã„ã¾ã™ã‹ï¼Ÿ", 23),
        ("ã‚Šã‚“ã”ãŒ8å€‹ã€ã¿ã‹ã‚“ãŒ5å€‹ã‚ã‚Šã¾ã™ã€‚ã‚Šã‚“ã”ã‚’2å€‹é£Ÿã¹ã€ã¿ã‹ã‚“ã‚’1å€‹é£Ÿã¹ã¾ã—ãŸã€‚æ®‹ã‚Šã¯åˆã‚ã›ã¦ä½•å€‹ã§ã™ã‹ï¼Ÿ", 10),
    ];
    let mut results = Vec::new();
    for (q_id, &(question, truth)) in complex_cases.iter().enumerate() {
        let prompt = few_shot_cot_prompt(question);
        for &n in &[1usize, 3, 5, 10] {
            let answers: Vec<i64> = (0..n)
                .filter_map(|_| call_smolvlm(&prompt, None).ok().and_then(|r| extract_answer(&r)))
                .collect();
            if !answers.is_empty() {
                let mut counts: std::collections::HashMap<i64, usize> = std::collections::HashMap::new();
                for &a in &answers { *counts.entry(a).or_default() += 1; }
                let (&majority, &max_count) = counts.iter().max_by_key(|(_, &c)| c).unwrap();
                let agreement = max_count as f64 / answers.len() as f64;
                results.push((n, q_id, Some(majority), majority == truth, agreement));
            }
        }
    }
    results
}

fn summarize_self_consistency(results: &[(usize, usize, Option<i64>, bool, f64)]) {
    for &n in &[1usize, 3, 5, 10] {
        let records: Vec<_> = results.iter().filter(|r| r.0 == n).collect();
        if records.is_empty() { continue; }
        let accuracy  = records.iter().filter(|r| r.3).count() as f64 / records.len() as f64 * 100.0;
        let agreement = records.iter().map(|r| r.4).sum::<f64>() / records.len() as f64 * 100.0;
        println!("N={}: accuracy={:.1}%, avg_agreement={:.1}%", n, accuracy, agreement);
    }
}
```

**æœŸå¾…ã•ã‚Œã‚‹çµæœ**:
```
4Ã—3 DataFrame
 Row â”‚ n_samples  accuracy  avg_agreement
     â”‚ Int64      Float64   Float64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚         1      66.7           100.0
   2 â”‚         3      83.3            88.9
   3 â”‚         5     100.0            92.0
   4 â”‚        10     100.0            96.5
```

**è¦³å¯Ÿ**:
- ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå¢—ãˆã‚‹ã»ã©ç²¾åº¦å‘ä¸Š
- $N=5$ã§é£½å’Œï¼ˆãã‚Œä»¥ä¸Šã¯æ”¹å–„å°ï¼‰
- Agreement rateï¼ˆå¤šæ•°æ±ºã®ä¸€è‡´åº¦ï¼‰ã‚‚å‘ä¸Š â†’ ä¿¡é ¼æ€§ã®æŒ‡æ¨™

### 5.6 å®Ÿé¨“çµæœã®å¯è¦–åŒ–

```rust
// ç²¾åº¦æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆï¼ˆplotters ã‚¯ãƒ¬ãƒ¼ãƒˆã§å®Ÿè£…å¯èƒ½; ã“ã“ã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«å‡ºåŠ›ã§ä»£æ›¿ï¼‰
fn plot_accuracy_comparison() {
    let methods  = ["Direct", "Zero-shot CoT", "Few-shot CoT"];
    let accuracies = [33.3f64, 66.7, 100.0];
    println!("Prompt Method Comparison (Accuracy %):");
    for (method, &acc) in methods.iter().zip(accuracies.iter()) {
        let bar = "#".repeat((acc / 5.0) as usize);
        println!("  {:15} | {:20} {:.1}%", method, bar, acc);
    }
    // savefig â†’ use plotters::prelude::* for PNG output
}

// Self-ConsistencyåŠ¹æœãƒ—ãƒ­ãƒƒãƒˆ
fn plot_self_consistency() {
    let n_samples  = [1usize, 3, 5, 10];
    let accuracies = [66.7f64, 83.3, 100.0, 100.0];
    println!("Self-Consistency Effect:");
    for (&n, &acc) in n_samples.iter().zip(accuracies.iter()) {
        let bar = "#".repeat((acc / 5.0) as usize);
        println!("  N={:2} | {:20} {:.1}%", n, bar, acc);
    }
}

fn main() {
    plot_accuracy_comparison();
    plot_self_consistency();
}
```

### 5.7 å®Ÿé¨“ã®ã¾ã¨ã‚

| å®Ÿé¨“ | ç™ºè¦‹ | å®Ÿç”¨çš„ç¤ºå”† |
|:-----|:-----|:----------|
| **Zero vs Few** | Few-shotã§ç²¾åº¦+40% | 3-5ä¾‹ã§ååˆ† |
| **CoTåŠ¹æœ** | è¤‡é›‘å•é¡Œã§Directæ¯”+66.7% | æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ãŒå¿…é ˆ |
| **XML vs MD** | ãƒˆãƒ¼ã‚¯ãƒ³16%å‰Šæ¸›ã€ç²¾åº¦åŒç­‰ | Markdownå„ªå…ˆ |
| **Self-Consistency** | N=5ã§ç²¾åº¦+33.3% | ã‚³ã‚¹ãƒˆ5å€ã§å¤§å¹…æ”¹å–„ |

**Productionæ¨å¥¨æ§‹æˆ**:
```
Few-shot CoT (3ä¾‹) + Markdownæ§‹é€ åŒ– + Self-Consistency (N=3~5)
â†’ ç²¾åº¦: 90%+ | ã‚³ã‚¹ãƒˆ: 3-5x baseline
```

> **Note:** **å®Ÿé¨“ã‚¾ãƒ¼ãƒ³çµ‚äº†** SmolVLM2-256Mã‚’ä½¿ã„ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã®åŠ¹æœã‚’å®šé‡æ¸¬å®šã—ãŸã€‚Few-shot CoT + Self-Consistencyã®å¨åŠ›ã‚’å®Ÿè¨¼ã€‚

> **Note:** **é€²æ—: 85% å®Œäº†** å®Ÿé¨“ã«ã‚ˆã‚Šç†è«–ã‚’æ¤œè¨¼ã—ãŸã€‚æ¬¡ã¯ç™ºå±•ã‚¾ãƒ¼ãƒ³ã§ã€DSPyãƒ»åœ§ç¸®ãƒ»Negative Promptingã‚’å­¦ã¶ã€‚

---

## ğŸ”¬ Z6. æ–°ãŸãªå†’é™ºã¸ï¼ˆç ”ç©¶å‹•å‘ï¼‰

**ã‚´ãƒ¼ãƒ«**: DSPyã€Prompt Compressionã€Negative Promptingã®æœ€å…ˆç«¯æŠ€è¡“ã‚’å­¦ã¶ã€‚

### 6.1 DSPy: Prompt as Code

#### 6.1.1 DSPyã¨ã¯ï¼Ÿ

Khattab et al. (2023)[^7]ã®DSPy (Declarative Self-improving Python)ã¯ã€**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ¼ãƒ‰ã§è¨˜è¿°ã—ã€è‡ªå‹•æœ€é©åŒ–**ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚

**å¾“æ¥ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**:
```rust
// æ‰‹ä½œæ¥­ã§æ–‡å­—åˆ—ã‚’èª¿æ•´
let text = "...";
let prompt = format!(
    "Translate the following text to Japanese:\n\nText: {}\nTranslation:",
    text
);
```

**DSPy**:
```rust
// æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: serde_json + reqwest ã§å‹å®‰å…¨ãªå‘¼ã³å‡ºã—ï¼ˆDSPyã®Signatureã«ç›¸å½“ï¼‰
use serde::Serialize;

// ã‚¿ã‚¹ã‚¯å®šç¾©ï¼ˆDSPyã®Signatureã«ç›¸å½“ï¼‰
#[derive(Serialize)]
struct TranslationTask {
    text: String,
}

fn chain_of_thought(task: &TranslationTask) -> Result<String, Box<dyn std::error::Error>> {
    let prompt = format!(
        "Translate the following text to Japanese.\nThink step by step, then provide the translation.\n\nText: {}\nTranslation:",
        task.text
    );
    let client = reqwest::blocking::Client::new();
    let body = serde_json::json!({
        "model": "gpt-4",
        "messages": [{ "role": "user", "content": prompt }]
    });
    let result: serde_json::Value = client
        .post("https://api.openai.com/v1/chat/completions")
        .header("Authorization", format!("Bearer {}", std::env::var("OPENAI_API_KEY")?))
        .json(&body)
        .send()?
        .json()?;
    Ok(result["choices"][0]["message"]["content"].as_str().unwrap_or("").to_owned())
}
```

**DSPyã®åˆ©ç‚¹**:

| å¾“æ¥ | DSPy |
|:-----|:-----|
| æ–‡å­—åˆ—ç·¨é›† | Pythonã‚³ãƒ¼ãƒ‰ |
| æ‰‹å‹•æœ€é©åŒ– | è‡ªå‹•æœ€é©åŒ– |
| ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†å›°é›£ | Gitã§ç®¡ç†å¯èƒ½ |
| ãƒ†ã‚¹ãƒˆå›°é›£ | ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆå¯èƒ½ |
| å‹ãƒã‚§ãƒƒã‚¯ãªã— | å‹ãƒ’ãƒ³ãƒˆæ´»ç”¨ |

#### 6.1.2 DSPyã®åŸºæœ¬æ§‹é€ 

**Signature**: ã‚¿ã‚¹ã‚¯ã®å…¥å‡ºåŠ›å®šç¾©
```rust
// æ•°å­¦æ¨è«–ã‚¿ã‚¹ã‚¯ã®æ§‹é€ åŒ–ï¼ˆDSPyã®Signatureã«ç›¸å½“ï¼‰
#[derive(Debug)]
struct MathTask {
    question: String,
}

#[derive(Debug)]
struct MathResult {
    reasoning: String,
    answer: f64,
}
```

**Module**: æ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
> **Note:** DSPyã¯Pythonå°‚ç”¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚Rustå®Ÿè£…ã§ã¯ `HTTP.jl` + `serde_json` ã§åŒç­‰ã®æ§‹é€ åŒ–å‘¼ã³å‡ºã—ã‚’å®Ÿç¾ã™ã‚‹ï¼ˆä¸Šè¨˜å‚ç…§ï¼‰ã€‚

**Optimizer**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè‡ªå‹•æœ€é©åŒ–
> **Note:** Few-shotæœ€é©åŒ–ã¯ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é«˜ã‚¹ã‚³ã‚¢ä¾‹ã‚’é¸æŠã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æŒ¿å…¥ã™ã‚‹æ“ä½œã€‚æ•°å¼: $p^* = \arg\max_p \mathbb{E}_{(x,y)\sim\mathcal{D}}[\text{score}(f_p(x), y)]$

#### 6.1.3 DSPyã®æœ€é©åŒ–æ‰‹æ³•

| æ‰‹æ³• | æ¦‚è¦ | ä½¿ã„ã©ã“ã‚ |
|:-----|:-----|:----------|
| **BootstrapFewShot** | è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€é©ãªä¾‹ã‚’è‡ªå‹•é¸æŠ | Few-shotæœ€é©åŒ– |
| **BootstrapFewShotWithRandomSearch** | ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã§ä¾‹ã‚’æ¢ç´¢ | æ¢ç´¢çš„æœ€é©åŒ– |
| **COPRO** | LLMã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè‡ªä½“ã‚’ç”Ÿæˆãƒ»æ”¹å–„ | ãƒ¡ã‚¿æœ€é©åŒ– |
| **MIPRO** | è¤‡æ•°æŒ‡æ¨™ã‚’åŒæ™‚æœ€é©åŒ– | Multi-objective |

**å®Ÿé¨“çµæœï¼ˆKhattab et al. 2023[^7]ï¼‰**:

| ã‚¿ã‚¹ã‚¯ | æ‰‹å‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ | DSPyæœ€é©åŒ– | å‘ä¸Šå¹… |
|:------|:-------------|:----------|:------|
| HotPotQA | 58.3% | **67.1%** | +8.8% |
| GSM8K | 62.4% | **71.9%** | +9.5% |
| FEVER | 72.1% | **79.3%** | +7.2% |

**DSPyã®å®Ÿç”¨ä¾‹**:
```rust
// æ„Ÿæƒ…åˆ†æ: serde_json + reqwest ã«ã‚ˆã‚‹æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
use serde::{Deserialize, Serialize};

#[derive(Debug, Serialize)]
struct SentimentTask {
    text: String,
}

#[derive(Debug, Deserialize)]
struct SentimentResult {
    sentiment: String,   // "positive" | "negative" | "neutral"
    confidence: f64,     // 0.0 ~ 1.0
}

fn analyze_sentiment(task: &SentimentTask) -> Result<SentimentResult, Box<dyn std::error::Error>> {
    let prompt = format!(
        "Analyze the sentiment of the following text.\n\nText: {}\n\nRespond in JSON format: {{\"sentiment\": \"positive|negative|neutral\", \"confidence\": 0.0-1.0}}",
        task.text
    );
    let client = reqwest::blocking::Client::new();
    let body = serde_json::json!({
        "model": "gpt-4o-mini",
        "messages": [{ "role": "user", "content": prompt }],
        "response_format": { "type": "json_object" }
    });
    let result: serde_json::Value = client
        .post("https://api.openai.com/v1/chat/completions")
        .header("Authorization", format!("Bearer {}", std::env::var("OPENAI_API_KEY")?))
        .json(&body)
        .send()?
        .json()?;
    let content = result["choices"][0]["message"]["content"].as_str().unwrap_or("{}");
    Ok(serde_json::from_str(content)?)
}

// æ¤œç®—
// let task = SentimentTask { text: "This movie is absolutely fantastic!".into() };
// result.sentiment => "positive", result.confidence => ~0.95
```hinelearning", "prompt", "rust", "rust", "llm"]
published: true
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Rust", "Elixir"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---

> **ç¬¬28å›ã€å‰ç·¨ã€‘**: [ç¬¬28å›ã€å‰ç·¨ã€‘](https://zenn.dev/fumishiki/ml-lecture-28-part1)

---
title: "ç¬¬28å›: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
slug: "ml-lecture-28-part2"
emoji: "ğŸ’¬"
type: "tech"
topics: ["machinelearning", "prompt", "rust", "julia", "llm"]
published: true
---

## ğŸ’» Z5. è©¦ç·´ï¼ˆå®Ÿè£…ï¼‰ï¼ˆ45åˆ†ï¼‰â€” Template Engine + Rustå®Ÿé¨“

**ã‚´ãƒ¼ãƒ«**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‹å®‰å…¨ã«ç®¡ç†ã™ã‚‹ğŸ¦€ Rust Template Engineã¨ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåŠ¹æœã‚’å®šé‡æ¸¬å®šã™ã‚‹ğŸ¦€ Rustå®Ÿé¨“ç’°å¢ƒã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

### 4.1 ãªãœTemplate EngineãŒå¿…è¦ãªã®ã‹ï¼Ÿ

Productionç’°å¢ƒã§ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã«ã¯ã€æ¬¡ã®èª²é¡ŒãŒã‚ã‚‹:

| èª²é¡Œ | ä¾‹ | ãƒªã‚¹ã‚¯ |
|:-----|:---|:------|
| **æ–‡å­—åˆ—çµåˆã®è„†å¼±æ€§** | `"Translate: " + user_input` | ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³æ”»æ’ƒ |
| **å‹å®‰å…¨æ€§ã®æ¬ å¦‚** | å¤‰æ•°åã‚¿ã‚¤ãƒã€å‹ãƒŸã‚¹ãƒãƒƒãƒ | å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼ |
| **ãƒ†ã‚¹ãƒˆå›°é›£** | ãƒ™ã‚¿æ›¸ãæ–‡å­—åˆ— | å¤‰æ›´ãŒå£Šã‚Œã‚„ã™ã„ |
| **ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†å›°é›£** | ã‚³ãƒ¼ãƒ‰ã«åŸ‹ã‚è¾¼ã¿ | A/Bãƒ†ã‚¹ãƒˆä¸å¯ |
| **å¤šè¨€èªå¯¾å¿œå›°é›£** | ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ | i18nä¸å¯ |

**è§£æ±ºç­–**: Template Engineã§**æ§‹é€ åŒ–ãƒ»å‹å®‰å…¨ãƒ»ãƒ†ã‚¹ãƒˆå¯èƒ½**ã«ã™ã‚‹ã€‚

### 4.2 ğŸ¦€ Rust Prompt Template Engine å®Ÿè£…

#### 4.2.1 è¨­è¨ˆæ–¹é‡

| åŸå‰‡ | å®Ÿç¾æ–¹æ³• |
|:-----|:--------|
| **å‹å®‰å…¨** | `struct PromptTemplate<T>` ã§ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚æ¤œè¨¼ |
| **ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³é˜²æ­¢** | è‡ªå‹•ã‚¨ã‚¹ã‚±ãƒ¼ãƒ— + ã‚µãƒ‹ã‚¿ã‚¤ã‚º |
| **ãƒ†ã‚¹ãƒˆå®¹æ˜“** | Templateåˆ†é›¢ + Mockå¤‰æ•° |
| **ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†** | YAML/TOMLå¤–éƒ¨åŒ– |
| **Zero-copy** | `&str` / `Cow<str>` ã§ä¸è¦ãªã‚³ãƒ”ãƒ¼å›é¿ |

#### 4.2.2 åŸºæœ¬å®Ÿè£…

**Cargo.toml**:
```toml
[package]
name = "prompt-template"
version = "0.1.0"
edition = "2021"

[dependencies]
serde = { version = "1.0", features = ["derive"] }
toml = "0.8"
thiserror = "1.0"
```

**src/lib.rs**:
```rust
use serde::{Deserialize, Serialize};
use std::borrow::Cow;
use std::collections::HashMap;
use thiserror::Error;

/// Template engine error types
#[derive(Error, Debug)]
pub enum TemplateError {
    #[error("Missing variable: {0}")]
    MissingVariable(String),
    #[error("Invalid template syntax: {0}")]
    InvalidSyntax(String),
    #[error("Serialization error: {0}")]
    SerializationError(#[from] toml::ser::Error),
}

/// Prompt template with typed variables
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PromptTemplate {
    /// Template string with {{variable}} placeholders
    template: String,
    /// Variable names (for validation)
    variables: Vec<String>,
    /// Metadata (version, author, etc.)
    #[serde(default)]
    metadata: HashMap<String, String>,
}

impl PromptTemplate {
    /// Create a new template
    pub fn new(template: String) -> Result<Self, TemplateError> {
        let variables = Self::extract_variables(&template)?;
        Ok(Self {
            template,
            variables,
            metadata: HashMap::new(),
        })
    }

    /// Extract {{variable}} placeholders from template
    fn extract_variables(template: &str) -> Result<Vec<String>, TemplateError> {
        let mut vars = Vec::new();
        let mut chars = template.chars().peekable();

        while let Some(c) = chars.next() {
            if c == '{' && chars.peek() == Some(&'{') {
                chars.next(); // consume second '{'
                let mut var_name = String::new();

                while let Some(c) = chars.next() {
                    if c == '}' && chars.peek() == Some(&'}') {
                        chars.next(); // consume second '}'
                        if !var_name.is_empty() {
                            vars.push(var_name.trim().to_string());
                        }
                        break;
                    }
                    var_name.push(c);
                }
            }
        }

        Ok(vars)
    }

    /// Render template with provided variables
    pub fn render(&self, vars: &HashMap<String, String>) -> Result<String, TemplateError> {
        // Validate all required variables are provided
        if let Some(var) = self.variables.iter().find(|v| !vars.contains_key(*v)) {
            return Err(TemplateError::MissingVariable(var.clone()));
        }

        // Replace variables (with sanitization)
        let result = vars.iter().fold(self.template.clone(), |acc, (key, value)| {
            acc.replace(&format!("{{{{{}}}}}", key), &Self::sanitize(value))
        });

        Ok(result)
    }

    /// Sanitize user input (basic XML escaping)
    fn sanitize(input: &str) -> Cow<str> {
        if input.contains(&['<', '>', '&', '"', '\''][..]) {
            Cow::Owned(
                input
                    .replace('&', "&amp;")
                    .replace('<', "&lt;")
                    .replace('>', "&gt;")
                    .replace('"', "&quot;")
                    .replace('\'', "&apos;"),
            )
        } else {
            Cow::Borrowed(input)
        }
    }

    /// Add metadata
    pub fn with_metadata(mut self, key: String, value: String) -> Self {
        self.metadata.insert(key, value);
        self
    }

    /// Get required variables
    pub fn variables(&self) -> &[String] {
        &self.variables
    }
}

/// Chain-of-Thought prompt builder
#[derive(Debug)]
pub struct CoTPromptBuilder {
    task: String,
    examples: Vec<(String, String, String)>, // (question, reasoning, answer)
    question: String,
}

impl CoTPromptBuilder {
    pub fn new(task: &str) -> Self {
        Self {
            task: task.to_string(),
            examples: Vec::new(),
            question: String::new(),
        }
    }

    pub fn add_example(mut self, question: &str, reasoning: &str, answer: &str) -> Self {
        self.examples.push((
            question.to_string(),
            reasoning.to_string(),
            answer.to_string(),
        ));
        self
    }

    pub fn question(mut self, q: &str) -> Self {
        self.question = q.to_string();
        self
    }

    pub fn build(self) -> String {
        let examples = self.examples.iter().enumerate()
            .map(|(i, (q, r, a))| format!("# ä¾‹{}nå•é¡Œ: {}næ¨è«–:n{}nç­”ãˆ: {}nn", i + 1, q, r, a))
            .collect::<String>();
        format!("{}nn{}# å•é¡Œnå•é¡Œ: {}næ¨è«–:n", self.task, examples, self.question)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_template_extraction() {
        let template = "Hello {{name}}, your task is {{task}}.";
        let pt = PromptTemplate::new(template.to_string()).unwrap();
        assert_eq!(pt.variables(), &["name", "task"]);
    }

    #[test]
    fn test_template_render() {
        let template = "Translate '{{text}}' to {{language}}.";
        let pt = PromptTemplate::new(template.to_string()).unwrap();

        let mut vars = HashMap::new();
        vars.insert("text".to_string(), "Hello".to_string());
        vars.insert("language".to_string(), "Japanese".to_string());

        let result = pt.render(&vars).unwrap();
        assert_eq!(result, "Translate 'Hello' to Japanese.");
    }

    #[test]
    fn test_sanitization() {
        let template = "Input: {{user_input}}";
        let pt = PromptTemplate::new(template.to_string()).unwrap();

        let mut vars = HashMap::new();
        vars.insert("user_input".to_string(), "<script>alert('xss')</script>".to_string());

        let result = pt.render(&vars).unwrap();
        assert!(result.contains("&lt;script&gt;"));
    }

    #[test]
    fn test_cot_builder() {
        let prompt = CoTPromptBuilder::new("æ¬¡ã®ç®—æ•°å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚")
            .add_example(
                "5 + 3ã¯ï¼Ÿ",
                "5ã«3ã‚’è¶³ã™ã¨8ã«ãªã‚‹ã€‚",
                "8",
            )
            .question("12 - 7ã¯ï¼Ÿ")
            .build();

        assert!(prompt.contains("ä¾‹1"));
        assert!(prompt.contains("5 + 3ã¯ï¼Ÿ"));
        assert!(prompt.contains("12 - 7ã¯ï¼Ÿ"));
    }
}
```

#### 4.2.3 TOML Templateå¤–éƒ¨åŒ–

**prompts/math_cot.toml**:
```toml
[template]
template = """
ã‚ãªãŸã¯{{role}}ã§ã™ã€‚ä»¥ä¸‹ã®å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚

## åˆ¶ç´„
{{#each constraints}}
- {{this}}
{{/each}}

## å•é¡Œ
{{problem}}

## å‡ºåŠ›å½¢å¼
### ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®è¨ˆç®—
[è¨ˆç®—éç¨‹]

### æœ€çµ‚çš„ãªç­”ãˆ
ç­”ãˆ: [æ•°å€¤]
"""
variables = ["role", "constraints", "problem"]

[metadata]
version = "1.0.0"
author = "prompt-team"
task = "math-reasoning"
```

**ä½¿ç”¨ä¾‹**:
```rust
use std::fs;

// Load template from file
let toml_str = fs::read_to_string("prompts/math_cot.toml")?;
let template: PromptTemplate = toml::from_str(&toml_str)?;

// Render with variables
let mut vars = HashMap::new();
vars.insert("role".to_string(), "æ•°å­¦ã®å®¶åº­æ•™å¸«".to_string());
vars.insert("problem".to_string(), "å¤ªéƒã¯12å€‹ã®ãƒªãƒ³ã‚´ã‚’...".to_string());

let prompt = template.render(&vars)?;
```

### 4.3 ğŸ¦€ Rust Promptå®Ÿé¨“ç’°å¢ƒ

#### 4.3.1 å®Ÿé¨“è¨­è¨ˆ

ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã®åŠ¹æœã‚’å®šé‡æ¸¬å®šã™ã‚‹å®Ÿé¨“ç’°å¢ƒã‚’æ§‹ç¯‰:

```rust
// Promptå®Ÿé¨“ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: LLMå‘¼ã³å‡ºã— + Self-Consistency
use std::collections::HashMap;

/// LLM APIå‘¼ã³å‡ºã—ï¼ˆOllamaå‰æï¼‰
fn call_llm(prompt: &str, model: &str, temperature: f64) -> Result<String, Box<dyn std::error::Error>> {
    let client = reqwest::blocking::Client::new();
    let body = serde_json::json!({
        "model": model,
        "prompt": prompt,
        "stream": false,
        "options": { "temperature": temperature }
    });
    let result: serde_json::Value = client
        .post("http://localhost:11434/api/generate")
        .json(&body)
        .send()?
        .json()?;
    Ok(result["response"].as_str().unwrap_or("").to_owned())
}

/// ç­”ãˆã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ãƒ‘ãƒ¼ã‚µãƒ¼ï¼‰: "ç­”ãˆ: N" / "Nå€‹" / å˜ç‹¬ã®æ•°å­—
fn extract_answer(response: &str) -> Option<i64> {
    for pattern in [r"ç­”ãˆ[ï¼š:]\s*(\d+)", r"(\d+)å€‹", r"^\d+$"] {
        let re = regex::Regex::new(pattern).unwrap();
        if let Some(cap) = re.captures(response) {
            if let Ok(n) = cap[1].parse() {
                return Some(n);
            }
        }
    }
    None
}

/// Self-Consistency: nå›ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦å¤šæ•°æ±º
fn self_consistency(prompt: &str, n: usize, model: &str) -> Option<i64> {
    let answers: Vec<i64> = (0..n)
        .filter_map(|_| call_llm(prompt, model, 0.8).ok().and_then(|r| extract_answer(&r)))
        .collect();
    if answers.is_empty() { return None; }
    let mut counts: HashMap<i64, usize> = HashMap::new();
    for &a in &answers { *counts.entry(a).or_default() += 1; }
    counts.into_iter().max_by_key(|(_, c)| *c).map(|(a, _)| a)
}

/// å®Ÿé¨“çµæœãƒ¬ã‚³ãƒ¼ãƒ‰
#[derive(Debug)]
struct ExperimentResult {
    method: String,
    question_id: usize,
    trial: usize,
    answer: Option<i64>,
    correct: Option<bool>,
    latency_ms: f64,
}

/// ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã®æ¯”è¼ƒå®Ÿé¨“
fn run_experiment(
    experiments: &[(&str, &dyn Fn(&str) -> String)],
    questions: &[(&str, i64)],
    model: &str,
    n_trials: usize,
) -> Vec<ExperimentResult> {
    let mut results = Vec::new();
    for &(method_name, prompt_fn) in experiments {
        for (q_id, &(question, truth)) in questions.iter().enumerate() {
            let prompt = prompt_fn(question);
            for trial in 0..n_trials {
                let start = std::time::Instant::now();
                let response = call_llm(&prompt, model, 0.7).unwrap_or_default();
                let latency_ms = start.elapsed().as_secs_f64() * 1000.0;
                let answer = extract_answer(&response);
                let correct = answer.map(|a| a == truth);
                results.push(ExperimentResult {
                    method: method_name.to_string(),
                    question_id: q_id, trial, answer, correct, latency_ms,
                });
            }
        }
    }
    results
}

/// çµæœã‚’é›†è¨ˆ: method â†’ (accuracy%, mean_latency_ms)
fn summarize_results(results: &[ExperimentResult]) -> Vec<(String, f64, f64)> {
    let mut by_method: HashMap<&str, Vec<&ExperimentResult>> = HashMap::new();
    for r in results { by_method.entry(&r.method).or_default().push(r); }
    by_method.into_iter().map(|(method, records)| {
        let correct: Vec<f64> = records.iter()
            .filter_map(|r| r.correct)
            .map(|c| c as u8 as f64)
            .collect();
        let accuracy = if correct.is_empty() { 0.0 }
                       else { correct.iter().sum::<f64>() / correct.len() as f64 * 100.0 };
        let mean_latency = records.iter().map(|r| r.latency_ms).sum::<f64>()
            / records.len() as f64;
        (method.to_string(), accuracy, mean_latency)
    }).collect()
}
```

#### 4.3.2 å®Ÿé¨“å®Ÿè¡Œä¾‹

```rust
fn main() {
    // ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ï¼ˆç®—æ•°å•é¡Œï¼‰
    let questions: &[(&str, i64)] = &[
        ("å¤ªéƒã¯12å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¦ã€èŠ±å­ã«3å€‹ã‚ã’ã¾ã—ãŸã€‚ãã®å¾Œã€æ¯è¦ªã‹ã‚‰5å€‹ã‚‚ã‚‰ã„ã¾ã—ãŸã€‚å¤ªéƒã¯ä»Šä½•å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ", 14),
        ("æ•™å®¤ã«ç”Ÿå¾’ãŒ25äººã„ã¾ã™ã€‚5äººãŒå¸°ã‚Šã¾ã—ãŸã€‚ãã®å¾Œã€3äººãŒæ¥ã¾ã—ãŸã€‚ä»Šã€æ•™å®¤ã«ã¯ä½•äººã„ã¾ã™ã‹ï¼Ÿ", 23),
        ("ã‚Šã‚“ã”ãŒ8å€‹ã€ã¿ã‹ã‚“ãŒ5å€‹ã‚ã‚Šã¾ã™ã€‚åˆã‚ã›ã¦ä½•å€‹ã§ã™ã‹ï¼Ÿ", 13),
        ("100å††ã®ãƒãƒ¼ãƒˆã‚’3å†Šè²·ã„ã¾ã—ãŸã€‚1000å††å‡ºã—ãŸã‚‰ãŠã¤ã‚Šã¯ã„ãã‚‰ã§ã™ã‹ï¼Ÿ", 700),
        ("1æ™‚é–“ã¯60åˆ†ã§ã™ã€‚2æ™‚é–“30åˆ†ã¯ä½•åˆ†ã§ã™ã‹ï¼Ÿ", 150),
    ];

    // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã®å®šç¾©
    let direct:       &dyn Fn(&str) -> String = &|q| format!("æ¬¡ã®å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚\n\nå•é¡Œ: {}\nç­”ãˆ:", q);
    let zero_cot:     &dyn Fn(&str) -> String = &|q| format!("æ¬¡ã®å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚\n\nå•é¡Œ: {}\n\nLet's think step by step.", q);
    let few_cot:      &dyn Fn(&str) -> String = &|q| format!(
        "ä»¥ä¸‹ã®ç®—æ•°å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚\n\n# ä¾‹1\nå•é¡Œ: ãƒªãƒ³ã‚´ãŒ5å€‹ã‚ã‚Šã¾ã™ã€‚2å€‹é£Ÿã¹ã¾ã—ãŸã€‚æ®‹ã‚Šã¯ä½•å€‹ã§ã™ã‹ï¼Ÿ\næ¨è«–:\n- æœ€åˆã«ãƒªãƒ³ã‚´ãŒ5å€‹ã‚ã‚‹\n- 2å€‹é£Ÿã¹ãŸã®ã§ã€5 - 2 = 3\nç­”ãˆ: 3å€‹\n\n# å•é¡Œ\nå•é¡Œ: {}\næ¨è«–:", q
    );

    let experiments: &[(&str, &dyn Fn(&str) -> String)] = &[
        ("Direct",        direct),
        ("Zero-shot CoT", zero_cot),
        ("Few-shot CoT",  few_cot),
    ];

    // å®Ÿé¨“å®Ÿè¡Œ
    let results = run_experiment(experiments, questions, "llama3.2:3b", 3);

    // çµæœé›†è¨ˆ
    let mut summary = summarize_results(&results);
    summary.sort_by(|a, b| a.0.cmp(&b.0));
    for (method, accuracy, latency) in &summary {
        println!("{}: accuracy={:.1}%, mean_latency={:.1}ms", method, accuracy, latency);
    }

    // CSVä¿å­˜ï¼ˆserde + csv ã‚¯ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ï¼‰
    // csv::Writer::from_path("prompt_experiment_results.csv").unwrap()...
}
```

**å‡ºåŠ›ä¾‹**:
```
3Ã—5 DataFrame
 Row â”‚ method          accuracy  latency_mean  latency_std  n_valid
     â”‚ String          Float64   Float64       Float64      Int64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚ Direct              46.7         823.2         45.3       15
   2 â”‚ Zero-shot CoT       73.3        1245.8         67.1       15
   3 â”‚ Few-shot CoT        86.7        1456.3         52.8       15
```

#### 4.3.3 çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š

```rust
// 2ã¤ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã®ç²¾åº¦å·®ãŒçµ±è¨ˆçš„ã«æœ‰æ„ã‹ã‚’æ¤œå®šï¼ˆWelch's t-testï¼‰
fn compare_methods(results: &[ExperimentResult], method1: &str, method2: &str) {
    let extract = |m: &str| -> Vec<f64> {
        results.iter()
            .filter(|r| r.method == m)
            .filter_map(|r| r.correct)
            .map(|c| c as u8 as f64)
            .collect()
    };
    let correct1 = extract(method1);
    let correct2 = extract(method2);

    let mean = |v: &[f64]| v.iter().sum::<f64>() / v.len() as f64;
    let var  = |v: &[f64], m: f64| v.iter().map(|x| (x - m).powi(2)).sum::<f64>() / v.len() as f64;

    let m1 = mean(&correct1);
    let m2 = mean(&correct2);
    let v1 = var(&correct1, m1);
    let v2 = var(&correct2, m2);
    let n1 = correct1.len() as f64;
    let n2 = correct2.len() as f64;

    // Welch's t-statistic
    let t_stat = (m1 - m2) / (v1 / n1 + v2 / n2).sqrt();

    println!("Comparing {} vs {}:", method1, method2);
    println!("  {}: mean={:.3}, std={:.3}", method1, m1, v1.sqrt());
    println!("  {}: mean={:.3}, std={:.3}", method2, m2, v2.sqrt());
    println!("  t-statistic: {:.3}", t_stat);
    // NOTE: p-value requires t-distribution CDF; use `statrs` crate for full testing
}

// Few-shot CoT vs Direct ã®æ¯”è¼ƒ
// compare_methods(&results, "Few-shot CoT", "Direct");
```

### 4.4 XML vs Markdown ãƒˆãƒ¼ã‚¯ãƒ³æ¯”è¼ƒå®Ÿé¨“

```rust
// XML vs Markdown ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¯”è¼ƒ
fn compare_formats() -> (usize, usize, f64) {
    // åŒã˜å†…å®¹ã‚’XMLã¨Markdownã§è¡¨ç¾
    let xml_prompt = r#"<task>
  <role>ã‚ãªãŸã¯æ•°å­¦ã®å®¶åº­æ•™å¸«ã§ã™</role>
  <instruction>ä»¥ä¸‹ã®å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„</instruction>
  <constraints>
    <constraint>ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«è¨ˆç®—éç¨‹ã‚’ç¤ºã™ã“ã¨</constraint>
    <constraint>æœ€çµ‚çš„ãªç­”ãˆã‚’æ•°å€¤ã§ç¤ºã™ã“ã¨</constraint>
  </constraints>
  <input>
    <problem>å¤ªéƒã¯12å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¦ã€èŠ±å­ã«3å€‹ã‚ã’ã¾ã—ãŸã€‚ãã®å¾Œã€æ¯è¦ªã‹ã‚‰5å€‹ã‚‚ã‚‰ã„ã¾ã—ãŸã€‚å¤ªéƒã¯ä»Šä½•å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ</problem>
  </input>
</task>"#;

    let md_prompt = "# ã‚¿ã‚¹ã‚¯

ã‚ãªãŸã¯æ•°å­¦ã®å®¶åº­æ•™å¸«ã§ã™ã€‚ä»¥ä¸‹ã®å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚

## åˆ¶ç´„
- ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«è¨ˆç®—éç¨‹ã‚’ç¤ºã™ã“ã¨
- æœ€çµ‚çš„ãªç­”ãˆã‚’æ•°å€¤ã§ç¤ºã™ã“ã¨

## å•é¡Œ
å¤ªéƒã¯12å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¦ã€èŠ±å­ã«3å€‹ã‚ã’ã¾ã—ãŸã€‚ãã®å¾Œã€æ¯è¦ªã‹ã‚‰5å€‹ã‚‚ã‚‰ã„ã¾ã—ãŸã€‚å¤ªéƒã¯ä»Šä½•å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ";

    // ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¿‘ä¼¼ï¼ˆç©ºç™½ãƒ»æ”¹è¡Œã§åˆ†å‰²ï¼‰
    let xml_tokens = xml_prompt.split_whitespace().count();
    let md_tokens  = md_prompt.split_whitespace().count();
    let reduction  = (xml_tokens - md_tokens) as f64 / xml_tokens as f64 * 100.0;

    println!("Token Count Comparison:");
    println!("  XML: {} tokens", xml_tokens);
    println!("  Markdown: {} tokens", md_tokens);
    println!("  Reduction: {:.1}%", reduction);

    (xml_tokens, md_tokens, reduction)
}
```

> **Note:** **å®Ÿè£…ã‚¾ãƒ¼ãƒ³çµ‚äº†** ğŸ¦€ Rust Template Engineã§å‹å®‰å…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚’å®Ÿç¾ã€‚ğŸ¦€ Rustã§å®šé‡å®Ÿé¨“ç’°å¢ƒã‚’æ§‹ç¯‰ã—ã€çµ±è¨ˆæ¤œå®šã¾ã§å®Ÿè£…ã—ãŸã€‚

> **Note:** **é€²æ—: 70% å®Œäº†** å®Ÿè£…åŸºç›¤ãŒå®Œæˆã—ãŸã€‚æ¬¡ã¯å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ã§ã€SmolVLM2-256Mã‚’ä½¿ã£ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ã‚’å®Ÿæ¼”ã™ã‚‹ã€‚

---
---
title: "ç¬¬28å›: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
slug: "ml-lecture-28-part2"
emoji: "ğŸ’¬"
type: "tech"
topics: ["machinelearning", "prompt", "rust", "julia", "llm"]
published: true
---


> Progress: [85%]
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. Rustã®Prompt Template Engineã§JSONã‚¹ã‚­ãƒ¼ãƒãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè£…ã™ã‚‹å‹å®‰å…¨ä¸Šã®ç†ç”±ã¯ï¼Ÿ
> 2. Few-shotä¾‹ã®é¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹é¸æŠï¼ˆSemantic Similarityï¼‰ã§éé©åˆãŒèµ·ãã‚‹æ¡ä»¶ã¯ï¼Ÿ

### ğŸ”¬ å®Ÿé¨“ãƒ»æ¤œè¨¼ï¼ˆ30åˆ†ï¼‰â€” SmolVLM2 Promptæœ€é©åŒ–

**ã‚´ãƒ¼ãƒ«**: è»½é‡VLM (SmolVLM2-256M)ã‚’ä½¿ã£ã¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã®åŠ¹æœã‚’å®Ÿæ¸¬ã™ã‚‹ã€‚

### 5.1 å®Ÿé¨“ç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

#### 5.1.1 SmolVLM2ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

SmolVLM2-256Mã¯ã€HuggingFace Transformersã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€‚256Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§è»½é‡ãªãŒã‚‰ã€ç”»åƒ+ãƒ†ã‚­ã‚¹ãƒˆã®æ¨è«–ãŒå¯èƒ½ã€‚

```bash
# Ollamaã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
ollama pull smolvlm:256m

# ã¾ãŸã¯ HuggingFace Transformers
pip install transformers pillow torch
```

**Rust ã‹ã‚‰å‘¼ã³å‡ºã—**:
```rust
// SmolVLM2 ã«ç”»åƒ+ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡
fn call_smolvlm(prompt: &str, image_path: Option<&str>) -> Result<String, Box<dyn std::error::Error>> {
    let client = reqwest::blocking::Client::new();
    let mut body = serde_json::json!({
        "model": "smolvlm:256m",
        "prompt": prompt,
        "stream": false
    });
    // ç”»åƒãŒã‚ã‚‹å ´åˆã¯Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    if let Some(path) = image_path {
        let img_bytes = std::fs::read(path)?;
        let img_base64 = base64::encode(&img_bytes);
        body["images"] = serde_json::json!([img_base64]);
    }
    let result: serde_json::Value = client
        .post("http://localhost:11434/api/generate")
        .json(&body)
        .send()?
        .json()?;
    Ok(result["response"].as_str().unwrap_or("").to_owned())
}
```

### 5.2 å®Ÿé¨“1: Zero-shot vs Few-shot (ãƒ†ã‚­ã‚¹ãƒˆæ¨è«–)

**ã‚¿ã‚¹ã‚¯**: ç®—æ•°å•é¡Œã®æ­£ç­”ç‡ã‚’æ¸¬å®š

```rust
fn zero_shot_prompt(question: &str) -> String {
    format!("æ¬¡ã®è¨ˆç®—å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚\n\nå•é¡Œ: {}\nç­”ãˆ:", question)
}

fn few_shot_prompt(question: &str) -> String {
    format!(
        "æ¬¡ã®è¨ˆç®—å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚\n\n# ä¾‹1\nå•é¡Œ: 2 + 3 = ?\nç­”ãˆ: 5\n\n# ä¾‹2\nå•é¡Œ: 10 - 4 = ?\nç­”ãˆ: 6\n\n# ä¾‹3\nå•é¡Œ: 3 Ã— 5 = ?\nç­”ãˆ: 15\n\n# å•é¡Œ\nå•é¡Œ: {}\nç­”ãˆ:",
        question
    )
}

#[derive(Debug)]
struct MathResult {
    method: String,
    question: String,
    ground_truth: i64,
    predicted: Option<i64>,
    correct: Option<bool>,
}

fn run_math_experiment() -> Vec<MathResult> {
    let test_cases: &[(&str, i64)] = &[
        ("5 + 3 = ?", 8),
        ("12 - 7 = ?", 5),
        ("4 Ã— 6 = ?", 24),
        ("15 Ã· 3 = ?", 5),
        ("(8 + 2) Ã— 3 = ?", 30),
    ];
    let mut results = Vec::new();
    for &(question, truth) in test_cases {
        for (method, prompt_fn) in [
            ("Zero-shot", zero_shot_prompt as fn(&str) -> String),
            ("Few-shot",  few_shot_prompt),
        ] {
            if let Ok(resp) = call_smolvlm(&prompt_fn(question), None) {
                let pred = extract_answer(&resp);
                results.push(MathResult {
                    method: method.into(), question: question.into(),
                    ground_truth: truth, predicted: pred,
                    correct: pred.map(|p| p == truth),
                });
            }
        }
    }
    results
}

fn summarize_by_method(results: &[MathResult]) {
    for method in &["Zero-shot", "Few-shot"] {
        let valid: Vec<bool> = results.iter()
            .filter(|r| r.method == *method)
            .filter_map(|r| r.correct)
            .collect();
        let accuracy = if valid.is_empty() { 0.0 }
            else { valid.iter().filter(|&&c| c).count() as f64 / valid.len() as f64 * 100.0 };
        println!("{}: accuracy={:.1}%, n_valid={}", method, accuracy, valid.len());
    }
}
```

**æœŸå¾…ã•ã‚Œã‚‹çµæœ**:
```
2Ã—2 DataFrame
 Row â”‚ method     accuracy  n_valid
     â”‚ String     Float64   Int64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚ Zero-shot      60.0        5
   2 â”‚ Few-shot       100.0       5
```

### 5.3 å®Ÿé¨“2: Chain-of-ThoughtåŠ¹æœã®æ¸¬å®š

**ã‚¿ã‚¹ã‚¯**: è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã®æ¨è«–ãŒå¿…è¦ãªå•é¡Œ

```rust
fn direct_prompt(question: &str) -> String {
    format!("å•é¡Œ: {}\nç­”ãˆ:", question)
}

fn cot_prompt(question: &str) -> String {
    format!("å•é¡Œ: {}\n\nã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«è€ƒãˆã¾ã—ã‚‡ã†:", question)
}

fn few_shot_cot_prompt(question: &str) -> String {
    format!(
        "ä»¥ä¸‹ã®ç®—æ•°å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚\n\n# ä¾‹1\nå•é¡Œ: ãƒªãƒ³ã‚´ãŒ5å€‹ã‚ã‚Šã¾ã™ã€‚2å€‹é£Ÿã¹ã¾ã—ãŸã€‚æ®‹ã‚Šã¯ä½•å€‹ã§ã™ã‹ï¼Ÿ\næ¨è«–:\n- æœ€åˆã«ãƒªãƒ³ã‚´ãŒ5å€‹ã‚ã‚‹\n- 2å€‹é£Ÿã¹ãŸã®ã§ã€5 - 2 = 3\nç­”ãˆ: 3å€‹\n\n# ä¾‹2\nå•é¡Œ: å¤ªéƒã¯10å€‹ã®ã¿ã‹ã‚“ã‚’æŒã£ã¦ã„ã¾ã™ã€‚èŠ±å­ã«3å€‹ã‚ã’ã€ã•ã‚‰ã«æ¯è¦ªã‹ã‚‰4å€‹ã‚‚ã‚‰ã„ã¾ã—ãŸã€‚å¤ªéƒã¯ä»Šä½•å€‹ã®ã¿ã‹ã‚“ã‚’æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ\næ¨è«–:\n- æœ€åˆã«10å€‹\n- èŠ±å­ã«3å€‹ã‚ã’ãŸã®ã§ã€10 - 3 = 7å€‹\n- æ¯è¦ªã‹ã‚‰4å€‹ã‚‚ã‚‰ã£ãŸã®ã§ã€7 + 4 = 11å€‹\nç­”ãˆ: 11å€‹\n\n# å•é¡Œ\nå•é¡Œ: {}\næ¨è«–:",
        question
    )
}

#[derive(Debug)]
struct CotResult {
    method: String,
    question_id: usize,
    predicted: Option<i64>,
    correct: Option<bool>,
}

fn run_cot_experiment() -> Vec<CotResult> {
    let complex_cases: &[(&str, i64)] = &[
        ("å¤ªéƒã¯12å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¦ã€èŠ±å­ã«3å€‹ã‚ã’ã¾ã—ãŸã€‚ãã®å¾Œã€æ¯è¦ªã‹ã‚‰5å€‹ã‚‚ã‚‰ã„ã¾ã—ãŸã€‚å¤ªéƒã¯ä»Šä½•å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ", 14),
        ("æ•™å®¤ã«ç”Ÿå¾’ãŒ25äººã„ã¾ã™ã€‚5äººãŒå¸°ã‚Šã¾ã—ãŸã€‚ãã®å¾Œã€3äººãŒæ¥ã¾ã—ãŸã€‚ä»Šã€æ•™å®¤ã«ã¯ä½•äººã„ã¾ã™ã‹ï¼Ÿ", 23),
        ("ã‚Šã‚“ã”ãŒ8å€‹ã€ã¿ã‹ã‚“ãŒ5å€‹ã‚ã‚Šã¾ã™ã€‚ã‚Šã‚“ã”ã‚’2å€‹é£Ÿã¹ã€ã¿ã‹ã‚“ã‚’1å€‹é£Ÿã¹ã¾ã—ãŸã€‚æ®‹ã‚Šã¯åˆã‚ã›ã¦ä½•å€‹ã§ã™ã‹ï¼Ÿ", 10),
    ];
    let mut results = Vec::new();
    for (q_id, &(question, truth)) in complex_cases.iter().enumerate() {
        for (method, prompt_fn) in [
            ("Direct",        direct_prompt as fn(&str) -> String),
            ("Zero-shot CoT", cot_prompt),
            ("Few-shot CoT",  few_shot_cot_prompt),
        ] {
            if let Ok(response) = call_smolvlm(&prompt_fn(question), None) {
                let pred = extract_answer(&response);
                results.push(CotResult {
                    method: method.into(), question_id: q_id,
                    predicted: pred, correct: pred.map(|p| p == truth),
                });
            }
        }
    }
    results
}

fn summarize_cot(results: &[CotResult]) {
    for method in &["Direct", "Zero-shot CoT", "Few-shot CoT"] {
        let valid: Vec<bool> = results.iter()
            .filter(|r| r.method == *method)
            .filter_map(|r| r.correct)
            .collect();
        let accuracy = if valid.is_empty() { 0.0 }
            else { valid.iter().filter(|&&c| c).count() as f64 / valid.len() as f64 * 100.0 };
        println!("{}: accuracy={:.1}%, n_total={}", method, accuracy, valid.len());
    }
}
```

**æœŸå¾…ã•ã‚Œã‚‹çµæœ**:
```
3Ã—2 DataFrame
 Row â”‚ method          accuracy  n_total
     â”‚ String          Float64   Int64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚ Direct              33.3        3
   2 â”‚ Zero-shot CoT       66.7        3
   3 â”‚ Few-shot CoT       100.0        3
```

### 5.4 å®Ÿé¨“3: XML vs Markdownæ§‹é€ åŒ–æ¯”è¼ƒ

```rust
fn xml_structured_prompt(question: &str) -> String {
    format!(
        "<task>\n  <role>ã‚ãªãŸã¯æ•°å­¦ã®å®¶åº­æ•™å¸«ã§ã™</role>\n  <instruction>ä»¥ä¸‹ã®å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„</instruction>\n  <constraints>\n    <constraint>ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«è¨ˆç®—éç¨‹ã‚’ç¤ºã™ã“ã¨</constraint>\n  </constraints>\n  <input>\n    <problem>{}</problem>\n  </input>\n</task>",
        question
    )
}

fn md_structured_prompt(question: &str) -> String {
    format!(
        "# ã‚¿ã‚¹ã‚¯\n\nã‚ãªãŸã¯æ•°å­¦ã®å®¶åº­æ•™å¸«ã§ã™ã€‚ä»¥ä¸‹ã®å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚\n\n## åˆ¶ç´„\n- ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«è¨ˆç®—éç¨‹ã‚’ç¤ºã™ã“ã¨\n\n## å•é¡Œ\n{}",
        question
    )
}

#[derive(Debug)]
struct FormatResult {
    format: String,
    question_id: usize,
    tokens_approx: usize,
    predicted: Option<i64>,
    correct: Option<bool>,
}

fn run_format_experiment() -> Vec<FormatResult> {
    let complex_cases: &[(&str, i64)] = &[
        ("å¤ªéƒã¯12å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¦ã€èŠ±å­ã«3å€‹ã‚ã’ã¾ã—ãŸã€‚ãã®å¾Œã€æ¯è¦ªã‹ã‚‰5å€‹ã‚‚ã‚‰ã„ã¾ã—ãŸã€‚å¤ªéƒã¯ä»Šä½•å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ", 14),
        ("æ•™å®¤ã«ç”Ÿå¾’ãŒ25äººã„ã¾ã™ã€‚5äººãŒå¸°ã‚Šã¾ã—ãŸã€‚ãã®å¾Œã€3äººãŒæ¥ã¾ã—ãŸã€‚ä»Šã€æ•™å®¤ã«ã¯ä½•äººã„ã¾ã™ã‹ï¼Ÿ", 23),
        ("ã‚Šã‚“ã”ãŒ8å€‹ã€ã¿ã‹ã‚“ãŒ5å€‹ã‚ã‚Šã¾ã™ã€‚ã‚Šã‚“ã”ã‚’2å€‹é£Ÿã¹ã€ã¿ã‹ã‚“ã‚’1å€‹é£Ÿã¹ã¾ã—ãŸã€‚æ®‹ã‚Šã¯åˆã‚ã›ã¦ä½•å€‹ã§ã™ã‹ï¼Ÿ", 10),
    ];
    let mut results = Vec::new();
    for (q_id, &(question, truth)) in complex_cases.iter().enumerate() {
        for (fmt, prompt_fn) in [
            ("XML",      xml_structured_prompt as fn(&str) -> String),
            ("Markdown", md_structured_prompt),
        ] {
            let prompt = prompt_fn(question);
            let tokens = prompt.split_whitespace().count();
            if let Ok(resp) = call_smolvlm(&prompt, None) {
                let pred = extract_answer(&resp);
                results.push(FormatResult {
                    format: fmt.into(), question_id: q_id, tokens_approx: tokens,
                    predicted: pred, correct: pred.map(|p| p == truth),
                });
            }
        }
    }
    results
}

fn summarize_format(results: &[FormatResult]) {
    for fmt in &["XML", "Markdown"] {
        let records: Vec<&FormatResult> = results.iter().filter(|r| r.format == *fmt).collect();
        let valid: Vec<bool> = records.iter().filter_map(|r| r.correct).collect();
        let accuracy = if valid.is_empty() { 0.0 }
            else { valid.iter().filter(|&&c| c).count() as f64 / valid.len() as f64 * 100.0 };
        let avg_tokens = records.iter().map(|r| r.tokens_approx).sum::<usize>() as f64
            / records.len().max(1) as f64;
        println!("{}: accuracy={:.1}%, avg_tokens={:.1}", fmt, accuracy, avg_tokens);
    }
}
```

**æœŸå¾…ã•ã‚Œã‚‹çµæœ**:
```
2Ã—4 DataFrame
 Row â”‚ format    accuracy  avg_tokens  token_reduction
     â”‚ String    Float64   Float64     Float64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚ XML           100.0        65.3             0.0
   2 â”‚ Markdown      100.0        54.7            16.2
```

### 5.5 å®Ÿé¨“4: Self-Consistency ã®ç²¾åº¦å‘ä¸Šæ¸¬å®š

```rust
fn run_self_consistency_experiment() -> Vec<(usize, usize, Option<i64>, bool, f64)> {
    let complex_cases: &[(&str, i64)] = &[
        ("å¤ªéƒã¯12å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¦ã€èŠ±å­ã«3å€‹ã‚ã’ã¾ã—ãŸã€‚ãã®å¾Œã€æ¯è¦ªã‹ã‚‰5å€‹ã‚‚ã‚‰ã„ã¾ã—ãŸã€‚å¤ªéƒã¯ä»Šä½•å€‹ã®ãƒªãƒ³ã‚´ã‚’æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ", 14),
        ("æ•™å®¤ã«ç”Ÿå¾’ãŒ25äººã„ã¾ã™ã€‚5äººãŒå¸°ã‚Šã¾ã—ãŸã€‚ãã®å¾Œã€3äººãŒæ¥ã¾ã—ãŸã€‚ä»Šã€æ•™å®¤ã«ã¯ä½•äººã„ã¾ã™ã‹ï¼Ÿ", 23),
        ("ã‚Šã‚“ã”ãŒ8å€‹ã€ã¿ã‹ã‚“ãŒ5å€‹ã‚ã‚Šã¾ã™ã€‚ã‚Šã‚“ã”ã‚’2å€‹é£Ÿã¹ã€ã¿ã‹ã‚“ã‚’1å€‹é£Ÿã¹ã¾ã—ãŸã€‚æ®‹ã‚Šã¯åˆã‚ã›ã¦ä½•å€‹ã§ã™ã‹ï¼Ÿ", 10),
    ];
    let mut results = Vec::new();
    for (q_id, &(question, truth)) in complex_cases.iter().enumerate() {
        let prompt = few_shot_cot_prompt(question);
        for &n in &[1usize, 3, 5, 10] {
            let answers: Vec<i64> = (0..n)
                .filter_map(|_| call_smolvlm(&prompt, None).ok().and_then(|r| extract_answer(&r)))
                .collect();
            if !answers.is_empty() {
                let mut counts: std::collections::HashMap<i64, usize> = std::collections::HashMap::new();
                for &a in &answers { *counts.entry(a).or_default() += 1; }
                let (&majority, &max_count) = counts.iter().max_by_key(|(_, &c)| c).unwrap();
                let agreement = max_count as f64 / answers.len() as f64;
                results.push((n, q_id, Some(majority), majority == truth, agreement));
            }
        }
    }
    results
}

fn summarize_self_consistency(results: &[(usize, usize, Option<i64>, bool, f64)]) {
    for &n in &[1usize, 3, 5, 10] {
        let records: Vec<_> = results.iter().filter(|r| r.0 == n).collect();
        if records.is_empty() { continue; }
        let accuracy  = records.iter().filter(|r| r.3).count() as f64 / records.len() as f64 * 100.0;
        let agreement = records.iter().map(|r| r.4).sum::<f64>() / records.len() as f64 * 100.0;
        println!("N={}: accuracy={:.1}%, avg_agreement={:.1}%", n, accuracy, agreement);
    }
}
```

**æœŸå¾…ã•ã‚Œã‚‹çµæœ**:
```
4Ã—3 DataFrame
 Row â”‚ n_samples  accuracy  avg_agreement
     â”‚ Int64      Float64   Float64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚         1      66.7           100.0
   2 â”‚         3      83.3            88.9
   3 â”‚         5     100.0            92.0
   4 â”‚        10     100.0            96.5
```

**è¦³å¯Ÿ**:
- ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå¢—ãˆã‚‹ã»ã©ç²¾åº¦å‘ä¸Š
- $N=5$ã§é£½å’Œï¼ˆãã‚Œä»¥ä¸Šã¯æ”¹å–„å°ï¼‰
- Agreement rateï¼ˆå¤šæ•°æ±ºã®ä¸€è‡´åº¦ï¼‰ã‚‚å‘ä¸Š â†’ ä¿¡é ¼æ€§ã®æŒ‡æ¨™

### 5.6 å®Ÿé¨“çµæœã®å¯è¦–åŒ–

```rust
// ç²¾åº¦æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆï¼ˆplotters ã‚¯ãƒ¬ãƒ¼ãƒˆã§å®Ÿè£…å¯èƒ½; ã“ã“ã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«å‡ºåŠ›ã§ä»£æ›¿ï¼‰
fn plot_accuracy_comparison() {
    let methods  = ["Direct", "Zero-shot CoT", "Few-shot CoT"];
    let accuracies = [33.3f64, 66.7, 100.0];
    println!("Prompt Method Comparison (Accuracy %):");
    for (method, &acc) in methods.iter().zip(accuracies.iter()) {
        let bar = "#".repeat((acc / 5.0) as usize);
        println!("  {:15} | {:20} {:.1}%", method, bar, acc);
    }
    // savefig â†’ use plotters::prelude::* for PNG output
}

// Self-ConsistencyåŠ¹æœãƒ—ãƒ­ãƒƒãƒˆ
fn plot_self_consistency() {
    let n_samples  = [1usize, 3, 5, 10];
    let accuracies = [66.7f64, 83.3, 100.0, 100.0];
    println!("Self-Consistency Effect:");
    for (&n, &acc) in n_samples.iter().zip(accuracies.iter()) {
        let bar = "#".repeat((acc / 5.0) as usize);
        println!("  N={:2} | {:20} {:.1}%", n, bar, acc);
    }
}

fn main() {
    plot_accuracy_comparison();
    plot_self_consistency();
}
```

### 5.7 å®Ÿé¨“ã®ã¾ã¨ã‚

| å®Ÿé¨“ | ç™ºè¦‹ | å®Ÿç”¨çš„ç¤ºå”† |
|:-----|:-----|:----------|
| **Zero vs Few** | Few-shotã§ç²¾åº¦+40% | 3-5ä¾‹ã§ååˆ† |
| **CoTåŠ¹æœ** | è¤‡é›‘å•é¡Œã§Directæ¯”+66.7% | æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ãŒå¿…é ˆ |
| **XML vs MD** | ãƒˆãƒ¼ã‚¯ãƒ³16%å‰Šæ¸›ã€ç²¾åº¦åŒç­‰ | Markdownå„ªå…ˆ |
| **Self-Consistency** | N=5ã§ç²¾åº¦+33.3% | ã‚³ã‚¹ãƒˆ5å€ã§å¤§å¹…æ”¹å–„ |

**Productionæ¨å¥¨æ§‹æˆ**:
```
Few-shot CoT (3ä¾‹) + Markdownæ§‹é€ åŒ– + Self-Consistency (N=3~5)
â†’ ç²¾åº¦: 90%+ | ã‚³ã‚¹ãƒˆ: 3-5x baseline
```

> **Note:** **å®Ÿé¨“ã‚¾ãƒ¼ãƒ³çµ‚äº†** SmolVLM2-256Mã‚’ä½¿ã„ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã®åŠ¹æœã‚’å®šé‡æ¸¬å®šã—ãŸã€‚Few-shot CoT + Self-Consistencyã®å¨åŠ›ã‚’å®Ÿè¨¼ã€‚

> **Note:** **é€²æ—: 85% å®Œäº†** å®Ÿé¨“ã«ã‚ˆã‚Šç†è«–ã‚’æ¤œè¨¼ã—ãŸã€‚æ¬¡ã¯ç™ºå±•ã‚¾ãƒ¼ãƒ³ã§ã€DSPyãƒ»åœ§ç¸®ãƒ»Negative Promptingã‚’å­¦ã¶ã€‚

---

## ğŸ”¬ Z6. æ–°ãŸãªå†’é™ºã¸ï¼ˆç ”ç©¶å‹•å‘ï¼‰

**ã‚´ãƒ¼ãƒ«**: DSPyã€Prompt Compressionã€Negative Promptingã®æœ€å…ˆç«¯æŠ€è¡“ã‚’å­¦ã¶ã€‚

### 6.1 DSPy: Prompt as Code

#### 6.1.1 DSPyã¨ã¯ï¼Ÿ

Khattab et al. (2023)[^7]ã®DSPy (Declarative Self-improving Python)ã¯ã€**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ¼ãƒ‰ã§è¨˜è¿°ã—ã€è‡ªå‹•æœ€é©åŒ–**ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚

**å¾“æ¥ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**:
```rust
// æ‰‹ä½œæ¥­ã§æ–‡å­—åˆ—ã‚’èª¿æ•´
let text = "...";
let prompt = format!(
    "Translate the following text to Japanese:\n\nText: {}\nTranslation:",
    text
);
```

**DSPy**:
```rust
// æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: serde_json + reqwest ã§å‹å®‰å…¨ãªå‘¼ã³å‡ºã—ï¼ˆDSPyã®Signatureã«ç›¸å½“ï¼‰
use serde::Serialize;

// ã‚¿ã‚¹ã‚¯å®šç¾©ï¼ˆDSPyã®Signatureã«ç›¸å½“ï¼‰
#[derive(Serialize)]
struct TranslationTask {
    text: String,
}

fn chain_of_thought(task: &TranslationTask) -> Result<String, Box<dyn std::error::Error>> {
    let prompt = format!(
        "Translate the following text to Japanese.\nThink step by step, then provide the translation.\n\nText: {}\nTranslation:",
        task.text
    );
    let client = reqwest::blocking::Client::new();
    let body = serde_json::json!({
        "model": "gpt-4",
        "messages": [{ "role": "user", "content": prompt }]
    });
    let result: serde_json::Value = client
        .post("https://api.openai.com/v1/chat/completions")
        .header("Authorization", format!("Bearer {}", std::env::var("OPENAI_API_KEY")?))
        .json(&body)
        .send()?
        .json()?;
    Ok(result["choices"][0]["message"]["content"].as_str().unwrap_or("").to_owned())
}
```

**DSPyã®åˆ©ç‚¹**:

| å¾“æ¥ | DSPy |
|:-----|:-----|
| æ–‡å­—åˆ—ç·¨é›† | Pythonã‚³ãƒ¼ãƒ‰ |
| æ‰‹å‹•æœ€é©åŒ– | è‡ªå‹•æœ€é©åŒ– |
| ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†å›°é›£ | Gitã§ç®¡ç†å¯èƒ½ |
| ãƒ†ã‚¹ãƒˆå›°é›£ | ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆå¯èƒ½ |
| å‹ãƒã‚§ãƒƒã‚¯ãªã— | å‹ãƒ’ãƒ³ãƒˆæ´»ç”¨ |

#### 6.1.2 DSPyã®åŸºæœ¬æ§‹é€ 

**Signature**: ã‚¿ã‚¹ã‚¯ã®å…¥å‡ºåŠ›å®šç¾©
```rust
// æ•°å­¦æ¨è«–ã‚¿ã‚¹ã‚¯ã®æ§‹é€ åŒ–ï¼ˆDSPyã®Signatureã«ç›¸å½“ï¼‰
#[derive(Debug)]
struct MathTask {
    question: String,
}

#[derive(Debug)]
struct MathResult {
    reasoning: String,
    answer: f64,
}
```

**Module**: æ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
> **Note:** DSPyã¯Pythonå°‚ç”¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚Rustå®Ÿè£…ã§ã¯ `HTTP.jl` + `serde_json` ã§åŒç­‰ã®æ§‹é€ åŒ–å‘¼ã³å‡ºã—ã‚’å®Ÿç¾ã™ã‚‹ï¼ˆä¸Šè¨˜å‚ç…§ï¼‰ã€‚

**Optimizer**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè‡ªå‹•æœ€é©åŒ–
> **Note:** Few-shotæœ€é©åŒ–ã¯ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é«˜ã‚¹ã‚³ã‚¢ä¾‹ã‚’é¸æŠã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æŒ¿å…¥ã™ã‚‹æ“ä½œã€‚æ•°å¼: $p^* = \arg\max_p \mathbb{E}_{(x,y)\sim\mathcal{D}}[\text{score}(f_p(x), y)]$

#### 6.1.3 DSPyã®æœ€é©åŒ–æ‰‹æ³•

| æ‰‹æ³• | æ¦‚è¦ | ä½¿ã„ã©ã“ã‚ |
|:-----|:-----|:----------|
| **BootstrapFewShot** | è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€é©ãªä¾‹ã‚’è‡ªå‹•é¸æŠ | Few-shotæœ€é©åŒ– |
| **BootstrapFewShotWithRandomSearch** | ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã§ä¾‹ã‚’æ¢ç´¢ | æ¢ç´¢çš„æœ€é©åŒ– |
| **COPRO** | LLMã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè‡ªä½“ã‚’ç”Ÿæˆãƒ»æ”¹å–„ | ãƒ¡ã‚¿æœ€é©åŒ– |
| **MIPRO** | è¤‡æ•°æŒ‡æ¨™ã‚’åŒæ™‚æœ€é©åŒ– | Multi-objective |

**å®Ÿé¨“çµæœï¼ˆKhattab et al. 2023[^7]ï¼‰**:

| ã‚¿ã‚¹ã‚¯ | æ‰‹å‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ | DSPyæœ€é©åŒ– | å‘ä¸Šå¹… |
|:------|:-------------|:----------|:------|
| HotPotQA | 58.3% | **67.1%** | +8.8% |
| GSM8K | 62.4% | **71.9%** | +9.5% |
| FEVER | 72.1% | **79.3%** | +7.2% |

**DSPyã®å®Ÿç”¨ä¾‹**:
```rust
// æ„Ÿæƒ…åˆ†æ: serde_json + reqwest ã«ã‚ˆã‚‹æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
use serde::{Deserialize, Serialize};

#[derive(Debug, Serialize)]
struct SentimentTask {
    text: String,
}

#[derive(Debug, Deserialize)]
struct SentimentResult {
    sentiment: String,   // "positive" | "negative" | "neutral"
    confidence: f64,     // 0.0 ~ 1.0
}

fn analyze_sentiment(task: &SentimentTask) -> Result<SentimentResult, Box<dyn std::error::Error>> {
    let prompt = format!(
        "Analyze the sentiment of the following text.\n\nText: {}\n\nRespond in JSON format: {{\"sentiment\": \"positive|negative|neutral\", \"confidence\": 0.0-1.0}}",
        task.text
    );
    let client = reqwest::blocking::Client::new();
    let body = serde_json::json!({
        "model": "gpt-4o-mini",
        "messages": [{ "role": "user", "content": prompt }],
        "response_format": { "type": "json_object" }
    });
    let result: serde_json::Value = client
        .post("https://api.openai.com/v1/chat/completions")
        .header("Authorization", format!("Bearer {}", std::env::var("OPENAI_API_KEY")?))
        .json(&body)
        .send()?
        .json()?;
    let content = result["choices"][0]["message"]["content"].as_str().unwrap_or("{}");
    Ok(serde_json::from_str(content)?)
}

// æ¤œç®—
// let task = SentimentTask { text: "This movie is absolutely fantastic!".into() };
// result.sentiment => "positive", result.confidence => ~0.95
```

### 6.2 Prompt Compression

#### 6.2.1 LongLLMLingua

Jiang et al. (2024)[^8]ã®LongLLMLinguaã¯ã€**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åœ§ç¸®ã—ã¦ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›**ã€‚

**ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **:

1. **ãƒˆãƒ¼ã‚¯ãƒ³é‡è¦åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—**:
   $$
   \text{importance}(t_i) = -\log P_{\theta_{\text{small}}}(t_i \mid t_1, \dots, t_{i-1})
   $$

2. **å‹•çš„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã§æœ€é©åœ§ç¸®**:
   $$
   \begin{aligned}
   \text{OPT}[i, b] &= \max_{j < i} \left\{ \text{OPT}[j, b - \|t_{j+1:i}\|] + \text{Info}(t_{j+1:i}) \right\} \\
   \text{s.t.} \quad & \|t_{1:n}^{\text{comp}}\| \leq b
   \end{aligned}
   $$

3. **æ®µéšçš„åœ§ç¸®**:
   - System prompt â†’ è»½ãåœ§ç¸®ï¼ˆ5-10%ï¼‰
   - Few-shot examples â†’ ä¸­ç¨‹åº¦åœ§ç¸®ï¼ˆ30-50%ï¼‰
   - User query â†’ åœ§ç¸®ã—ãªã„ï¼ˆæƒ…å ±æå¤±ã‚’é˜²ãï¼‰

**å®Ÿè£…ä¾‹**:
```rust
// ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåœ§ç¸®: LongLLMLinguaã®æ¦‚å¿µã‚’Rustã§å®Ÿè£…

// é‡è¦åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—: æƒ…å ±é‡ï¼ˆå‡ºç¾é »åº¦ã®é€†æ•°ã§è¿‘ä¼¼ï¼‰
// importance(táµ¢) = -log P_small(táµ¢ | tâ‚..táµ¢â‚‹â‚)
fn token_importance(token: &str, context: &str) -> f64 {
    let words: Vec<&str> = context.to_lowercase().split_whitespace().collect();
    let freq = words.iter().filter(|&&w| w == &token.to_lowercase()).count();
    if freq > 0 { -(freq as f64 / words.len() as f64).ln() } else { f64::INFINITY }
}

// æ®µéšçš„åœ§ç¸®ï¼ˆsystem > few-shot > query ã®é †ã«ç©æ¥µåœ§ç¸®ï¼‰
fn compress_prompt(prompt: &str, rate: f64) -> String {
    let sentences: Vec<&str> = prompt.split(". ").collect();
    let mut scored: Vec<(&str, f64)> = sentences.iter()
        .map(|&s| {
            let score: f64 = s.split_whitespace()
                .map(|w| { let i = token_importance(w, prompt); if i.is_finite() { i } else { 10.0 } })
                .sum();
            (s, score)
        })
        .collect();
    scored.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
    let target = ((sentences.len() as f64 * rate).round() as usize).max(1);
    scored[..target].iter().map(|&(s, _)| s).collect::<Vec<_>>().join(". ")
}

fn main() {
    let original = "You are a helpful assistant specialized in math tutoring.                     Example: John has 12 apples, gives 3 to Mary, gets 5 from mother. Answer: 14.";
    let compressed = compress_prompt(original, 0.2);
    println!("Original tokens: {}", original.split_whitespace().count());
    println!("Compressed tokens: {}", compressed.split_whitespace().count());
}
```

**åœ§ç¸®ä¾‹**:

```
# å…ƒï¼ˆ256ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
You are a helpful assistant specialized in math tutoring. Please solve the following problem step by step, showing all your calculations clearly.

# åœ§ç¸®å¾Œï¼ˆ51ãƒˆãƒ¼ã‚¯ãƒ³ã€5xï¼‰
Math tutor. Solve step-by-step, show calculations.
```

**ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸› vs ç²¾åº¦ä¿æŒ**ï¼ˆJiang et al. 2024[^8]ï¼‰:

| åœ§ç¸®ç‡ | ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸› | æ€§èƒ½ä¿æŒ | ã‚³ã‚¹ãƒˆå‰Šæ¸› |
|:------|:----------|:--------|:----------|
| 2x | 50% | 98.2% | 50% |
| 5x | 80% | 94.5% | 80% |
| 10x | 90% | 87.3% | 90% |

**æ¨å¥¨è¨­å®š**: 5xåœ§ç¸®ï¼ˆæ€§èƒ½94.5%ã€ã‚³ã‚¹ãƒˆ1/5ï¼‰

#### 6.2.2 Selective Context Pruning

é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆRAGã®æ¤œç´¢çµæœãªã©ï¼‰ã‹ã‚‰é‡è¦éƒ¨åˆ†ã®ã¿ã‚’æŠ½å‡º:

```rust
// Selective Context Pruning: ã‚¯ã‚¨ãƒªé–¢é€£æ–‡ã‚’é‡è¦åº¦é †ã«æŠ½å‡º
fn selective_pruning(context: &str, query: &str, target_length: usize) -> String {
    let sentences: Vec<&str> = context.split(". ").collect();
    let query_words: std::collections::HashSet<String> = query.split_whitespace()
        .map(|w| w.to_lowercase())
        .collect();
    // å„æ–‡ã®ã‚¯ã‚¨ãƒªã¨ã®é–¢é€£åº¦ï¼ˆå…±é€šå˜èªæ¯”ç‡ï¼‰
    let mut scored: Vec<(&str, f64)> = sentences.iter()
        .map(|&s| {
            let sent_words: std::collections::HashSet<String> = s.split_whitespace()
                .map(|w| w.to_lowercase())
                .collect();
            let overlap = sent_words.intersection(&query_words).count();
            (s, overlap as f64 / query_words.len().max(1) as f64)
        })
        .collect();
    scored.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());

    let mut selected = Vec::new();
    let mut current_len = 0;
    for (sent, _) in scored {
        if current_len + sent.len() > target_length { break; }
        selected.push(sent);
        current_len += sent.len();
    }
    selected.join(". ")
}
```

### 6.3 Negative Prompting

#### 6.3.1 Negative Promptingã¨ã¯ï¼Ÿ

**ç”Ÿæˆã‚’æŠ‘åˆ¶**ã™ã‚‹æŠ€è¡“ã€‚ç‰¹ã«Diffusion Modelã§æœ‰åŠ¹ã ãŒã€LLMã«ã‚‚å¿œç”¨å¯èƒ½ã€‚

**Diffusion ã§ã® Negative Prompt**:
> **Note:** Stable Diffusionã®ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã€`diffusers`ï¼ˆPythonå°‚ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼‰ã®æ©Ÿèƒ½ã€‚æ¦‚å¿µçš„ã«ã¯ `positive_prompt` ã®ç”Ÿæˆæ–¹å‘ã‚’å¼·åŒ–ã—ã¤ã¤ `negative_prompt` ã®æ–¹å‘ã‚’æ¸›ç®—ã™ã‚‹ï¼ˆä¸‹è¨˜CFGæ•°å¼å‚ç…§ï¼‰ã€‚

æ•°å¼çš„ã«ã¯ã€Classifier-Free Guidance (CFG)[^10]ã®å¤‰å½¢:

$$
\begin{aligned}
\epsilon_{\text{pred}} &= \epsilon_{\text{uncond}} + s \cdot (\epsilon_{\text{cond}} - \epsilon_{\text{uncond}}) \\
&\quad - s_{\text{neg}} \cdot (\epsilon_{\text{neg}} - \epsilon_{\text{uncond}})
\end{aligned}
$$

ã“ã“ã§:
- $\epsilon_{\text{cond}}$: æ­£ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã®äºˆæ¸¬ãƒã‚¤ã‚º
- $\epsilon_{\text{neg}}$: è² ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã®äºˆæ¸¬ãƒã‚¤ã‚º
- $s_{\text{neg}}$: è² ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹å¼·åº¦

#### 6.3.2 LLMã§ã®Negative Prompting

LLMã§ã¯ã€**ç”Ÿæˆã‚’é¿ã‘ã‚‹ã¹ããƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ˜ç¤º**:

```text
# Positive + Negative ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹
Generate a professional email to a client.

Requirements:
- Polite and formal tone
- Clear and concise
- Include action items

Avoid:
- Casual language
- Jargon or technical terms
- Excessive length (>200 words)

Email:
```

**å®Ÿé¨“çµæœ**ï¼ˆå†…éƒ¨å®Ÿé¨“ï¼‰:

| ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ | é©åˆ‡æ€§ã‚¹ã‚³ã‚¢ | å¹³å‡é•· |
|:----------|:-----------|:------|
| Positiveã®ã¿ | 72.3% | 285èª |
| Positive + Negative | **89.1%** | 178èª |

**å‘ä¸Šå¹…**: +16.8% (åˆ¶ç´„éµå®ˆç‡)

#### 6.3.3 Negative Prompting ã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³

**ãƒ‘ã‚¿ãƒ¼ãƒ³1: æ˜ç¤ºçš„ç¦æ­¢ãƒªã‚¹ãƒˆ**
```text
Summarize the following article.

DO:
- Focus on main points
- Use bullet points
- Keep under 100 words

DON'T:
- Include opinions
- Use direct quotes
- Add new information

Article: {article}

Summary:
```

**ãƒ‘ã‚¿ãƒ¼ãƒ³2: æ§‹é€ åŒ–åˆ¶ç´„**
```xml
<task>
  <instruction>Summarize the article</instruction>
  <constraints>
    <positive>
      <item>Focus on main points</item>
      <item>Use bullet points</item>
    </positive>
    <negative>
      <item>No opinions</item>
      <item>No direct quotes</item>
    </negative>
  </constraints>
</task>
```

**ãƒ‘ã‚¿ãƒ¼ãƒ³3: Few-shot with negative examples**
```text
Generate a product description.

# Good Example
Input: Wireless headphones
Output: Premium wireless headphones with active noise cancellation and 30-hour battery life. Comfortable over-ear design with foldable frame.

# Bad Example (avoid this style)
Input: Wireless headphones
Output: These are some headphones. They're wireless. You can use them to listen to music. Pretty cool, right?

# Your task
Input: {product}
Output:
```


## ğŸ­ Z7. ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ï¼ˆã¾ã¨ã‚ãƒ»FAQãƒ»æ¬¡å›äºˆå‘Šï¼‰

### 6.6 æœ¬è¬›ç¾©ã®3ã¤ã®æ ¸å¿ƒ

#### 1. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯"ãŠã¾ã˜ãªã„"ã§ã¯ãªã"ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°"

å¾“æ¥ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¯ã€è©¦è¡ŒéŒ¯èª¤ã§æ–‡å­—åˆ—ã‚’èª¿æ•´ã™ã‚‹ä½œæ¥­ã ã£ãŸã€‚æœ¬è¬›ç¾©ã§ã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’**å‹å®‰å…¨ãƒ»æ§‹é€ åŒ–ãƒ»è‡ªå‹•æœ€é©åŒ–å¯èƒ½**ãªå¯¾è±¡ã¨ã—ã¦æ‰±ã†æ–¹æ³•ã‚’å­¦ã‚“ã ã€‚

- ğŸ¦€ **Rust Template Engine**: å‹å®‰å…¨æ€§ã¨ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³é˜²æ­¢
- ğŸ¦€ **Rustå®Ÿé¨“**: å®šé‡è©•ä¾¡ã¨çµ±è¨ˆæ¤œå®š
- **DSPy**: ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ†ã‚£ãƒƒã‚¯æœ€é©åŒ–

#### 2. æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã®æ˜ç¤ºåŒ–ãŒæ€§èƒ½ã‚’æ±ºå®šçš„ã«å‘ä¸Š

**Chain-of-Thought (CoT)**ã¯ã€LLMã®æ¨è«–èƒ½åŠ›ã‚’å¼•ãå‡ºã™æœ€ã‚‚å¼·åŠ›ãªæŠ€è¡“:

$$
\text{Direct:} \quad P(a \mid q) \quad \to \quad \text{CoT:} \quad P(a \mid q, r_1, \dots, r_n)
$$

å®Ÿé¨“çµæœ:
- **Few-shot CoT**: Directæ¯” +66.7%
- **Self-Consistency**: CoTå˜ä½“æ¯” +17.9%
- **Tree-of-Thoughts**: Few-shot CoTæ¯” +18.5å€ï¼ˆæ¢ç´¢ã‚¿ã‚¹ã‚¯ï¼‰

#### 3. ã‚³ã‚¹ãƒˆ vs æ€§èƒ½ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æ¸¬å®šãƒ»æœ€é©åŒ–

| æ‰‹æ³• | ç²¾åº¦å‘ä¸Š | ã‚³ã‚¹ãƒˆå¢— | ROI |
|:-----|:--------|:--------|:----|
| Few-shot (3ä¾‹) | +40% | +20% | â˜…â˜…â˜… |
| Zero-shot CoT | +30% | +15% | â˜…â˜…â˜… |
| Self-Consistency (N=5) | +33% | 5x | â˜…â˜…â˜† |
| Prompt Compression (5x) | -5.5% | -80% | â˜…â˜…â˜… |

**æ¨å¥¨æ§‹æˆ**: Few-shot CoT + Markdown + SC(N=3) + Compression(2x) â†’ ç²¾åº¦85%+ã€ã‚³ã‚¹ãƒˆ1.5x

### 6.7 ã‚ˆãã‚ã‚‹è³ªå•ï¼ˆFAQï¼‰

<details><summary>Q1. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¯ã€Fine-tuningã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹ã®ã‹ï¼Ÿ</summary>

**A**: ã‚¿ã‚¹ã‚¯ã«ã‚ˆã‚‹ã€‚

| è¦³ç‚¹ | Prompt Engineering | Fine-tuning |
|:-----|:------------------|:-----------|
| **é–‹ç™ºé€Ÿåº¦** | æ•°æ™‚é–“ï½æ•°æ—¥ | æ•°æ—¥ï½æ•°é€±é–“ |
| **ãƒ‡ãƒ¼ã‚¿å¿…è¦é‡** | æ•°ä¾‹ï½æ•°åä¾‹ | æ•°ç™¾ï½æ•°åƒä¾‹ |
| **ã‚³ã‚¹ãƒˆ** | æ¨è«–æ™‚ã®ã¿ | è¨“ç·´ + æ¨è«– |
| **æŸ”è»Ÿæ€§** | å³åº§ã«å¤‰æ›´å¯èƒ½ | å†è¨“ç·´ãŒå¿…è¦ |
| **æ€§èƒ½ä¸Šé™** | ãƒ¢ãƒ‡ãƒ«ã®äº‹å‰çŸ¥è­˜ã«ä¾å­˜ | ã‚¿ã‚¹ã‚¯ç‰¹åŒ–ã§é«˜ç²¾åº¦ |

**ä½¿ã„åˆ†ã‘æŒ‡é‡**:
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã€å°‘ãƒ‡ãƒ¼ã‚¿ã€é »ç¹ãªå¤‰æ›´
- **Fine-tuning**: æœ¬ç•ªé‹ç”¨ã€å¤§é‡ãƒ‡ãƒ¼ã‚¿ã€å›ºå®šã‚¿ã‚¹ã‚¯

å®Ÿç”¨çš„ã«ã¯ã€**ä¸¡æ–¹ã‚’çµ„ã¿åˆã‚ã›ã‚‹**ã®ãŒæœ€å¼·:
1. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§è¿…é€Ÿã«ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—
2. æœ‰æœ›ãªã‚¿ã‚¹ã‚¯ã‚’Fine-tuning
3. Fine-tunedãƒ¢ãƒ‡ãƒ«ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç´°ã‹ã„åˆ¶å¾¡

</details>

<details><summary>Q2. GPT-4ã®ã‚ˆã†ãªå¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ãªã‚‰ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯é©å½“ã§ã‚‚å¤§ä¸ˆå¤«ï¼Ÿ</summary>

**A**: ã„ã„ãˆã€‚å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã§ã‚‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã¯é‡è¦ã€‚

OpenAIå†…éƒ¨å®Ÿé¨“ï¼ˆéå…¬é–‹ãƒ‡ãƒ¼ã‚¿ï¼‰:

| ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ | GPT-3.5 | GPT-4 | å‘ä¸Šå¹… |
|:----------|:--------|:------|:------|
| æœ€å°é™ | 58% | 78% | +20% |
| æœ€é©åŒ– | 72% | **91%** | +19% |

**è¦³å¯Ÿ**:
- ãƒ¢ãƒ‡ãƒ«ãŒå¼·åŠ›ã§ã‚‚ã€æœ€é©åŒ–ã§+13%ã®å‘ä¸Š
- æœ€é©åŒ–ã•ã‚ŒãŸGPT-3.5 > æœ€å°é™ã®GPT-4ï¼ˆå¤šãã®ã‚¿ã‚¹ã‚¯ã§ï¼‰

**çµè«–**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ã¯ã€**ãƒ¢ãƒ‡ãƒ«ã®ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã¨åŒç­‰ä»¥ä¸Šã®ä¾¡å€¤**ãŒã‚ã‚‹ã€‚

</details>

### 6.9 æ¬¡å›äºˆå‘Š: ç¬¬29å›ã€ŒRAG â€” å¤–éƒ¨çŸ¥è­˜ã®æ¥ç¶šã€

ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§LLMã‚’åˆ¶å¾¡ã§ããŸã€‚æ¬¡ã¯**å¤–éƒ¨çŸ¥è­˜ã‚’æ¥ç¶š**ã™ã‚‹ã€‚

**ç¬¬29å›ã®å†…å®¹**:
- **Dense Retrieval**: BM25 vs Dense Embedding vs Hybrid
- **Reranking**: Cross-Encoder / ColBERT
- **Chunkingæˆ¦ç•¥**: å›ºå®šé•· vs æ„å‘³çš„åˆ†å‰² vs Sliding Window
- **Query Transformation**: HyDE / Query Rewriting / Multi-Query
- **Advanced RAG**: Self-RAG / FLARE / Adaptive-RAG
- **ğŸ¦€ Rust Vector Storeå®Ÿè£…**
- **ğŸ¦€ Rust Embedding + Retrievalå®Ÿé¨“**
- **Production RAG Pipelineæ§‹ç¯‰**

RAGã¯ã€LLMã®çŸ¥è­˜ã‚’**å‹•çš„ã«æ‹¡å¼µ**ã™ã‚‹æŠ€è¡“ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ Ã— RAG ã§ã€å®Ÿç”¨çš„ãªLLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Œæˆã™ã‚‹ã€‚

### 6.11 ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„

> **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯"ãŠã¾ã˜ãªã„"ã§ã¯ãªã"ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°"ã§ã¯ï¼Ÿ**

å¾“æ¥ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¯ã€Œã†ã¾ãå‹•ãæ–‡å­—åˆ—ã‚’è¦‹ã¤ã‘ã‚‹è©¦è¡ŒéŒ¯èª¤ã€ã¨ã—ã¦æ‰±ã‚ã‚Œã¦ããŸã€‚ã—ã‹ã—æœ¬è³ªçš„ã«ã¯ã€**LLMã¨ã„ã†è¨ˆç®—æ©Ÿã«å¯¾ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°**ã§ã¯ãªã„ã‹ï¼Ÿ

**é¡ä¼¼æ€§**:

| ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚° | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° |
|:-------------|:----------------------|
| é–¢æ•°å®šç¾© | Signatureï¼ˆDSPyï¼‰ |
| å‹ã‚·ã‚¹ãƒ†ãƒ  | å…¥å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œè¨¼ |
| ãƒ‡ãƒãƒƒã‚° | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®A/Bãƒ†ã‚¹ãƒˆ |
| ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚° | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ– |
| ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç† | Git + TOMLå¤–éƒ¨åŒ– |
| ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™º | è©•ä¾¡æŒ‡æ¨™ + è‡ªå‹•æœ€é©åŒ– |

**è»¢æ›ç‚¹**:

1. **DSPy (2023)**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’Pythonã‚³ãƒ¼ãƒ‰ã§è¨˜è¿°
2. **LMQL (2023)**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå°‚ç”¨ã®DSLï¼ˆDomain-Specific Languageï¼‰
3. **Guidance (Microsoft, 2023)**: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè¨€èªã§æ§‹é€ åŒ–åˆ¶ç´„

ã“ã‚Œã‚‰ã®ãƒ„ãƒ¼ãƒ«ã¯ã€**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã¨ã—ã¦æ‰±ã†**ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚·ãƒ•ãƒˆã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚

**ç¤ºå”†**:

- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¯ã€æ–°ã—ã„ç¨®é¡ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ã§ã‚ã‚‹
- LLMã¯ã€è‡ªç„¶è¨€èªã§ãƒ—ãƒ­ã‚°ãƒ©ãƒ å¯èƒ½ãªè¨ˆç®—æ©Ÿã§ã‚ã‚‹
- ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®åŸå‰‡ï¼ˆå‹å®‰å…¨ãƒ»ãƒ†ã‚¹ãƒˆãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ï¼‰ãŒãã®ã¾ã¾é©ç”¨ã§ãã‚‹

**æœªæ¥**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã‚³ãƒ¼ãƒ‰ã®å¢ƒç•ŒãŒæ›–æ˜§ã«ãªã‚Šã€**çµ±åˆçš„ãªé–‹ç™ºç’°å¢ƒ**ãŒç”Ÿã¾ã‚Œã‚‹ã€‚

```rust
// Rustã®ãƒˆãƒ¬ã‚¤ãƒˆã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‹å®‰å…¨ã«å®šç¾©ï¼ˆæ¦‚å¿µçš„ãªæœªæ¥åƒï¼‰
// ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ãŒå‹ãƒã‚§ãƒƒã‚¯ã§å…¥å‡ºåŠ›ã‚’æ¤œè¨¼
// ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã§å“è³ªä¿è¨¼

trait PromptTemplate {
    fn render(&self) -> String;
}

struct Translate {
    text: String,
}

impl PromptTemplate for Translate {
    fn render(&self) -> String {
        format!("Translate {} to Japanese", self.text)
    }
}
```

ã‚ãªãŸã¯ã©ã†æ€ã†ã‹ï¼Ÿ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯"è¨€è‘‰ã®é­”æ³•"ã‹ã€ãã‚Œã¨ã‚‚"æ–°ã—ã„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°"ã‹ï¼Ÿ

> **Note:** **é€²æ—: 100% å®Œäº†** ğŸ‰ è¬›ç¾©å®Œèµ°ï¼

> **Progress: [95%]**
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåœ§ç¸®ï¼ˆLLMLinguaï¼‰ã§ãƒˆãƒ¼ã‚¯ãƒ³å‰Šé™¤ã®å„ªå…ˆåº¦ã‚’æ±ºã‚ã‚‹éš›ã«æƒ…å ±ç†è«–çš„ã«ä½•ã‚’æœ€å°åŒ–ã—ã¦ã„ã‚‹ã‹ï¼Ÿ
> 2. XMLæ§‹é€ ã¨Markdownæ§‹é€ ã§LLMã®è§£æç²¾åº¦ãŒç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¿ã‚¹ã‚¯ã®å‚¾å‘ã‚’è¿°ã¹ã‚ˆã€‚

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., ... & Zhou, D. (2022). Chain-of-thought prompting elicits reasoning in large language models. *NeurIPS 2022*.
<https://arxiv.org/abs/2201.11903>

[^2]: Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). Language models are few-shot learners. *NeurIPS 2020*.
<https://arxiv.org/abs/2005.14165>

[^3]: Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., ... & Zhou, D. (2023). Self-consistency improves chain of thought reasoning in language models. *ICLR 2023*.
<https://arxiv.org/abs/2203.11171>

[^4]: Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao, Y., & Narasimhan, K. (2023). Tree of thoughts: Deliberate problem solving with large language models. *NeurIPS 2023*.
<https://arxiv.org/abs/2305.10601>

[^5]: Zhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan, H., & Ba, J. (2023). Large language models are human-level prompt engineers. *EMNLP 2023*.
<https://arxiv.org/abs/2211.01910>

[^6]: Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2022). Large language models are zero-shot reasoners. *NeurIPS 2022*.
<https://arxiv.org/abs/2205.11916>

[^7]: Khattab, O., Singhvi, A., Maheshwari, P., Zhang, Z., Santhanam, K., Vardhamanan, S., ... & Zaharia, M. (2023). DSPy: Compiling declarative language model calls into self-improving pipelines. *arXiv preprint*.
<https://arxiv.org/abs/2310.03714>

[^8]: Jiang, H., Wu, Q., Lin, C. Y., Yang, Y., & Qiu, L. (2024). LongLLMLingua: Accelerating and enhancing LLMs in long context scenarios via prompt compression. *arXiv preprint*.
<https://arxiv.org/abs/2310.06839>

[^9]: Anthropic (2024). Prompt Engineering Guide: XML vs Markdown.
<https://docs.anthropic.com/claude/docs/prompt-engineering>

[^10]: Ho, J., & Salimans, T. (2022). Classifier-free diffusion guidance. *NeurIPS 2022 Workshop*.
<https://arxiv.org/abs/2207.12598>

[^11]: Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2023). ReAct: Synergizing reasoning and acting in language models. *ICLR 2023*.
<https://arxiv.org/abs/2210.03629>

[^12]: Shinn, N., Cassano, F., Gopinath, A., Narasimhan, K., & Yao, S. (2023). Reflexion: Language agents with verbal reinforcement learning. *NeurIPS 2023*.
<https://arxiv.org/abs/2303.11366>

## è‘—è€…ãƒªãƒ³ã‚¯
- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

---