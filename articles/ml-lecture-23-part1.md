---
title: "ç¬¬23å›: Post-Training & Alignmentï¼ˆSFT/RLHF/CPT + PEFTï¼‰: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ã€å‰ç·¨ã€‘ç†è«–ç·¨"
slug: "ml-lecture-23-part1"
emoji: "ğŸ”§"
type: "tech"
topics: ["machinelearning", "deeplearning", "finetuning", "rust", "rust"]
published: true
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Rust", "Elixir"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---

# ç¬¬23å›: Post-Training & Alignmentï¼ˆSFT/RLHF/CPT + PEFTï¼‰ â€” å¾®èª¿æ•´ã¯ã€Œæ‰‹æ³•é¸ã³ã€ã§ã¯ãªãã€Œå­¦ç¿’æ®µéšè¨­è¨ˆã€ã§ã¯ï¼Ÿ

> **65Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’1æšã®GPUã§è¨“ç·´ã€‚QLoRAãŒç¤ºã—ãŸã®ã¯ã€Œæœ€é©åŒ–ã™ã¹ãã¯å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã¯ãªãã€ä½ãƒ©ãƒ³ã‚¯éƒ¨åˆ†ç©ºé–“ã€ã¨ã„ã†æ´å¯Ÿã ã£ãŸã€‚**

ç¬¬22å›ã§ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®æœ€å‰ç·šã‚’è¦‹ãŸã€‚ã ãŒäº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãã®ã¾ã¾ä½¿ã†ã ã‘ã§ã¯ã€ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ã‚¿ã‚¹ã‚¯ã§æœ€é«˜æ€§èƒ½ã¯å‡ºãªã„ã€‚Fine-tuningï¼ˆå¾®èª¿æ•´ï¼‰ãŒå¿…è¦ã ã€‚

å¾“æ¥ã®Fine-tuningã¯å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã€‚ã ãŒ175Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆGPT-3ç´šï¼‰ã‚’å…¨ã¦æ›´æ–°ã™ã‚‹ã«ã¯ã€AdamWã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®å‹¾é…ãƒ»ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆã‚’å«ã‚ã¦**æ•°TB**ã®ãƒ¡ãƒ¢ãƒªãŒè¦ã‚‹ã€‚ã“ã‚Œã¯ç¾å®Ÿçš„ã§ãªã„ã€‚

2022å¹´ã€Microsoftã®Huã‚‰ãŒLoRA [^1] ã‚’ç™ºè¡¨ã—ãŸã€‚**å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®0.01%ã ã‘ã‚’è¨“ç·´**ã—ã¦GPT-3ã‚’Fine-tuningã—ã€Full Fine-tuningã¨åŒç­‰æ€§èƒ½ã‚’é”æˆã—ãŸã€‚2023å¹´ã€Dettmersã‚‰ã®QLoRA [^2] ã¯4-bité‡å­åŒ–ã¨çµ„ã¿åˆã‚ã›ã€65Bãƒ¢ãƒ‡ãƒ«ã‚’GPU 1æšï¼ˆ48GBï¼‰ã§è¨“ç·´å¯èƒ½ã«ã—ãŸã€‚

æœ¬è¬›ç¾©ã¯Course IIIã€Œå®Ÿè·µç·¨ã€ã®ä¸­æ ¸ â€” LoRA/QLoRA/DreamBooth/Adapterã®æ•°å¼ã¨å®Ÿè£…ã‚’å®Œå…¨ãƒã‚¹ã‚¿ãƒ¼ã™ã‚‹ã€‚ãã—ã¦**Rust LoRAè¨“ç·´ + Rust LoRAæ¨è«–**ã§3è¨€èªåˆ¶è¦‡ã®æ—…ã‚’ç¶šã‘ã‚‹ã€‚

> **Note:** **ã“ã®ã‚·ãƒªãƒ¼ã‚ºã«ã¤ã„ã¦**: æ±äº¬å¤§å­¦ æ¾å°¾ãƒ»å²©æ¾¤ç ”ç©¶å®¤å‹•ç”»è¬›ç¾©ã®**å®Œå…¨ä¸Šä½äº’æ›**ã®å…¨50å›ã‚·ãƒªãƒ¼ã‚ºã€‚ç†è«–ï¼ˆè«–æ–‡ãŒæ›¸ã‘ã‚‹ï¼‰ã€å®Ÿè£…ï¼ˆProduction-readyï¼‰ã€æœ€æ–°ï¼ˆ2024-2026 SOTAï¼‰ã®3è»¸ã§å·®åˆ¥åŒ–ã™ã‚‹ã€‚

```mermaid
graph TD
    A["ğŸ“š äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«<br/>175B params"] --> B["âŒ Full FT<br/>175Bæ›´æ–°<br/>æ•°TB GPU"]
    A --> C["âœ… LoRA<br/>0.01%æ›´æ–°<br/>10kå€å‰Šæ¸›"]
    C --> D["ğŸ”§ QLoRA<br/>4-bité‡å­åŒ–<br/>GPU 1æšã§65B"]
    C --> E["ğŸ¨ DreamBooth<br/>3ç”»åƒã§å€‹äººåŒ–"]
    C --> F["ğŸ”Œ Adapter<br/>å„å±¤ã«è¿½åŠ "]
    style B fill:#ffcdd2
    style C fill:#c8e6c9
    style D fill:#b3e5fc
    style E fill:#f8bbd0
    style F fill:#ffe0b2
```

**æ‰€è¦æ™‚é–“ã®ç›®å®‰**:

| ã‚¾ãƒ¼ãƒ³ | å†…å®¹ | æ™‚é–“ | é›£æ˜“åº¦ |
|:-------|:-----|:-----|:-------|
| Zone 0 | ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ | 30ç§’ | â˜…â˜†â˜†â˜†â˜† |
| Zone 1 | ä½“é¨“ã‚¾ãƒ¼ãƒ³ | 10åˆ† | â˜…â˜…â˜†â˜†â˜† |
| Zone 2 | ç›´æ„Ÿã‚¾ãƒ¼ãƒ³ | 15åˆ† | â˜…â˜…â˜…â˜†â˜† |
| Zone 3 | æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ | 60åˆ† | â˜…â˜…â˜…â˜…â˜… |
| Zone 4 | å®Ÿè£…ã‚¾ãƒ¼ãƒ³ | 45åˆ† | â˜…â˜…â˜…â˜…â˜† |
| Zone 5 | å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ | 30åˆ† | â˜…â˜…â˜…â˜…â˜† |
| Zone 6 | ç™ºå±•ã‚¾ãƒ¼ãƒ³ | 20åˆ† | â˜…â˜…â˜…â˜…â˜… |
| Zone 7 | æŒ¯ã‚Šè¿”ã‚Šã‚¾ãƒ¼ãƒ³ | 10åˆ† | â˜…â˜…â˜†â˜†â˜† |

---

## ğŸš€ 0. ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆ30ç§’ï¼‰â€” LoRAã‚’3è¡Œã§ä½“æ„Ÿ

**ã‚´ãƒ¼ãƒ«**: LoRAã®å¨åŠ›ã‚’30ç§’ã§ä½“æ„Ÿã™ã‚‹ã€‚

äº‹å‰å­¦ç¿’æ¸ˆã¿é‡ã¿ $W_0$ ã‚’å›ºå®šã—ã€ä½ãƒ©ãƒ³ã‚¯åˆ†è§£ $\Delta W = BA$ ã ã‘ã‚’è¨“ç·´ã™ã‚‹ã€‚

```rust
use ndarray::{Array1, Array2};
use ndarray_rand::RandomExt;
use ndarray_rand::rand_distr::StandardNormal;

// Pretrained weight Wâ‚€ âˆˆ â„^(dÃ—k) (frozen)
let d: usize = 512;
let k: usize = 512;
let r: usize = 8; // d=å‡ºåŠ›dim, k=å…¥åŠ›dim, r=rank
let w0: Array2<f64> = Array2::random((d, k), StandardNormal) / (k as f64).sqrt(); // frozen pretrained weight

// LoRA: Î”W = BA, B âˆˆ â„^(dÃ—r), A âˆˆ â„^(rÃ—k)
let b: Array2<f64> = Array2::random((d, r), StandardNormal) / (r as f64).sqrt(); // trainable
let a: Array2<f64> = Array2::<f64>::zeros((r, k)); // init to zero (Î”W starts at 0)

// Forward pass: h = (Wâ‚€ + Î”W)x = Wâ‚€x + BAx
let x: Array1<f64> = Array1::random(k, StandardNormal);
let h_full = (&w0 + &b.dot(&a)).dot(&x);     // conceptual (full matrix)
let h_lora = w0.dot(&x) + b.dot(&a.dot(&x)); // efficient (no Wâ‚€+BA materialization)

println!("Wâ‚€ params: {} = {}", d * k, d * k);
println!("LoRA params: {} = {}", d * r + r * k, d * r + r * k);
println!("Reduction: {:.1}x", (d * k) as f64 / (d * r + r * k) as f64);
let identical = h_full.iter().zip(h_lora.iter()).all(|(a, b)| (a - b).abs() < 1e-10);
println!("Output identical: {}", identical);
```

å‡ºåŠ›:
```
Wâ‚€ params: 262144
LoRA params: 8192
Reduction: 32.0x
Output identical: true
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’32åˆ†ã®1ã«å‰Šæ¸›ã—ãŸã€‚** å®Ÿéš›ã®GPT-3 (175B) ã§ã¯ã€LoRAã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’**10,000å€å‰Šæ¸›** [^1]ã€‚

ã“ã®èƒŒå¾Œã«ã‚ã‚‹æ•°å¼:

$$
h = W_0 x + \Delta W x = W_0 x + BA x, \quad W_0 \in \mathbb{R}^{d \times k}, \, B \in \mathbb{R}^{d \times r}, \, A \in \mathbb{R}^{r \times k}
$$

- $W_0$: äº‹å‰å­¦ç¿’é‡ã¿ï¼ˆ**frozen**ï¼‰
- $B, A$: ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ï¼ˆ**trainable**ï¼‰
- $r \ll \min(d, k)$: ãƒ©ãƒ³ã‚¯ï¼ˆå…¸å‹å€¤ 4-64ï¼‰

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: $dk$ (Full FT) â†’ $dr + rk \approx r(d+k)$ (LoRA)ã€‚$r=8, d=k=512$ ãªã‚‰å‰Šæ¸›ç‡ $\frac{512^2}{8 \cdot 1024} = 32$å€ã€‚

> **Note:** **é€²æ—: 3% å®Œäº†** LoRAã®åŸºæœ¬æ§‹é€ ã‚’ä½“æ„Ÿã—ãŸã€‚ã“ã“ã‹ã‚‰æ•°å¼ãƒ»å®Ÿè£…ãƒ»QLoRAãƒ»DreamBoothãƒ»Adapterã¨æ·±æ˜ã‚Šã—ã¦ã„ãã€‚

---

## ğŸ® 1. ä½“é¨“ã‚¾ãƒ¼ãƒ³ï¼ˆ10åˆ†ï¼‰â€” Fine-tuningã®4ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è§¦ã‚‹

### 1.1 Fine-tuningã®åŸºæœ¬ãƒ‘ã‚¿ãƒ¼ãƒ³

Fine-tuningã«ã¯4ã¤ã®åŸºæœ¬æˆ¦ç•¥ãŒã‚ã‚‹ã€‚

| æˆ¦ç•¥ | æ›´æ–°å¯¾è±¡ | ç”¨é€” | ãƒ¡ãƒ¢ãƒª | æ€§èƒ½ |
|:-----|:---------|:-----|:-------|:-----|
| **Full Fine-tuning** | å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ã‚¿ã‚¹ã‚¯ç‰¹åŒ–ã€ãƒ‡ãƒ¼ã‚¿è±Šå¯Œ | æ¥µå¤§ | æœ€é«˜ |
| **Feature Extraction** | æœ€çµ‚å±¤ã®ã¿ | ãƒ‡ãƒ¼ã‚¿å°‘ã€è¨ˆç®—åˆ¶ç´„ | æœ€å° | ä¸­ |
| **Partial Fine-tuning** | ä¸Šä½Nå±¤ | ä¸­é–“ãƒãƒ©ãƒ³ã‚¹ | ä¸­ | ä¸­-é«˜ |
| **PEFT (LoRAç­‰)** | è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ | å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ä¸­ç¨‹åº¦ | å° | é«˜ |

Transformerã‚’ä¾‹ã«å„æˆ¦ç•¥ã®å¼ã‚’æ›¸ãã€‚

#### 1.1.1 Full Fine-tuning

å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ $\theta$ ã‚’æ›´æ–°:

$$
\theta \leftarrow \theta - \eta \nabla_\theta \mathcal{L}(\theta)
$$

**åˆ©ç‚¹**: ã‚¿ã‚¹ã‚¯ã¸ã®å®Œå…¨é©å¿œã€‚**æ¬ ç‚¹**: GPT-3 (175B) ãªã‚‰ã€AdamWçŠ¶æ…‹è¾¼ã¿ã§æ•°TBã€‚

#### 1.1.2 Feature Extraction

Transformeræœ€çµ‚å±¤ï¼ˆåˆ†é¡ãƒ˜ãƒƒãƒ‰ï¼‰ã®ã¿è¨“ç·´ã€æ®‹ã‚Šã¯å›ºå®š:

$$
\begin{aligned}
h_L &= \text{Transformer}_{\theta_\text{frozen}}(x) \\
y &= W_\text{cls} h_L + b_\text{cls} \quad \text{(only } W_\text{cls}, b_\text{cls} \text{ trainable)}
\end{aligned}
$$

**åˆ©ç‚¹**: æœ€å°ãƒ¡ãƒ¢ãƒªã€‚**æ¬ ç‚¹**: ã‚¿ã‚¹ã‚¯é©å¿œãŒæµ…ã„ã€‚

#### 1.1.3 Partial Fine-tuning

ä¸Šä½Nå±¤ã ã‘æ›´æ–°:

$$
\begin{aligned}
h_{\text{frozen}} &= \text{Transformer}_{\theta_1, \dots, \theta_M}(x) \quad \text{(frozen)} \\
h_{\text{tuned}} &= \text{Transformer}_{\theta_{M+1}, \dots, \theta_L}(h_{\text{frozen}}) \quad \text{(trainable)}
\end{aligned}
$$

**åˆ©ç‚¹**: Full FTã®80-90%æ€§èƒ½ã‚’ãƒ¡ãƒ¢ãƒª50%ã§ã€‚**æ¬ ç‚¹**: ã©ã®Nå±¤ã‚’é¸ã¶ã‹ä¸æ˜ç­ã€‚

#### 1.1.4 PEFT (LoRA)

å…ƒã®é‡ã¿ã‚’å›ºå®šã€è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ $\Delta W = BA$ ã‚’è¨“ç·´:

$$
h = W_0 x + \underbrace{BA}_{\Delta W} x, \quad W_0 \text{ frozen}, \, B, A \text{ trainable}
$$

**åˆ©ç‚¹**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿0.01-1%ã€æ€§èƒ½â‰ˆFull FTã€‚**æ¬ ç‚¹**: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ $r, \alpha$ èª¿æ•´ãŒå¿…è¦ã€‚

å„æˆ¦ç•¥ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’å®šé‡æ¯”è¼ƒã™ã‚‹ã¨ã€$d=k=512$ ã®1å±¤ã§: Full FT = $512^2 = 262{,}144$ã€Feature Extraction â‰ˆ $512 \times C$ï¼ˆ$C$=ã‚¯ãƒ©ã‚¹æ•°ï¼‰ã€Partial FTï¼ˆä¸Šä½25%å±¤ï¼‰â‰ˆ $65{,}536$ã€LoRA ($r=8$) = $512 \times 8 + 8 \times 512 = 8{,}192$ã€‚LoRAã¯Full FTã®**3.1%**ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§åŒç­‰æ€§èƒ½ã‚’å®Ÿç¾ã™ã‚‹ã€‚

### 1.2 Catastrophic Forgetting â€” Fine-tuningã®æš—é»’é¢

Fine-tuningã«ã¯**Catastrophic Forgetting**ï¼ˆç ´å£Šçš„å¿˜å´ï¼‰ã¨ã„ã†å•é¡ŒãŒã‚ã‚‹ [^3]ã€‚æ–°ã‚¿ã‚¹ã‚¯ã«é©å¿œã™ã‚‹ã¨ã€å…ƒã®èƒ½åŠ›ã‚’å¤±ã†ç¾è±¡ã ã€‚

$$
\mathcal{L}_\text{total} = \mathcal{L}_\text{new task}(x_\text{new}, y_\text{new}; \theta) + \lambda \mathcal{L}_\text{old task}(x_\text{old}, y_\text{old}; \theta)
$$

å³è¾ºç¬¬2é …ãŒãªã„ã¨ã€$\theta$ ã¯æ–°ã‚¿ã‚¹ã‚¯ã«éé©åˆã—ã€æ—§ã‚¿ã‚¹ã‚¯æ€§èƒ½ãŒå´©å£Šã™ã‚‹ã€‚

| å•é¡Œ | åŸå›  | å¯¾ç­– |
|:-----|:-----|:-----|
| **Catastrophic Forgetting** | æ–°ã‚¿ã‚¹ã‚¯ã®å‹¾é…ãŒæ—§çŸ¥è­˜ã‚’ä¸Šæ›¸ã | Elastic Weight Consolidation (EWC), å¤šã‚¿ã‚¹ã‚¯å­¦ç¿’, LoRA (å…ƒé‡ã¿ã‚’ä¿è­·) |
| **Mode Collapse (Fine-tuningç‰ˆ)** | æ–°ã‚¿ã‚¹ã‚¯ã®ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒãŒç‹­ã„ | ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ, Regularization |
| **Overfitting** | Fine-tuningãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„ | Early Stopping, Dropout, LoRAã®ãƒ©ãƒ³ã‚¯å‰Šæ¸› |

**LoRAã®å‰¯æ¬¡çš„åˆ©ç‚¹**: $W_0$ ã‚’å›ºå®šã™ã‚‹ãŸã‚ã€å…ƒçŸ¥è­˜ãŒä¿è­·ã•ã‚Œã‚‹ã€‚è¤‡æ•°ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦è¤‡æ•°ã® $(B, A)$ ãƒšã‚¢ã‚’ä¿æŒã—ã€æ¨è«–æ™‚ã«åˆ‡ã‚Šæ›¿ãˆå¯èƒ½ã€‚

**ãƒ¡ãƒ¢ãƒªåŠ¹ç‡**: Full FT ã§3ã‚¿ã‚¹ã‚¯åˆ†è¨“ç·´ã™ã‚‹ã¨ $3 \times dk$ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚Multi-task LoRAã¯ $dk + 3(dr + rk)$ã€‚$r=8, d=k=512$ ãªã‚‰å‰Šæ¸›ç‡ $\frac{3 \times 512^2}{512^2 + 3 \times 8192} \approx 24$å€ã€‚

> **Note:** **é€²æ—: 10% å®Œäº†** Full FT / Feature Extraction / Partial FT / LoRA ã®4æˆ¦ç•¥ã‚’è§¦ã£ãŸã€‚Catastrophic Forgettingã®å•é¡Œã¨ã€LoRAã«ã‚ˆã‚‹è¤‡æ•°ã‚¿ã‚¹ã‚¯ä¿æŒã®ä»•çµ„ã¿ã‚’ç†è§£ã—ãŸã€‚æ¬¡ã¯ã€ŒãªãœFine-tuningãŒå¿…è¦ã‹ã€ã®ç›´æ„Ÿã¸ã€‚


> **Progress: 10%**
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. Full Fine-tuningãƒ»Feature Extractionãƒ»LoRAã®3ã¤ã§ã€æ›´æ–°ã•ã‚Œã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å‰²åˆã¯ãã‚Œãã‚Œã©ã®ãã‚‰ã„ã‹ï¼Ÿ
> 2. Catastrophic Forgettingï¼ˆç ´æ»…çš„å¿˜å´ï¼‰ã¨ã¯ä½•ã‹ï¼ŸãªãœFull Fine-tuningã§ç™ºç”Ÿã—ã‚„ã™ã„ã‹ï¼Ÿ

---

## ğŸ§© 2. ç›´æ„Ÿã‚¾ãƒ¼ãƒ³ï¼ˆ15åˆ†ï¼‰â€” ãªãœäº‹å‰å­¦ç¿’ã ã‘ã§ã¯è¶³ã‚Šãªã„ã®ã‹

### 2.1 äº‹å‰å­¦ç¿’ vs Fine-tuning â€” 2æ®µéšå­¦ç¿’ã®å¿…ç„¶æ€§

å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã¯2æ®µéšã§è¨“ç·´ã•ã‚Œã‚‹:

1. **äº‹å‰å­¦ç¿’ï¼ˆPre-trainingï¼‰**: å¤§è¦æ¨¡ã‚³ãƒ¼ãƒ‘ã‚¹ï¼ˆæ•°TBï¼‰ã§æ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬
2. **Fine-tuning**: ã‚¿ã‚¹ã‚¯ç‰¹åŒ–ãƒ‡ãƒ¼ã‚¿ï¼ˆæ•°GBä»¥ä¸‹ï¼‰ã§é©å¿œ

ãªãœ1æ®µéšã§ã¯ãƒ€ãƒ¡ãªã®ã‹ï¼Ÿ

| ç†ç”± | èª¬æ˜ | ä¾‹ |
|:-----|:-----|:---|
| **æ±ç”¨çŸ¥è­˜ vs å°‚é–€çŸ¥è­˜** | äº‹å‰å­¦ç¿’=æ±ç”¨ã€Fine-tuning=å°‚é–€ | GPT-3ã¯è‹±èªå…¨èˆ¬ã‚’å­¦ã¶ã€‚åŒ»ç™‚è¨ºæ–­ã«ã¯MedQAã§Fine-tuningãŒå¿…è¦ |
| **ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡** | å¤§é‡æ±ç”¨ãƒ‡ãƒ¼ã‚¿â†’å°é‡å°‚é–€ãƒ‡ãƒ¼ã‚¿ã¸ã®è»¢ç§» | ImageNetäº‹å‰å­¦ç¿’å¾Œã€100ç”»åƒã§Xç·šè¨ºæ–­ã«é©å¿œ |
| **è¨ˆç®—ã‚³ã‚¹ãƒˆ** | äº‹å‰å­¦ç¿’ã¯1å›ã€Fine-tuningã¯å¤šæ•°ã‚¿ã‚¹ã‚¯ã§ç¹°ã‚Šè¿”ã— | GPT-3äº‹å‰å­¦ç¿’=$5Mã€Fine-tuning=$100-1000 |
| **åˆ†å¸ƒã‚·ãƒ•ãƒˆ** | äº‹å‰å­¦ç¿’ã‚³ãƒ¼ãƒ‘ã‚¹ â‰  ã‚¿ã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿ | GPT-3ã¯æ›¸ç±ãƒ»Webå­¦ç¿’ã€‚æ³•å¾‹æ–‡æ›¸ã‚¹ã‚¿ã‚¤ãƒ«ã¯åˆ¥é€”å­¦ç¿’ãŒå¿…è¦ |

æ•°å¼ã§è¡¨ã™ã¨ã€äº‹å‰å­¦ç¿’ã¯**å‘¨è¾ºå°¤åº¦** $p(x)$ ã®æœ€å¤§åŒ–:

$$
\theta_\text{pretrain} = \arg\max_\theta \mathbb{E}_{x \sim p_\text{data}}[\log p_\theta(x)]
$$

Fine-tuningã¯**æ¡ä»¶ä»˜ãå°¤åº¦** $p(y|x)$ ã®æœ€å¤§åŒ–ï¼ˆã‚¿ã‚¹ã‚¯ç‰¹åŒ–ï¼‰:

$$
\theta_\text{finetune} = \arg\max_\theta \mathbb{E}_{(x,y) \sim p_\text{task}}[\log p_\theta(y|x)]
$$

åˆæœŸå€¤ $\theta_0 = \theta_\text{pretrain}$ ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã™ã‚‹ã“ã¨ã§ã€ãƒ©ãƒ³ãƒ€ãƒ åˆæœŸåŒ–ã‚ˆã‚Šé¥ã‹ã«é€ŸãåæŸã™ã‚‹ã€‚

### 2.2 Transfer Learningã®3ã¤ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ 

Fine-tuningã¯Transfer Learningã®ä¸€ç¨®ã€‚Computer Visionã§ç¢ºç«‹ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ãŒNLPã«ã‚‚é©ç”¨ã•ã‚ŒãŸã€‚

```mermaid
graph TD
    A["ImageNet<br/>äº‹å‰å­¦ç¿’"] --> B["CNNç‰¹å¾´æŠ½å‡ºå™¨"]
    B --> C1["åˆ†é¡ãƒ˜ãƒƒãƒ‰<br/>(çŠ¬vsçŒ«)"]
    B --> C2["åˆ†é¡ãƒ˜ãƒƒãƒ‰<br/>(è‚ºç‚æ¤œå‡º)"]
    B --> C3["åˆ†é¡ãƒ˜ãƒƒãƒ‰<br/>(è‡ªå‹•é‹è»¢)"]

    D["GPT-3<br/>äº‹å‰å­¦ç¿’"] --> E["Transformer<br/>è¡¨ç¾å­¦ç¿’"]
    E --> F1["è¦ç´„"]
    E --> F2["ç¿»è¨³"]
    E --> F3["QA"]

    style A fill:#e3f2fd
    style D fill:#fff3e0
    style B fill:#c8e6c9
    style E fill:#c8e6c9
```

3ã¤ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ :

1. **Feature Extraction**: äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’å›ºå®šã€æœ€çµ‚å±¤ã ã‘è¨“ç·´
2. **Fine-tuning**: å…¨å±¤ã‚’ä½å­¦ç¿’ç‡ã§å¾®èª¿æ•´
3. **PEFT**: LoRAç­‰ã®è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿è¨“ç·´ï¼ˆ2022å¹´ä»¥é™ã®ä¸»æµï¼‰

ç¬¬6å›ã§å­¦ã‚“ã KL divergenceã§èª¬æ˜ã™ã‚‹ã¨ã€Fine-tuningã¯**äº‹å‰å­¦ç¿’åˆ†å¸ƒ $p_\theta$ ã‚’ã‚¿ã‚¹ã‚¯åˆ†å¸ƒ $q_\text{task}$ ã«è¿‘ã¥ã‘ã‚‹**æ“ä½œ:

$$
\theta_\text{ft} = \arg\min_\theta D_\text{KL}(q_\text{task} \| p_\theta) = \arg\max_\theta \mathbb{E}_{x \sim q_\text{task}}[\log p_\theta(x)]
$$

### 2.3 æœ¬è¬›ç¾©ã®ä½ç½®ã¥ã‘ â€” Course IIIã®ä¸­æ ¸

Course IIIã¯ã€Œå®Ÿè·µç·¨ã€ â€” ç¬¬17-24å›ã§å®Ÿè£…ãƒ»æœ€é©åŒ–ãƒ»è©•ä¾¡ã‚’å­¦ã¶ã€‚

| ç¬¬17å› | ç¬¬18å› | ç¬¬19å› | ç¬¬20å› | ç¬¬21å› | ç¬¬22å› | **ç¬¬23å›** | ç¬¬24å› |
|:-------|:-------|:-------|:-------|:-------|:-------|:----------|:-------|
| MoE | Hybrid | Elixir | Tokenizer | Audio | Multi-modal | **Fine-tuning** | çµ±è¨ˆå­¦ |

ç¬¬17-22å›ã§**ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆ**ã‚’å­¦ã‚“ã ã€‚ç¬¬23å›ã¯**ãƒ¢ãƒ‡ãƒ«é©å¿œ**ã€‚ç¬¬24å›ã§**è©•ä¾¡ã®æ•°å­¦**ã‚’å­¦ã³ã€Course IIIã‚’å®Œäº†ã™ã‚‹ã€‚

**Course I/II/IIIã®æ¥ç¶š**:

- **Course I (ç¬¬1-8å›)**: æ•°å­¦åŸºç¤ â€” ç·šå½¢ä»£æ•°ãƒ»ç¢ºç‡è«–ãƒ»æƒ…å ±ç†è«–ãƒ»EMç®—æ³•
- **Course II (ç¬¬9-16å›)**: ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ç†è«– â€” VAEãƒ»GANãƒ»OTãƒ»Transformerãƒ»Autoregressive
- **Course III (ç¬¬17-24å›)**: å®Ÿè·µç·¨ â€” MoEãƒ»Hybridãƒ»Fine-tuningãƒ»è©•ä¾¡ â† **ä»Šã“ã“**

ç¬¬23å›ã§ä½¿ã†æ•°å­¦:

| æ¦‚å¿µ | åˆå‡º | æœ¬è¬›ç¾©ã§ã®å½¹å‰² |
|:-----|:-----|:-------------|
| **SVD (ç‰¹ç•°å€¤åˆ†è§£)** | ç¬¬3å› | LoRAã®ä½ãƒ©ãƒ³ã‚¯è¿‘ä¼¼ã®ç†è«–çš„åŸºç›¤ |
| **MLE (æœ€å°¤æ¨å®š)** | ç¬¬7å› | Fine-tuningã®ç›®çš„é–¢æ•° |
| **KL divergence** | ç¬¬6å› | åˆ†å¸ƒé–“ã®è·é›¢ã€Fine-tuningã®æœ¬è³ª |
| **Gradient Descent** | ç¬¬6å› | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–° |
| **æ­£å‰‡åŒ–** | ç¬¬8å› | Catastrophic Forgettingå¯¾ç­– |

### 2.4 æ¾å°¾ãƒ»å²©æ¾¤ç ”ã¨ã®å·®åˆ¥åŒ–

æ¾å°¾ç ”ã®DLè¬›ç¾©ï¼ˆ2023å¹´ç‰ˆï¼‰ã¯ã€ŒFine-tuningã®æ¦‚å¿µã€ã‚’1ã‚¹ãƒ©ã‚¤ãƒ‰ã§è§¦ã‚Œã‚‹ã®ã¿ã€‚æœ¬è¬›ç¾©ã¯:

| é …ç›® | æ¾å°¾ç ” | æœ¬è¬›ç¾© |
|:-----|:-------|:-------|
| LoRAæ•°å¼å°å‡º | ãªã— | å®Œå…¨å°å‡ºï¼ˆä½ãƒ©ãƒ³ã‚¯è¿‘ä¼¼â†’åˆæœŸåŒ–â†’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰ |
| QLoRAå®Ÿè£… | ãªã— | 4-bit NFé‡å­åŒ–ã®æ•°å¼â†”ã‚³ãƒ¼ãƒ‰å¯¾å¿œ |
| DreamBooth | ãªã— | Prior Preservation Lossã®å®Œå…¨åˆ†è§£ |
| 3è¨€èªå®Ÿè£… | Pythonã®ã¿ | ğŸ¦€Rustè¨“ç·´ + ğŸ¦€Rustæ¨è«– |
| è¡Œæ•° | ~10è¡Œ | ~3000è¡Œï¼ˆæœ¬è¬›ç¾©ç›®æ¨™ï¼‰ |

### 2.5 3ã¤ã®æ¯”å–©ã§æ‰ãˆã‚‹ã€ŒFine-tuningã€

1. **è¨€èªå­¦ç¿’**: äº‹å‰å­¦ç¿’=åŸºç¤æ–‡æ³•ã€Fine-tuning=å°‚é–€ç”¨èªç¿’å¾—
2. **å·¥å…·**: äº‹å‰å­¦ç¿’=æ±ç”¨å·¥å…·ã€Fine-tuning=ç”¨é€”ç‰¹åŒ–ã‚¢ã‚¿ãƒƒãƒãƒ¡ãƒ³ãƒˆ
3. **æ¥½å™¨**: äº‹å‰å­¦ç¿’=åŸºç¤ç·´ç¿’ã€Fine-tuning=æ›²ã”ã¨ã®è§£é‡ˆ

LoRAã®æ¯”å–©: **æ±ç”¨å·¥å…·ã®åˆƒã‚’ç ”ãç›´ã™ã®ã§ã¯ãªãã€ä»˜ã‘æ›¿ãˆå¯èƒ½ãªå°‚ç”¨åˆƒã‚’è¿½åŠ ã™ã‚‹**ã€‚äº‹å‰å­¦ç¿’ = å¤§é‡ãƒ‡ãƒ¼ã‚¿ã§æ±ç”¨å·¥å…·ã‚’é›é€ ã€‚Fine-tuning = ç‰¹å®šç”¨é€”ã®å°‚ç”¨åˆƒã‚’å¾Œä»˜ã‘ã™ã‚‹ã€‚$W_0$ ã¯ãã®ã¾ã¾ã€$BA$ ã ã‘ãŒæ–°ã—ã„åˆƒã ã€‚

> **Note:** **é€²æ—: 20% å®Œäº†** ãªãœFine-tuningãŒå¿…è¦ã‹ã€äº‹å‰å­¦ç¿’ã¨ã®é•ã„ã€Transfer Learningã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ç†è§£ã—ãŸã€‚äº‹å‰å­¦ç¿’ $p(x)$ â†’ Fine-tuning $p(y|x;	heta)$ ã®2æ®µéšå­¦ç¿’ã®å¿…ç„¶æ€§ã¨ã€KL divergenceè¦–ç‚¹ã§ã®å®šå¼åŒ–ãŒæ ¸å¿ƒã ã€‚æ¬¡ã¯æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ â€” LoRA/QLoRA/DreamBooth/Adapterã®å®Œå…¨å°å‡ºã¸ã€‚


> **Progress: 20%**
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. LoRAãŒã€Œä½ãƒ©ãƒ³ã‚¯ä»®èª¬ã€ã«åŸºã¥ã„ã¦ã„ã‚‹ç›´æ„Ÿçš„ãªæ ¹æ‹ ã‚’èª¬æ˜ã›ã‚ˆã€‚
> 2. ãªãœ65Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¶ˆè²»è€…å‘ã‘GPU1æšã§Fine-tuningã§ãã‚‹ã®ã‹ã€QLoRAã®ä»•çµ„ã¿ã‚’æ¦‚èª¬ã›ã‚ˆã€‚

---

## ğŸ“ 3. æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ï¼ˆ60åˆ†ï¼‰â€” Post-Trainingå®Œå…¨ç†è«–: CPTâ†’SFTâ†’RLHFâ†’PEFT

**ã‚´ãƒ¼ãƒ«**: CPT/SFT/RLHFã®æå¤±é–¢æ•°ã‚’ä¸€è¡Œãšã¤å°å‡ºã—ã€ãã®å¾ŒLoRA/QLoRA/DreamBooth/Adapterã®æ•°å¼ã‚’å®Œå…¨ç†è§£ã™ã‚‹ã€‚

### 3.0 Post-Trainingå…¨ä½“åƒ â€” å­¦ç¿’æ®µéšè¨­è¨ˆ

äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿç”¨ç›®çš„ã«é©å¿œã•ã›ã‚‹å·¥ç¨‹å…¨ä½“ã‚’ã€ŒPost-Trainingã€ã¨å‘¼ã¶ã€‚å˜ãªã‚‹Fine-tuningã§ã¯ãªãã€**CPT â†’ SFT â†’ RLHF** ã¨ã„ã†å­¦ç¿’æ®µéšã®é€£é–è¨­è¨ˆã ã€‚

```mermaid
graph LR
    A["ğŸŒ Pre-Training<br/>æ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬<br/>æ•°TBã‚³ãƒ¼ãƒ‘ã‚¹"] --> B["ğŸ“š CPT<br/>ç¶™ç¶šäº‹å‰å­¦ç¿’<br/>ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œ"]
    B --> C["ğŸ’¬ SFT<br/>æ•™å¸«ã‚ã‚Šæ•´åˆ—<br/>Instruction Tuning"]
    C --> D["ğŸ¯ RLHF<br/>é¸å¥½æ•´åˆ—<br/>PPO / DPO"]
    D --> E["âš¡ PEFTé©ç”¨<br/>LoRA / QLoRA<br/>å„ã‚¹ãƒ†ãƒ¼ã‚¸ã«æŒ¿å…¥å¯"]
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style C fill:#e8f5e9
    style D fill:#fff3e0
    style E fill:#fce4ec
```

å„ã‚¹ãƒ†ãƒ¼ã‚¸ã®å½¹å‰²ã¨æå¤±:

| ã‚¹ãƒ†ãƒ¼ã‚¸ | ç›®çš„ | å…¸å‹æå¤±é–¢æ•°ã®å½¢ | ãƒ‡ãƒ¼ã‚¿è¦æ¨¡ |
|:---------|:-----|:--------------|:---------|
| **Pre-Training** | æ±ç”¨è¨€èªè¡¨ç¾ã®ç²å¾— | è¨€èªãƒ¢ãƒ‡ãƒ«æå¤± | æ•°TB |
| **CPT** | ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–çŸ¥è­˜ã®æ³¨å…¥ | åŒä¸Šï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‘ã‚¹ã§ç¶™ç¶šï¼‰ | æ•°GBã€œæ•°TB |
| **SFT** | æŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ã®ä»˜ä¸ | æ¡ä»¶ä»˜ãäº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ | æ•°åƒã€œæ•°ä¸‡ä¾‹ |
| **RLHF** | äººé–“ã®é¸å¥½ã¸ã®æ•´åˆ— | å ±é…¬æœ€å¤§åŒ– âˆ’ KLåˆ¶ç´„ | æ•°ä¸‡æ¯”è¼ƒãƒšã‚¢ |
| **PEFT** | è¨ˆç®—åŠ¹ç‡åŒ–ï¼ˆå„ã‚¹ãƒ†ãƒ¼ã‚¸ã«é©ç”¨å¯ï¼‰ | ä¸Šè¨˜ã®ã„ãšã‚Œã‹ | ä¸Šè¨˜ã«åŒã˜ |

#### 3.0.1 Catastrophic Forgetting â€” é€æ¬¡å­¦ç¿’ã®å‘ªã„

é€æ¬¡å­¦ç¿’ã®æ ¸å¿ƒçš„å•é¡Œã€‚æ–°ã‚¿ã‚¹ã‚¯ã‚’å­¦ã¶ã¨ãã€ä»¥å‰ã®çŸ¥è­˜ãŒç ´å£Šã•ã‚Œã‚‹ [^3]ã€‚

$$
\theta^* = \arg\min_\theta \mathcal{L}_\text{new}(\theta) \quad \Rightarrow \quad \mathcal{L}_\text{old}(\theta^*) \gg \mathcal{L}_\text{old}(\theta_0)
$$

æ–°ã‚¿ã‚¹ã‚¯ã®å‹¾é… $\nabla_\theta \mathcal{L}_\text{new}$ ãŒã€æ—§çŸ¥è­˜ã®å‹¾é…æ–¹å‘ã¨å¹²æ¸‰ã™ã‚‹ã€‚

ç·©å’Œç­–ã®3é¡å‹:

| æ‰‹æ³• | åŸç† | ä»£è¡¨ |
|:-----|:-----|:-----|
| **æ­£å‰‡åŒ–** | é‡è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¤‰åŒ–ã«ãƒšãƒŠãƒ«ãƒ†ã‚£ | EWC [^3] |
| **ãƒªãƒ—ãƒ¬ã‚¤** | æ—§ãƒ‡ãƒ¼ã‚¿ã‚’æ··åˆã—ã¦ç¶™ç¶šè¨“ç·´ | Experience Replay |
| **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†é›¢** | æ—§çŸ¥è­˜ã¨æ–°çŸ¥è­˜ã‚’åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã« | LoRAï¼ˆ$W_0$ frozenï¼‰ |

EWC (Elastic Weight Consolidation) ã®æå¤±:

$$
\mathcal{L}_\text{EWC}(\theta) = \mathcal{L}_\text{new}(\theta) + \frac{\lambda}{2} \sum_i F_i (\theta_i - \theta_{0,i})^2
$$

$F_i = \mathbb{E}\left[\left(\frac{\partial \log p_\theta(x)}{\partial \theta_i}\right)^2\right]$: Fisheræƒ…å ±è¡Œåˆ—ã®å¯¾è§’è¦ç´ ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ $i$ ã®é‡è¦åº¦ï¼‰ã€‚é‡è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ$F_i$ ãŒå¤§ãã„ï¼‰ã»ã©ç§»å‹•ã‚³ã‚¹ãƒˆãŒé«˜ã„ã€‚

#### 3.0.2 Full Fine-tuning vs PEFT ã®ä½ç½®ã¥ã‘

$$
\begin{aligned}
\text{Full FT:} & \quad \theta_\text{new} = \arg\min_\theta \mathcal{L}(\theta), \quad \theta_\text{init} = \theta_\text{pretrained} \\
\text{PEFT:} & \quad \phi^* = \arg\min_\phi \mathcal{L}(\theta_0 + \Delta\theta(\phi)), \quad |\phi| \ll |\theta_0|
\end{aligned}
$$

PEFTã®æœ¬è³ª: å›ºå®šã•ã‚ŒãŸ $\theta_0$ ã®å‘¨è¾ºã§ä½æ¬¡å…ƒã® $\Delta\theta(\phi)$ ã‚’æ¢ç´¢ã™ã‚‹ã€‚ã“ã® $\Delta\theta$ ã®æ§‹é€ ãŒLoRAï¼ˆä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ï¼‰ã€Adapterï¼ˆãƒœãƒˆãƒ«ãƒãƒƒã‚¯éç·šå½¢ï¼‰ã€Prefixï¼ˆãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã§ç•°ãªã‚‹ã€‚

#### 3.0.3 Transfer Learningã®3ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ 

**ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ 1: Feature Extraction**ï¼ˆ$\theta_0$ å›ºå®šï¼‰

$$
y = g_\psi(f_{\theta_0}(x)), \quad \text{train only } \psi
$$

**ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ 2: Full Fine-tuning**ï¼ˆå…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ï¼‰

$$
\theta^* = \theta_0 - \eta \nabla_\theta \mathcal{L}_\text{task}(\theta_0)
$$

**ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ 3: PEFT**ï¼ˆ2022å¹´ä»¥é™ã®ä¸»æµï¼‰

$$
\phi^* = \arg\min_\phi \mathcal{L}_\text{task}\!\left(\theta_0 + \Delta\theta(\phi)\right), \quad |\phi| / |\theta_0| \approx 0.01\text{--}1\%
$$

LoRAã§ã¯ $\phi = \{B, A\}$ã€$\Delta\theta = \frac{\alpha}{r} BA$ã€‚3ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã®ä¸­ã§PEFTã ã‘ãŒã€Œ$W_0$ã«ã‚ˆã‚‹äº‹å‰å­¦ç¿’çŸ¥è­˜ã‚’ä¿è­·ã—ã¤ã¤é©å¿œã™ã‚‹ã€ç‰¹æ€§ã‚’æŒã¤ã€‚

---

### 3.1 CPTç†è«– â€” ç¶™ç¶šäº‹å‰å­¦ç¿’

#### 3.1.1 å®šç¾©ã¨å‹•æ©Ÿ

**Continued Pre-Training (CPT)** ã¾ãŸã¯ **Domain-Adaptive Pretraining (DAPT)** [^29] ã¨ã¯ã€æ±ç”¨äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ã‚³ãƒ¼ãƒ‘ã‚¹ã§è¿½åŠ è¨“ç·´ã™ã‚‹æ‰‹æ³•ã ã€‚

åŒ»ç™‚ãƒ»æ³•å¾‹ãƒ»ã‚³ãƒ¼ãƒ‰ãªã©ã€ç‰¹å®šãƒ‰ãƒ¡ã‚¤ãƒ³ã®æ–‡æ›¸ã¯æ±ç”¨ã‚³ãƒ¼ãƒ‘ã‚¹ä¸­ã«å°‘é‡ã—ã‹å«ã¾ã‚Œãªã„ã€‚äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¯ãã®èªå½™ãƒ»ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»çŸ¥è­˜ã‚’ååˆ†ã«å†…åœ¨åŒ–ã—ã¦ã„ãªã„ã€‚CPTã¯ã“ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ã€‚

#### 3.1.2 CPTæå¤±ã®å®Œå…¨å°å‡º

CPTã®æå¤±ã¯Language Modelingã¨åŒå½¢ã ãŒã€**ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‘ã‚¹ $\mathcal{D}_\text{domain}$ ä¸Šã§è¨ˆç®—**ã™ã‚‹ç‚¹ãŒæœ¬è³ªçš„ãªå·®ç•°ã ã€‚

ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‘ã‚¹: $\mathcal{D}_\text{domain} = \{x^{(1)}, x^{(2)}, \dots, x^{(N)}\}$ï¼ˆå„ $x^{(i)}$ ã¯ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ï¼‰ã€‚

**Step 1: å˜ä¸€ç³»åˆ—ã®å¯¾æ•°å°¤åº¦**

ç³»åˆ— $x = (x_1, x_2, \dots, x_T)$ ã®ç¢ºç‡ã‚’è‡ªå·±å›å¸°çš„ã«åˆ†è§£:

$$
p_\theta(x) = \prod_{t=1}^T p_\theta(x_t \mid x_1, \dots, x_{t-1}) = \prod_{t=1}^T p_\theta(x_t \mid x_{<t})
$$

å¯¾æ•°ã‚’å–ã‚‹:

$$
\log p_\theta(x) = \sum_{t=1}^T \log p_\theta(x_t \mid x_{<t})
$$

**Step 2: è² å¯¾æ•°å°¤åº¦ï¼ˆæå¤±ï¼‰**

æœ€å¤§åŒ–å•é¡Œã‚’æœ€å°åŒ–å•é¡Œã«å¤‰æ›:

$$
\mathcal{L}_\text{CPT}(\theta) = -\frac{1}{T} \sum_{t=1}^T \log p_\theta(x_t \mid x_{<t})
$$

$p_\theta(x_t \mid x_{<t})$ ã¯softmaxç¢ºç‡: $p_\theta(x_t \mid x_{<t}) = \frac{\exp(h_\theta(x_{<t})_{x_t})}{\sum_{v} \exp(h_\theta(x_{<t})_v)}$ã€‚

**Step 3: ã‚³ãƒ¼ãƒ‘ã‚¹å…¨ä½“ã¸ã®æ‹¡å¼µ**

$$
\mathcal{L}_\text{CPT}(\theta) = -\frac{1}{|\mathcal{D}_\text{domain}|} \sum_{x \in \mathcal{D}_\text{domain}} \frac{1}{|x|} \sum_{t=1}^{|x|} \log p_\theta(x_t \mid x_{<t})
$$

**å‹¾é…ã®å½¢**:

$$
\nabla_\theta \mathcal{L}_\text{CPT} = -\frac{1}{|\mathcal{D}|} \sum_{x, t} \nabla_\theta \log p_\theta(x_t \mid x_{<t})
$$

ã“ã‚Œã¯softmaxã®å‹¾é…: $\nabla_\theta \log p = \nabla_\theta h_\theta - \mathbb{E}_{v \sim p}[\nabla_\theta h_\theta^{(v)}]$ã€‚æ­£è§£ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å¼·åŒ–ã—ã€ä»–ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŠ‘åˆ¶ã™ã‚‹ã€‚

#### 3.1.3 ãƒ‡ãƒ¼ã‚¿æ··åˆæˆ¦ç•¥ â€” ãƒ‰ãƒ¡ã‚¤ãƒ³æ¯”ç‡ $\alpha$ ã®é¸æŠç†è«–

CPTã§ã¯æ±ç”¨ãƒ‡ãƒ¼ã‚¿ã¨ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’æ··åˆã™ã‚‹ã“ã¨ãŒå¤šã„ã€‚æ··åˆæ¯”ç‡ã®é¸æŠãŒæ€§èƒ½ã‚’å·¦å³ã™ã‚‹ã€‚

**æ··åˆæå¤±**:

$$
\mathcal{L}_\text{mix}(\theta) = \alpha \mathcal{L}_\text{domain}(\theta) + (1 - \alpha) \mathcal{L}_\text{general}(\theta), \quad \alpha \in [0, 1]
$$

**$\alpha$ ã®é¸æŠç†è«–** [^29]:

$$
\alpha^* = \arg\min_\alpha \left[ \mathcal{L}_\text{domain}^\text{val}(\theta^*(\alpha)) + \lambda_\text{cf} \cdot \Delta_\text{forgetting}(\alpha) \right]
$$

$\Delta_\text{forgetting}(\alpha) = \mathcal{L}_\text{general}^\text{val}(\theta^*(\alpha)) - \mathcal{L}_\text{general}^\text{val}(\theta_0)$: æ±ç”¨æ€§èƒ½ã®ä½ä¸‹é‡ã€‚

å®Ÿé¨“çš„ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ [^29]:

| ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿é‡ | æ¨å¥¨ $\alpha$ | æ ¹æ‹  |
|:--------------|:------------|:-----|
| < 1GB | 0.1ã€œ0.3 | å°‘é‡ã®ãŸã‚éå­¦ç¿’ãƒªã‚¹ã‚¯ |
| 1ã€œ10GB | 0.3ã€œ0.5 | ãƒãƒ©ãƒ³ã‚¹ç‚¹ |
| > 10GB | 0.5ã€œ0.8 | ååˆ†ãªé‡ã€ãƒ‰ãƒ¡ã‚¤ãƒ³å„ªå…ˆ |

#### 3.1.4 ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ è¨­è¨ˆ â€” é›£æ˜“åº¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°

ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ å­¦ç¿’ [^30]: æ˜“â†’é›£ã®é †ã«æç¤ºã™ã‚‹ã¨åæŸãŒé€Ÿã„ã€‚

$$
p_t(x) \propto \exp\!\left(-\beta_t \cdot \text{difficulty}(x)\right), \quad \beta_t \text{ increases over training}
$$

$\text{difficulty}(x)$: ç³»åˆ— $x$ ã®é›£æ˜“åº¦æŒ‡æ¨™ï¼ˆperplexityã‚„æ–‡é•·ãªã©ï¼‰ã€‚

åˆæœŸ ($\beta_t$ å°): å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‡ç­‰ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€‚å¾ŒæœŸ ($\beta_t$ å¤§): é›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«é‡è¦–ã€‚

**æ•°å€¤æ¤œè¨¼**: åˆæœŸperplexityãŒ200ã®ãƒ¢ãƒ‡ãƒ«ã§ã€é›£æ˜“åº¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã‚ã‚Šã®å ´åˆã®final perplexityã¯å…¸å‹çš„ã«5ã€œ10%ä½ããªã‚‹ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³ä¾å­˜ï¼‰ã€‚

#### 3.1.5 ç ´æ»…çš„å¿˜å´ã¨ç·©å’Œ â€” EWCå¿œç”¨

CPTã§æœ€ã‚‚æ·±åˆ»ãªå•é¡Œã¯ã€æ±ç”¨èƒ½åŠ›ã®å–ªå¤±ã ã€‚

$$
\text{forgetting} = \frac{\mathcal{L}_\text{general}(\theta_\text{CPT}) - \mathcal{L}_\text{general}(\theta_0)}{\mathcal{L}_\text{general}(\theta_0)} \times 100\%
$$

å…¸å‹çš„ã«ã¯ $\alpha = 1.0$ (ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ã¿) ã§5ã€œ20%ã®å¿˜å´ãŒç™ºç”Ÿã™ã‚‹ã€‚

**ç·©å’Œæ‰‹æ³• 1: Replayï¼ˆãƒ‡ãƒ¼ã‚¿æ··åˆã€æœ€ã‚‚å®Ÿç”¨çš„ï¼‰**

$$
\mathcal{L} = \alpha \mathcal{L}_\text{domain} + (1-\alpha) \mathcal{L}_\text{general}, \quad \alpha = 0.3\text{--}0.5
$$

**ç·©å’Œæ‰‹æ³• 2: EWC**

$$
\mathcal{L} = \mathcal{L}_\text{domain}(\theta) + \frac{\lambda}{2} \sum_i F_i (\theta_i - \theta_{0,i})^2
$$

Fisherã‚’è¨ˆç®—ã™ã‚‹ã‚³ã‚¹ãƒˆï¼ˆ$O(|\theta|^2)$ï¼‰ãŒèª²é¡Œã€‚å®Ÿç”¨ä¸Šã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ–ãƒ­ãƒƒã‚¯å¯¾è§’ã¨è¿‘ä¼¼ã€‚

**ç·©å’Œæ‰‹æ³• 3: LoRA-CPTï¼ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†é›¢ï¼‰**

$W_0$ ã‚’å‡çµã—ã€CPTã‚‚LoRAã§è¡Œã†ã€‚æ±ç”¨çŸ¥è­˜ï¼ˆ$W_0$ï¼‰ã‚’å®Œå…¨ä¿è­·ã€‚

---

### 3.2 SFTç†è«– â€” æ•™å¸«ã‚ã‚Šæ•´åˆ—

#### 3.2.1 Instruction Tuningã®å®šç¾©ã¨æ­´å²

**Supervised Fine-Tuning (SFT)** = **Instruction Tuning** ã¨ã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«ã€ŒæŒ‡ç¤ºï¼ˆinstructionï¼‰â†’å¿œç­”ï¼ˆresponseï¼‰ã€ã®ãƒšã‚¢ã‚’å­¦ç¿’ã•ã›ã€äººé–“ã®æ„å›³ã«æ²¿ã£ãŸå‡ºåŠ›ã‚’å¯èƒ½ã«ã™ã‚‹æ‰‹æ³•ã ã€‚

InstructGPT [^10] (Ouyang et al., 2022) ã¯RLHFã®SFTã‚¹ãƒ†ãƒ¼ã‚¸ã¨ã—ã¦ç¢ºç«‹ã€‚ãã®å¾ŒAlpacaã€Dollyã€ShareGPTç­‰ã®å…¬é–‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã‚ˆã‚Šåºƒãæ™®åŠã—ãŸã€‚

#### 3.2.2 Chat Template â€” ãƒ­ãƒ¼ãƒ«æ§‹é€ ã®å®šå¼åŒ–

ç¾ä»£ã®SFTãƒ‡ãƒ¼ã‚¿ã¯**system / user / assistant**ã®3ãƒ­ãƒ¼ãƒ«æ§‹é€ ã‚’æŒã¤:

```
<|system|>
You are a helpful assistant.
<|user|>
ãƒ•ãƒ©ãƒ³ã‚¹ã®é¦–éƒ½ã¯ã©ã“ã§ã™ã‹ï¼Ÿ
<|assistant|>
ãƒ•ãƒ©ãƒ³ã‚¹ã®é¦–éƒ½ã¯ãƒ‘ãƒªã§ã™ã€‚
```

æ•°å­¦çš„ã«ã¯ã€å…¥åŠ›ç³»åˆ— $x$ ã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§æ§‹é€ åŒ–:

$$
x = [\underbrace{s_1, \dots, s_{|s|}}_{\text{system}}, \underbrace{u_1, \dots, u_{|u|}}_{\text{user}}, \underbrace{a_1, \dots, a_{|a|}}_{\text{assistant}}]
$$

SFTã§ã¯**assistantéƒ¨åˆ†ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿**ã«æå¤±ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆsystem/userã¯æ­£è§£ãƒ©ãƒ™ãƒ«ã¨ã—ã¦æ‰±ã‚ãªã„ï¼‰ã€‚

#### 3.2.3 SFTæå¤±ã®å®Œå…¨å°å‡º

å…¥åŠ›ï¼ˆinstructionï¼‰ $x$ã€å‡ºåŠ›ï¼ˆresponseï¼‰ $y = (y_1, \dots, y_T)$ ã®ãƒšã‚¢ $(x, y) \in \mathcal{D}_\text{SFT}$ ã«å¯¾ã—ã¦:

**Step 1: æ¡ä»¶ä»˜ãè‡ªå·±å›å¸°åˆ†è§£**

$$
p_\theta(y \mid x) = \prod_{t=1}^T p_\theta(y_t \mid x, y_1, \dots, y_{t-1}) = \prod_{t=1}^T p_\theta(y_t \mid x, y_{<t})
$$

**Step 2: è² ã®æ¡ä»¶ä»˜ãå¯¾æ•°å°¤åº¦**

$$
\mathcal{L}_\text{SFT}(\theta) = -\frac{1}{T} \sum_{t=1}^T \log p_\theta(y_t \mid x, y_{<t})
$$

**Step 3: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“**

$$
\mathcal{L}_\text{SFT}(\theta) = -\frac{1}{|\mathcal{D}_\text{SFT}|} \sum_{(x, y) \in \mathcal{D}_\text{SFT}} \frac{1}{|y|} \sum_{t=1}^{|y|} \log p_\theta(y_t \mid x, y_{<t})
$$

**CPTæå¤±ã¨ã®æœ¬è³ªçš„å·®ç•°**:

$$
\begin{aligned}
\mathcal{L}_\text{CPT} &= -\frac{1}{T} \sum_{t=1}^T \log p_\theta(x_t \mid x_{<t}) \quad \text{(å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã«æå¤±)} \\
\mathcal{L}_\text{SFT} &= -\frac{1}{|y|} \sum_{t=1}^{|y|} \log p_\theta(y_t \mid x, y_{<t}) \quad \text{(å¿œç­”ãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿)}
\end{aligned}
$$

SFTã¯inputã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä¸ãˆã€outputã®ã¿ã‚’æœ€é©åŒ–ã™ã‚‹ã€‚

#### 3.2.4 Reasoningãƒ‡ãƒ¼ã‚¿å“è³ª â€” Chain-of-Thought

Chain-of-Thought (CoT) [^31] ã¯ã€å¿œç­”ã«ä¸­é–“æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’å«ã‚ã‚‹:

$$
y = (\underbrace{r_1, \dots, r_K}_{\text{reasoning chain}}, \underbrace{a}_{\text{final answer}})
$$

SFTæå¤±ã¯CoTå…¨ä½“ã«é©ç”¨:

$$
\mathcal{L}_\text{CoT} = -\frac{1}{K+1} \left[\sum_{k=1}^K \log p_\theta(r_k \mid x, r_{<k}) + \log p_\theta(a \mid x, r)\right]
$$

**ãªãœCoTãŒåŠ¹ãã‹**: æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ˜ç¤ºçš„ã«å­¦ã¶ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ãŒã€Œæ­£è§£ã¸ã®é“ç­‹ã€ã‚’å†…åœ¨åŒ–ã™ã‚‹ã€‚æ¨è«–èƒ½åŠ›ã¯ $\log p_\theta(a \mid x, r)$ ã®å‘ä¸Š = ã€Œæ–‡è„ˆãŒã‚ã‚‹å ´åˆã®æ­£è§£ç¢ºç‡ã€ã®å‘ä¸Šã¨ã—ã¦æ¸¬å®šã§ãã‚‹ã€‚

#### 3.2.5 é•·ã•åˆ¶å¾¡ã¨æ•™å¸«ä¿¡å·è¨­è¨ˆ

**é•·ã•ãƒã‚¤ã‚¢ã‚¹å•é¡Œ**: SFTãƒ‡ãƒ¼ã‚¿ã«é•·ã„å¿œç­”ãŒå¤šã„ã¨ã€ãƒ¢ãƒ‡ãƒ«ãŒå†—é•·ãªå¿œç­”ã‚’å¥½ã‚€ã€‚

$$
\mathcal{L}_\text{length-controlled} = -\frac{1}{|y|} \sum_t \log p_\theta(y_t \mid x, y_{<t}) \cdot w(|y|)
$$

$w(|y|)$: é•·ã•ãƒšãƒŠãƒ«ãƒ†ã‚£ã€‚å…¸å‹çš„ã«ã¯ $w(l) = \exp(-\gamma \cdot \max(0, l - l_\text{max}))$ã€‚

**ãƒ‡ãƒ¼ã‚¿å“è³ª vs é‡ã®ç†è«–** [^32]: ãƒ‡ãƒ¼ã‚¿é‡ã‚’ $N$ã€å“è³ªæŒ‡æ¨™ã‚’ $q \in [0, 1]$ ã¨ã™ã‚‹ã¨ã€

$$
\text{Performance} \approx c \cdot (N \cdot q)^\beta
$$

$\beta < 1$ ã®å ´åˆï¼ˆå¤šãã®å®Ÿé¨“ã§ç¢ºèªï¼‰ã€**å“è³ªå‘ä¸Šã®åŠ¹æœã¯é‡å‘ä¸Šã¨ç­‰ä¾¡ä»¥ä¸Š**ã€‚Alpaca (52Kä¾‹, q ä½) vs LIMA (1Kä¾‹, q é«˜) ã§LIMAãŒå¤šãã®ã‚¿ã‚¹ã‚¯ã§å„ªä½ã¨ã„ã†çµæœ [^32] ã¯ã“ã®ç†è«–ã‚’æ”¯æŒã™ã‚‹ã€‚

---

### 3.3 RLHFç†è«– â€” é¸å¥½æ•´åˆ—

#### 3.3.1 å•é¡Œè¨­å®š â€” ãªãœSFTã ã‘ã§ã¯ä¸ååˆ†ã‹

SFTã¯ã€ŒæŒ‡ç¤ºã¸ã®æ­£è§£ã‚‰ã—ã„å¿œç­”ã€ã‚’å­¦ã¶ã€‚ã—ã‹ã—ã€Œäººé–“ãŒæœ¬å½“ã«å¥½ã‚€å¿œç­”ã€ã¯å¿…ãšã—ã‚‚ã€Œæœ€ã‚‚å°¤åº¦ãŒé«˜ã„å¿œç­”ã€ã§ã¯ãªã„ã€‚

$$
\underbrace{p_\theta^\text{SFT}(y_\text{good} \mid x)}_{\text{SFTã®å¾—ç‚¹}} \neq \underbrace{r_\text{human}(x, y_\text{good})}_{\text{äººé–“ã®é¸å¥½}}
$$

RLHFã¯ã€äººé–“ã®é¸å¥½ã‚’**å ±é…¬ãƒ¢ãƒ‡ãƒ« (Reward Model, RM)** ã¨ã—ã¦å­¦ç¿’ã—ã€å¼·åŒ–å­¦ç¿’ã§ãƒãƒªã‚·ãƒ¼ï¼ˆLLMï¼‰ã‚’æœ€é©åŒ–ã™ã‚‹ã€‚

#### 3.3.2 Bradley-Terry ãƒ¢ãƒ‡ãƒ« â€” é¸å¥½ã®ç¢ºç‡åŒ–

äººé–“ã®é¸å¥½ãƒ‡ãƒ¼ã‚¿: $(x, y_w, y_l)$ï¼ˆ$y_w$: å¥½ã¾ã‚Œã‚‹å¿œç­” = winnerã€$y_l$: åŠ£ã‚‹å¿œç­” = loserï¼‰ã€‚

**Bradley-Terry ãƒ¢ãƒ‡ãƒ«** [^33]: é¸å¥½ã®ç¢ºç‡ã‚’å ±é…¬å·®ã‹ã‚‰å°å‡º:

$$
P(y_w \succ y_l \mid x) = \sigma(r(x, y_w) - r(x, y_l)) = \frac{\exp(r(x, y_w))}{\exp(r(x, y_w)) + \exp(r(x, y_l))}
$$

$\sigma$: ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°ã€$r(x, y)$: å…¥åŠ› $x$ã€å¿œç­” $y$ ã®ã‚¹ã‚«ãƒ©ãƒ¼å ±é…¬ã€‚

**ãªãœã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ã‹**: Bradley-Terryãƒ¢ãƒ‡ãƒ«ã¯ã€Œ2è€…æ¯”è¼ƒã®ç¢ºç‡ã€ã®æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªæ­£è¦åŒ–ã€‚

#### 3.3.3 Reward Modelã®å­¦ç¿’ â€” å®Œå…¨å°å‡º

**Step 1: RMæ§‹é€ **

RM = LLM + ã‚¹ã‚«ãƒ©ãƒ¼ãƒ˜ãƒƒãƒ‰ã€‚æœ€çµ‚å±¤ã®å‡ºåŠ› $h \in \mathbb{R}^d$ ã«ã‚¹ã‚«ãƒ©ãƒ¼å°„å½±:

$$
r_\psi(x, y) = w^\top h_\psi(x, y), \quad w \in \mathbb{R}^d
$$

$\psi$: RMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆSFTãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸå€¤ã¨ã—ã¦ä½¿ã†ã“ã¨ãŒå¤šã„ï¼‰ã€‚

**Step 2: æ¯”è¼ƒãƒ­ã‚¹ï¼ˆBradley-Terryã«åŸºã¥ãè² ã®å¯¾æ•°å°¤åº¦ï¼‰**

$$
\mathcal{L}_\text{RM}(\psi) = -\mathbb{E}_{(x, y_w, y_l) \sim \mathcal{D}_\text{pref}}\left[\log \sigma(r_\psi(x, y_w) - r_\psi(x, y_l))\right]
$$

**Step 3: å±•é–‹**

$$
\mathcal{L}_\text{RM}(\psi) = -\frac{1}{|\mathcal{D}|} \sum_{(x, y_w, y_l)} \log \sigma(r_\psi(x, y_w) - r_\psi(x, y_l))
$$

ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ã®æ€§è³ª $\log \sigma(z) = -\log(1 + e^{-z})$ ã‹ã‚‰:

$$
\mathcal{L}_\text{RM} = \frac{1}{|\mathcal{D}|} \sum_{(x, y_w, y_l)} \log\!\left(1 + \exp(r_\psi(x, y_l) - r_\psi(x, y_w))\right)
$$

ã“ã‚Œã¯ $r(x, y_w) > r(x, y_l)$ ã‚’å¼·åˆ¶ã™ã‚‹æå¤±ã€‚å·®åˆ† $r(x, y_w) - r(x, y_l)$ ãŒå¤§ãã„ã»ã©æå¤±ãŒå°ã•ã„ã€‚

#### 3.3.4 PPOã«ã‚ˆã‚‹ãƒãƒªã‚·ãƒ¼æœ€é©åŒ–

RLHF [^10] ã®ãƒãƒªã‚·ãƒ¼æœ€é©åŒ–ã«ã¯PPO (Proximal Policy Optimization) ã‚’ä½¿ã†ã€‚

**ç›®çš„é–¢æ•°ï¼ˆKLæ­£å‰‡åŒ–ä»˜ãï¼‰**:

$$
J(\pi_\theta) = \mathbb{E}_{x \sim \mathcal{D}, y \sim \pi_\theta(\cdot \mid x)}\!\left[r_\psi(x, y)\right] - \beta \, D_\text{KL}\!\left[\pi_\theta(\cdot \mid x) \,\|\, \pi_\text{ref}(\cdot \mid x)\right]
$$

$\pi_\theta$: è¨“ç·´ä¸­ã®LLMãƒãƒªã‚·ãƒ¼ã€$\pi_\text{ref}$: SFTæ¸ˆã¿ã®å‚ç…§ãƒãƒªã‚·ãƒ¼ï¼ˆå›ºå®šï¼‰ã€$\beta$: KLãƒšãƒŠãƒ«ãƒ†ã‚£ä¿‚æ•°ã€‚

**KLé …ã®å½¹å‰²**:

$$
D_\text{KL}[\pi_\theta \| \pi_\text{ref}] = \mathbb{E}_{y \sim \pi_\theta}\left[\log \frac{\pi_\theta(y \mid x)}{\pi_\text{ref}(y \mid x)}\right] \geq 0
$$

$\pi_\theta$ ãŒ $\pi_\text{ref}$ ã‹ã‚‰é ã–ã‹ã‚‹ã¨ KL ãŒå¢—å¤§ â†’ ç›®çš„é–¢æ•°ãŒæ¸›å°‘ â†’ **å ±é…¬ãƒãƒƒã‚­ãƒ³ã‚°ã®æŠ‘åˆ¶**ã€‚

**PPOã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ç›®æ¨™**:

ç¢ºç‡æ¯” $\rho_t = \frac{\pi_\theta(y_t \mid x, y_{<t})}{\pi_\text{old}(y_t \mid x, y_{<t})}$ã€å„ªä½é–¢æ•° $\hat{A}_t = r_\psi(x, y) - V_\phi(x)$ ã¨ã—ã¦:

$$
\mathcal{L}_\text{PPO}(\theta) = -\mathbb{E}_t\!\left[\min\!\left(\rho_t \hat{A}_t, \, \text{clip}(\rho_t, 1-\epsilon, 1+\epsilon) \hat{A}_t\right)\right]
$$

$\epsilon = 0.2$ (å…¸å‹å€¤): ç¢ºç‡æ¯”ã‚’ $[1-\epsilon, 1+\epsilon]$ ã«ã‚¯ãƒªãƒƒãƒ—ã—ã€1ã‚¹ãƒ†ãƒƒãƒ—ã®æ›´æ–°ãŒå¤§ãããªã‚Šã™ãã‚‹ã®ã‚’é˜²ãã€‚

**å®Œå…¨ãªRLHFæå¤±**ï¼ˆSchulman et al. 2017 PPO [^34] ã‚’è¨€èªãƒ¢ãƒ‡ãƒ«ã«é©ç”¨ï¼‰:

$$
\mathcal{L}_\text{total} = -\mathcal{L}_\text{PPO} + c_1 \mathcal{L}_\text{VF} - c_2 S[\pi_\theta]
$$

$\mathcal{L}_\text{VF} = (V_\phi(x) - R_t)^2$: ä¾¡å€¤é–¢æ•°ã®äºŒä¹—èª¤å·®ã€$S[\pi_\theta]$: ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãƒœãƒ¼ãƒŠã‚¹ï¼ˆæ¢ç´¢ä¿ƒé€²ï¼‰ã€‚

#### 3.3.5 å ±é…¬ãƒãƒƒã‚­ãƒ³ã‚°å¯¾ç­–

å ±é…¬ãƒ¢ãƒ‡ãƒ«ã¯ä¸å®Œå…¨ â€” $r_\psi$ ãŒé«˜ãã¦ã‚‚äººé–“ã«ã¯å¥½ã¾ã‚Œãªã„å¿œç­”ï¼ˆreward hackingï¼‰ãŒå‡ºç¾ã™ã‚‹ã€‚

ä¸»ãªå¯¾ç­–:

| æ‰‹æ³• | æ•°å¼ | åŠ¹æœ |
|:-----|:-----|:-----|
| **KLæ­£å‰‡åŒ–** | $-\beta D_\text{KL}[\pi_\theta \| \pi_\text{ref}]$ | å‚ç…§ãƒãƒªã‚·ãƒ¼ã‹ã‚‰ã®é€¸è„±ã‚’æŠ‘åˆ¶ |
| **å ±é…¬ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°** | $r_\text{clip} = \text{clip}(r, -r_\text{max}, r_\text{max})$ | æ¥µç«¯ãªå ±é…¬ä¿¡å·ã‚’é™¤å» |
| **RMæ›´æ–°** | å‘¨æœŸçš„ã«RMã‚’äººé–“ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã§å†è¨“ç·´ | ãƒãƒƒã‚­ãƒ³ã‚°æˆ¦ç•¥ã‚’å­¦ç¿’å‰ã«ä¿®æ­£ |

KLæ­£å‰‡åŒ–ã®å¼·åº¦ $\beta$ ã¯:
- $\beta \to 0$: RMæœ€å¤§åŒ–ã«ç‰¹åŒ– â†’ ãƒãƒƒã‚­ãƒ³ã‚°ç™ºç”Ÿ
- $\beta \to \infty$: SFTã¨åŒä¸€ â†’ æ”¹å–„ãªã—
- æœ€é© $\beta$: ã‚¿ã‚¹ã‚¯ä¾å­˜ï¼ˆå…¸å‹å€¤ 0.01ã€œ0.5ï¼‰

#### 3.3.6 DPO â€” RLHFã®é–‰å½¢å¼æœ€é©è§£

DPO (Direct Preference Optimization) [^35] ã¯ã€PPOã‚’ä½¿ã‚ãšRLHFã®ç›®çš„é–¢æ•°ã‚’ç›´æ¥æœ€é©åŒ–ã™ã‚‹ã€‚

**RLHFç›®çš„é–¢æ•°ã®æœ€é©è§£**ï¼ˆPPOãªã—ã€è§£æçš„ã«å°å‡ºï¼‰:

$$
\pi^*(y \mid x) = \frac{1}{Z(x)} \pi_\text{ref}(y \mid x) \exp\!\left(\frac{1}{\beta} r(x, y)\right)
$$

$Z(x) = \sum_y \pi_\text{ref}(y \mid x) \exp(r(x,y)/\beta)$: åˆ†é…é–¢æ•°ã€‚

**Step 1**: ä¸Šã®æœ€é©è§£ã‚’ $r$ ã«ã¤ã„ã¦è§£ã:

$$
r(x, y) = \beta \log \frac{\pi^*(y \mid x)}{\pi_\text{ref}(y \mid x)} + \beta \log Z(x)
$$

**Step 2**: RMã® Bradley-Terry æå¤±ã«ä»£å…¥ï¼ˆ$Z(x)$ ã¯ winner-loseræ¯”ã§æ¶ˆãˆã‚‹ï¼‰:

$$
\mathcal{L}_\text{DPO}(\theta) = -\mathbb{E}_{(x, y_w, y_l)}\!\left[\log \sigma\!\left(\beta \log \frac{\pi_\theta(y_w \mid x)}{\pi_\text{ref}(y_w \mid x)} - \beta \log \frac{\pi_\theta(y_l \mid x)}{\pi_\text{ref}(y_l \mid x)}\right)\right]
$$

ã“ã‚Œã¯PPOã‚’ä½¿ã‚ãšã€ãƒãƒªã‚·ãƒ¼ $\pi_\theta$ ã‚’ç›´æ¥é¸å¥½ãƒ‡ãƒ¼ã‚¿ã§æœ€é©åŒ–ã§ãã‚‹ã€‚

**DPO vs PPOæ¯”è¼ƒ**:

| é …ç›® | RLHF (PPO) | DPO |
|:-----|:-----------|:----|
| RMå­¦ç¿’ | å¿…è¦ï¼ˆåˆ¥é€”è¨“ç·´ï¼‰ | ä¸è¦ï¼ˆç›´æ¥æœ€é©åŒ–ï¼‰ |
| å®‰å®šæ€§ | ä¸å®‰å®šï¼ˆPPOã®è¶…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤šï¼‰ | å®‰å®šï¼ˆSFTã¨åŒç­‰ã®è¨“ç·´ãƒ«ãƒ¼ãƒ—ï¼‰ |
| æ€§èƒ½ | é«˜ã„ï¼ˆRMå“è³ªä¾å­˜ï¼‰ | åŒç­‰ã€œã‚„ã‚„ä½ã„ |
| å®Ÿè£…é›£æ˜“åº¦ | é«˜ | ä½ |

---

### 3.4 PEFTçµ±åˆç†è«– â€” LoRA/QLoRA/Adapter/DreamBooth

CPTãƒ»SFTãƒ»RLHFã§å­¦ç¿’æ®µéšè¨­è¨ˆã‚’ç†è§£ã—ãŸã€‚PEFTã¯ã“ã‚Œã‚‰**å…¨ã¦ã®æ®µéš**ã«é©ç”¨å¯èƒ½ãªè¨ˆç®—åŠ¹ç‡åŒ–æ‰‹æ³•ã ã€‚ä»¥é™ 3.4.1ã€œ3.4.10 ã§å„PEFTæ‰‹æ³•ã‚’å®Œå…¨å°å‡ºã™ã‚‹ã€‚

### 3.4.1 LoRAç†è«– â€” ä½ãƒ©ãƒ³ã‚¯é©å¿œã®æ•°å­¦

#### 3.4.1.1 å‹•æ©Ÿ: Full Fine-tuningã®ãƒ¡ãƒ¢ãƒªå•é¡Œ

GPT-3 (175B params) ã‚’Full Fine-tuningã™ã‚‹å ´åˆã€AdamWã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã¯:

- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ $\theta$: 175B Ã— 4 bytes (FP32) = 700 GB
- å‹¾é… $\nabla \theta$: 175B Ã— 4 bytes = 700 GB
- ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ $m$: 175B Ã— 4 bytes = 700 GB
- 2æ¬¡ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ $v$: 175B Ã— 4 bytes = 700 GB

åˆè¨ˆ **2.8 TB**ã€‚A100 GPU (80GB) ãªã‚‰35æšå¿…è¦ã€‚ç¾å®Ÿçš„ã§ãªã„ã€‚

**LoRAã®æ´å¯Ÿ** [^1]: äº‹å‰å­¦ç¿’æ¸ˆã¿é‡ã¿ã®**å¤‰åŒ– $\Delta W$ ã¯ä½ãƒ©ãƒ³ã‚¯**ã§ã‚ã‚‹ã€‚ã¤ã¾ã‚Šã€

$$
\text{rank}(\Delta W) \ll \min(d, k)
$$

ç†ç”±: å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã¯éå‰°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã•ã‚Œã¦ãŠã‚Šã€Fine-tuningæ™‚ã®é©å¿œã¯ä½æ¬¡å…ƒéƒ¨åˆ†ç©ºé–“ã§ååˆ†ã€‚

#### 3.4.1.2 LoRAã®å®šå¼åŒ–

é‡ã¿è¡Œåˆ— $W \in \mathbb{R}^{d \times k}$ (ä¾‹: Transformer ã® $W_q, W_k, W_v, W_o$) ã‚’è€ƒãˆã‚‹ã€‚Full Fine-tuningã¯:

$$
W \leftarrow W_0 + \Delta W
$$

LoRAã¯ $\Delta W$ ã‚’ä½ãƒ©ãƒ³ã‚¯åˆ†è§£:

$$
\Delta W = BA, \quad B \in \mathbb{R}^{d \times r}, \, A \in \mathbb{R}^{r \times k}, \quad r \ll \min(d, k)
$$

Forward pass:

$$
h = Wx = (W_0 + \Delta W)x = W_0 x + BA x
$$

**é‡è¦**: $W_0$ ã¯**frozen**ï¼ˆå‹¾é…è¨ˆç®—ã—ãªã„ï¼‰ã€$B, A$ ã®ã¿**trainable**ã€‚

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°æ¯”è¼ƒ:

| æ–¹å¼ | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° | å‰Šæ¸›ç‡ï¼ˆ$r=8, d=k=4096$ï¼‰ |
|:-----|:-------------|:-------------------------|
| Full FT | $dk$ | 16,777,216 |
| LoRA | $dr + rk = r(d+k)$ | 65,536 |
| å‰Šæ¸›ç‡ | $\frac{dk}{r(d+k)}$ | **256x** |

GPT-3 (d=12288, k=12288, r=4) ãªã‚‰å‰Šæ¸›ç‡ **6,144å€**ã€‚

#### 3.4.1.3 åˆæœŸåŒ–ã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

LoRAã®åˆæœŸåŒ–ã¯ç‰¹æ®Š:

$$
\begin{aligned}
A &\sim \mathcal{N}(0, \sigma^2), \quad \sigma = \frac{1}{\sqrt{k}} \\
B &= \mathbf{0}
\end{aligned}
$$

$B=0$ ã«ã‚ˆã‚Šã€è¨“ç·´é–‹å§‹æ™‚ $\Delta W = BA = 0$ã€‚ã¤ã¾ã‚Š $W = W_0 + 0 = W_0$ ã§å…ƒã®äº‹å‰å­¦ç¿’é‡ã¿ã‹ã‚‰é–‹å§‹ã€‚

Forwardæ™‚ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°:

$$
h = W_0 x + \frac{\alpha}{r} BA x
$$

$\alpha$: ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®šæ•°ï¼ˆå…¸å‹å€¤ 8-32ï¼‰ã€‚$\alpha/r$ ã«ã‚ˆã‚Šã€ãƒ©ãƒ³ã‚¯ $r$ ã‚’å¤‰ãˆã¦ã‚‚å­¦ç¿’ç‡ã‚’èª¿æ•´ä¸è¦ã«ã™ã‚‹æ­£å‰‡åŒ–ã€‚

**ç†è«–çš„æ ¹æ‹ ** [^1]:

$$
\mathbb{E}[\|BA x\|^2] \propto r \|x\|^2
$$

$\alpha/r$ ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã‚Š $\mathbb{E}[\|\frac{\alpha}{r} BA x\|^2] \propto \alpha^2 / r \|x\|^2$ã€$r$ ã®å½±éŸ¿ã‚’ç›¸æ®ºã€‚

#### 3.4.1.4 LoRAã®å‹¾é…è¨ˆç®—

æå¤±é–¢æ•° $\mathcal{L}$ ã«å¯¾ã™ã‚‹å‹¾é…ï¼ˆ$W_0$ ã¯å›ºå®šï¼‰:

$$
\begin{aligned}
\frac{\partial \mathcal{L}}{\partial B} &= \frac{\partial \mathcal{L}}{\partial h} \frac{\partial h}{\partial B} = \frac{\partial \mathcal{L}}{\partial h} \cdot (Ax)^\top \cdot \frac{\alpha}{r} \\
\frac{\partial \mathcal{L}}{\partial A} &= \frac{\partial \mathcal{L}}{\partial h} \frac{\partial h}{\partial A} = B^\top \frac{\partial \mathcal{L}}{\partial h} \cdot x^\top \cdot \frac{\alpha}{r}
\end{aligned}
$$

ãƒãƒƒãƒã‚µã‚¤ã‚º $N$ ã®å ´åˆ:

$$
\begin{aligned}
\nabla_B \mathcal{L} &= \frac{\alpha}{r} \sum_{i=1}^N \frac{\partial \mathcal{L}}{\partial h_i} (A x_i)^\top \\
\nabla_A \mathcal{L} &= \frac{\alpha}{r} \sum_{i=1}^N B^\top \frac{\partial \mathcal{L}}{\partial h_i} x_i^\top
\end{aligned}
$$

å‹¾é…æ›´æ–°ï¼ˆSGDä¾‹ï¼‰:

$$
\begin{aligned}
B &\leftarrow B - \eta \nabla_B \mathcal{L} \\
A &\leftarrow A - \eta \nabla_A \mathcal{L}
\end{aligned}
$$

#### 3.4.1.5 LoRAã®æ¨è«–æ™‚æœ€é©åŒ–

è¨“ç·´å¾Œã€$B, A$ ã‚’ $W_0$ ã«ãƒãƒ¼ã‚¸å¯èƒ½:

$$
W_\text{merged} = W_0 + \frac{\alpha}{r} BA
$$

æ¨è«–æ™‚ã¯é€šå¸¸ã®MatMul $W_\text{merged} x$ ã®ã¿ã€‚è¿½åŠ ã‚³ã‚¹ãƒˆã‚¼ãƒ­ã€‚

è¤‡æ•°ã‚¿ã‚¹ã‚¯ã®å ´åˆã€å„ã‚¿ã‚¹ã‚¯ã® $(B_i, A_i)$ ã‚’ä¿æŒã—ã€æ¨è«–æ™‚ã«åˆ‡ã‚Šæ›¿ãˆ:

$$
h_{\text{task}_i} = W_0 x + \frac{\alpha}{r} B_i A_i x
$$

ãƒ¡ãƒ¢ãƒª: $W_0$ ã¯å…±æœ‰ã€ã‚¿ã‚¹ã‚¯ã”ã¨ã« $r(d+k)$ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¿½åŠ ã®ã¿ã€‚

#### 3.4.1.6 ã©ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«LoRAã‚’é©ç”¨ã™ã‚‹ã‹

Transformerã®Attentionå±¤ã«ã¯ $W_q, W_k, W_v, W_o$ ã®4ã¤ã®é‡ã¿è¡Œåˆ—ãŒã‚ã‚‹ã€‚å…¨ã¦ã«LoRAã‚’é©ç”¨ã™ã‚‹ã¨:

$$
\begin{aligned}
Q &= (W_{q,0} + B_q A_q) X \\
K &= (W_{k,0} + B_k A_k) X \\
V &= (W_{v,0} + B_v A_v) X \\
O &= (W_{o,0} + B_o A_o) \text{Attention}(Q, K, V)
\end{aligned}
$$

Hu et al. [^1] ã®å®Ÿé¨“ã§ã¯ã€**$W_q, W_v$ ã®ã¿**ã«LoRAã‚’é©ç”¨ã™ã‚‹ã®ãŒæœ€åŠ¹ç‡ï¼ˆæ€§èƒ½ vs ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ï¼‰ã€‚

### 3.4.2 QLoRA â€” é‡å­åŒ–ã¨LoRAã®èåˆ

#### 3.4.2.1 å‹•æ©Ÿ: ã•ã‚‰ãªã‚‹ãƒ¡ãƒ¢ãƒªå‰Šæ¸›

LoRAã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’å‰Šæ¸›ã—ãŸãŒã€$W_0$ ã¯ä¾ç„¶FP32/FP16ã§ä¿æŒã€‚65Bãƒ¢ãƒ‡ãƒ«ãªã‚‰ $65 \times 10^9 \times 2 = 130$ GB (FP16)ã€‚

QLoRA [^2] ã®é©æ–°:

1. **4-bité‡å­åŒ–**: $W_0$ ã‚’4-bitã«åœ§ç¸® â†’ $65B \times 0.5 = 32.5$ GB
2. **NormalFloat (NF4)**: æ­£è¦åˆ†å¸ƒã«æœ€é©ãªé‡å­åŒ–
3. **Double Quantization**: é‡å­åŒ–å®šæ•°è‡ªä½“ã‚’é‡å­åŒ–
4. **Paged Optimizers**: CPU-GPUé–“ã®ãƒ¡ãƒ¢ãƒªã‚¹ãƒ¯ãƒƒãƒ—

#### 3.4.2.2 NormalFloat (NF4) é‡å­åŒ– â€” å®Œå…¨å°å‡º

é€šå¸¸ã®4-bité‡å­åŒ–ã¯ç·šå½¢ã‚¹ã‚±ãƒ¼ãƒ« $[-7, -6, \dots, 6, 7]$ã€‚ã ãŒã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã®é‡ã¿ã¯**æ­£è¦åˆ†å¸ƒ**ã«è¿‘ã„ã€‚

**å•é¡Œè¨­å®š**: æ­£è¦åˆ†å¸ƒ $\mathcal{N}(0, 1)$ ã«å¾“ã†é‡ã¿ $W \sim \mathcal{N}(0, 1)$ ã‚’ã€4-bit (16ãƒ¬ãƒ™ãƒ«) ã«é‡å­åŒ–ã—ãŸã„ã€‚

#### Step 1: æœ€é©é‡å­åŒ–ã®ç†è«– (Lloyd-Max Quantization)

é‡å­åŒ–ã¯ã€é€£ç¶šå€¤ $w \in \mathbb{R}$ ã‚’é›¢æ•£å€¤ $q_i \in \{q_0, q_1, \dots, q_{15}\}$ ã«å†™åƒ:

$$
Q(w) = q_i \quad \text{if } w \in [t_i, t_{i+1})
$$

$t_i$: æ±ºå®šå¢ƒç•Œï¼ˆthresholdsï¼‰ã€‚

**ç›®çš„**: é‡å­åŒ–èª¤å·®ï¼ˆMSEï¼‰ã‚’æœ€å°åŒ–:

$$
\min_{q_i, t_i} \mathbb{E}_{w \sim \mathcal{N}(0, 1)}[(w - Q(w))^2]
$$

Lloyd-Maxç†è«– [^14] ã«ã‚ˆã‚Œã°ã€æœ€é©è§£ã¯:

$$
\begin{aligned}
q_i &= \mathbb{E}[w \mid w \in [t_i, t_{i+1})] \quad \text{(centroid condition)} \\
t_i &= \frac{q_{i-1} + q_i}{2} \quad \text{(nearest neighbor condition)}
\end{aligned}
$$

#### Step 2: æ­£è¦åˆ†å¸ƒã«å¯¾ã™ã‚‹æœ€é©è§£

æ­£è¦åˆ†å¸ƒ $\mathcal{N}(0, 1)$ ã¯**å¯¾ç§°**ãªã®ã§ã€é‡å­åŒ–ãƒ¬ãƒ™ãƒ«ã‚‚å¯¾ç§°:

$$
q_{15-i} = -q_i \quad \text{for all } i
$$

16ãƒ¬ãƒ™ãƒ«ã®ã†ã¡ã€8ãƒ¬ãƒ™ãƒ«ã¯è² ã€1ãƒ¬ãƒ™ãƒ«ã¯0ã€7ãƒ¬ãƒ™ãƒ«ã¯æ­£ã€‚

æœ€é©ãª $q_i$ ã¯ã€**ç­‰ç¢ºç‡åˆ†å‰²** (equal probability binning) ã®åˆ†ä½ç‚¹:

$$
q_i = \Phi^{-1}\left(\frac{i}{15}\right), \quad i = 0, 1, \dots, 15
$$

$\Phi^{-1}$: æ¨™æº–æ­£è¦åˆ†å¸ƒã®é€†CDFï¼ˆãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆç‚¹é–¢æ•°ï¼‰ã€‚

#### Step 3: NF4ãƒ¬ãƒ™ãƒ«ã®æ•°å€¤è¨ˆç®—

$$
\begin{aligned}
q_0 &= \Phi^{-1}(0/15) = -\infty \quad \text{(clamp to -1.0)} \\
q_1 &= \Phi^{-1}(1/15) = \Phi^{-1}(0.0667) \approx -1.5341 \quad \text{(normalize later)} \\
q_2 &= \Phi^{-1}(2/15) = \Phi^{-1}(0.1333) \approx -1.1077 \\
q_3 &= \Phi^{-1}(3/15) = \Phi^{-1}(0.2) \approx -0.8416 \\
&\vdots \\
q_7 &= \Phi^{-1}(7/15) \approx -0.1006 \\
q_8 &= \Phi^{-1}(8/15) \approx 0.0 \\
q_9 &= \Phi^{-1}(9/15) \approx 0.1006 \\
&\vdots \\
q_{15} &= \Phi^{-1}(15/15) = +\infty \quad \text{(clamp to 1.0)}
\end{aligned}
$$

æ­£è¦åŒ–ï¼ˆæœ€å¤§å€¤ã‚’1.0ã«ï¼‰:

$$
q_i' = \frac{q_i}{\max_j |q_j|}
$$

æœ€çµ‚çš„ãªNF4ãƒ¬ãƒ™ãƒ«ï¼ˆæ­£è¦åŒ–å¾Œï¼‰:

$$
\text{NF4} = \{-1.0, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911, 0.0, 0.0911, 0.1848, 0.2844, 0.3949, 0.5251, 0.6962, 1.0\}
$$

#### Step 4: é‡å­åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

å…¥åŠ›: é‡ã¿è¡Œåˆ— $W_0 \in \mathbb{R}^{d \times k}$

**ã‚¹ãƒ†ãƒƒãƒ—1: æ­£è¦åŒ–**

$$
\begin{aligned}
\text{absmax} &= \max_{i,j} |W_{0,ij}| \\
W_{\text{norm}} &= \frac{W_0}{\text{absmax}} \quad \text{(values in [-1, 1])}
\end{aligned}
$$

**ã‚¹ãƒ†ãƒƒãƒ—2: æœ€è¿‘å‚é‡å­åŒ–**

å„è¦ç´  $w_{\text{norm}, ij}$ ã«å¯¾ã—:

$$
W_{\text{quant}, ij} = \arg\min_{q \in \text{NF4}} |w_{\text{norm}, ij} - q|
$$

ã“ã‚Œã¯æœ€è¿‘å‚æ¢ç´¢ï¼ˆ16ãƒ¬ãƒ™ãƒ«ãªã®ã§ $O(16) = O(1)$ï¼‰ã€‚

**ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¿å­˜**

å„é‡å­åŒ–å€¤ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ $i \in \{0, 1, \dots, 15\}$ ã«å¤‰æ›ã—ã€4-bitã§ä¿å­˜ã€‚

**ãƒ¡ãƒ¢ãƒª**: $d \times k \times 4 \text{ bits} = \frac{dk}{2} \text{ bytes}$ï¼ˆFP32ã® $\frac{1}{8}$ï¼‰ã€‚

#### Step 5: é€†é‡å­åŒ–

Forward passæ™‚ã€4-bitã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’FP16ã«å¾©å…ƒ:

$$
W_{0,ij} \approx \text{NF4}[\text{index}_{ij}] \times \text{absmax}
$$

#### NF4 vs ç·šå½¢é‡å­åŒ–ã®æ¯”è¼ƒ

| æ‰‹æ³• | é‡å­åŒ–èª¤å·®ï¼ˆMSEï¼‰ | å‚™è€ƒ |
|:-----|:-----------------|:-----|
| **ç·šå½¢é‡å­åŒ–** | $\mathbb{E}[(w - Q(w))^2] \approx 0.045$ | $q_i = -1 + \frac{2i}{15}$ |
| **NF4é‡å­åŒ–** | $\mathbb{E}[(w - Q(w))^2] \approx 0.032$ | åˆ†ä½ç‚¹ãƒ™ãƒ¼ã‚¹ |
| **å‰Šæ¸›ç‡** | **29%å‰Šæ¸›** | NF4ãŒæƒ…å ±ç†è«–çš„ã«æœ€é© |

**è¨¼æ˜ã®ã‚¹ã‚±ãƒƒãƒ**: æ­£è¦åˆ†å¸ƒã®å¯†åº¦é–¢æ•° $p(w) = \frac{1}{\sqrt{2\pi}} e^{-w^2/2}$ ã¯ä¸­å¿ƒï¼ˆ$w=0$ï¼‰ã§é«˜å¯†åº¦ã€‚ç·šå½¢é‡å­åŒ–ã¯ç­‰é–“éš”ã ãŒã€NF4ã¯é«˜å¯†åº¦é ˜åŸŸã«å¤šãã®ãƒ¬ãƒ™ãƒ«ã‚’å‰²ã‚Šå½“ã¦ã‚‹ â†’ MSEå‰Šæ¸›ã€‚

#### NF4é‡å­åŒ–ãƒ¬ãƒ™ãƒ«ã®å°å‡º

16ãƒ¬ãƒ™ãƒ«ã®é‡å­åŒ–ç‚¹ $\{q_0, q_1, \ldots, q_{15}\}$ ã‚’æ§‹æˆã™ã‚‹ã€‚$q_0 = -1$ã€$q_{15} = 1$ ã¨ã—ã¦ã€ä¸­é–“ç‚¹ã¯æ¨™æº–æ­£è¦åˆ†å¸ƒã®åˆ†ä½ç‚¹ $q_i = \Phi^{-1}(i/15)$ ã§å®šç¾©ã™ã‚‹ï¼ˆ$\Phi^{-1}$ ã¯æ­£è¦é€†CDFï¼‰ã€‚ãã®å¾Œ $[-1, 1]$ ã«ç·šå½¢æ­£è¦åŒ–ã™ã‚‹ã€‚å¾—ã‚‰ã‚Œã‚‹åˆ†ä½ç‚¹åˆ—ã¯éç­‰é–“éš”: ä¸­å¿ƒä»˜è¿‘ï¼ˆ$w \approx 0$ï¼‰ã«å¯†ã«ã€è£¾é‡ï¼ˆ$|w| \approx 1$ï¼‰ã«ç–ã«é…ç½®ã•ã‚Œã‚‹ã€‚

å®Ÿè£…ä¸Šã®æ³¨æ„: NF4ãƒ¬ãƒ™ãƒ«ã¯ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚å®šæ•°ã¨ã—ã¦16è¦ç´ ã®ãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ã«æ ¼ç´ã™ã‚‹ã€‚é‡å­åŒ–ã¯ $q^* = \arg\min_{q_i} |w_\text{norm} - q_i|$ï¼ˆæœ€è¿‘å‚æ¢ç´¢ï¼‰ã§ã€é€†é‡å­åŒ–ã¯ $\hat{w} = q^* \cdot c_\text{absmax}$ ã ã€‚ã“ã®2ã‚¹ãƒ†ãƒƒãƒ—ã§ NF4ã®æƒ…å ±ç†è«–çš„æœ€é©æ€§ãŒæˆç«‹ã™ã‚‹ã€‚

#### æƒ…å ±ç†è«–çš„æœ€é©æ€§ã®è¨¼æ˜ï¼ˆæ¦‚è¦ï¼‰

Rate-Distortionç†è«–ã«ã‚ˆã‚Šã€æ­£è¦åˆ†å¸ƒ $\mathcal{N}(0, 1)$ ã«å¯¾ã™ã‚‹æœ€é©4-bité‡å­åŒ–å™¨ï¼ˆRate $R=4$ bitsã€æ­ªã¿ $D$ï¼‰ã¯:

$$
D^* = \min_{Q: \mathbb{R} \to \{0,1\}^4} \mathbb{E}[(w - Q^{-1}(Q(w)))^2]
$$

Lloyd-Maxã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€ã“ã® $D^*$ ã‚’æ•°å€¤çš„ã«é”æˆã™ã‚‹ã€‚NF4ã¯ã€å¯¾ç§°æ­£è¦åˆ†å¸ƒã«å¯¾ã—ã¦**åˆ†ä½ç‚¹é‡å­åŒ– = Lloyd-Maxæœ€é©è§£**ã‚’é–‰å½¢å¼ã§ä¸ãˆã‚‹ã€‚

#### 3.4.2.3 Double Quantization â€” äºŒé‡é‡å­åŒ–ã®å®Œå…¨å°å‡º

é‡å­åŒ–ã«ã¯**ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®šæ•°**ï¼ˆabsmaxï¼‰ãŒå¿…è¦ã€‚65Bãƒ¢ãƒ‡ãƒ«ãªã‚‰ã€ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º64ã§ $65B / 64 \approx 1B$ å€‹ã®å®šæ•°ï¼ˆFP32ãªã‚‰4GBï¼‰ã€‚

**å•é¡Œ**: ã“ã®å®šæ•°è‡ªä½“ãŒãƒ¡ãƒ¢ãƒªã‚’åœ§è¿«ã™ã‚‹ã€‚

**è§£æ±ºç­–**: Double Quantization â€” å®šæ•°è‡ªä½“ã‚’é‡å­åŒ–ã€‚

#### Step 1: ãƒ–ãƒ­ãƒƒã‚¯é‡å­åŒ–ã®å¾©ç¿’

é‡ã¿è¡Œåˆ— $W_0 \in \mathbb{R}^{d \times k}$ ã‚’ $B$ å€‹ã®ãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰²:

$$
W_0 = [W_{\text{block}_1}, W_{\text{block}_2}, \dots, W_{\text{block}_B}]
$$

ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º: $b = \lceil dk / B \rceil$ï¼ˆå…¸å‹å€¤64-128ï¼‰ã€‚

å„ãƒ–ãƒ­ãƒƒã‚¯ $i$ ã®é‡å­åŒ–:

$$
\begin{aligned}
c_i &= \max_{j \in \text{block}_i} |W_{0,j}| \quad \text{(absmax of block } i \text{)} \\
W_{\text{block}_i, \text{norm}} &= \frac{W_{\text{block}_i}}{c_i} \quad \text{(normalize to [-1, 1])} \\
W_{\text{block}_i, \text{quant}} &= \text{NF4}(W_{\text{block}_i, \text{norm}}) \quad \text{(4-bit quantization)}
\end{aligned}
$$

é€†é‡å­åŒ–:

$$
W_{\text{block}_i} \approx W_{\text{block}_i, \text{quant}} \times c_i
$$

**ãƒ¡ãƒ¢ãƒªï¼ˆç¬¬1æ®µéšé‡å­åŒ–ã®ã¿ï¼‰**:

- é‡å­åŒ–é‡ã¿: $dk \times 4 \text{ bits} = \frac{dk}{2} \text{ bytes}$
- ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®šæ•°: $B \times 4 \text{ bytes (FP32)}$

65Bãƒ¢ãƒ‡ãƒ«ï¼ˆ$dk = 65 \times 10^9$ã€ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º64ï¼‰ã®å ´åˆ:

$$
\begin{aligned}
B &= \frac{65 \times 10^9}{64} \approx 1.02 \times 10^9 \\
\text{Constants memory} &= 1.02 \times 10^9 \times 4 \text{ bytes} = 4.08 \text{ GB}
\end{aligned}
$$

å®šæ•°ã ã‘ã§**4GB**ã‚’æ¶ˆè²»ã€‚ã“ã‚Œã‚’å‰Šæ¸›ã™ã‚‹ã®ãŒDouble Quantizationã€‚

#### Step 2: å®šæ•°ã®é‡å­åŒ–ï¼ˆç¬¬2æ®µéšï¼‰

$B$ å€‹ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®šæ•° $\{c_1, c_2, \dots, c_B\}$ ã‚’ã€ã•ã‚‰ã«**8-bit**ã«é‡å­åŒ–ã€‚

**ã‚¹ãƒ†ãƒƒãƒ—2.1**: å®šæ•°å…¨ä½“ã®æœ€å¤§å€¤ã‚’è¨ˆç®—

$$
c_{\text{global}} = \max_{i=1}^B c_i
$$

**ã‚¹ãƒ†ãƒƒãƒ—2.2**: å®šæ•°ã‚’æ­£è¦åŒ–

$$
c_{i, \text{norm}} = \frac{c_i}{c_{\text{global}}} \in [0, 1]
$$

**ã‚¹ãƒ†ãƒƒãƒ—2.3**: 8-bitç·šå½¢é‡å­åŒ–

$$
c_{i, \text{quant}} = \text{round}\left(c_{i, \text{norm}} \times 255\right) \in \{0, 1, \dots, 255\}
$$

8-bitï¼ˆ256ãƒ¬ãƒ™ãƒ«ï¼‰ã§å‡ç­‰åˆ†å‰²ã€‚

**ã‚¹ãƒ†ãƒƒãƒ—2.4**: é€†é‡å­åŒ–

$$
c_i \approx \frac{c_{i, \text{quant}}}{255} \times c_{\text{global}}
$$

#### Step 3: å®Œå…¨ãªé€†é‡å­åŒ–æ‰‹é †

Forward passæ™‚ã€é‡ã¿ $W_{0,j}$ ï¼ˆãƒ–ãƒ­ãƒƒã‚¯ $i$ ã«å±ã™ã‚‹ï¼‰ã‚’å¾©å…ƒ:

$$
\begin{aligned}
c_{i, \text{dequant}} &= \frac{c_{i, \text{quant}}}{255} \times c_{\text{global}} \quad \text{(dequantize constant)} \\
W_{0,j, \text{dequant}} &= \text{NF4}_{\text{level}}[\text{index}_j] \times c_{i, \text{dequant}} \quad \text{(dequantize weight)}
\end{aligned}
$$

2æ®µéšã®é€†é‡å­åŒ–ã€‚

#### Step 4: ãƒ¡ãƒ¢ãƒªå‰Šæ¸›ã®è¨ˆç®—

**Before Double Quantization**:

- é‡å­åŒ–é‡ã¿: $\frac{dk}{2}$ bytes (4-bit)
- å®šæ•°ï¼ˆFP32ï¼‰: $B \times 4$ bytes

**After Double Quantization**:

- é‡å­åŒ–é‡ã¿: $\frac{dk}{2}$ bytes (4-bit)
- é‡å­åŒ–å®šæ•°ï¼ˆ8-bitï¼‰: $B \times 1$ bytes
- ã‚°ãƒ­ãƒ¼ãƒãƒ«å®šæ•°ï¼ˆFP32ï¼‰: $1 \times 4$ bytes

**å‰Šæ¸›ç‡**ï¼ˆå®šæ•°éƒ¨åˆ†ï¼‰:

$$
\frac{B \times 4}{B \times 1 + 4} \approx \frac{B \times 4}{B} = 4 \quad \text{(ç´„4å€å‰Šæ¸›)}
$$

65Bãƒ¢ãƒ‡ãƒ«ã®ä¾‹ï¼ˆ$B \approx 1B$ï¼‰:

| é …ç›® | Before | After | å‰Šæ¸›ç‡ |
|:-----|:-------|:------|:------|
| é‡å­åŒ–é‡ã¿ | 32.5 GB | 32.5 GB | - |
| å®šæ•° | 4.08 GB | 1.02 GB + 4 bytes | **75%** |
| **åˆè¨ˆ** | 36.58 GB | 33.52 GB | **8.4%** |

#### Step 5: é‡å­åŒ–èª¤å·®ã®è§£æ

ç¬¬1æ®µéšï¼ˆNF4ï¼‰ã®é‡å­åŒ–èª¤å·®: $\epsilon_1 \approx 0.032$ï¼ˆå‰è¿°ï¼‰

ç¬¬2æ®µéšï¼ˆ8-bitç·šå½¢ï¼‰ã®é‡å­åŒ–èª¤å·®:

$$
\epsilon_2 = \mathbb{E}\left[\left(\frac{c_{i, \text{quant}}}{255} - c_{i, \text{norm}}\right)^2\right] \approx \frac{1}{12 \times 255^2} \approx 1.3 \times 10^{-5}
$$

ï¼ˆç·šå½¢é‡å­åŒ–ã®å‡ç­‰åˆ†å¸ƒè¿‘ä¼¼ï¼‰

**åˆæˆèª¤å·®**:

$$
\begin{aligned}
W_{0,j, \text{true}} &= W_{0,j, \text{norm}} \times c_i \\
W_{0,j, \text{dequant}} &= (W_{0,j, \text{norm}} + \epsilon_1) \times (c_i + \epsilon_2 c_{\text{global}}) \\
&\approx W_{0,j, \text{norm}} \times c_i + \epsilon_1 c_i + W_{0,j, \text{norm}} \epsilon_2 c_{\text{global}}
\end{aligned}
$$

ç¬¬2æ®µéšã®èª¤å·® $\epsilon_2$ ã¯æ¥µå°ï¼ˆ$10^{-5}$ï¼‰ãªã®ã§ã€å®Ÿç”¨ä¸Šã¯ç¬¬1æ®µéšã®NF4èª¤å·®ãŒæ”¯é…çš„ã€‚

**çµè«–**: Double Quantizationã¯å®šæ•°ãƒ¡ãƒ¢ãƒªã‚’75%å‰Šæ¸›ã—ã€ç²¾åº¦ä½ä¸‹ã¯ç„¡è¦–å¯èƒ½ï¼ˆ$<0.1\%$ï¼‰ã€‚

#### Double Quantization â€” å®Ÿè£…ã®è¦ç‚¹

ç¬¬1æ®µéš: ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º $b_1 = 64$ ã§weight tensorã‚’ãƒ–ãƒ­ãƒƒã‚¯åˆ†å‰²ã—ã€å„ãƒ–ãƒ­ãƒƒã‚¯ã® $c_1 = \text{absmax}(W_b)$ ã‚’æ±‚ã‚ã‚‹ï¼ˆFP32ã€$N/64$ å€‹ï¼‰ã€‚ç¬¬2æ®µéš: $\{c_1\}$ ã‚’å†ã³ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º $b_2 = 256$ ã§ã¾ã¨ã‚ã€$c_2 = \text{absmax}(\{c_1\})$ ã‚’æ±‚ã‚ã€$c_1$ ã‚’ FP8ã«é‡å­åŒ–ã™ã‚‹ã€‚

ãƒ¡ãƒ¢ãƒªè¨ˆç®—: 65Bãƒ¢ãƒ‡ãƒ«ã§ $N = 65 \times 10^9$ weightsã€‚ç¬¬1æ®µéšå®šæ•° = $N/64 \times 4\,\text{byte} \approx 4.06\,\text{GB}$ã€‚Double Quantizationå¾Œ = $N/64 \times 1\,\text{byte} + N/16384 \times 4\,\text{byte} \approx 1.03\,\text{GB}$ã€‚å‰Šæ¸›é‡ $\approx 3\,\text{GB}$ã€‚65Bãƒ¢ãƒ‡ãƒ«å…¨ä½“ã®4-bit weighté‡ $\approx 32.5\,\text{GB}$ ã«å¯¾ã—ã¦ç´„9%ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰å‰Šæ¸›ã€‚

#### 3.4.2.4 QLoRA Forward Pass

$$
\begin{aligned}
W_0^{\text{FP16}} &= \text{Dequant}_\text{NF4}(W_{0,\text{quant}}) \quad \text{(on-the-fly)} \\
h &= W_0^{\text{FP16}} x + \frac{\alpha}{r} BA x \quad \text{(B, A in FP16/BF16)}
\end{aligned}
$$

**ãƒ¡ãƒ¢ãƒª**: $W_0$ ã¯4-bitä¿æŒã€è¨ˆç®—æ™‚ã®ã¿FP16ã«å±•é–‹ã€‚å‹¾é…ã¯ $B, A$ ã«ã®ã¿æµã‚Œã‚‹ã€‚

#### 3.4.2.5 Paged Optimizers

è¨“ç·´ä¸­ã€ãƒãƒƒãƒã‚µã‚¤ã‚ºã®ã‚¹ãƒ‘ã‚¤ã‚¯ã§OOMï¼ˆOut of Memoryï¼‰ãŒç™ºç”Ÿã—ã†ã‚‹ã€‚Paged Optimizersã¯ã€NVIDIA Unified Memoryã‚’ä½¿ã„ã€GPUâ†’CPUé–“ã§ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶çŠ¶æ…‹ã‚’ã‚¹ãƒ¯ãƒƒãƒ—:

$$
\text{GPU memory} \xleftrightarrow{\text{page fault}} \text{CPU memory (slower but larger)}
$$

ã“ã‚Œã«ã‚ˆã‚Šã€OOMã‚’å›é¿ã—ã¤ã¤å¤§ãƒãƒƒãƒã‚µã‚¤ã‚ºã«å¯¾å¿œã€‚

### 3.4.3 DreamBooth â€” å°‘æ•°ç”»åƒã§ã®å€‹äººåŒ–

#### 3.4.3.1 å‹•æ©Ÿ: Few-shotç”Ÿæˆã®èª²é¡Œ

Stable Diffusionã¯ã€ŒçŠ¬ã€ã®ç”»åƒã‚’ç”Ÿæˆã§ãã‚‹ã€‚ã ãŒã€**ã‚ãªãŸã®çŠ¬**ã®ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ã«ã¯ï¼Ÿ 3-5æšã®å†™çœŸã‹ã‚‰å€‹äººåŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚

DreamBooth [^4] ã¯ã€Diffusionãƒ¢ãƒ‡ãƒ«ã‚’æ•°ç”»åƒã§Fine-tuningã—ã€ç‰¹å®šè¢«å†™ä½“ã‚’ç”Ÿæˆå¯èƒ½ã«ã™ã‚‹ã€‚

#### 3.4.3.2 DreamBoothã®å®šå¼åŒ–

**ç›®æ¨™**: è¢«å†™ä½“ã®ç”»åƒ $\{x_1, \dots, x_K\}$ (K=3-10) ã‚’ä¸ãˆã€ã€Œa [V] dogã€ã®ã‚ˆã†ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç”Ÿæˆå¯èƒ½ã«ã™ã‚‹ã€‚

[V]: ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆä¾‹: "sks"ï¼‰ã€‚

Fine-tuningã®æå¤±:

$$
\mathcal{L} = \mathbb{E}_{x, c, \epsilon, t}\left[\|\epsilon - \epsilon_\theta(z_t, c)\|_2^2\right]
$$

$c$: "a [V] dog" ãªã©ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã€$z_t$: ãƒã‚¤ã‚ºä»˜åŠ æ½œåœ¨å¤‰æ•°ï¼ˆç¬¬25å›Diffusionå‚ç…§ï¼‰ã€‚

**å•é¡Œ**: å°‘æ•°ç”»åƒã®ã¿ã§è¨“ç·´ã™ã‚‹ã¨**overfitting** + **language drift**ï¼ˆ"dog"ä¸€èˆ¬ã®æ„å‘³ã‚’å¿˜ã‚Œã‚‹ï¼‰ã€‚

#### 3.4.3.3 Prior Preservation Loss â€” å®Œå…¨å°å‡º

DreamBoothã®é©æ–°ã¯**Prior Preservation Loss**ã€‚ãªãœã“ã‚ŒãŒå¿…è¦ã‹ã€æ•°å¼ã§å®Œå…¨ã«å°å‡ºã™ã‚‹ã€‚

#### Step 1: å•é¡Œè¨­å®š â€” Overfitting ã¨ Language Drift

è¢«å†™ä½“ç”»åƒ $\{x_1, \dots, x_K\}$ (K=3-10)ã€ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ $c_{[V]} = \text{``a [V] dog''}$ã€‚

é€šå¸¸ã®Fine-tuningæå¤±:

$$
\mathcal{L}_\text{naive} = \frac{1}{K} \sum_{i=1}^K \mathbb{E}_{\epsilon, t}\left[\|\epsilon - \epsilon_\theta(z_{t,i}, c_{[V]})\|_2^2\right]
$$

**å•é¡Œ1: Overfitting**

$K$ ãŒå°ã•ã„ï¼ˆ3-10ï¼‰ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ã¯ $\{x_1, \dots, x_K\}$ ã‚’æš—è¨˜ã€‚æ–°ã—ã„ãƒãƒ¼ã‚ºãƒ»èƒŒæ™¯ã§ã®ç”ŸæˆãŒã§ããªã„ã€‚

**å•é¡Œ2: Language Drift**

$c_{[V]} = \text{``a [V] dog''}$ ã®ã¿ã§è¨“ç·´ã™ã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ã¯ã€Œdogã€ãƒˆãƒ¼ã‚¯ãƒ³ä¸€èˆ¬ã®æ„å‘³ã‚’å¤±ã†:

$$
p_\theta(\text{dog}) \to p_\theta(\text{dog} \mid [V]) \neq p_{\theta_0}(\text{dog})
$$

"a dog" ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç”Ÿæˆã—ã¦ã‚‚ã€**ã‚ãªãŸã®çŠ¬**ã®ç‰¹å¾´ãŒæ··å…¥ã—ã¦ã—ã¾ã†ï¼ˆä¸€èˆ¬çš„ãªçŠ¬ãŒç”Ÿæˆã§ããªããªã‚‹ï¼‰ã€‚

#### Step 2: Prior Preservation Lossã®å°å…¥

ç›®æ¨™:
1. $c_{[V]}$ ã§**ã‚ãªãŸã®çŠ¬**ã‚’ç”Ÿæˆ
2. $c_{\text{class}} = \text{``a dog''}$ ã§**ä¸€èˆ¬çš„ãªçŠ¬**ã‚’ç”Ÿæˆï¼ˆä¿æŒï¼‰

æå¤±é–¢æ•°:

$$
\mathcal{L}_\text{total} = \underbrace{\mathbb{E}_{x \sim \mathcal{D}_\text{instance}, \epsilon, t}\left[\|\epsilon - \epsilon_\theta(z_t, c_{[V]})\|_2^2\right]}_{\mathcal{L}_\text{instance}} + \lambda \underbrace{\mathbb{E}_{x_{pr} \sim \mathcal{D}_\text{prior}, \epsilon, t}\left[\|\epsilon - \epsilon_\theta(z_t^{pr}, c_{\text{class}})\|_2^2\right]}_{\mathcal{L}_\text{prior}}
$$

$\mathcal{D}_\text{instance} = \{x_1, \dots, x_K\}$: ã‚ãªãŸã®çŠ¬ã®ç”»åƒ
$\mathcal{D}_\text{prior}$: ä¸€èˆ¬çš„ãªçŠ¬ã®ç”»åƒï¼ˆäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆï¼‰

#### Step 3: $\mathcal{D}_\text{prior}$ ã®ç”Ÿæˆ

äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ« $\theta_0$ ã‚’ä½¿ã„ã€$c_{\text{class}} = \text{``a dog''}$ ã‹ã‚‰ç”»åƒã‚’ç”Ÿæˆ:

$$
x_{pr} \sim p_{\theta_0}(x \mid c_{\text{class}})
$$

**æ‰‹é †**:
1. Fine-tuningé–‹å§‹å‰ã«ã€$\theta_0$ ã§100-200æšã®ã€Œä¸€èˆ¬çš„ãªçŠ¬ã€ç”»åƒã‚’ç”Ÿæˆ
2. ã“ã‚Œã‚’ $\mathcal{D}_\text{prior}$ ã¨ã—ã¦ä¿å­˜
3. Fine-tuningæ™‚ã€$\mathcal{D}_\text{instance}$ ã¨ $\mathcal{D}_\text{prior}$ ã‚’åŒæ™‚ã«ãƒãƒƒãƒã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

#### Step 4: $\mathcal{L}_\text{prior}$ ã®å½¹å‰² â€” KLæ­£å‰‡åŒ–ã¨ã—ã¦è§£é‡ˆ

$\mathcal{L}_\text{prior}$ ã¯ã€**äº‹å‰å­¦ç¿’åˆ†å¸ƒã®ä¿æŒ**ã‚’å¼·åˆ¶:

$$
\mathcal{L}_\text{prior} = \mathbb{E}_{x_{pr} \sim p_{\theta_0}(\cdot \mid c_{\text{class}})}\left[\|\epsilon - \epsilon_\theta(z_t^{pr}, c_{\text{class}})\|_2^2\right]
$$

ã“ã‚Œã¯ã€$p_\theta(x \mid c_{\text{class}})$ ã‚’ $p_{\theta_0}(x \mid c_{\text{class}})$ ã«è¿‘ã¥ã‘ã‚‹åŠ¹æœ:

$$
\arg\min_\theta \mathcal{L}_\text{prior} \approx \arg\min_\theta D_\text{KL}(p_{\theta_0}(\cdot \mid c_{\text{class}}) \| p_\theta(\cdot \mid c_{\text{class}}))
$$

ï¼ˆDiffusionã®æå¤±ã¨KLã®é–¢ä¿‚ã¯ç¬¬25å›ã§è©³è¿°ï¼‰

#### Step 5: $\lambda$ ã®é¸æŠ

$\lambda$ ã¯ã€instanceå­¦ç¿’ã¨priorä¿æŒã®ãƒãƒ©ãƒ³ã‚¹:

$$
\mathcal{L}_\text{total} = \mathcal{L}_\text{instance} + \lambda \mathcal{L}_\text{prior}
$$

- $\lambda = 0$: Priorç„¡è¦– â†’ overfitting + language drift
- $\lambda \to \infty$: Priorå®Œå…¨ä¿æŒ â†’ instanceå­¦ç¿’ãŒé€²ã¾ãªã„
- $\lambda = 1$: ç­‰é‡ã¿ï¼ˆRuiz et al. [^4] æ¨å¥¨ï¼‰

**ç†è«–çš„æ ¹æ‹ **: $|\mathcal{D}_\text{instance}| = K \ll |\mathcal{D}_\text{prior}|$ ã®ãŸã‚ã€ç­‰é‡ã¿ã§ã‚‚priorãŒæ”¯é…çš„ã«ãªã‚Šã™ããªã„ã€‚å®Ÿé¨“çš„ã« $\lambda=1$ ãŒæœ€é©ã€‚

#### Step 6: è¨“ç·´ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

è¨“ç·´ã¯2ãƒ•ã‚§ãƒ¼ã‚ºã§æ§‹æˆã•ã‚Œã‚‹ã€‚

**ãƒ•ã‚§ãƒ¼ã‚º1 â€” å…ˆè¡Œãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ**: å‡çµã—ãŸ $\theta_0$ ã‚’ä½¿ã£ã¦ã€ã‚¯ãƒ©ã‚¹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ $c_\text{class}$ï¼ˆä¾‹: "a dog"ï¼‰ã‹ã‚‰200æšã®ç”»åƒ $\{x_\text{pr}^{(i)}\}$ ã‚’ç”Ÿæˆã™ã‚‹ã€‚ã“ã‚ŒãŒæ­£å‰‡åŒ–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ $\mathcal{D}_\text{prior}$ ã¨ãªã‚‹ã€‚ç”Ÿæˆã¯æ¨è«–ã®ã¿ã®ãŸã‚ã€$\theta_0$ ã®å‹¾é…ã¯ä¸è¦ã€‚

**ãƒ•ã‚§ãƒ¼ã‚º2 â€” Fine-tuning**: $\theta_0$ ã‚’åˆæœŸå€¤ã¨ã—ã¦ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ $\mathcal{D}_\text{instance}$ï¼ˆK=3ã€œ5æšï¼‰ã¨ $\mathcal{D}_\text{prior}$ ã‚’äº¤äº’ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€æå¤± $\mathcal{L} = \mathcal{L}_\text{instance} + \lambda \mathcal{L}_\text{prior}$ ã§æœ€é©åŒ–ã™ã‚‹ã€‚å­¦ç¿’ç‡ã¯ $10^{-6}$ï¼ˆFull FTï¼‰ã¾ãŸã¯ $10^{-4}$ï¼ˆLoRAä½¿ç”¨æ™‚ï¼‰ãŒå…¸å‹çš„ã€‚

é‡è¦ãªå®Ÿè£…è©³ç´°: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¨priorã®ãƒãƒƒãƒã¯åŒä¸€ãƒãƒƒãƒå†…ã«æ··åœ¨ã•ã›ã‚‹ï¼ˆåˆ¥ã€…ã§ã¯ãªã„ï¼‰ã€‚ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚º = 2ï¼ˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹1 + prior1ï¼‰ã§å®Ÿè£…ã™ã‚‹ã®ãŒè«–æ–‡ [^4] ã®è¨­å®šã«æº–ã˜ã‚‹ã€‚ã‚¹ãƒ†ãƒƒãƒ—æ•°ã¯é€šå¸¸800ã€œ1500ï¼ˆK=5ã®å ´åˆï¼‰ã§ã€ãã‚Œä»¥ä¸Šã§ã¯overfittingãŒç™ºç”Ÿã™ã‚‹ã€‚

#### Step 7: æ•°å€¤ä¾‹ â€” Prior Preservation ã®åŠ¹æœ

å®Ÿé¨“è¨­å®š: K=5 ç”»åƒã€$\lambda=1$ã€200 priorç”»åƒ

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | w/o Prior | w/ Prior |
|:----------|:----------|:---------|
| **Instance CLIP Score** | 0.85 | 0.82 (-3%) |
| **Class CLIP Score** | 0.42 | 0.78 (+86%) |
| **Prompt Fidelity** | 0.65 | 0.88 (+35%) |

**è§£é‡ˆ**:
- Instance Scoreå¾®æ¸›: ã‚ãªãŸã®çŠ¬ã®å†ç¾æ€§ãŒè‹¥å¹²ä¸‹ãŒã‚‹ï¼ˆéé©åˆå›é¿ã®å‰¯ä½œç”¨ï¼‰
- Class Scoreå¤§å¹…å‘ä¸Š: "a dog" ã§ä¸€èˆ¬çš„ãªçŠ¬ã‚’ç”Ÿæˆå¯èƒ½ã«
- Prompt Fidelityå‘ä¸Š: ã€Œé›ªå±±ã®ã‚ãªãŸã®çŠ¬ã€ãªã©ã®æ–°ã‚·ãƒ¼ãƒ³ã§å“è³ªå‘ä¸Š

#### Step 8: Language Drift ã®å®šé‡çš„è§£æ

Language driftã‚’æ¸¬å®šã™ã‚‹æŒ‡æ¨™ [^4]:

$$
\text{Drift}(\text{token}) = D_\text{KL}(p_{\theta_0}(\cdot \mid \text{token}) \| p_\theta(\cdot \mid \text{token}))
$$

| ãƒˆãƒ¼ã‚¯ãƒ³ | Naive FT (no prior) | DreamBooth ($\lambda=1$) |
|:---------|:-------------------|:------------------------|
| "dog" | 2.34 (å¤§) | 0.12 (å°) |
| "cat" | 0.08 | 0.05 |
| "car" | 0.11 | 0.06 |

Naive FTã¯ "dog" ãƒˆãƒ¼ã‚¯ãƒ³ã®æ„å‘³ãŒå¤§å¹…ã«ãšã‚Œã‚‹ï¼ˆKL=2.34ï¼‰ã€‚DreamBoothã¯KL=0.12ã§ä¿æŒã€‚

#### 3.4.3.4 Class-specific Prior ã®ç†è«–çš„æ­£å½“åŒ–

ãªãœã€Œä¸€èˆ¬çš„ãªçŠ¬ã€ã ã‘ã‚’ prior ã¨ã—ã¦ä¿æŒã™ã‚Œã°ååˆ†ã‹ï¼Ÿ

**ä»®èª¬**: Diffusionãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã¯**éšå±¤çš„**ã€‚

- **ä½å±¤**: æ±ç”¨çš„ç‰¹å¾´ï¼ˆã‚¨ãƒƒã‚¸ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ï¼‰
- **ä¸­å±¤**: ã‚¯ãƒ©ã‚¹ç‰¹å¾´ï¼ˆçŠ¬ã®å½¢ã€çŒ«ã®å½¢ï¼‰
- **é«˜å±¤**: å€‹ä½“ç‰¹å¾´ï¼ˆã‚ãªãŸã®çŠ¬ã®æ¨¡æ§˜ï¼‰

Fine-tuningã¯ä¸»ã«**é«˜å±¤**ã‚’å¤‰æ›´ã€‚Class-specific priorã¯**ä¸­å±¤**ã‚’ä¿è­· â†’ ä»–ã‚¯ãƒ©ã‚¹ï¼ˆçŒ«ã€è»Šï¼‰ã¸ã®å½±éŸ¿ã¯å¾®å°ã€‚

æ•°å¼çš„ã«ã¯:

$$
\theta = [\theta_\text{low}, \theta_\text{mid}, \theta_\text{high}]
$$

Instanceå­¦ç¿’: $\Delta \theta_\text{high} \gg \Delta \theta_\text{mid} \approx \Delta \theta_\text{low}$

Prior preservation: $\theta_\text{mid}$ ã‚’ $\theta_{0,\text{mid}}$ ä»˜è¿‘ã«ä¿æŒã€‚

#### 3.4.3.5 DreamBoothã¨LoRAã®çµ„ã¿åˆã‚ã›

DreamBoothã¯Full Fine-tuningï¼ˆå…¨UNeté‡ã¿ã‚’æ›´æ–°ï¼‰ã ãŒã€**DreamBooth + LoRA**ã‚‚å¯èƒ½:

$$
\epsilon_\theta = \epsilon_{\theta_0} + \Delta \epsilon_{BA}
$$

UNetã®å„Attentionå±¤ã« $(B, A)$ ã‚’è¿½åŠ ã€$\theta_0$ ã¯å›ºå®šã€‚ãƒ¡ãƒ¢ãƒªå‰Šæ¸› + æ¨è«–æ™‚ã®è¤‡æ•°è¢«å†™ä½“åˆ‡ã‚Šæ›¿ãˆãŒå¯èƒ½ã€‚

### 3.4.4 Adapter Tuning â€” å„å±¤ã«è¿½åŠ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

#### 3.4.4.1 Adapterã®æ§‹é€ 

Adapter [^5] ã¯ã€Transformerå„å±¤ã«**å°ã•ãªãƒœãƒˆãƒ«ãƒãƒƒã‚¯ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**ã‚’æŒ¿å…¥:

$$
\begin{aligned}
h_\text{attn} &= \text{Attention}(x) \\
h_\text{adapter} &= \text{Adapter}(h_\text{attn}) \\
h_\text{out} &= h_\text{attn} + h_\text{adapter} \quad \text{(residual connection)}
\end{aligned}
$$

Adapterã®å†…éƒ¨æ§‹é€ :

$$
\text{Adapter}(h) = W_{\text{up}} \cdot \text{ReLU}(W_{\text{down}} h + b_{\text{down}}) + b_{\text{up}}
$$

$W_{\text{down}} \in \mathbb{R}^{r \times d}$, $W_{\text{up}} \in \mathbb{R}^{d \times r}$ã€$r \ll d$ï¼ˆãƒœãƒˆãƒ«ãƒãƒƒã‚¯æ¬¡å…ƒï¼‰ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°**: $2dr + d + r \approx 2dr$ï¼ˆ$r=64, d=768$ ãªã‚‰ $2 \times 64 \times 768 = 98,304$ï¼‰ã€‚

Transformer 12å±¤ãªã‚‰ã€Adapterãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ $12 \times 2dr \approx 1.2M$ï¼ˆBERT-baseå…¨ä½“110Mã®ç´„1%ï¼‰ã€‚

#### 3.4.4.2 Adapter vs LoRAæ¯”è¼ƒ

| é …ç›® | Adapter | LoRA |
|:-----|:--------|:-----|
| æŒ¿å…¥ç®‡æ‰€ | å„å±¤ã®å¾Œ | Attentioné‡ã¿è¡Œåˆ—å†… |
| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° | $L \times 2dr$ | $L \times 4 \times r(d+k)$ (4=Attnå±¤æ•°) |
| æ¨è«–é€Ÿåº¦ | è¿½åŠ è¨ˆç®—ã‚ã‚Šï¼ˆ10-20%é…å»¶ï¼‰ | ãƒãƒ¼ã‚¸å¯èƒ½ï¼ˆé…å»¶ã‚¼ãƒ­ï¼‰ |
| æŸ”è»Ÿæ€§ | éç·šå½¢æ´»æ€§åŒ– | ç·šå½¢å¤‰æ›ã®ã¿ |

**æ€§èƒ½**: GLUEãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§Adapterã¨LoRAã¯åŒç­‰ï¼ˆFull FTã®98-99%ï¼‰[^1] [^5]ã€‚

#### 3.4.4.3 Prefix Tuning â€” é€£ç¶šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

Prefix Tuning [^6] ã¯ã€å…¥åŠ›ã®**å…ˆé ­ã«trainableãªãƒ™ã‚¯ãƒˆãƒ«åˆ—**ã‚’è¿½åŠ :

$$
\begin{aligned}
P &= [p_1, p_2, \dots, p_l] \in \mathbb{R}^{l \times d} \quad \text{(trainable prefix)} \\
X' &= [P; X] \in \mathbb{R}^{(l+n) \times d} \quad \text{(concatenate)} \\
H &= \text{Transformer}(X')
\end{aligned}
$$

$l$: ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹é•·ï¼ˆå…¸å‹å€¤10-20ï¼‰ã€$X$: å…ƒã®å…¥åŠ›ã€‚

Transformerãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å›ºå®šã€$P$ ã®ã¿trainableã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° $l \times d \times L$ï¼ˆ$l=10, d=768, L=12$ ãªã‚‰ $92K$ï¼‰ã€‚

**å•é¡Œ**: ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒé•·ã„ã¨ã€æœ‰åŠ¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ãŒæ¸›ã‚‹ã€‚

#### 3.4.4.4 P-Tuning v2 â€” Deep Prompt Tuning

P-Tuning v2 [^7] ã¯ã€**å„å±¤ã®å…¥åŠ›**ã«ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’è¿½åŠ :

$$
\begin{aligned}
H_0 &= [P_0; X] \\
H_i &= [P_i; \text{TransformerLayer}_i(H_{i-1})] \quad \text{for } i = 1, \dots, L
\end{aligned}
$$

å„å±¤ $i$ ã«å°‚ç”¨ã® $P_i \in \mathbb{R}^{l \times d}$ ã‚’æŒã¤ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° $L \times l \times d$ã€‚

**æ€§èƒ½**: P-Tuning v2ã¯ã€å¤šãã®ã‚¿ã‚¹ã‚¯ã§**Full FTã‚’è¶…ãˆã‚‹** [^7]ã€‚ç†ç”±ã¯ä¸æ˜ã ãŒã€ä»®èª¬ã¨ã—ã¦ã€Œå„å±¤ã§ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã€éšå±¤çš„ãªç‰¹å¾´æŠ½å‡ºã‚’å¼·åŒ–ã€ã€‚

#### 3.4.4.5 Prompt Tuning â€” Softãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

Prompt Tuning [^8] ã¯ã€**åŸ‹ã‚è¾¼ã¿å±¤ã«ã®ã¿**é€£ç¶šãƒ™ã‚¯ãƒˆãƒ«ã‚’è¿½åŠ :

$$
\begin{aligned}
E_\text{input} &= \text{Embed}([\text{"summarize:"}, x_1, x_2, \dots]) \\
E_\text{prompt} &= [p_1, p_2, \dots, p_k] \quad \text{(trainable soft prompt)} \\
E &= [E_\text{prompt}; E_\text{input}]
\end{aligned}
$$

Transformerãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å›ºå®šã€$E_\text{prompt}$ ã®ã¿trainableã€‚

**æ¥µå°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**: $k \times d$ï¼ˆ$k=20, d=768$ ãªã‚‰ $15K$ï¼‰ã€‚

**å•é¡Œ**: å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ï¼ˆ<1Bï¼‰ã§ã¯æ€§èƒ½ãŒä½ã„ã€‚10Bè¶…ã§åŠ¹æœãŒé¡•è‘— [^8]ã€‚

**Prompt Tuning vs Prefix Tuning**: Prompt Tuningã¯å…¥åŠ›å±¤ã®embeddingç©ºé–“ã«ã®ã¿ä½œç”¨ã™ã‚‹ã®ã«å¯¾ã—ã€Prefix Tuningã¯å…¨å±¤ã®key/valueã« prefix vectorã‚’æ³¨å…¥ã™ã‚‹ã€‚å‰è€…ã¯ã‚·ãƒ³ãƒ—ãƒ«ã ãŒå¾Œè€…ã®ã»ã†ãŒè¡¨ç¾åŠ›ãŒé«˜ãã€ç‰¹ã«çŸ­ã„task descriptionã§ã®æ€§èƒ½å·®ãŒé¡•è‘—ã ã€‚

### 3.4.5 PEFTæ‰‹æ³•ã®çµ±ä¸€ç†è«–

å…¨PEFTæ‰‹æ³•ã‚’çµ±ä¸€è¦–ç‚¹ã§æ‰ãˆã‚‹:

$$
h = f_{\theta_0}(x) + \Delta f_\phi(x)
$$

$\theta_0$: frozenäº‹å‰å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€$\phi$: trainableè¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚

| æ‰‹æ³• | $\Delta f_\phi(x)$ ã®å½¢ | $\phi$ ã®æ¬¡å…ƒ |
|:-----|:----------------------|:-------------|
| **LoRA** | $\frac{\alpha}{r} B (A x)$ | $r(d+k)$ per layer |
| **Adapter** | $W_{\text{up}} \text{ReLU}(W_{\text{down}} h)$ | $2dr$ per layer |
| **Prefix Tuning** | Attention to prefix $P$ | $l \times d \times L$ |
| **Prompt Tuning** | Input embedding prefix | $k \times d$ |
| **P-Tuning v2** | Layer-wise prefix | $L \times l \times d$ |

å…¨ã¦ $|\phi| \ll |\theta_0|$ï¼ˆå…¸å‹çš„ã«0.01-1%ï¼‰ã€‚

### 3.4.6 âš”ï¸ Boss Battle: LoRAå®Œå…¨å®Ÿè£…ã®æ•°å¼åˆ†è§£

GPT-2ã‚¹ã‚¿ã‚¤ãƒ«ã®Transformer 1å±¤ã«å¯¾ã—ã€LoRAã‚’å®Œå…¨å®Ÿè£…ã™ã‚‹æ•°å¼ã‚’åˆ†è§£ã™ã‚‹ã€‚

#### ã‚¹ãƒ†ãƒƒãƒ—1: å…ƒã®Attentionå±¤

$$
\begin{aligned}
Q &= W_q X, \quad W_q \in \mathbb{R}^{d \times d_k} \\
K &= W_k X, \quad W_k \in \mathbb{R}^{d \times d_k} \\
V &= W_v X, \quad W_v \in \mathbb{R}^{d \times d_v} \\
\text{Attn} &= \text{softmax}\left(\frac{QK^\top}{\sqrt{d_k}}\right) V \in \mathbb{R}^{n \times d_v} \\
O &= W_o \cdot \text{Attn}, \quad W_o \in \mathbb{R}^{d \times d_v}
\end{aligned}
$$

$X \in \mathbb{R}^{n \times d}$ (n=ç³»åˆ—é•·, d=åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ)ã€‚

#### ã‚¹ãƒ†ãƒƒãƒ—2: LoRAè¿½åŠ 

$W_q, W_v$ ã«LoRAã‚’é©ç”¨ï¼ˆHu et al. [^1] æ¨å¥¨ï¼‰:

$$
\begin{aligned}
Q &= (W_{q,0} + \frac{\alpha}{r} B_q A_q) X \\
V &= (W_{v,0} + \frac{\alpha}{r} B_v A_v) X \\
K &= W_{k,0} X \quad \text{(no LoRA)} \\
O &= W_{o,0} \cdot \text{Attn} \quad \text{(no LoRA)}
\end{aligned}
$$

$B_q \in \mathbb{R}^{d \times r}$, $A_q \in \mathbb{R}^{r \times d_k}$ï¼ˆåŒæ§˜ã« $B_v, A_v$ï¼‰ã€‚

#### ã‚¹ãƒ†ãƒƒãƒ—3: Forward Passè©³ç´°

$$
\begin{aligned}
Q &= W_{q,0} X + \frac{\alpha}{r} B_q (A_q X) \quad \text{(2 MatMuls: } A_q X \text{ then } B_q \cdot) \\
V &= W_{v,0} X + \frac{\alpha}{r} B_v (A_v X) \\
S &= \frac{QK^\top}{\sqrt{d_k}} = \frac{(W_{q,0} X + \frac{\alpha}{r} B_q A_q X)(W_{k,0} X)^\top}{\sqrt{d_k}} \\
&= \frac{W_{q,0} X X^\top W_{k,0}^\top}{\sqrt{d_k}} + \frac{\alpha}{r\sqrt{d_k}} (B_q A_q X) X^\top W_{k,0}^\top \\
P &= \text{softmax}(S) \in \mathbb{R}^{n \times n} \\
\text{Attn} &= P V = P (W_{v,0} X + \frac{\alpha}{r} B_v A_v X) \\
O &= W_{o,0} \cdot \text{Attn}
\end{aligned}
$$

#### ã‚¹ãƒ†ãƒƒãƒ—4: Backward Passï¼ˆå‹¾é…è¨ˆç®—ï¼‰

æå¤± $\mathcal{L}$ ã«å¯¾ã™ã‚‹ $B_q, A_q$ ã®å‹¾é…ï¼ˆ$W_{q,0}$ ã¯å›ºå®šï¼‰:

$$
\begin{aligned}
\frac{\partial \mathcal{L}}{\partial Q} &= \frac{\partial \mathcal{L}}{\partial S} \frac{\partial S}{\partial Q} = \frac{1}{\sqrt{d_k}} \frac{\partial \mathcal{L}}{\partial S} K \quad \text{(chain rule)} \\
\frac{\partial \mathcal{L}}{\partial B_q} &= \frac{\partial \mathcal{L}}{\partial Q} \frac{\partial Q}{\partial B_q} = \frac{\alpha}{r} \frac{\partial \mathcal{L}}{\partial Q} (A_q X)^\top \\
\frac{\partial \mathcal{L}}{\partial A_q} &= \frac{\partial \mathcal{L}}{\partial Q} \frac{\partial Q}{\partial A_q} = \frac{\alpha}{r} B_q^\top \frac{\partial \mathcal{L}}{\partial Q} X^\top
\end{aligned}
$$

ãƒãƒƒãƒã‚µã‚¤ã‚º $N$ ã®å ´åˆã€ãƒãƒƒãƒæ¬¡å…ƒã§å’Œã‚’å–ã‚‹:

$$
\nabla_{B_q} = \frac{\alpha}{r} \sum_{i=1}^N \frac{\partial \mathcal{L}}{\partial Q_i} (A_q X_i)^\top
$$

åŒæ§˜ã« $\nabla_{A_q}, \nabla_{B_v}, \nabla_{A_v}$ ã‚’è¨ˆç®—ã€‚

#### ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°

AdamWæ›´æ–°:

$$
\begin{aligned}
m_{B_q} &\leftarrow \beta_1 m_{B_q} + (1-\beta_1) \nabla_{B_q} \\
v_{B_q} &\leftarrow \beta_2 v_{B_q} + (1-\beta_2) \nabla_{B_q}^2 \\
B_q &\leftarrow B_q - \eta \frac{m_{B_q}}{\sqrt{v_{B_q}} + \epsilon} - \lambda B_q \quad \text{(weight decay)}
\end{aligned}
$$

åŒæ§˜ã« $A_q, B_v, A_v$ ã‚’æ›´æ–°ã€‚

**ãƒœã‚¹æ’ƒç ´**: LoRAã®Forward/Backward/Updateã‚’å®Œå…¨åˆ†è§£ã—ãŸã€‚

### 3.4.7 AdaLoRA â€” ãƒ©ãƒ³ã‚¯é©å¿œå‹LoRA

#### 3.4.7.1 å‹•æ©Ÿ: ãƒ©ãƒ³ã‚¯$r$ã¯å›ºå®šã§ã‚ˆã„ã‹ï¼Ÿ

LoRAã¯å…¨å±¤ã§åŒã˜ãƒ©ãƒ³ã‚¯ $r$ ã‚’ä½¿ç”¨ã™ã‚‹ã€‚ã ãŒã€å„å±¤ã®**é‡è¦åº¦**ã¯ç•°ãªã‚‹:

- ä½å±¤: æ±ç”¨ç‰¹å¾´æŠ½å‡º â†’ å°ã•ãª $r$ ã§ååˆ†
- é«˜å±¤: ã‚¿ã‚¹ã‚¯ç‰¹åŒ–è¡¨ç¾ â†’ å¤§ããª $r$ ãŒå¿…è¦

AdaLoRA [^15] ã¯ã€è¨“ç·´ä¸­ã«**å±¤ã”ã¨ã®ãƒ©ãƒ³ã‚¯ã‚’å‹•çš„ã«èª¿æ•´**ã™ã‚‹ã€‚

#### 3.4.7.2 AdaLoRAã®å®šå¼åŒ–

AdaLoRA ã¯ã€ç‰¹ç•°å€¤åˆ†è§£ï¼ˆSVDï¼‰ã®æ çµ„ã¿ã§LoRAã‚’å†å®šå¼åŒ–:

$$
\Delta W = P \Lambda Q^\top
$$

$P \in \mathbb{R}^{d \times r}$, $Q \in \mathbb{R}^{k \times r}$: ç›´äº¤è¡Œåˆ—ï¼ˆå·¦/å³ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ï¼‰
$\Lambda = \text{diag}(\sigma_1, \dots, \sigma_r)$: ç‰¹ç•°å€¤è¡Œåˆ—

é€šå¸¸ã®LoRA $\Delta W = BA$ ã¨ç•°ãªã‚Šã€AdaLoRAã¯ $\Lambda$ ã‚’**trainable diagonal matrix**ã¨ã—ã¦æ‰±ã†ã€‚

#### 3.4.7.3 ãƒ©ãƒ³ã‚¯èª¿æ•´ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 

è¨“ç·´ä¸­ã€å„ç‰¹ç•°å€¤ $\sigma_i$ ã®**é‡è¦åº¦**ã‚’è©•ä¾¡:

$$
\text{Importance}(\sigma_i) = |\sigma_i| \cdot \left\|\frac{\partial \mathcal{L}}{\partial \sigma_i}\right\|
$$

é‡è¦åº¦ãŒä½ã„ç‰¹ç•°å€¤ã‚’pruningï¼ˆå‰Šé™¤ï¼‰:

$$
\Lambda' = \text{diag}(\sigma_1, \dots, \sigma_{r'}) \quad \text{where } r' < r
$$

#### Step 1: SVD-based LoRAåˆæœŸåŒ–

é€šå¸¸ã®LoRAåˆæœŸåŒ– $(B, A)$ ã‚’SVDåˆ†è§£:

$$
\begin{aligned}
A &\sim \mathcal{N}(0, \sigma^2), \quad B = 0 \\
[U, \Sigma, V^\top] &= \text{SVD}(BA) \quad \text{(conceptual)} \\
P &\leftarrow U[:, :r], \quad \Lambda \leftarrow \Sigma[:r, :r], \quad Q \leftarrow V[:, :r]
\end{aligned}
$$

åˆæœŸã§ã¯ $B=0$ ãªã®ã§ $\Lambda=0$ã€‚

#### Step 2: é‡è¦åº¦ãƒ™ãƒ¼ã‚¹ã®pruning

å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¾Œã€ç‰¹ç•°å€¤ã®é‡è¦åº¦ã‚’è¨ˆç®—:

$$
I_i = |\sigma_i| \cdot \left\|\frac{\partial \mathcal{L}}{\partial \sigma_i}\right\|_2
$$

é‡è¦åº¦ã§ã‚½ãƒ¼ãƒˆã—ã€ä¸‹ä½ $k\%$ ã‚’pruning:

$$
\Lambda_{\text{pruned}} = \text{diag}(\sigma_{i_1}, \dots, \sigma_{i_{r'}}) \quad \text{where } I_{i_1} \geq I_{i_2} \geq \dots \geq I_{i_{r'}}
$$

å¯¾å¿œã™ã‚‹ $P, Q$ ã®åˆ—ã‚‚å‰Šé™¤ã€‚

#### Step 3: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿äºˆç®—ã®å†åˆ†é…

å‰Šæ¸›ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’ã€ä»–ã®é‡è¦ãªå±¤ã«**å†åˆ†é…**:

$$
\begin{aligned}
\text{Budget}_\text{total} &= \sum_{\ell=1}^L r_\ell (d_\ell + k_\ell) \quad \text{(fixed)} \\
r_{\ell, \text{new}} &\leftarrow r_{\ell, \text{old}} + \Delta r_\ell \quad \text{where } \sum_\ell \Delta r_\ell = 0
\end{aligned}
$$

é«˜é‡è¦åº¦å±¤ã®ãƒ©ãƒ³ã‚¯ã‚’å¢—ã‚„ã—ã€ä½é‡è¦åº¦å±¤ã®ãƒ©ãƒ³ã‚¯ã‚’æ¸›ã‚‰ã™ã€‚

#### 3.4.7.4 AdaLoRAã®è¨“ç·´ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

è¨“ç·´ãƒ«ãƒ¼ãƒ—ã®å…¨ä½“æ§‹é€ ã‚’æ•´ç†ã™ã‚‹ã€‚

**é€šå¸¸ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆæ¯å›ï¼‰**: forward pass â†’ lossã‚’è¨ˆç®— â†’ backpropã§ $\nabla_{P_\ell}, \nabla_{\Lambda_\ell}, \nabla_{Q_\ell}$ ã‚’å–å¾— â†’ AdamWã§æ›´æ–°ã€‚$P, Q$ ã¯æ­£è¦ç›´äº¤æ€§ã‚’ä¿ã¤ãŸã‚ã€æ›´æ–°å¾Œã«**QRåˆ†è§£**ã§re-orthogonalization ã™ã‚‹ã€‚

**æåˆˆã‚Šã‚¹ãƒ†ãƒƒãƒ—ï¼ˆ$T$ ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ï¼‰**: å„å±¤ã®é‡è¦åº¦ã‚¹ã‚³ã‚¢ $I_i = |\lambda_i| \cdot \|\nabla_{\lambda_i} \mathcal{L}\|$ ã‚’è¨ˆç®—ã™ã‚‹ã€‚ã‚¹ã‚³ã‚¢ã¯ã€Œç¾åœ¨ã®å¯„ä¸ï¼ˆ$|\lambda_i|$ï¼‰Ã— å¤‰åŒ–æ„Ÿåº¦ï¼ˆå‹¾é…ãƒãƒ«ãƒ ï¼‰ã€ã®ç©ã§ã€å¤§ãã„ã»ã©ä¿æŒä¾¡å€¤ãŒé«˜ã„ã€‚ã—ãã„å€¤ã‚’æ±ºã‚ã¦ä½ã‚¹ã‚³ã‚¢ç‰¹ç•°å€¤ã‚’ $\lambda_i = 0$ ã«å›ºå®šï¼ˆå®Ÿè³ªå‰Šé™¤ï¼‰ã€‚ç©ºã„ãŸäºˆç®—ã‚’é«˜é‡è¦åº¦å±¤ã«å†é…åˆ†ã™ã‚‹ã€‚

**äºˆç®—ç®¡ç†**: ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿äºˆç®— $B_\text{total}$ ã‚’äº‹å‰è¨­å®šã—ã€$\sum_\ell r_\ell \cdot (d_\ell + k_\ell) \leq B_\text{total}$ ã‚’ç¶­æŒã—ãªãŒã‚‰ã€å„ $r_\ell$ ã‚’å‹•çš„èª¿æ•´ã™ã‚‹ã€‚åˆæœŸãƒ©ãƒ³ã‚¯ $r_\text{init} > r_\text{target}$ ã«è¨­å®šã—ã€æ®µéšçš„ã«æåˆˆã‚Šã—ã¦ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆç®—ã«åæŸã•ã›ã‚‹ã€‚

å®Ÿé¨“è¨­å®š: DeBERTa-v3-base (86M) ã‚’GLUEã§Fine-tuning

| æ‰‹æ³• | ãƒ©ãƒ³ã‚¯è¨­å®š | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° | GLUEå¹³å‡ |
|:-----|:----------|:------------|:---------|
| Full FT | - | 86M (100%) | 88.2 |
| LoRA | $r=8$ (all layers) | 0.3M (0.35%) | 85.4 |
| LoRA | $r=16$ | 0.6M (0.7%) | 86.1 |
| **AdaLoRA** | $r \in [2, 32]$ adaptive | 0.3M (0.35%) | **86.8** |

**è§£é‡ˆ**:
- AdaLoRAã¯ã€å›ºå®šãƒ©ãƒ³ã‚¯LoRA ($r=8$) ã¨åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§**+1.4pt**å‘ä¸Š
- å›ºå®š $r=16$ (2å€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿) ã‚ˆã‚Šé«˜æ€§èƒ½
- å±¤ã”ã¨ã®æœ€é©ãƒ©ãƒ³ã‚¯é…åˆ†ãŒæ€§èƒ½å‘ä¸Šã®éµ

#### 3.4.7.6 å±¤åˆ¥ãƒ©ãƒ³ã‚¯åˆ†å¸ƒã®å¯è¦–åŒ–

AdaLoRAè¨“ç·´å¾Œã®å±¤åˆ¥ãƒ©ãƒ³ã‚¯ï¼ˆDeBERTa-v3 12å±¤ï¼‰:

| å±¤ | åˆæœŸãƒ©ãƒ³ã‚¯ | æœ€çµ‚ãƒ©ãƒ³ã‚¯ | é‡è¦åº¦ã‚¹ã‚³ã‚¢ |
|:---|:----------|:----------|:------------|
| 1 (ä½å±¤) | 8 | 2 | 0.12 |
| 2 | 8 | 3 | 0.18 |
| 3 | 8 | 4 | 0.25 |
| ... | ... | ... | ... |
| 10 (é«˜å±¤) | 8 | 28 | 0.89 |
| 11 | 8 | 32 | 0.95 |
| 12 (æœ€çµ‚å±¤) | 8 | 32 | 1.00 |

**è¦³å¯Ÿ**: ä½å±¤ã®ãƒ©ãƒ³ã‚¯ãŒå¤§å¹…å‰Šæ¸›ï¼ˆ8â†’2ï¼‰ã€é«˜å±¤ãŒå¤§å¹…å¢—åŠ ï¼ˆ8â†’32ï¼‰ã€‚äºˆç®—ã¯å›ºå®šã€‚

### 3.4.8 LoRA+ â€” å­¦ç¿’ç‡ã®å±¤åˆ¥æœ€é©åŒ–

#### 3.4.8.1 å‹•æ©Ÿ: $B$ã¨$A$ã¯åŒã˜å­¦ç¿’ç‡ã§ã‚ˆã„ã‹ï¼Ÿ

LoRAã®åˆæœŸåŒ–: $B=0, A \sim \mathcal{N}(0, \sigma^2)$

Forward: $h = W_0 x + \frac{\alpha}{r} BA x$

è¨“ç·´é–‹å§‹æ™‚ã€$B=0$ ãªã®ã§å‡ºåŠ›ã¯ $W_0 x$ ã®ã¿ã€‚$B$ ã®å‹¾é…ã¯å¤§ãã„ãŒã€$A$ ã®å‹¾é…ã¯å°ã•ã„ï¼ˆ$B=0$ ã§æŠ‘åˆ¶ï¼‰ã€‚

**å•é¡Œ**: $B$ ã¨ $A$ ã«åŒã˜å­¦ç¿’ç‡ $\eta$ ã‚’ä½¿ã†ã¨ã€$A$ ã®å­¦ç¿’ãŒé…ã„ã€‚

LoRA+ [^16] ã¯ã€$B$ ã¨ $A$ ã«**ç•°ãªã‚‹å­¦ç¿’ç‡**ã‚’ä½¿ã†:

$$
\begin{aligned}
B &\leftarrow B - \eta_B \nabla_B \mathcal{L} \\
A &\leftarrow A - \eta_A \nabla_A \mathcal{L} \quad \text{where } \eta_A > \eta_B
\end{aligned}
$$

#### 3.4.8.2 ç†è«–çš„æ ¹æ‹ : Hessianã®æ¡ä»¶æ•°

$B$ ã¨ $A$ ã®Hessianï¼ˆ2æ¬¡å°é–¢æ•°è¡Œåˆ—ï¼‰ã®æ¡ä»¶æ•°ã‚’æ¯”è¼ƒ:

$$
\kappa(H_B) \ll \kappa(H_A)
$$

$B$ ã¯åˆæœŸå€¤0ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã—ã€æå¤±ã¸ã®å½±éŸ¿ãŒç›´æ¥çš„ â†’ Hessianã®æ¡ä»¶æ•°ãŒå°ã•ã„ï¼ˆæœ€é©åŒ–ã—ã‚„ã™ã„ï¼‰

$A$ ã¯ $B$ ã‚’ä»‹ã—ã¦é–“æ¥çš„ã«å½±éŸ¿ â†’ Hessianã®æ¡ä»¶æ•°ãŒå¤§ãã„ï¼ˆæœ€é©åŒ–ãŒé›£ã—ã„ï¼‰

æ¡ä»¶æ•°ãŒå¤§ãã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã¯**å¤§ããªå­¦ç¿’ç‡**ãŒå¿…è¦ï¼ˆ[^17] Adaptive LRç†è«–ï¼‰ã€‚

#### 3.4.8.3 æœ€é©å­¦ç¿’ç‡æ¯”ã®å°å‡º

LoRA+è«–æ–‡ [^16] ã¯ã€ç†è«–çš„ã«æœ€é©ãªå­¦ç¿’ç‡æ¯”ã‚’å°å‡º:

$$
\frac{\eta_A}{\eta_B} = \frac{\|B\|_F}{\|A\|_F} \cdot \sqrt{\frac{d}{r}}
$$

**ç›´æ„Ÿçš„èª¬æ˜**:
- $\|B\|_F / \|A\|_F$: è¡Œåˆ—ã®ãƒãƒ«ãƒ æ¯”ï¼ˆå½±éŸ¿åº¦ã®è£œæ­£ï¼‰
- $\sqrt{d/r}$: æ¬¡å…ƒæ¯”ï¼ˆ$A$ ã®æ¬¡å…ƒ $r \times k$ vs $B$ ã®æ¬¡å…ƒ $d \times r$ï¼‰

å®Ÿç”¨ä¸Šã€è«–æ–‡ã¯**å›ºå®šæ¯” $\eta_A / \eta_B = 16$**ã‚’æ¨å¥¨ï¼ˆå¤šãã®ã‚¿ã‚¹ã‚¯ã§æœ€é©ã«è¿‘ã„ï¼‰ã€‚

#### 3.4.8.4 LoRA+ vs LoRAã®å®Ÿé¨“æ¯”è¼ƒ

å®Ÿé¨“è¨­å®š: RoBERTa-base (125M) ã‚’GLUEã§Fine-tuning

| æ‰‹æ³• | å­¦ç¿’ç‡è¨­å®š | åæŸã‚¹ãƒ†ãƒƒãƒ—æ•° | GLUEå¹³å‡ |
|:-----|:----------|:-------------|:---------|
| LoRA | $\eta_B = \eta_A = 3e-4$ | 30,000 | 85.2 |
| LoRA+ | $\eta_B = 3e-4, \eta_A = 4.8e-3$ (16x) | **15,000** | **85.9** |
| Full FT | $\eta = 1e-5$ | 50,000 | 86.1 |

**çµæœ**:
- LoRA+ã¯åæŸé€Ÿåº¦**2å€**ï¼ˆ30Kâ†’15K stepsï¼‰
- æ€§èƒ½ã‚‚+0.7ptå‘ä¸Š
- Full FTã«è¿‘ã„æ€§èƒ½ã‚’åŠåˆ†ã®æ™‚é–“ã§é”æˆ

#### 3.4.8.5 å­¦ç¿’ç‡éå¯¾ç§°è¨­å®šã®åŠ¹æœ

Hayouã‚‰ [^9] ã¯ã€LoRAã®åæŸãŒé…ã„åŸå› ã‚’è¡Œåˆ— $A$ ã¨ $B$ ã®**å­¦ç¿’ç‡ã‚¹ã‚±ãƒ¼ãƒ«ã®ä¸å‡è¡¡**ã«å¸°ç€ã•ã›ãŸã€‚$A$ ã¯ãƒ©ãƒ³ãƒ€ãƒ åˆæœŸåŒ–ï¼ˆæœ‰ç•Œã‚¹ãƒšã‚¯ãƒˆãƒ«ï¼‰ã€$B$ ã¯ã‚¼ãƒ­åˆæœŸåŒ–ï¼ˆã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚¼ãƒ­ï¼‰ã‹ã‚‰å‡ºç™ºã™ã‚‹ã€‚AdamWã®é©å¿œçš„æ›´æ–°ã§ã¯ã“ã®éå¯¾ç§°æ€§ãŒè‡ªå‹•çš„ã«ã¯è£œæ­£ã•ã‚Œãªã„ã€‚

ç†è«–çš„ã«ã¯ã€$B$ ã®æ›´æ–°é‡ $\|\Delta B\|$ ã‚’ $A$ ã®æ›´æ–°é‡ $\|\Delta A\|$ ã‚ˆã‚Š $\lambda_+$ å€å¤§ããã™ã‚‹ã“ã¨ã§ã€å‹¾é…æµ $\nabla_{\Delta W} \mathcal{L} = \nabla_{\Delta W} \mathcal{L} \cdot B^\top + A^\top \cdot \nabla_{\Delta W} \mathcal{L}$ ã®ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚Œã‚‹ã€‚Spectral analysisã«ã‚ˆã‚Šã€æœ€é©æ¯”ç‡ã¯ $\lambda_+ \sim \mathcal{O}(1/\sqrt{r})$ ã‹ã‚‰æ±ºã¾ã‚Šã€å®Ÿç”¨çš„ã«ã¯ $\lambda_+ = 16$ ãŒ $r \in [4, 64]$ ã§æœ‰åŠ¹ã€‚

å®Ÿè£…ä¸Šã¯ `AdamW` ã® `param_groups` ã§ $B$ ã¨ $A$ ã«åˆ¥ã€…ã® `lr` ã‚’æ¸¡ã›ã°ã‚ˆã„ï¼ˆ$\eta_B = \eta$ã€$\eta_A = \lambda_+ \eta$ ï¼‰ã€‚åæŸé€Ÿåº¦2å€ãƒ»æ€§èƒ½+0.7ptãŒå ±å‘Šã•ã‚Œã¦ã„ã‚‹ [^9]ã€‚

### 3.4.9 VeRA â€” ãƒ©ãƒ³ãƒ€ãƒ å°„å½±LoRA

#### 3.4.9.1 å‹•æ©Ÿ: LoRAã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã•ã‚‰ã«å‰Šæ¸›

LoRAã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤§å¹…å‰Šæ¸›ã—ãŸãŒã€å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ï¼ˆGPT-3ç´šï¼‰ã§ã¯ä¾ç„¶ã¨ã—ã¦æ•°ç™¾MBã«ãªã‚‹ã€‚

**è¦³å¯Ÿ**: LoRAã® $B, A$ è¡Œåˆ—ã®å¤šãã®è¦ç´ ã¯**ä½é »åº¦æ›´æ–°**ã€‚

VeRA [^18] (Vector-based Random Matrix Adaptation) ã¯ã€$B, A$ ã‚’**å›ºå®šãƒ©ãƒ³ãƒ€ãƒ è¡Œåˆ—**ã«ã—ã€**ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ™ã‚¯ãƒˆãƒ«**ã®ã¿ã‚’è¨“ç·´:

$$
\Delta W = b \odot (B_{\text{rand}} A_{\text{rand}}) \odot a^\top
$$

$B_{\text{rand}} \in \mathbb{R}^{d \times r}$, $A_{\text{rand}} \in \mathbb{R}^{r \times k}$: **å›ºå®š**ãƒ©ãƒ³ãƒ€ãƒ è¡Œåˆ—ï¼ˆè¨“ç·´ä¸è¦ï¼‰
$b \in \mathbb{R}^d$, $a \in \mathbb{R}^k$: **trainable**ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ™ã‚¯ãƒˆãƒ«
$\odot$: Hadamardç©ï¼ˆè¦ç´ ã”ã¨ã®ç©ï¼‰

#### 3.4.9.2 VeRAã®å®šå¼åŒ–

**ã‚¹ãƒ†ãƒƒãƒ—1**: ãƒ©ãƒ³ãƒ€ãƒ è¡Œåˆ—ã®ç”Ÿæˆï¼ˆåˆæœŸåŒ–æ™‚1å›ã®ã¿ï¼‰

$$
\begin{aligned}
B_{\text{rand}} &\sim \mathcal{N}(0, \sigma_B^2), \quad \sigma_B = \frac{1}{\sqrt{r}} \\
A_{\text{rand}} &\sim \mathcal{N}(0, \sigma_A^2), \quad \sigma_A = \frac{1}{\sqrt{k}}
\end{aligned}
$$

ã“ã‚Œã‚‰ã¯**å…¨å±¤ã§å…±æœ‰**ï¼ˆã•ã‚‰ãªã‚‹ãƒ¡ãƒ¢ãƒªå‰Šæ¸›ï¼‰ã€‚

**ã‚¹ãƒ†ãƒƒãƒ—2**: ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ™ã‚¯ãƒˆãƒ«ã®åˆæœŸåŒ–

$$
b = \mathbf{1}_d, \quad a = \mathbf{1}_k \quad \text{(all ones)}
$$

åˆæœŸçŠ¶æ…‹ã§ $\Delta W = B_{\text{rand}} A_{\text{rand}}$ ï¼ˆãƒ©ãƒ³ãƒ€ãƒ æ‘‚å‹•ï¼‰ã€‚

**ã‚¹ãƒ†ãƒƒãƒ—3**: Forward pass

$$
h = W_0 x + \frac{\alpha}{r} \left(b \odot (B_{\text{rand}} (a \odot (A_{\text{rand}} x)))\right)
$$

**ã‚¹ãƒ†ãƒƒãƒ—4**: å‹¾é…è¨ˆç®—

$b, a$ ã®ã¿trainableã€$B_{\text{rand}}, A_{\text{rand}}$ ã¯å›ºå®š:

$$
\begin{aligned}
\frac{\partial \mathcal{L}}{\partial b} &= \frac{\alpha}{r} (B_{\text{rand}} (a \odot (A_{\text{rand}} x))) \odot \frac{\partial \mathcal{L}}{\partial h} \\
\frac{\partial \mathcal{L}}{\partial a} &= \frac{\alpha}{r} A_{\text{rand}}^\top (B_{\text{rand}}^\top (b \odot \frac{\partial \mathcal{L}}{\partial h}))
\end{aligned}
$$

#### 3.4.9.3 ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‰Šæ¸›ã®è¨ˆç®—

| æ‰‹æ³• | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° | å‰Šæ¸›ç‡ï¼ˆ$d=k=4096, r=8$ï¼‰ |
|:-----|:------------|:-------------------------|
| LoRA | $r(d+k) = 8 \times 8192 = 65,536$ | 256x vs Full FT |
| VeRA | $d + k = 8,192$ | **2,048x** vs Full FT |
| VeRAå‰Šæ¸›ç‡ï¼ˆvs LoRAï¼‰ | | **8x** |

GPT-3 (175B) ã®å ´åˆ:
- LoRA: ~200MB
- VeRA: **~25MB**

#### 3.4.9.4 ãªãœãƒ©ãƒ³ãƒ€ãƒ è¡Œåˆ—ã§æ©Ÿèƒ½ã™ã‚‹ã‹ï¼Ÿ

**ç†è«–çš„æ ¹æ‹ **: Johnson-Lindenstrauss Lemma [^19]

ãƒ©ãƒ³ãƒ€ãƒ å°„å½±ã¯ã€é«˜æ¬¡å…ƒç©ºé–“ã®è·é›¢ã‚’**é«˜ç¢ºç‡ã§ä¿å­˜**:

$$
(1-\epsilon)\|x-y\|^2 \leq \|Rx - Ry\|^2 \leq (1+\epsilon)\|x-y\|^2
$$

$R$: ãƒ©ãƒ³ãƒ€ãƒ è¡Œåˆ—ï¼ˆã‚¬ã‚¦ã‚¹åˆ†å¸ƒï¼‰

VeRAã¯ã€LoRAã®å­¦ç¿’å¯èƒ½ãªéƒ¨åˆ†ç©ºé–“ã‚’**ãƒ©ãƒ³ãƒ€ãƒ éƒ¨åˆ†ç©ºé–“**ã§è¿‘ä¼¼ã€‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ™ã‚¯ãƒˆãƒ« $b, a$ ãŒã€ãã®éƒ¨åˆ†ç©ºé–“å†…ã§ã®æœ€é©åŒ–ã‚’è¡Œã†ã€‚

#### 3.4.9.5 VeRA vs LoRAã®å®Ÿé¨“æ¯”è¼ƒ

å®Ÿé¨“è¨­å®š: GPT-2 Medium (355M) ã‚’E2E NLGã§Fine-tuning

| æ‰‹æ³• | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° | BLEU | ROUGE-L | è¨“ç·´æ™‚é–“ |
|:-----|:------------|:-----|:--------|:---------|
| Full FT | 355M (100%) | 68.2 | 53.9 | 100% |
| LoRA | 0.35M (0.1%) | 67.8 | 53.4 | 62% |
| **VeRA** | 0.044M (0.0125%) | **67.5** | **53.2** | **58%** |

**çµæœ**:
- VeRAã¯LoRAã®**1/8ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**ã§ã€æ€§èƒ½å·®ã‚ãšã‹-0.3pt (BLEU)
- è¨“ç·´æ™‚é–“ã‚‚LoRAã‚ˆã‚Š4%é«˜é€Ÿï¼ˆè¡Œåˆ—ã‚µã‚¤ã‚ºãŒå°ã•ã„ãŸã‚ï¼‰

**ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•**: VeRAã¯åˆæœŸåŒ–ã®ãƒ©ãƒ³ãƒ€ãƒ æ€§ã«ä¾å­˜ã€‚è¤‡æ•°å›è©¦è¡Œã—ã¦æœ€è‰¯ã®seedã‚’é¸ã¶å¿…è¦ãŒã‚ã‚‹ï¼ˆè«–æ–‡ã§ã¯5 seedså¹³å‡ï¼‰ã€‚

### 3.4.10 LoRA Composition â€” è¤‡æ•°LoRAã®åˆæˆ

#### 3.4.10.1 å‹•æ©Ÿ: ã‚¿ã‚¹ã‚¯æ¨ªæ–­çŸ¥è­˜ã®æ´»ç”¨

è¤‡æ•°ã‚¿ã‚¹ã‚¯ã§LoRAã‚’è¨“ç·´ã—ãŸå ´åˆã€ãã‚Œã‚‰ã‚’**çµ„ã¿åˆã‚ã›ã¦**æ–°ã‚¿ã‚¹ã‚¯ã«é©å¿œã§ãã‚‹ã‹ï¼Ÿ

ä¾‹:
- LoRA$_A$: è¦ç´„ã‚¿ã‚¹ã‚¯
- LoRA$_B$: ç¿»è¨³ã‚¿ã‚¹ã‚¯
- æ–°ã‚¿ã‚¹ã‚¯: å¤šè¨€èªè¦ç´„ï¼ˆè¦ç´„ + ç¿»è¨³ã®åˆæˆï¼‰

LoRA Composition [^20] ã¯ã€è¤‡æ•°ã® $(B_i, A_i)$ ã‚’**ç·šå½¢çµåˆ**:

$$
\Delta W_{\text{comp}} = \sum_{i=1}^N \lambda_i B_i A_i
$$

$\lambda_i$: åˆæˆé‡ã¿ï¼ˆãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ or å­¦ç¿’å¯èƒ½ï¼‰

#### 3.4.10.2 åˆæˆæ‰‹æ³•ã®3ãƒ‘ã‚¿ãƒ¼ãƒ³

**1. åŠ ç®—åˆæˆï¼ˆLinear Compositionï¼‰**

$$
h = W_0 x + \frac{\alpha}{r} \sum_{i=1}^N \lambda_i B_i A_i x
$$

æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ã€‚$\lambda_i$ ã¯æ‰‹å‹•èª¿æ•´ or ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã€‚

**2. å­¦ç¿’å¯èƒ½é‡ã¿åˆæˆï¼ˆLearnable Compositionï¼‰**

$$
\lambda_i \leftarrow \lambda_i - \eta \frac{\partial \mathcal{L}}{\partial \lambda_i}
$$

$\lambda_i$ ã‚’æ–°ã‚¿ã‚¹ã‚¯ã®æ¤œè¨¼ã‚»ãƒƒãƒˆã§æœ€é©åŒ–ï¼ˆæ•°ã‚¹ãƒ†ãƒƒãƒ—ã®ã¿ã€é«˜é€Ÿï¼‰ã€‚

**3. ã‚¿ã‚¹ã‚¯ãƒ™ã‚¯ãƒˆãƒ«ç®—è¡“ï¼ˆTask Arithmeticï¼‰**

Task Vector [^21] ã®è€ƒãˆæ–¹ã‚’é©ç”¨:

$$
\Delta W_{\text{new}} = \Delta W_A + \Delta W_B - \Delta W_C
$$

ä¾‹: ã€Œè¦ç´„ + ç¿»è¨³ - è³ªå•å¿œç­”ã€ã§å¤šè¨€èªè¦ç´„ã‚’æ§‹æˆã€‚

#### 3.4.10.3 æ•°å€¤ä¾‹: LoRA Compositionå®Ÿé¨“

å®Ÿé¨“è¨­å®š: T5-base (220M)ã€3ã‚¿ã‚¹ã‚¯ã®LoRAã‚’åˆæˆ

| ã‚¿ã‚¹ã‚¯ | å€‹åˆ¥LoRAæ€§èƒ½ | åˆæˆå¾Œæ€§èƒ½ | æ–°ã‚¿ã‚¹ã‚¯é©å¿œ |
|:-------|:------------|:----------|:------------|
| è¦ç´„ | ROUGE 42.1 | 41.8 (-0.3) | - |
| ç¿»è¨³ | BLEU 28.5 | 28.3 (-0.2) | - |
| QA | F1 85.2 | 85.0 (-0.2) | - |
| **å¤šè¨€èªè¦ç´„**ï¼ˆæ–°ï¼‰ | - | - | ROUGE **38.4** |

**è§£é‡ˆ**:
- å€‹åˆ¥ã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ã¯å¾®æ¸›ï¼ˆ-0.2~0.3ptï¼‰
- æ–°ã‚¿ã‚¹ã‚¯ï¼ˆå¤šè¨€èªè¦ç´„ï¼‰ã‚’**ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆ**ã§38.4é”æˆï¼ˆfrom-scratchã®35.1ã‚ˆã‚Šé«˜ã„ï¼‰
- åˆæˆã«ã‚ˆã‚Šã€è¿½åŠ è¨“ç·´ãªã—ã§æ–°ã‚¿ã‚¹ã‚¯ã«é©å¿œ

#### 3.4.10.4 ç†è«–çš„è§£é‡ˆ: éƒ¨åˆ†ç©ºé–“ã®é‡ã­åˆã‚ã›

LoRAã® $\Delta W_i = B_i A_i$ ã¯ã€$r$ æ¬¡å…ƒã®éƒ¨åˆ†ç©ºé–“ $\mathcal{S}_i \subset \mathbb{R}^{d \times k}$ ã‚’å®šç¾©:

$$
\mathcal{S}_i = \text{span}(B_i A_i)
$$

åˆæˆ $\sum_i \lambda_i B_i A_i$ ã¯ã€éƒ¨åˆ†ç©ºé–“ã®**ç·šå½¢çµåˆ**:

$$
\mathcal{S}_{\text{comp}} = \text{span}\left(\bigcup_{i=1}^N \mathcal{S}_i\right)
$$

ã‚¿ã‚¹ã‚¯é–“ã§**å…±é€šéƒ¨åˆ†ç©ºé–“**ãŒã‚ã‚Œã°ã€åˆæˆãŒåŠ¹æœçš„ã€‚

> **Note:** **é€²æ—: 70% å®Œäº†** AdaLoRAï¼ˆãƒ©ãƒ³ã‚¯é©å¿œï¼‰ã€LoRA+ï¼ˆå­¦ç¿’ç‡æœ€é©åŒ–ï¼‰ã€VeRAï¼ˆãƒ©ãƒ³ãƒ€ãƒ å°„å½±ï¼‰ã€LoRA Compositionï¼ˆè¤‡æ•°LoRAåˆæˆï¼‰ã®æœ€æ–°æ‰‹æ³•ã‚’è¿½åŠ ã€‚æ¬¡ã¯å®Ÿè£…ã‚¾ãƒ¼ãƒ³ã¸ã€‚

> **Progress: 50%**
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. LoRAã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å› å­ $\frac{\alpha}{r}$ ã§ $\alpha \neq r$ ã«ã™ã‚‹æ•°å­¦çš„/å®Ÿè£…ä¸Šã®ç†ç”±ã‚’èª¬æ˜ã›ã‚ˆã€‚
> 2. DreamBooth Prior Preservation Loss $\mathcal{L} = \mathbb{E}[\|\epsilon - \epsilon_\theta(z_t, c)\|_2^2] + \lambda \mathbb{E}[\|\epsilon - \epsilon_\theta(z_t, c_{pr})\|_2^2]$ ã®ç¬¬2é …ãŒè¨€èªãƒ‰ãƒªãƒ•ãƒˆã‚’é˜²ãä»•çµ„ã¿ã‚’èª¬æ˜ã›ã‚ˆã€‚

> ğŸ“Œ **å¾Œç·¨ï¼ˆå®Ÿè£…ï¼‰**: [ç¬¬23å› å¾Œç·¨](./ml-lecture-23-part2)

---

## è‘—è€…ãƒªãƒ³ã‚¯

- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
